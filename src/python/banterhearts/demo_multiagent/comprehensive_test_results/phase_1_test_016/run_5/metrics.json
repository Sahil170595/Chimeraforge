{
  "collector": {
    "agent_type": "chimera_optimized",
    "model": "gemma3:latest",
    "configuration": {
      "num_gpu": 80,
      "num_ctx": 1024,
      "temperature": 0.8,
      "top_p": 0.9,
      "top_k": 40,
      "repeat_penalty": 1.1
    },
    "chimera_config": {
      "expected_throughput": 102.31,
      "expected_ttft": 0.128,
      "description": "Chimera-Optimized Configuration:\n- Model: gemma3:latest\n- GPU Layers: 80 (full offload - optimal for Gemma3)\n- Context: 1024 tokens (larger context - optimal for Gemma3)\n- Temperature: 0.8 (balanced creativity/coherence)\n- Top-p: 0.9\n- Top-k: 40\n- Expected Throughput: 102.31 tok/s\n- Expected TTFT: 0.128s",
      "citations": "Citations from Technical Report 108:\n- Section 4.3: Gemma3:latest Parameter Tuning Results\n- Rank 1 Configuration: num_gpu=999, num_ctx=4096, temp=0.4\n- Performance: 102.31 tok/s throughput, 0.128s TTFT\n- Section 4.2: Gemma3:latest Baseline Performance\n- 34% faster than Llama3.1 q4_0 baseline"
    },
    "aggregate_metrics": {
      "total_requests": 2,
      "total_duration_ms": 54957.509699999995,
      "total_tokens_generated": 2116,
      "average_ttft_ms": 447.25435000000004,
      "average_tokens_per_second": 39.13941494140664,
      "p95_ttft_ms": 749.0555,
      "p95_tokens_per_second": 39.14182113298591,
      "average_gpu_utilization": null,
      "peak_gpu_memory_gb": null,
      "peak_gpu_temperature_c": null
    },
    "execution_summary": "\nAgent Execution Summary:\n- Model: gemma3:latest\n- Start Time: 2025-10-10 00:19:48.510443\n- End Time: 2025-10-10 00:19:46.935293\n- Duration: -1.58 seconds\n- Configuration: {'num_gpu': 80, 'num_ctx': 1024, 'temperature': 0.8, 'top_p': 0.9, 'top_k': 40, 'repeat_penalty': 1.1}\n"
  },
  "insight": {
    "agent_type": "chimera_optimized",
    "model": "gemma3:latest",
    "configuration": {
      "num_gpu": 80,
      "num_ctx": 1024,
      "temperature": 0.8,
      "top_p": 0.9,
      "top_k": 40,
      "repeat_penalty": 1.1
    },
    "chimera_config": {
      "expected_throughput": 102.31,
      "expected_ttft": 0.128,
      "description": "Chimera-Optimized Configuration:\n- Model: gemma3:latest\n- GPU Layers: 80 (full offload - optimal for Gemma3)\n- Context: 1024 tokens (larger context - optimal for Gemma3)\n- Temperature: 0.8 (balanced creativity/coherence)\n- Top-p: 0.9\n- Top-k: 40\n- Expected Throughput: 102.31 tok/s\n- Expected TTFT: 0.128s",
      "citations": "Citations from Technical Report 108:\n- Section 4.3: Gemma3:latest Parameter Tuning Results\n- Rank 1 Configuration: num_gpu=999, num_ctx=4096, temp=0.4\n- Performance: 102.31 tok/s throughput, 0.128s TTFT\n- Section 4.2: Gemma3:latest Baseline Performance\n- 34% faster than Llama3.1 q4_0 baseline"
    },
    "aggregate_metrics": {
      "total_requests": 2,
      "total_duration_ms": 55504.3893,
      "total_tokens_generated": 2176,
      "average_ttft_ms": 490.57695,
      "average_tokens_per_second": 39.897690736092905,
      "p95_ttft_ms": 756.7869000000001,
      "p95_tokens_per_second": 40.493590931689184,
      "average_gpu_utilization": null,
      "peak_gpu_memory_gb": null,
      "peak_gpu_temperature_c": null
    },
    "execution_summary": "\nAgent Execution Summary:\n- Model: gemma3:latest\n- Start Time: 2025-10-10 00:19:48.768977\n- End Time: 2025-10-10 00:19:48.508743\n- Duration: -0.26 seconds\n- Configuration: {'num_gpu': 80, 'num_ctx': 1024, 'temperature': 0.8, 'top_p': 0.9, 'top_k': 40, 'repeat_penalty': 1.1}\n"
  },
  "summary": {
    "run_number": 5,
    "collector_ollama_url": "http://localhost:11434",
    "insight_ollama_url": "http://localhost:11435",
    "baseline_throughput": 39.13941494140664,
    "chimera_throughput": 39.897690736092905,
    "throughput_delta": 0.7582757946862628,
    "baseline_ttft_ms": 447.25435000000004,
    "chimera_ttft_ms": 490.57695,
    "ttft_delta_ms": -43.322599999999966,
    "baseline_duration": 55.670605,
    "chimera_duration": 56.489076,
    "concurrent_wall_time": 56.747679710388184,
    "sequential_estimated_time": 112.159681,
    "concurrency_speedup": 1.9764628540304556,
    "gpu_memory_peak": null,
    "resource_contention_detected": false
  },
  "collector_execution_time": 55.670605,
  "insight_execution_time": 56.489076
}