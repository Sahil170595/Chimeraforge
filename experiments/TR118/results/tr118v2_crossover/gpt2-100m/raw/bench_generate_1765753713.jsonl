{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.522999999840977, 21.70220000334666], "ttft_ms": [5.82580000263988, 4.939999998896383], "tokens_processed": [4, 4], "throughput_tok_s": [170.04633762815294, 184.31311108473642], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3305.525799998577, 323.2070999983989, 5.490100000315579], "resource_metrics": {"samples": 27, "duration_s": 3.8723952770233154, "gpu_memory_mean_mb": 2445.056568287037, "gpu_memory_peak_mb": 2908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.963148148148147, "gpu_power_peak_watts": 30.134, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1600.0367476851852, "cpu_memory_peak_mb": 1940.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754176.972572}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.93199999985518, 21.748299997852882], "ttft_ms": [5.8535999996820465, 4.983500002708752], "tokens_processed": [4, 4], "throughput_tok_s": [174.42874585841884, 183.92242154075964], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.467099999805214, 5.715100000088569, 5.021100001613377], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2910.01953125, "gpu_memory_peak_mb": 2910.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 32.442, "gpu_power_peak_watts": 32.442, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1945.3046875, "cpu_memory_peak_mb": 1945.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754177.102967}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.909400002186885, 22.168799998325994], "ttft_ms": [5.049700001109159, 5.3210000005492475], "tokens_processed": [4, 4], "throughput_tok_s": [182.57003841276986, 180.43376277931358], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.436599996959558, 5.052000000432599, 5.783000000519678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2910.01953125, "gpu_memory_peak_mb": 2910.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 32.442, "gpu_power_peak_watts": 32.442, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1945.3828125, "cpu_memory_peak_mb": 1945.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754177.2246723}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.6958999990311, 21.532099999603815], "ttft_ms": [5.062699998234166, 4.8843000004126225], "tokens_processed": [4, 4], "throughput_tok_s": [184.3666314916013, 185.7691539642487], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.945099997916259, 4.919200000585988, 5.822999999509193], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2910.01953125, "gpu_memory_peak_mb": 2910.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 32.442, "gpu_power_peak_watts": 32.442, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1945.47265625, "cpu_memory_peak_mb": 1945.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754177.3514762}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.64730000004056, 21.492799998668488], "ttft_ms": [5.006299998058239, 4.957799999829149], "tokens_processed": [4, 4], "throughput_tok_s": [184.78054999896085, 186.10883645908424], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.319899999652989, 5.030800002714386, 5.744099998992169], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2910.01953125, "gpu_memory_peak_mb": 2910.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 32.442, "gpu_power_peak_watts": 32.442, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1945.53515625, "cpu_memory_peak_mb": 1945.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754177.478041}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [111.32449999786331, 96.60359999907087], "ttft_ms": [12.971699998161057, 11.709700000210432], "tokens_processed": [8, 8], "throughput_tok_s": [71.86198905140868, 82.81264880477481], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1455.7346999972651, 12.100799998734146, 11.818099999800324], "resource_metrics": {"samples": 18, "duration_s": 1.8981451988220215, "gpu_memory_mean_mb": 3272.4639756944443, "gpu_memory_peak_mb": 3306.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.11111111111111, "gpu_power_mean_watts": 40.07833333333333, "gpu_power_peak_watts": 46.08, "gpu_temperature_mean_c": 47.55555555555556, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1956.7821180555557, "cpu_memory_peak_mb": 2128.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754179.486307}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [100.2662999999302, 106.63990000102785], "ttft_ms": [12.100799998734146, 11.79999999658321], "tokens_processed": [8, 8], "throughput_tok_s": [79.78752581880023, 75.0188250356845], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.577199999213917, 12.656799997785129, 11.682199998176657], "resource_metrics": {"samples": 3, "duration_s": 0.21579432487487793, "gpu_memory_mean_mb": 3306.01953125, "gpu_memory_peak_mb": 3306.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.503, "gpu_power_peak_watts": 34.503, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1960.640625, "cpu_memory_peak_mb": 1960.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754179.8111088}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.07340000063414, 99.066100003256], "ttft_ms": [11.77790000292589, 12.243499997566687], "tokens_processed": [8, 8], "throughput_tok_s": [80.74821294059551, 80.75416312681195], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.342399997374741, 20.632600000681123, 11.447599998064106], "resource_metrics": {"samples": 3, "duration_s": 0.22056984901428223, "gpu_memory_mean_mb": 3306.01953125, "gpu_memory_peak_mb": 3306.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.333333333333334, "gpu_power_mean_watts": 34.76433333333333, "gpu_power_peak_watts": 35.287, "gpu_temperature_mean_c": 47.666666666666664, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1960.6692708333333, "cpu_memory_peak_mb": 1960.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754180.140243}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [101.21110000181943, 100.05799999998999], "ttft_ms": [13.602099999843631, 12.129099999583559], "tokens_processed": [8, 8], "throughput_tok_s": [79.04271369302563, 79.95362689640808], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.950199998158496, 11.192199999641161, 11.22160000159056], "resource_metrics": {"samples": 3, "duration_s": 0.21565628051757812, "gpu_memory_mean_mb": 3306.01953125, "gpu_memory_peak_mb": 3306.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 35.287, "gpu_power_peak_watts": 35.287, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1960.72265625, "cpu_memory_peak_mb": 1960.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754180.4639075}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [101.0673000018869, 101.26700000182609], "ttft_ms": [11.589699999603909, 12.590300000738353], "tokens_processed": [8, 8], "throughput_tok_s": [79.15517679655676, 78.99908163425144], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.539900002389913, 11.95259999803966, 11.615399998845533], "resource_metrics": {"samples": 3, "duration_s": 0.21417546272277832, "gpu_memory_mean_mb": 3306.01953125, "gpu_memory_peak_mb": 3306.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 32.074999999999996, "gpu_power_peak_watts": 35.287, "gpu_temperature_mean_c": 46.333333333333336, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1960.8203125, "cpu_memory_peak_mb": 1960.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754180.790552}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [115.73780000253464, 37.54450000269571], "ttft_ms": [11.810299998614937, 11.783599999034777], "tokens_processed": [8, 3], "throughput_tok_s": [69.12175624406893, 79.90517918162709], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1443.4191000000283, 12.218999996548519, 11.752300000807736], "resource_metrics": {"samples": 19, "duration_s": 1.8806724548339844, "gpu_memory_mean_mb": 3669.177425986842, "gpu_memory_peak_mb": 3702.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.05263157894737, "gpu_power_mean_watts": 19.628526315789475, "gpu_power_peak_watts": 30.469, "gpu_temperature_mean_c": 45.36842105263158, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1984.4340049342106, "cpu_memory_peak_mb": 2310.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754182.7783604}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.65599999850383, 37.752100000943756], "ttft_ms": [11.676699999952689, 11.655400001473026], "tokens_processed": [8, 3], "throughput_tok_s": [80.27614995705333, 79.46577806069077], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.859900001785718, 11.950600001000566, 11.775099999795202], "resource_metrics": {"samples": 2, "duration_s": 0.11305618286132812, "gpu_memory_mean_mb": 3702.01953125, "gpu_memory_peak_mb": 3702.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.562, "gpu_power_peak_watts": 15.562, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1973.55078125, "cpu_memory_peak_mb": 1973.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754183.0069869}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [97.71639999962645, 36.4971000017249], "ttft_ms": [11.598200002481462, 11.64980000248761], "tokens_processed": [8, 3], "throughput_tok_s": [81.86957358263896, 82.19831164279397], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.591399998404086, 11.44660000136355, 11.608299999352312], "resource_metrics": {"samples": 2, "duration_s": 0.10730338096618652, "gpu_memory_mean_mb": 3702.01953125, "gpu_memory_peak_mb": 3702.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 17.599, "gpu_power_peak_watts": 17.599, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1973.5546875, "cpu_memory_peak_mb": 1973.5546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754183.2238336}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [100.0452000007499, 36.9581000013568], "ttft_ms": [11.833199998363853, 11.882999999215826], "tokens_processed": [8, 3], "throughput_tok_s": [79.96385633633632, 81.17300402049523], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.633400001708651, 12.13360000110697, 11.9739000001573], "resource_metrics": {"samples": 2, "duration_s": 0.10869836807250977, "gpu_memory_mean_mb": 3702.01953125, "gpu_memory_peak_mb": 3702.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 17.599, "gpu_power_peak_watts": 17.599, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1973.59375, "cpu_memory_peak_mb": 1973.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754183.440358}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.70220000104746, 37.350599999626866], "ttft_ms": [11.670899999444373, 11.77109999844106], "tokens_processed": [8, 3], "throughput_tok_s": [80.23895159701544, 80.31999486032272], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.93040000059409, 11.489199998322874, 11.675999998260522], "resource_metrics": {"samples": 2, "duration_s": 0.10851383209228516, "gpu_memory_mean_mb": 3702.01953125, "gpu_memory_peak_mb": 3702.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 18.765, "gpu_power_peak_watts": 19.931, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1973.59375, "cpu_memory_peak_mb": 1973.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754183.6594095}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [172.42540000006557, 102.92289999779314], "ttft_ms": [25.29829999912181, 12.77240000126767], "tokens_processed": [8, 8], "throughput_tok_s": [46.39687656225219, 77.72808578238211], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1517.7230000008421, 24.9325000004319, 25.59569999721134], "resource_metrics": {"samples": 20, "duration_s": 2.0822765827178955, "gpu_memory_mean_mb": 4066.91953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.85, "gpu_power_mean_watts": 16.888849999999998, "gpu_power_peak_watts": 19.931, "gpu_temperature_mean_c": 45.15, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1991.9953125, "cpu_memory_peak_mb": 2299.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754185.8720338}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [101.38519999964046, 102.96870000092895], "ttft_ms": [12.333000002399785, 11.99320000159787], "tokens_processed": [8, 8], "throughput_tok_s": [78.90698050631029, 77.69351268810645], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.056400002620649, 13.301999999384861, 12.148999998316867], "resource_metrics": {"samples": 3, "duration_s": 0.2215423583984375, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.666666666666666, "gpu_power_mean_watts": 18.441666666666666, "gpu_power_peak_watts": 21.125, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1984.65234375, "cpu_memory_peak_mb": 1984.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754186.2053192}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.06930000317516, 104.07259999919916], "ttft_ms": [11.984700002358295, 13.100600001052953], "tokens_processed": [8, 8], "throughput_tok_s": [76.87185365670683, 76.86941615815844], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.158400000771508, 12.468200002331287, 11.934299996937625], "resource_metrics": {"samples": 3, "duration_s": 0.21664929389953613, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 21.125, "gpu_power_peak_watts": 21.125, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1984.65234375, "cpu_memory_peak_mb": 1984.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754186.529276}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [98.81920000043465, 100.09759999957168], "ttft_ms": [12.08039999983157, 12.7409999986412], "tokens_processed": [8, 8], "throughput_tok_s": [80.95592759266228, 79.92199613211737], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.601599999470636, 12.571399998705601, 12.07570000042324], "resource_metrics": {"samples": 3, "duration_s": 0.21859002113342285, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 30.365, "gpu_power_peak_watts": 30.365, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1984.65234375, "cpu_memory_peak_mb": 1984.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754186.8548138}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.07969999869238, 103.06159999890951], "ttft_ms": [12.840700001106597, 12.851200001023244], "tokens_processed": [8, 8], "throughput_tok_s": [76.8641723611858, 77.62347955091563], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.74219999727211, 13.320299996848917, 11.833399999886751], "resource_metrics": {"samples": 3, "duration_s": 0.21669340133666992, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 17.0, "gpu_power_mean_watts": 34.668, "gpu_power_peak_watts": 43.274, "gpu_temperature_mean_c": 47.333333333333336, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1984.67578125, "cpu_memory_peak_mb": 1984.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754187.181458}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [183.20850000236533, 125.89030000162893], "ttft_ms": [25.31499999895459, 16.24930000252789], "tokens_processed": [32, 32], "throughput_tok_s": [174.6643851108811, 254.18956027260197], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1805.7707000007213, 20.33079999819165, 24.600099997769576], "resource_metrics": {"samples": 21, "duration_s": 2.3726232051849365, "gpu_memory_mean_mb": 4463.733816964285, "gpu_memory_peak_mb": 4496.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.238095238095238, "gpu_power_mean_watts": 28.547857142857143, "gpu_power_peak_watts": 43.274, "gpu_temperature_mean_c": 45.857142857142854, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1999.2955729166667, "cpu_memory_peak_mb": 2305.48828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754189.6611345}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [119.94359999880544, 117.67419999887352], "ttft_ms": [13.479499997629318, 13.152400002581999], "tokens_processed": [32, 32], "throughput_tok_s": [266.7920589370229, 271.9372640757815], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.209799999865936, 22.141299999930197, 14.007099998707417], "resource_metrics": {"samples": 3, "duration_s": 0.22120189666748047, "gpu_memory_mean_mb": 4496.01953125, "gpu_memory_peak_mb": 4496.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.587, "gpu_power_peak_watts": 16.587, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2014.56640625, "cpu_memory_peak_mb": 2014.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754189.9927852}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [120.46769999869866, 119.66229999961797], "ttft_ms": [13.095800000883173, 13.791499997751089], "tokens_processed": [32, 32], "throughput_tok_s": [265.6313684111648, 267.4192289476482], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.567200000281446, 13.895799998863367, 13.707399997656466], "resource_metrics": {"samples": 3, "duration_s": 0.21268558502197266, "gpu_memory_mean_mb": 4496.01953125, "gpu_memory_peak_mb": 4496.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 27.540000000000003, "gpu_power_peak_watts": 27.54, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2014.0455729166667, "cpu_memory_peak_mb": 2014.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754190.3196826}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [126.89659999887226, 127.49629999962053], "ttft_ms": [14.774999999644933, 14.222700003301725], "tokens_processed": [32, 32], "throughput_tok_s": [252.17381711002807, 250.98767572153264], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [24.795799999992596, 13.109100000292528, 14.542900000378722], "resource_metrics": {"samples": 3, "duration_s": 0.21601629257202148, "gpu_memory_mean_mb": 4496.01953125, "gpu_memory_peak_mb": 4496.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 33.836, "gpu_power_peak_watts": 46.428, "gpu_temperature_mean_c": 47.666666666666664, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2009.703125, "cpu_memory_peak_mb": 2014.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754190.6458833}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [126.28700000277604, 124.44640000103391], "ttft_ms": [13.983199998619966, 15.355799998360453], "tokens_processed": [32, 32], "throughput_tok_s": [253.39108537930727, 257.13881638789184], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.985600002546562, 15.074800001457334, 15.194999999948777], "resource_metrics": {"samples": 3, "duration_s": 0.21740937232971191, "gpu_memory_mean_mb": 4496.01953125, "gpu_memory_peak_mb": 4496.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 46.428, "gpu_power_peak_watts": 46.428, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2009.7174479166667, "cpu_memory_peak_mb": 2014.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754190.9705522}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [170.52979999789386, 49.41970000072615], "ttft_ms": [15.166999997745734, 15.737500001705484], "tokens_processed": [32, 12], "throughput_tok_s": [187.6504868966903, 242.8181474153764], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1422.2207999991952, 17.671199999313103, 17.42010000089067], "resource_metrics": {"samples": 19, "duration_s": 1.9171056747436523, "gpu_memory_mean_mb": 4861.0721628289475, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.736842105263158, "gpu_power_mean_watts": 35.23178947368421, "gpu_power_peak_watts": 50.133, "gpu_temperature_mean_c": 46.578947368421055, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2013.3517680921052, "cpu_memory_peak_mb": 2333.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754192.9956086}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.50580000001355, 50.85930000132066], "ttft_ms": [15.281899999536108, 16.51029999993625], "tokens_processed": [32, 12], "throughput_tok_s": [243.33527494602293, 235.94504839210128], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [38.159199997608084, 16.026000001147622, 15.636100000847364], "resource_metrics": {"samples": 3, "duration_s": 0.21204257011413574, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 19.112, "gpu_power_peak_watts": 19.112, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2040.91796875, "cpu_memory_peak_mb": 2040.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754193.3160415}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [128.233999999793, 49.53480000040145], "ttft_ms": [14.796600000408944, 15.369900000223424], "tokens_processed": [32, 12], "throughput_tok_s": [249.54380273602672, 242.25393056806018], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.428500002395594, 24.413999999524094, 14.549100000294857], "resource_metrics": {"samples": 3, "duration_s": 0.2210226058959961, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 19.858, "gpu_power_peak_watts": 21.35, "gpu_temperature_mean_c": 46.333333333333336, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2040.91796875, "cpu_memory_peak_mb": 2040.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754193.6458015}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [128.52859999838984, 47.34620000090217], "ttft_ms": [14.405199999600882, 14.810000000579748], "tokens_processed": [32, 12], "throughput_tok_s": [248.9718241729925, 253.4522305860099], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [23.429000000760425, 18.25240000107442, 15.653099999326514], "resource_metrics": {"samples": 3, "duration_s": 0.22056984901428223, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 21.350000000000005, "gpu_power_peak_watts": 21.35, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2040.91796875, "cpu_memory_peak_mb": 2040.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754193.9735591}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [127.56960000115214, 49.1437999990012], "ttft_ms": [15.031700000690762, 15.114199999516131], "tokens_processed": [32, 12], "throughput_tok_s": [250.8434611358113, 244.181361641629], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.671900001208996, 26.370499999757158, 14.808799998718314], "resource_metrics": {"samples": 3, "duration_s": 0.21529698371887207, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 24.44666666666667, "gpu_power_peak_watts": 25.995, "gpu_temperature_mean_c": 46.333333333333336, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2040.953125, "cpu_memory_peak_mb": 2040.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2543.134800002008, "compile_ms": 959.2324999975972, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765754194.298031}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [61.468299998523435, 58.36660000204574], "ttft_ms": [15.558099999907427, 15.003699998487718], "tokens_processed": [4, 4], "throughput_tok_s": [65.0741927155312, 68.5323455513907], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.211899998073932, 15.129399998841109, 15.307199999369914], "resource_metrics": {"samples": 2, "duration_s": 0.1215355396270752, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.0, "gpu_power_mean_watts": 25.995, "gpu_power_peak_watts": 25.995, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2046.703125, "cpu_memory_peak_mb": 2048.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754194.5271997}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [62.334000002010725, 60.408499997720355], "ttft_ms": [15.8886999997776, 15.497899999900255], "tokens_processed": [4, 4], "throughput_tok_s": [64.17043667775164, 66.21584711010783], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.724500000942498, 14.980399999330984, 15.023299998574657], "resource_metrics": {"samples": 2, "duration_s": 0.11133694648742676, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.0, "gpu_power_mean_watts": 27.393, "gpu_power_peak_watts": 27.393, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2048.28515625, "cpu_memory_peak_mb": 2048.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754194.746182}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [60.0629000000481, 57.79700000130106], "ttft_ms": [16.41889999882551, 14.11530000041239], "tokens_processed": [4, 4], "throughput_tok_s": [66.59685096784865, 69.20774434503446], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.063200000440702, 15.376100000139559, 15.981099997588899], "resource_metrics": {"samples": 2, "duration_s": 0.11642718315124512, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.0, "gpu_power_mean_watts": 27.393, "gpu_power_peak_watts": 27.393, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2048.29296875, "cpu_memory_peak_mb": 2048.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754194.9721236}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [56.58970000149566, 57.67270000069402], "ttft_ms": [14.223999998648651, 14.423500000702916], "tokens_processed": [4, 4], "throughput_tok_s": [70.68424112328357, 69.35690543275874], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.774699997564312, 15.469499998289393, 14.164599997457117], "resource_metrics": {"samples": 2, "duration_s": 0.11910390853881836, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 25.844, "gpu_power_peak_watts": 27.393, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2048.36328125, "cpu_memory_peak_mb": 2048.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754195.2044375}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [61.90930000229855, 60.13359999997192], "ttft_ms": [15.089000000443775, 14.950300002965378], "tokens_processed": [4, 4], "throughput_tok_s": [64.61064815547081, 66.5185520241906], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.234200000122655, 14.664900001662318, 15.26670000021113], "resource_metrics": {"samples": 2, "duration_s": 0.12261176109313965, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.295, "gpu_power_peak_watts": 24.295, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2048.36328125, "cpu_memory_peak_mb": 2048.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754195.4397395}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [130.49260000116192, 130.72979999924428], "ttft_ms": [16.40870000119321, 16.034799999033567], "tokens_processed": [8, 8], "throughput_tok_s": [61.30615835632647, 61.19492265762088], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.42569999967236, 16.410299998824485, 15.40229999955045], "resource_metrics": {"samples": 3, "duration_s": 0.22179460525512695, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.302999999999997, "gpu_power_peak_watts": 24.295, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2049.4921875, "cpu_memory_peak_mb": 2049.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754195.774026}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [135.04249999823514, 135.55069999711122], "ttft_ms": [16.85910000014701, 16.966899998806184], "tokens_processed": [8, 8], "throughput_tok_s": [59.2406094385438, 59.01850746746783], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.135399997234344, 15.97330000004149, 15.4244999976072], "resource_metrics": {"samples": 4, "duration_s": 0.31848716735839844, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.807, "gpu_power_peak_watts": 22.807, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2049.68359375, "cpu_memory_peak_mb": 2049.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754196.2034707}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [124.05050000234041, 123.86499999774969], "ttft_ms": [15.560900003038114, 16.295900000841357], "tokens_processed": [8, 8], "throughput_tok_s": [64.48986501343458, 64.58644492104581], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.35319999695639, 16.71609999903012, 16.03609999801847], "resource_metrics": {"samples": 3, "duration_s": 0.21229982376098633, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.807, "gpu_power_peak_watts": 22.807, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2049.68359375, "cpu_memory_peak_mb": 2049.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754196.5272121}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.74609999987297, 133.7606000015512], "ttft_ms": [16.56379999985802, 16.565699999773642], "tokens_processed": [8, 8], "throughput_tok_s": [60.72286010749247, 59.80834416044205], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.202899998461362, 16.410500000347383, 15.619400001014583], "resource_metrics": {"samples": 4, "duration_s": 0.3138923645019531, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.294, "gpu_power_peak_watts": 12.294, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2049.734375, "cpu_memory_peak_mb": 2049.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754196.955302}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.4621999990777, 124.24699999974109], "ttft_ms": [16.86419999896316, 15.66639999873587], "tokens_processed": [8, 8], "throughput_tok_s": [60.853994532695516, 64.38787254434047], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.530500000953907, 16.737400001147762, 16.57830000112881], "resource_metrics": {"samples": 3, "duration_s": 0.22166919708251953, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.294000000000002, "gpu_power_peak_watts": 12.294, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2049.734375, "cpu_memory_peak_mb": 2049.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754197.2901428}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [148.31609999964712, 54.665099996782374], "ttft_ms": [18.219100002170308, 18.121199998859083], "tokens_processed": [8, 3], "throughput_tok_s": [53.938850873364615, 54.879621553360046], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.031700001098216, 16.80280000073253, 16.828399999212706], "resource_metrics": {"samples": 3, "duration_s": 0.21808385848999023, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.840333333333334, "gpu_power_peak_watts": 12.294, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2059.1510416666665, "cpu_memory_peak_mb": 2061.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754197.618034}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [145.74499999798718, 55.13819999760017], "ttft_ms": [17.885599998407997, 18.62510000137263], "tokens_processed": [8, 3], "throughput_tok_s": [54.890390751727224, 54.40874022239703], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.739300001470838, 18.481899998732843, 18.036000001302455], "resource_metrics": {"samples": 3, "duration_s": 0.22028613090515137, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.933, "gpu_power_peak_watts": 10.933, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2061.04296875, "cpu_memory_peak_mb": 2061.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754197.95035}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [147.1519000006083, 55.79639999996289], "ttft_ms": [17.741400002705632, 19.086799999058712], "tokens_processed": [8, 3], "throughput_tok_s": [54.36559092996373, 53.766909693134245], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.248799999331823, 18.237699998280732, 19.119200002023717], "resource_metrics": {"samples": 3, "duration_s": 0.215803861618042, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.933, "gpu_power_peak_watts": 10.933, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2061.13671875, "cpu_memory_peak_mb": 2061.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754198.2804134}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [139.32170000043698, 52.32560000149533], "ttft_ms": [16.51769999807584, 17.24130000002333], "tokens_processed": [8, 3], "throughput_tok_s": [57.42106218898354, 57.333312946516955], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.259899999771733, 16.080700002930826, 17.36439999876893], "resource_metrics": {"samples": 3, "duration_s": 0.21222710609436035, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.859999999999999, "gpu_power_peak_watts": 10.933, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2061.13671875, "cpu_memory_peak_mb": 2061.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754198.6057036}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [146.73229999971227, 54.76339999950142], "ttft_ms": [18.46039999873028, 18.34709999820916], "tokens_processed": [8, 3], "throughput_tok_s": [54.521056372834664, 54.78111293358909], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.901300001743948, 18.436999998812098, 17.90459999756422], "resource_metrics": {"samples": 3, "duration_s": 0.22010064125061035, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7139999999999997, "gpu_power_peak_watts": 1.714, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2061.16015625, "cpu_memory_peak_mb": 2061.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754198.9381192}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [162.32669999953941, 160.71690000171657], "ttft_ms": [21.152700002858182, 20.00950000001467], "tokens_processed": [8, 8], "throughput_tok_s": [49.283328004713326, 49.776968071898814], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.946000000549247, 20.58989999932237, 20.860099997662473], "resource_metrics": {"samples": 4, "duration_s": 0.31102657318115234, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.714, "gpu_power_peak_watts": 1.714, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2063.6220703125, "cpu_memory_peak_mb": 2064.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754199.3615806}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [163.0232999996224, 160.44770000007702], "ttft_ms": [20.722099998238264, 19.63400000022375], "tokens_processed": [8, 8], "throughput_tok_s": [49.072739909071466, 49.86048413281188], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.068199999717763, 20.472000000154367, 20.879600000625942], "resource_metrics": {"samples": 4, "duration_s": 0.31406474113464355, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7389999999999999, "gpu_power_peak_watts": 1.764, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2064.48046875, "cpu_memory_peak_mb": 2064.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754199.7853312}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [157.65789999932167, 151.10899999854155], "ttft_ms": [19.565599999623373, 18.43189999999595], "tokens_processed": [8, 8], "throughput_tok_s": [50.74277914417495, 52.941916100809436], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.34909999949741, 20.209199999953853, 19.38469999731751], "resource_metrics": {"samples": 4, "duration_s": 0.3131110668182373, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.764, "gpu_power_peak_watts": 1.764, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2064.48046875, "cpu_memory_peak_mb": 2064.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754200.2078748}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [155.29099999912432, 162.5196999993932], "ttft_ms": [17.547299998113886, 19.3362000027264], "tokens_processed": [8, 8], "throughput_tok_s": [51.51618574189819, 49.22480167038131], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.93819999936386, 19.040300001506694, 18.023599997832207], "resource_metrics": {"samples": 4, "duration_s": 0.31169986724853516, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.78475, "gpu_power_peak_watts": 1.847, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2064.48046875, "cpu_memory_peak_mb": 2064.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754200.6318293}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [144.61540000047535, 149.69669999845792], "ttft_ms": [17.291399999521673, 18.248499996843748], "tokens_processed": [8, 8], "throughput_tok_s": [55.31914305097316, 53.441391828159276], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.135200000164332, 19.027400001505157, 17.17849999840837], "resource_metrics": {"samples": 4, "duration_s": 0.32460904121398926, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.847, "gpu_power_peak_watts": 1.847, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2064.48046875, "cpu_memory_peak_mb": 2064.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754201.070501}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [244.07859999701031, 254.9799999978859], "ttft_ms": [29.537599999457598, 31.617299999197712], "tokens_processed": [32, 32], "throughput_tok_s": [131.10530788193626, 125.5000392198028], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [28.45990000059828, 28.187500000058208, 27.609500000835396], "resource_metrics": {"samples": 6, "duration_s": 0.5220963954925537, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8253333333333333, "gpu_power_peak_watts": 1.847, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2081.4088541666665, "cpu_memory_peak_mb": 2087.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754201.7039576}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [247.6652000004833, 240.19920000137063], "ttft_ms": [30.94989999954123, 31.37789999891538], "tokens_processed": [32, 32], "throughput_tok_s": [129.20668709183832, 133.22275844306475], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [33.44970000034664, 32.1529000029841, 30.839999999443535], "resource_metrics": {"samples": 6, "duration_s": 0.5146961212158203, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7169999999999999, "gpu_power_peak_watts": 1.717, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2087.921875, "cpu_memory_peak_mb": 2087.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754202.3307292}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [222.19310000218684, 215.31420000246726], "ttft_ms": [28.162200000224402, 25.92939999885857], "tokens_processed": [32, 32], "throughput_tok_s": [144.01887367197745, 148.62001669947136], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [27.13890000086394, 28.323600003204774, 27.157000000443077], "resource_metrics": {"samples": 6, "duration_s": 0.5146148204803467, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.703, "gpu_power_peak_watts": 1.717, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2087.921875, "cpu_memory_peak_mb": 2087.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754202.956536}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [219.69000000171945, 228.78619999755756], "ttft_ms": [27.85560000120313, 26.73529999810853], "tokens_processed": [32, 32], "throughput_tok_s": [145.65979334402815, 139.86857599077925], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [29.482099998858757, 28.882799997518305, 26.92190000016126], "resource_metrics": {"samples": 6, "duration_s": 0.5244197845458984, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.696, "gpu_power_peak_watts": 1.696, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2087.921875, "cpu_memory_peak_mb": 2087.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754203.5941277}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [228.44070000064676, 227.9244999990624], "ttft_ms": [30.525800000759773, 28.2186999975238], "tokens_processed": [32, 32], "throughput_tok_s": [140.08011707156126, 140.3973684274031], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [28.925300000992138, 31.22379999695113, 28.92249999786145], "resource_metrics": {"samples": 6, "duration_s": 0.5146496295928955, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.752, "gpu_power_peak_watts": 1.752, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2087.921875, "cpu_memory_peak_mb": 2087.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754204.2226171}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [324.002900000778, 113.30219999945257], "ttft_ms": [40.916600002674386, 40.45340000084252], "tokens_processed": [32, 12], "throughput_tok_s": [98.76454809485705, 105.91144743930815], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [35.758699999860255, 39.719500000501284, 41.22069999721134], "resource_metrics": {"samples": 6, "duration_s": 0.5126843452453613, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.755, "gpu_power_peak_watts": 1.758, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2108.1282552083335, "cpu_memory_peak_mb": 2116.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754204.846532}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [291.32640000170795, 112.87919999813312], "ttft_ms": [38.01490000114427, 37.614200002280995], "tokens_processed": [32, 12], "throughput_tok_s": [109.84243103203964, 106.30833670152221], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.817799999174895, 36.89659999872674, 36.30739999789512], "resource_metrics": {"samples": 5, "duration_s": 0.42055678367614746, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7579999999999998, "gpu_power_peak_watts": 1.758, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2116.7109375, "cpu_memory_peak_mb": 2116.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754205.3752942}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [292.6353000002564, 116.33609999989858], "ttft_ms": [39.34739999749581, 38.983400001598056], "tokens_processed": [32, 12], "throughput_tok_s": [109.35112749545924, 103.14940934078469], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.38069999963045, 38.74509999877773, 40.03770000053919], "resource_metrics": {"samples": 6, "duration_s": 0.5235934257507324, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7086666666666666, "gpu_power_peak_watts": 1.758, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2116.72265625, "cpu_memory_peak_mb": 2116.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754206.0103998}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [289.42239999742014, 116.115600001649], "ttft_ms": [37.070099999255035, 39.01209999821731], "tokens_processed": [32, 12], "throughput_tok_s": [110.56504265145075, 103.34528693672154], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.273300000379095, 35.78360000028624, 35.43490000083693], "resource_metrics": {"samples": 6, "duration_s": 0.5111873149871826, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.6896666666666667, "gpu_power_peak_watts": 1.718, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2116.72265625, "cpu_memory_peak_mb": 2116.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754206.6300862}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [301.0090999996464, 109.7444999977597], "ttft_ms": [35.843400000885595, 37.60150000016438], "tokens_processed": [32, 12], "throughput_tok_s": [106.30907836353649, 109.34488744533863], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [37.14109999782522, 37.38410000005388, 36.259299999073846], "resource_metrics": {"samples": 6, "duration_s": 0.5157742500305176, "gpu_memory_mean_mb": 4894.01953125, "gpu_memory_peak_mb": 4894.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.718, "gpu_power_peak_watts": 1.718, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2116.7330729166665, "cpu_memory_peak_mb": 2116.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1132.1089000011852, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754207.2542713}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [142.22629999858327, 97.07020000132616], "ttft_ms": [35.42750000269734, 35.06819999893196], "tokens_processed": [4, 4], "throughput_tok_s": [28.124193626916007, 41.20729121754516], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [136.96970000091824, 35.695500002475455, 35.8617999991111], "resource_metrics": {"samples": 5, "duration_s": 0.415175199508667, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.9515999999999998, "gpu_power_peak_watts": 2.302, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2239.5140625, "cpu_memory_peak_mb": 2270.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754207.7785478}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.662900001188973, 15.419799998198869], "ttft_ms": [4.1152999983751215, 3.575700000510551], "tokens_processed": [4, 4], "throughput_tok_s": [255.38054892110398, 259.4067368232549], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.482100001041545, 4.077100002177758, 3.849099997751182], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.302, "gpu_power_peak_watts": 2.302, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2270.09375, "cpu_memory_peak_mb": 2270.09375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754207.907658}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.626200001657708, 15.399399999296293], "ttft_ms": [3.6996000017097685, 3.6211000006005634], "tokens_processed": [4, 4], "throughput_tok_s": [273.48183393818266, 259.75037989680044], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.937099998438498, 3.876200000377139, 3.6422999983187765], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.302, "gpu_power_peak_watts": 2.302, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2270.09375, "cpu_memory_peak_mb": 2270.09375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.0316806}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.812800000276184, 15.455000000656582], "ttft_ms": [3.581300003133947, 3.8598999999521766], "tokens_processed": [4, 4], "throughput_tok_s": [252.95962763900997, 258.8159171679111], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9001000004645903, 3.6466000019572675, 3.6002000015287194], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 8.529, "gpu_power_peak_watts": 8.529, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2270.09375, "cpu_memory_peak_mb": 2270.09375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.156605}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.241299999615876, 15.886600001977058], "ttft_ms": [3.7607999984174967, 3.9797000026737805], "tokens_processed": [4, 4], "throughput_tok_s": [262.4448045836518, 251.78452277404904], "predicted_tokens": ["", ""], "outputs": ["Hello : \n<|endoftext|>", "Test : \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.06739999743877, 3.7262999976519495, 3.7104000002727844], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 8.529, "gpu_power_peak_watts": 8.529, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2270.09375, "cpu_memory_peak_mb": 2270.09375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.27912}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.03659999780939, 33.096999999543186], "ttft_ms": [4.016799997771159, 3.8609000002907123], "tokens_processed": [8, 8], "throughput_tok_s": [249.71438918446486, 241.71375049431725], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.536000000574859, 4.017299997940427, 3.888900002493756], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 8.529, "gpu_power_peak_watts": 8.529, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2271.0546875, "cpu_memory_peak_mb": 2271.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.4052596}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.373199999914505, 31.909200002701255], "ttft_ms": [4.1388999998162035, 3.757200000109151], "tokens_processed": [8, 8], "throughput_tok_s": [239.71330289035797, 250.71139355805738], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.74459999895771, 4.318400002375711, 4.075099997862708], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 8.529, "gpu_power_peak_watts": 8.529, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2271.6171875, "cpu_memory_peak_mb": 2271.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.5299325}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.86140000273008, 31.849200000579003], "ttft_ms": [3.8732000029995106, 4.046100002597086], "tokens_processed": [8, 8], "throughput_tok_s": [243.4467186223159, 251.1837031967699], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6029000004637055, 3.83720000172616, 4.01879999844823], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 30.914, "gpu_power_peak_watts": 30.914, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2271.6171875, "cpu_memory_peak_mb": 2271.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.6532564}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.682500000897562, 32.83269999883487], "ttft_ms": [3.8022999979148153, 3.934500000468688], "tokens_processed": [8, 8], "throughput_tok_s": [252.50532627707287, 243.659522375068], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.57459999981802, 4.240300000674324, 3.9580999982717913], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 30.914, "gpu_power_peak_watts": 30.914, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2271.62109375, "cpu_memory_peak_mb": 2271.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.7747595}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.51749999981257, 33.046999997168314], "ttft_ms": [4.129400000238093, 3.9537000011478085], "tokens_processed": [8, 8], "throughput_tok_s": [246.02137310820672, 242.07946260433604], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.16640000307234, 6.682499999442371, 4.349499999079853], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 30.914, "gpu_power_peak_watts": 30.914, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2271.62109375, "cpu_memory_peak_mb": 2271.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754208.8987067}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.540000000357395, 12.357300001895055], "ttft_ms": [4.28000000101747, 4.015800001070602], "tokens_processed": [8, 3], "throughput_tok_s": [238.52116875118526, 242.77147916939256], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.4579999996349216, 4.629100003512576, 4.257299999153474], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 30.914, "gpu_power_peak_watts": 30.914, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2277.11328125, "cpu_memory_peak_mb": 2277.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.0248275}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.910999998421175, 12.07809999687015], "ttft_ms": [4.081200000655372, 4.087100001925137], "tokens_processed": [8, 3], "throughput_tok_s": [243.07982134799246, 248.38343785673266], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.754800000431715, 4.243299998051953, 4.114600000320934], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 60.39, "gpu_power_peak_watts": 60.39, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2282.828125, "cpu_memory_peak_mb": 2282.828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.1664832}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.00369999872055, 12.113700002373662], "ttft_ms": [4.4809999999415595, 3.958900000725407], "tokens_processed": [8, 3], "throughput_tok_s": [235.2685149057607, 247.6534831977145], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.8534000015934, 4.377699999167817, 4.856499999732478], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 60.39, "gpu_power_peak_watts": 60.39, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2282.8359375, "cpu_memory_peak_mb": 2282.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.2900257}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.36919999876409, 12.330100002145628], "ttft_ms": [4.5523000007960945, 3.891299998940667], "tokens_processed": [8, 3], "throughput_tok_s": [232.76654680026533, 243.30702909773268], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.59709999995539, 4.149799999140669, 4.341399999248097], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 60.39, "gpu_power_peak_watts": 60.39, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2282.8359375, "cpu_memory_peak_mb": 2282.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.415908}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.683299999916926, 13.100699998176424], "ttft_ms": [4.303899997466942, 4.2557000015222], "tokens_processed": [8, 3], "throughput_tok_s": [244.77332460370693, 228.99539722439187], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.017500000685686, 10.64550000228337, 9.70460000098683], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 60.39, "gpu_power_peak_watts": 60.39, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2282.8359375, "cpu_memory_peak_mb": 2282.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.5373673}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.363200000778306, 36.00370000276598], "ttft_ms": [4.857899999478832, 4.939800001011463], "tokens_processed": [8, 8], "throughput_tok_s": [220.0026400269715, 222.1993850461314], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.604599999060156, 4.300199998397147, 4.832599999645026], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 34.855, "gpu_power_peak_watts": 34.855, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2284.37890625, "cpu_memory_peak_mb": 2284.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.6635725}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.91869999966002, 37.60580000016489], "ttft_ms": [5.004500002542045, 4.868999996688217], "tokens_processed": [8, 8], "throughput_tok_s": [216.69235374142835, 212.7331422271278], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.627700000535697, 4.497799996897811, 4.469999999855645], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 34.855, "gpu_power_peak_watts": 34.855, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2285.87890625, "cpu_memory_peak_mb": 2285.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.789616}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.76869999940391, 37.57649999897694], "ttft_ms": [5.285899998852983, 4.3178000014449935], "tokens_processed": [8, 8], "throughput_tok_s": [230.0920080456605, 212.89901933968858], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.702199999883305, 4.446799997822382, 5.186500002309913], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 34.855, "gpu_power_peak_watts": 34.855, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2285.87890625, "cpu_memory_peak_mb": 2285.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754209.9137635}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.73230000256444, 37.77749999790103], "ttft_ms": [4.869800002779812, 4.7594999996363185], "tokens_processed": [8, 8], "throughput_tok_s": [223.88707134513743, 211.76626299899385], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.426899999089073, 4.320400003052782, 4.583399997500237], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 34.855, "gpu_power_peak_watts": 34.855, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2285.87890625, "cpu_memory_peak_mb": 2285.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.0398245}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.4905000028084, 37.413899997773115], "ttft_ms": [4.790099999809172, 4.282699999748729], "tokens_processed": [8, 8], "throughput_tok_s": [207.84349383396662, 213.82427387885684], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. the game . He was a \" a"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.669600002671359, 4.543800001556519, 5.311300003086217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 49.791, "gpu_power_peak_watts": 49.791, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2285.87890625, "cpu_memory_peak_mb": 2285.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.1650112}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.37759999989066, 46.435699998255586], "ttft_ms": [6.32920000134618, 5.159899999853224], "tokens_processed": [32, 32], "throughput_tok_s": [675.424673264873, 689.124962070177], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.225600002537249, 6.877300002088305, 5.438799998955801], "resource_metrics": {"samples": 2, "duration_s": 0.11711335182189941, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 49.791, "gpu_power_peak_watts": 49.791, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2301.732421875, "cpu_memory_peak_mb": 2309.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.3920922}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.72449999957462, 45.12630000317586], "ttft_ms": [6.624300000112271, 6.7066000010527205], "tokens_processed": [32, 32], "throughput_tok_s": [715.4915091349117, 709.1208452221417], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.45580000107293, 6.50110000060522, 5.4209000008995645], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 49.791, "gpu_power_peak_watts": 49.791, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2309.5390625, "cpu_memory_peak_mb": 2309.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.5232828}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.8958000021521, 48.16729999947711], "ttft_ms": [5.965299998933915, 6.301299999904586], "tokens_processed": [32, 32], "throughput_tok_s": [668.1170373720064, 664.3511261861757], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.839599998580525, 6.543300001794705, 6.667600002401741], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 41.624, "gpu_power_peak_watts": 41.624, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2309.5390625, "cpu_memory_peak_mb": 2309.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.6497557}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.086499998840736, 45.93169999861857], "ttft_ms": [7.018499996775063, 5.7100000012724195], "tokens_processed": [32, 32], "throughput_tok_s": [679.6003100843732, 696.686602084452], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.265899999561952, 6.5533999986655544, 5.691400001524016], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 41.624, "gpu_power_peak_watts": 41.624, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2309.5390625, "cpu_memory_peak_mb": 2309.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.7743576}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [46.9262999977218, 47.340900000563124], "ttft_ms": [6.586600000446197, 5.634699999063741], "tokens_processed": [32, 32], "throughput_tok_s": [681.9203730435503, 675.9482814990707], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. , and the time of the time ,", "List two ways to improve throughput on local LLMs. , and the other other , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.621900000027381, 6.729800003085984, 5.612499997369014], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 41.624, "gpu_power_peak_watts": 41.624, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2309.5390625, "cpu_memory_peak_mb": 2309.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754210.912917}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.6087000000407, 20.16369999910239], "ttft_ms": [6.741200002579717, 6.5724999985832255], "tokens_processed": [32, 12], "throughput_tok_s": [596.9180375568836, 595.1288702239268], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.249599999544444, 6.9684000009146985, 6.624900001042988], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 41.624, "gpu_power_peak_watts": 41.624, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2315.6953125, "cpu_memory_peak_mb": 2315.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754211.0395234}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.070099998876685, 20.87549999851035], "ttft_ms": [6.663000000116881, 7.936399997561239], "tokens_processed": [32, 12], "throughput_tok_s": [602.9760637473329, 574.8365309025559], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.538999998359941, 6.747299998096423, 7.064699999318691], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 59.085, "gpu_power_peak_watts": 59.085, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2338.4296875, "cpu_memory_peak_mb": 2338.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754211.1652637}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.860499999747844, 19.596300000557676], "ttft_ms": [5.692800001270371, 7.586700001411373], "tokens_processed": [32, 12], "throughput_tok_s": [617.0399436981053, 612.3604966069361], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.213899996917462, 6.696899999951711, 7.103700001607649], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 59.085, "gpu_power_peak_watts": 59.085, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2338.44140625, "cpu_memory_peak_mb": 2338.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754211.287503}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [52.4957000016002, 21.429999997053528], "ttft_ms": [5.810200000269106, 6.371800001943484], "tokens_processed": [32, 12], "throughput_tok_s": [609.5737364969809, 559.9626692323804], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.573999999294756, 7.137600001442479, 7.4891000003844965], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 59.085, "gpu_power_peak_watts": 59.085, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2338.44140625, "cpu_memory_peak_mb": 2338.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754211.4123461}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.06349999975646, 21.686500000214437], "ttft_ms": [6.260800000745803, 6.930399998964276], "tokens_processed": [32, 12], "throughput_tok_s": [591.8965660777448, 553.3396352514857], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , the same time , the same time", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. \n<|endoftext|>"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.656199999270029, 7.287000000360422, 5.86969999858411], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4904.01953125, "gpu_memory_peak_mb": 4904.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 59.085, "gpu_power_peak_watts": 59.085, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2338.44140625, "cpu_memory_peak_mb": 2338.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2573.607999998785, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx"}, "started_at": 1765754211.535093}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [37.39339999810909, 2.3329999967245385, 2.0696999999927357], "resource_metrics": {"samples": 6, "duration_s": 0.5196316242218018, "gpu_memory_mean_mb": 5277.869140625, "gpu_memory_peak_mb": 6037.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.833333333333336, "gpu_power_mean_watts": 42.89333333333334, "gpu_power_peak_watts": 44.028, "gpu_temperature_mean_c": 49.666666666666664, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2714.873046875, "cpu_memory_peak_mb": 3032.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765754212.1623716}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5531999999657273, 2.0617000009224284, 1.9179999981133733], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 37.22, "gpu_power_peak_watts": 37.22, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2628.40625, "cpu_memory_peak_mb": 2628.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.283492}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.740800002356991, 2.0747000016854145, 2.202600000600796], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 37.22, "gpu_power_peak_watts": 37.22, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2628.4375, "cpu_memory_peak_mb": 2628.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.4064891}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0531999982486013, 2.4036999966483563, 2.486099998350255], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 37.22, "gpu_power_peak_watts": 37.22, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2628.56640625, "cpu_memory_peak_mb": 2628.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.5326686}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0143000003590714, 2.0525999971141573, 2.0035999987157993], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 38.287, "gpu_power_peak_watts": 38.287, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2628.58203125, "cpu_memory_peak_mb": 2628.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.656748}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.482300002564443, 2.155900001525879, 2.238299999589799], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 38.287, "gpu_power_peak_watts": 38.287, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2629.2734375, "cpu_memory_peak_mb": 2629.2734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.7813404}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8101000025344547, 2.3622000007890165, 2.3261999995156657], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 38.287, "gpu_power_peak_watts": 38.287, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2629.421875, "cpu_memory_peak_mb": 2629.421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754212.9066768}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8654000016103964, 2.3108000023057684, 2.3840000030759256], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 38.287, "gpu_power_peak_watts": 38.287, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2629.43359375, "cpu_memory_peak_mb": 2629.43359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.0314574}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0397999980777968, 2.3342999993474223, 2.1340000021154992], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.974, "gpu_power_peak_watts": 37.974, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2629.43359375, "cpu_memory_peak_mb": 2629.43359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.1579752}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.791099999740254, 2.3313999990932643, 2.431799999612849], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6043.0390625, "gpu_memory_peak_mb": 6043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.974, "gpu_power_peak_watts": 37.974, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2629.4453125, "cpu_memory_peak_mb": 2629.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.279334}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.960999998525949, 2.657799999724375, 2.5229999992006924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6045.0390625, "gpu_memory_peak_mb": 6045.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.974, "gpu_power_peak_watts": 37.974, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2630.984375, "cpu_memory_peak_mb": 2630.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.4028993}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.3761999984562863, 2.7650000010908116, 2.266200001031393], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6045.0390625, "gpu_memory_peak_mb": 6045.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.974, "gpu_power_peak_watts": 37.974, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2630.99609375, "cpu_memory_peak_mb": 2630.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.530186}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.3789000008255243, 2.8070999978808686, 2.728300001763273], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6045.0390625, "gpu_memory_peak_mb": 6045.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.823, "gpu_power_peak_watts": 35.823, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2630.99609375, "cpu_memory_peak_mb": 2630.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.655192}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.5257000017736573, 2.8746999996656086, 2.6906999992206693], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6045.0390625, "gpu_memory_peak_mb": 6045.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.823, "gpu_power_peak_watts": 35.823, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2630.99609375, "cpu_memory_peak_mb": 2630.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.7788634}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4048999987135176, 2.6816999998118263, 2.789499998471001], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6045.0390625, "gpu_memory_peak_mb": 6045.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.823, "gpu_power_peak_watts": 35.823, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2631.203125, "cpu_memory_peak_mb": 2631.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754213.9065797}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.036199999973178, 2.6407000004837755, 2.8619000004255213], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6047.0390625, "gpu_memory_peak_mb": 6047.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.823, "gpu_power_peak_watts": 35.823, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2632.76171875, "cpu_memory_peak_mb": 2632.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.0275998}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.247399999963818, 2.588100000139093, 2.907400001276983], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6047.0390625, "gpu_memory_peak_mb": 6047.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.631, "gpu_power_peak_watts": 33.631, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2632.76171875, "cpu_memory_peak_mb": 2632.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.152713}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.317599999718368, 2.568199997767806, 2.849399999831803], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6047.0390625, "gpu_memory_peak_mb": 6047.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.631, "gpu_power_peak_watts": 33.631, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2632.76171875, "cpu_memory_peak_mb": 2632.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.2783265}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.655400000046939, 4.186800000752555, 4.010100001323735], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6047.0390625, "gpu_memory_peak_mb": 6047.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.631, "gpu_power_peak_watts": 33.631, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2632.76171875, "cpu_memory_peak_mb": 2632.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.4021778}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.7809000023116823, 3.1404000001202803, 3.0726000004506204], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6047.0390625, "gpu_memory_peak_mb": 6047.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.631, "gpu_power_peak_watts": 33.631, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2632.76171875, "cpu_memory_peak_mb": 2632.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.5235898}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.151899998367298, 4.851300000154879, 5.058499998995103], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6039.0390625, "gpu_memory_peak_mb": 6039.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.075, "gpu_power_peak_watts": 33.075, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2630.26953125, "cpu_memory_peak_mb": 2630.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.6493566}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.668300000455929, 4.614600002241787, 4.29200000144192], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6055.0390625, "gpu_memory_peak_mb": 6055.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.075, "gpu_power_peak_watts": 33.075, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2649.96875, "cpu_memory_peak_mb": 2649.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.773709}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.056700000044657, 4.075300003023585, 3.620800001954194], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6055.0390625, "gpu_memory_peak_mb": 6055.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.075, "gpu_power_peak_watts": 33.075, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2649.9140625, "cpu_memory_peak_mb": 2649.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754214.8970854}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.985199998074677, 5.2843999983451795, 3.142099998513004], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6055.0390625, "gpu_memory_peak_mb": 6055.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 33.075, "gpu_power_peak_watts": 33.075, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2649.921875, "cpu_memory_peak_mb": 2649.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.0208535}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.025200000294717, 4.822700000659097, 4.5339999996940605], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6055.0390625, "gpu_memory_peak_mb": 6055.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 33.793, "gpu_power_peak_watts": 33.793, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2649.9296875, "cpu_memory_peak_mb": 2649.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.1448467}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.690400001796661, 6.624499997997191, 4.860000000917353], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6061.0390625, "gpu_memory_peak_mb": 6061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 33.793, "gpu_power_peak_watts": 33.793, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.0625, "cpu_memory_peak_mb": 2656.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.2703369}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.089899998594774, 5.291500001476379, 4.626499998266809], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6061.0390625, "gpu_memory_peak_mb": 6061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 33.793, "gpu_power_peak_watts": 33.793, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.06640625, "cpu_memory_peak_mb": 2656.06640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.3943558}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.967000001372071, 5.251700000371784, 4.6285999997053295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6061.0390625, "gpu_memory_peak_mb": 6061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 33.793, "gpu_power_peak_watts": 33.793, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.0703125, "cpu_memory_peak_mb": 2656.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.5220897}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.427499997400446, 6.40430000203196, 5.2097000007051975], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6061.0390625, "gpu_memory_peak_mb": 6061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 34.263, "gpu_power_peak_watts": 34.263, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2644.29296875, "cpu_memory_peak_mb": 2644.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.6412923}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.8711999994993676, 5.796599998575402, 3.6053999974683393], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6061.0390625, "gpu_memory_peak_mb": 6061.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 34.263, "gpu_power_peak_watts": 34.263, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.0703125, "cpu_memory_peak_mb": 2656.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 556.8299000005936, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754215.7695916}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.735300001717405, 2.2723000001860783, 2.2559999997611158], "resource_metrics": {"samples": 6, "duration_s": 0.515357255935669, "gpu_memory_mean_mb": 6349.705729166667, "gpu_memory_peak_mb": 7071.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.5, "gpu_power_mean_watts": 33.9095, "gpu_power_peak_watts": 34.263, "gpu_temperature_mean_c": 47.5, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 3214.923828125, "cpu_memory_peak_mb": 3486.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765754216.3981574}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.496400000381982, 2.206999997724779, 2.1039000021119136], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.556, "gpu_power_peak_watts": 33.556, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2652.58984375, "cpu_memory_peak_mb": 2652.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754216.5151577}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.260299999965355, 3.301699998701224, 3.2357999989471864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.908, "gpu_power_peak_watts": 33.908, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2652.59765625, "cpu_memory_peak_mb": 2652.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754216.6400504}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9902000023867004, 2.4468000010529067, 2.6336000009905547], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.908, "gpu_power_peak_watts": 33.908, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2652.6015625, "cpu_memory_peak_mb": 2652.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754216.7630303}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.281999997852836, 1.946600001247134, 2.266200001031393], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.908, "gpu_power_peak_watts": 33.908, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2652.6015625, "cpu_memory_peak_mb": 2652.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754216.8891883}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.071399998792913, 3.119700002571335, 2.8765000024577603], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.908, "gpu_power_peak_watts": 33.908, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2653.35546875, "cpu_memory_peak_mb": 2653.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.0153325}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6087000007682946, 3.3847999984573107, 3.4976999995706137], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.748, "gpu_power_peak_watts": 35.748, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2653.35546875, "cpu_memory_peak_mb": 2653.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.1403458}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2033000024966896, 2.9431000002659857, 3.476599998975871], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.748, "gpu_power_peak_watts": 35.748, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2653.35546875, "cpu_memory_peak_mb": 2653.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.261571}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.3533000023453496, 2.6756999977806117, 2.9757999982393812], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.748, "gpu_power_peak_watts": 35.748, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2653.359375, "cpu_memory_peak_mb": 2653.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.3862443}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.166599999531172, 2.716099999815924, 3.1610999976692256], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7075.0390625, "gpu_memory_peak_mb": 7075.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 35.748, "gpu_power_peak_watts": 35.748, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2653.359375, "cpu_memory_peak_mb": 2653.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.5091581}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.732399997214088, 3.764400000363821, 3.633500000432832], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7077.0390625, "gpu_memory_peak_mb": 7077.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.841, "gpu_power_peak_watts": 37.841, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2654.89453125, "cpu_memory_peak_mb": 2654.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.6325092}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2357999989471864, 2.7326000017637853, 3.215799999452429], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7077.0390625, "gpu_memory_peak_mb": 7077.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.841, "gpu_power_peak_watts": 37.841, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2654.8984375, "cpu_memory_peak_mb": 2654.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.7573473}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.583899997465778, 2.8884999992442317, 2.672599999641534], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7077.0390625, "gpu_memory_peak_mb": 7077.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.841, "gpu_power_peak_watts": 37.841, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2654.8984375, "cpu_memory_peak_mb": 2654.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754217.8819172}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.140499997243751, 3.2848999981069937, 3.497800000332063], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7077.0390625, "gpu_memory_peak_mb": 7077.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.841, "gpu_power_peak_watts": 37.841, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2654.9140625, "cpu_memory_peak_mb": 2654.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.0079188}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.571899997041328, 3.1529000007139985, 3.5313000007590745], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7077.0390625, "gpu_memory_peak_mb": 7077.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.627, "gpu_power_peak_watts": 37.627, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2654.9140625, "cpu_memory_peak_mb": 2654.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.1293144}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.414400002540788, 4.332500000600703, 4.022399996756576], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7079.0390625, "gpu_memory_peak_mb": 7079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.627, "gpu_power_peak_watts": 37.627, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.4453125, "cpu_memory_peak_mb": 2656.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.2534952}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.356199999368982, 5.432399997516768, 4.175499998382293], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7079.0390625, "gpu_memory_peak_mb": 7079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.627, "gpu_power_peak_watts": 37.627, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.44921875, "cpu_memory_peak_mb": 2656.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.3776524}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.169100000784965, 4.1189999974449165, 5.325800000719028], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7079.0390625, "gpu_memory_peak_mb": 7079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 37.627, "gpu_power_peak_watts": 37.627, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2656.44921875, "cpu_memory_peak_mb": 2656.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.5030837}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.533600000489969, 5.436299998109462, 5.512399999133777], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7079.0390625, "gpu_memory_peak_mb": 7079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.622, "gpu_power_peak_watts": 30.622, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2656.453125, "cpu_memory_peak_mb": 2656.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.627713}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.9932000001717824, 5.542599999898812, 4.08179999794811], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7079.0390625, "gpu_memory_peak_mb": 7079.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.622, "gpu_power_peak_watts": 30.622, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2656.453125, "cpu_memory_peak_mb": 2656.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.7496803}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [20.65000000220607, 9.320100001787068, 9.096599998883903], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7071.0390625, "gpu_memory_peak_mb": 7071.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.622, "gpu_power_peak_watts": 30.622, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2654.07421875, "cpu_memory_peak_mb": 2654.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754218.8777857}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.769700002332684, 9.17719999779365, 9.542600000713719], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7089.0390625, "gpu_memory_peak_mb": 7089.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.622, "gpu_power_peak_watts": 30.622, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2670.09375, "cpu_memory_peak_mb": 2670.09375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.0028703}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.74990000051912, 8.990599999378901, 9.63679999767919], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7089.0390625, "gpu_memory_peak_mb": 7089.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 21.583, "gpu_power_peak_watts": 21.583, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2665.3984375, "cpu_memory_peak_mb": 2665.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.1251822}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.659100000542821, 8.556199998565717, 8.680300001287833], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7089.0390625, "gpu_memory_peak_mb": 7089.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 21.583, "gpu_power_peak_watts": 21.583, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2672.5, "cpu_memory_peak_mb": 2672.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.2501478}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.589099998673191, 9.538499998598127, 9.88869999855524], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7089.0390625, "gpu_memory_peak_mb": 7089.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 21.583, "gpu_power_peak_watts": 21.583, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2672.5, "cpu_memory_peak_mb": 2672.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.3905482}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.790800000104355, 11.32309999957215, 10.925599999609403], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7095.0390625, "gpu_memory_peak_mb": 7095.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 21.583, "gpu_power_peak_watts": 21.583, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2661.671875, "cpu_memory_peak_mb": 2661.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.5125902}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.653400001407135, 11.555099998076912, 11.556399997061817], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7095.0390625, "gpu_memory_peak_mb": 7095.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 17.755, "gpu_power_peak_watts": 17.755, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2672.81640625, "cpu_memory_peak_mb": 2672.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.6405673}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.99429999946733, 11.703799998940667, 13.267499998619314], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7095.0390625, "gpu_memory_peak_mb": 7095.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 17.755, "gpu_power_peak_watts": 17.755, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2678.63671875, "cpu_memory_peak_mb": 2678.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.7938607}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.071600002556806, 11.481999998068204, 12.295099997572834], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7095.0390625, "gpu_memory_peak_mb": 7095.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 17.755, "gpu_power_peak_watts": 17.755, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2667.8203125, "cpu_memory_peak_mb": 2667.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754219.9190805}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.678500003152294, 12.98529999985476, 12.959100000443868], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7095.0390625, "gpu_memory_peak_mb": 7095.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 17.755, "gpu_power_peak_watts": 17.755, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2666.9765625, "cpu_memory_peak_mb": 2666.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 563.065699996514, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754220.0423138}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [24.95410000119591, 15.90809999834164, 18.341099999815924], "resource_metrics": {"samples": 6, "duration_s": 0.5145790576934814, "gpu_memory_mean_mb": 7396.372395833333, "gpu_memory_peak_mb": 7989.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 17.530666666666665, "gpu_power_peak_watts": 17.658, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 3019.9537760416665, "cpu_memory_peak_mb": 3180.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765754220.6860592}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.913799998088507, 15.276399997674162, 15.023500000097556], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 16.894, "gpu_power_peak_watts": 16.894, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.5546875, "cpu_memory_peak_mb": 2675.5546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754220.8067982}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.652400001476053, 15.984300000127405, 15.948600001138402], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 16.894, "gpu_power_peak_watts": 16.894, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.5703125, "cpu_memory_peak_mb": 2675.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754220.9355886}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.588700000284007, 15.828499999770429, 16.202899998461362], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 16.894, "gpu_power_peak_watts": 16.894, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.5703125, "cpu_memory_peak_mb": 2675.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.0605164}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.0991999982798, 15.57189999948605, 15.640300000086427], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 15.769, "gpu_power_peak_watts": 15.769, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.57421875, "cpu_memory_peak_mb": 2675.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.182183}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.978099996980745, 16.254800000751857, 15.966800001478987], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 15.769, "gpu_power_peak_watts": 15.769, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.63671875, "cpu_memory_peak_mb": 2675.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.3070877}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.201499998715008, 15.931900001305621, 15.92510000045877], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 15.769, "gpu_power_peak_watts": 15.769, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.66015625, "cpu_memory_peak_mb": 2675.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.4321864}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.245999999227934, 15.549600000667851, 18.74359999783337], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 15.769, "gpu_power_peak_watts": 15.769, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.6875, "cpu_memory_peak_mb": 2675.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.5584073}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.826299997570459, 15.572799999063136, 16.351900001609465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 14.859, "gpu_power_peak_watts": 14.859, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.6875, "cpu_memory_peak_mb": 2675.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.6835809}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.921099999104626, 15.826999999262625, 15.519799999310635], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7993.0390625, "gpu_memory_peak_mb": 7993.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 14.859, "gpu_power_peak_watts": 14.859, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.6875, "cpu_memory_peak_mb": 2675.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.8067868}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.149600000469945, 16.618899997411063, 16.750700000557117], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7995.0390625, "gpu_memory_peak_mb": 7995.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 14.859, "gpu_power_peak_watts": 14.859, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.765625, "cpu_memory_peak_mb": 2675.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754221.9303505}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.501700000138953, 16.72559999860823, 16.518299999006558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7995.0390625, "gpu_memory_peak_mb": 7995.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 14.859, "gpu_power_peak_watts": 14.859, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.765625, "cpu_memory_peak_mb": 2675.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.056277}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.73769999979413, 16.185799999220762, 16.18189999862807], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7995.0390625, "gpu_memory_peak_mb": 7995.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.335, "gpu_power_peak_watts": 14.335, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.765625, "cpu_memory_peak_mb": 2675.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.1786602}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.887200003111502, 16.40920000136248, 16.158300000824966], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7995.0390625, "gpu_memory_peak_mb": 7995.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.335, "gpu_power_peak_watts": 14.335, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.765625, "cpu_memory_peak_mb": 2675.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.3068454}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.35040000110166, 15.889499998593237, 16.171100000065053], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7995.0390625, "gpu_memory_peak_mb": 7995.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.335, "gpu_power_peak_watts": 14.335, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2675.765625, "cpu_memory_peak_mb": 2675.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.5091984}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.753800002741627, 17.169599999760976, 16.637699998682365], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 7997.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.377, "gpu_power_peak_watts": 14.377, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2675.76953125, "cpu_memory_peak_mb": 2675.76953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.6296864}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.140399999334477, 16.666200001054676, 18.98599999913131], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 7997.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.377, "gpu_power_peak_watts": 14.377, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2675.7734375, "cpu_memory_peak_mb": 2675.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.754017}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.015299999911804, 16.598700000031386, 17.14939999874332], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 7997.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.377, "gpu_power_peak_watts": 14.377, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2675.7734375, "cpu_memory_peak_mb": 2675.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.877287}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.32329999867943, 17.01179999872693, 19.69220000319183], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 7997.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 14.377, "gpu_power_peak_watts": 14.377, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2675.7734375, "cpu_memory_peak_mb": 2675.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754222.9991283}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.092499998398125, 17.169899998407345, 16.606799999863142], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 7997.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.835, "gpu_power_peak_watts": 14.835, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2675.8203125, "cpu_memory_peak_mb": 2675.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.1241846}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [26.221099997201236, 20.852000001468696, 20.51700000083656], "resource_metrics": {"samples": 2, "duration_s": 0.11532378196716309, "gpu_memory_mean_mb": 7997.0390625, "gpu_memory_peak_mb": 8005.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.835, "gpu_power_peak_watts": 14.835, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2690.93359375, "cpu_memory_peak_mb": 2700.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.3503122}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [22.052600001188694, 20.79329999833135, 20.795899999939138], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8005.0390625, "gpu_memory_peak_mb": 8005.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.835, "gpu_power_peak_watts": 14.835, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2694.8046875, "cpu_memory_peak_mb": 2694.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.4827175}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [22.429200002079597, 20.632699997804593, 21.11249999870779], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8005.0390625, "gpu_memory_peak_mb": 8005.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.835, "gpu_power_peak_watts": 14.835, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2686.36328125, "cpu_memory_peak_mb": 2686.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.6086116}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.86509999955888, 20.29420000326354, 20.26090000072145], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8005.0390625, "gpu_memory_peak_mb": 8005.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.955, "gpu_power_peak_watts": 14.955, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2686.36328125, "cpu_memory_peak_mb": 2686.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.73098}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.284700000251178, 20.907300000544637, 20.384799998282688], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8005.0390625, "gpu_memory_peak_mb": 8005.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.955, "gpu_power_peak_watts": 14.955, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2686.3671875, "cpu_memory_peak_mb": 2686.3671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.8538144}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.67870000062976, 6.148299999040319, 6.704900002659997], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8011.0390625, "gpu_memory_peak_mb": 8011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.955, "gpu_power_peak_watts": 14.955, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2687.26171875, "cpu_memory_peak_mb": 2687.26171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754223.9786785}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.346200000436511, 6.717500000377186, 6.684200001473073], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8011.0390625, "gpu_memory_peak_mb": 8011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 14.955, "gpu_power_peak_watts": 14.955, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2707.12890625, "cpu_memory_peak_mb": 2707.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754224.1029735}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.048600001027808, 6.964600001083454, 6.180700002005324], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8011.0390625, "gpu_memory_peak_mb": 8011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 15.512, "gpu_power_peak_watts": 15.512, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2707.12890625, "cpu_memory_peak_mb": 2707.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754224.225981}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.386999998241663, 6.570300000021234, 6.466200000431854], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8011.0390625, "gpu_memory_peak_mb": 8011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 15.512, "gpu_power_peak_watts": 15.512, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2707.1328125, "cpu_memory_peak_mb": 2707.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754224.3492134}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.87460000012652, 6.067899998015491, 6.914199999300763], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8011.0390625, "gpu_memory_peak_mb": 8011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 15.512, "gpu_power_peak_watts": 15.512, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2707.17578125, "cpu_memory_peak_mb": 2707.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "export_time_s": 8.140759300000354, "file_size_mb": 514.0790452957153, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "exists": true, "onnx_file_size_bytes": 539050949, "onnx_file_size_mb": 514.0790452957153, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 539050949, "total_artifact_size_mb": 514.0790452957153, "initializer_count": 101, "initializer_numel": 134685696, "initializer_bytes_est": 538742784, "initializer_bytes_est_mb": 513.78515625, "initializer_dtype_counts": {"FLOAT": 101}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-100m\\model.safetensors", "name": "model.safetensors", "size_bytes": 384363352, "size_mb": 366.55745697021484}], "total_size_bytes": 384363352, "total_size_mb": 366.55745697021484}, "timestamp": 1765753735.9776213, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 74.82365299999947, "file_size_mb": 520.480037689209, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan", "exists": true, "file_size_bytes": 545762876, "file_size_mb": 520.480037689209, "deserialize_error": null, "num_layers": 609, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 528}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753813.891008, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 162.66911529999925, "file_size_mb": 850.6318321228027, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan", "exists": true, "file_size_bytes": 891952124, "file_size_mb": 850.6318321228027, "deserialize_error": null, "num_layers": 594, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 168, "Float": 322, "Half": 190}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753985.9687772, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 93.64080459999968, "file_size_mb": 522.5654640197754, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "exists": true, "file_size_bytes": 547949604, "file_size_mb": 522.5654640197754, "deserialize_error": null, "num_layers": 694, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 169, "Float": 631}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765754088.0144768, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 532.1193999989191, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765754224.4743242}
