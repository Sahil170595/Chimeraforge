[
  {
    "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx",
    "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan",
    "precision": "fp32",
    "workspace_gb": 6,
    "builder_settings": {},
    "applied_builder_settings": {
      "builder_optimization_level": 3,
      "max_num_tactics": -1,
      "tiling_optimization_level": "TilingOptimizationLevel.NONE",
      "profiling_verbosity": "ProfilingVerbosity.DETAILED"
    },
    "tensorrt_version": "10.12.0.36",
    "build_time_s": 74.82365299999947,
    "file_size_mb": 520.480037689209,
    "engine_sha256": null,
    "engine_inspect": {
      "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp32.plan",
      "exists": true,
      "file_size_bytes": 545762876,
      "file_size_mb": 520.480037689209,
      "deserialize_error": null,
      "num_layers": 609,
      "num_profiles": 5,
      "io_names": [
        "input_ids",
        "attention_mask",
        "logits"
      ],
      "engine_inspector": {
        "layer_entry_type": "dict",
        "has_int8_in_json": false
      },
      "layer_output_dtype_counts": {
        "Int64": 168,
        "Float": 528
      },
      "has_int8_tensors": false
    },
    "int8_calibration": null,
    "dynamic_shapes": true,
    "profiles": 5,
    "timestamp": 1765753813.891008,
    "built": true,
    "reused": false
  },
  {
    "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx",
    "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan",
    "precision": "fp16",
    "workspace_gb": 6,
    "builder_settings": {},
    "applied_builder_settings": {
      "builder_optimization_level": 3,
      "max_num_tactics": -1,
      "tiling_optimization_level": "TilingOptimizationLevel.NONE",
      "profiling_verbosity": "ProfilingVerbosity.DETAILED"
    },
    "tensorrt_version": "10.12.0.36",
    "build_time_s": 162.66911529999925,
    "file_size_mb": 850.6318321228027,
    "engine_sha256": null,
    "engine_inspect": {
      "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_fp16.plan",
      "exists": true,
      "file_size_bytes": 891952124,
      "file_size_mb": 850.6318321228027,
      "deserialize_error": null,
      "num_layers": 594,
      "num_profiles": 5,
      "io_names": [
        "input_ids",
        "attention_mask",
        "logits"
      ],
      "engine_inspector": {
        "layer_entry_type": "dict",
        "has_int8_in_json": false
      },
      "layer_output_dtype_counts": {
        "Int64": 168,
        "Float": 322,
        "Half": 190
      },
      "has_int8_tensors": false
    },
    "int8_calibration": null,
    "dynamic_shapes": true,
    "profiles": 5,
    "timestamp": 1765753985.9687772,
    "built": true,
    "reused": false
  },
  {
    "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\onnx\\gpt2-100m.onnx",
    "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan",
    "precision": "int8",
    "workspace_gb": 6,
    "builder_settings": {},
    "applied_builder_settings": {
      "builder_optimization_level": 3,
      "max_num_tactics": -1,
      "tiling_optimization_level": "TilingOptimizationLevel.NONE",
      "profiling_verbosity": "ProfilingVerbosity.DETAILED"
    },
    "tensorrt_version": "10.12.0.36",
    "build_time_s": 93.64080459999968,
    "file_size_mb": 522.5654640197754,
    "engine_sha256": null,
    "engine_inspect": {
      "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-100m\\tensorrt\\gpt2-100m_int8.plan",
      "exists": true,
      "file_size_bytes": 547949604,
      "file_size_mb": 522.5654640197754,
      "deserialize_error": null,
      "num_layers": 694,
      "num_profiles": 6,
      "io_names": [
        "input_ids",
        "attention_mask",
        "logits"
      ],
      "engine_inspector": {
        "layer_entry_type": "dict",
        "has_int8_in_json": false
      },
      "layer_output_dtype_counts": {
        "Int64": 169,
        "Float": 631
      },
      "has_int8_tensors": false
    },
    "int8_calibration": {
      "source": "dataset",
      "tokenizer_available": true,
      "datasets_available": true,
      "dataset_name": "wikitext",
      "dataset_config": "wikitext-2-raw-v1",
      "split": "test",
      "text_field": "text",
      "samples": 512,
      "texts_loaded": 512,
      "batch_size": 8,
      "seq_len": 128,
      "seed": 42,
      "num_batches": 64,
      "random_vocab_size": null,
      "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib",
      "cache_hit_before": true,
      "cache_size_bytes_before": 27442,
      "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5",
      "cache_size_bytes_after": 27442,
      "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"
    },
    "dynamic_shapes": true,
    "profiles": 5,
    "timestamp": 1765754088.0144768,
    "built": true,
    "reused": false
  }
]