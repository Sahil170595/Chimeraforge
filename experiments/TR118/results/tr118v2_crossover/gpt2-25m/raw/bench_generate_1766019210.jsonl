{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.414900000010675, 23.478600000032657], "ttft_ms": [3.097500000023956, 2.4061000000301647], "tokens_processed": [8, 8], "throughput_tok_s": [327.6687596507257, 340.73581900065903], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1484.845900000039, 165.13290000000325, 3.0921000000034837], "resource_metrics": {"samples": 14, "duration_s": 1.7008240222930908, "gpu_memory_mean_mb": 1246.01953125, "gpu_memory_peak_mb": 1396.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.857142857142858, "gpu_power_mean_watts": 16.690428571428573, "gpu_power_peak_watts": 19.349, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1247.0106026785713, "cpu_memory_peak_mb": 1566.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019266.2304862}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.091499999997268, 22.52469999996265], "ttft_ms": [2.6245000000244545, 2.509700000018711], "tokens_processed": [8, 8], "throughput_tok_s": [332.06732665051607, 355.16566258433033], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.146000000015192, 3.0747000000133085, 2.855599999975311], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1398.01953125, "gpu_memory_peak_mb": 1398.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.349, "gpu_power_peak_watts": 19.349, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1570.359375, "cpu_memory_peak_mb": 1570.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019266.3642395}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.57760000001963, 22.423000000003412], "ttft_ms": [3.160299999990457, 2.3937000000273656], "tokens_processed": [8, 8], "throughput_tok_s": [312.7736769671064, 356.7765241046596], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.008500000021286, 2.861499999994521, 2.931300000000192], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1398.01953125, "gpu_memory_peak_mb": 1398.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.349, "gpu_power_peak_watts": 19.349, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1570.41015625, "cpu_memory_peak_mb": 1570.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019266.48501}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.071300000050087, 19.556599999987156], "ttft_ms": [2.591800000004696, 2.6957000000038533], "tokens_processed": [8, 8], "throughput_tok_s": [362.46165835187986, 409.0690610845062], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.11460000000352, 2.962999999965632, 2.6326000000267413], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1398.01953125, "gpu_memory_peak_mb": 1398.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.349, "gpu_power_peak_watts": 19.349, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1570.4375, "cpu_memory_peak_mb": 1570.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019266.6111007}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.204000000001997, 20.339900000010402], "ttft_ms": [2.331099999992148, 2.2364000000152373], "tokens_processed": [8, 8], "throughput_tok_s": [416.5798791917917, 393.3156013547711], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4796000000151253, 2.402000000017779, 2.3416999999881227], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1398.01953125, "gpu_memory_peak_mb": 1398.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 22.492, "gpu_power_peak_watts": 22.492, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1570.609375, "cpu_memory_peak_mb": 1570.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019266.7492783}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [17.79140000002144, 40.389699999991535], "ttft_ms": [7.255299999997078, 5.320999999980813], "tokens_processed": [3, 8], "throughput_tok_s": [168.6207943161519, 198.07030010130495], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [599.4876999999974, 6.735300000002553, 5.04990000001726], "resource_metrics": {"samples": 7, "duration_s": 0.6717851161956787, "gpu_memory_mean_mb": 1494.3052455357142, "gpu_memory_peak_mb": 1498.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 23.369714285714284, "gpu_power_peak_watts": 24.028, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1570.9224330357142, "cpu_memory_peak_mb": 1588.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019267.5270536}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.901500000017222, 48.32190000001901], "ttft_ms": [5.53309999997964, 4.681199999993169], "tokens_processed": [3, 8], "throughput_tok_s": [177.49903854669367, 165.55640403206107], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.218400000046586, 4.657300000019404, 4.418100000009417], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1498.01953125, "gpu_memory_peak_mb": 1498.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 22.02, "gpu_power_peak_watts": 22.02, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1579.41015625, "cpu_memory_peak_mb": 1579.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019267.6503537}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [16.152099999999336, 46.12799999995332], "ttft_ms": [6.648900000016056, 4.7482000000513835], "tokens_processed": [3, 8], "throughput_tok_s": [185.73436271445343, 173.43045438796602], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.384399999978086, 6.836800000030507, 6.83940000004668], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1498.01953125, "gpu_memory_peak_mb": 1498.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 22.02, "gpu_power_peak_watts": 22.02, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1579.46875, "cpu_memory_peak_mb": 1579.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019267.7733645}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.216200000021217, 46.26220000000103], "ttft_ms": [4.511700000023211, 6.6178999999806365], "tokens_processed": [3, 8], "throughput_tok_s": [211.02685668431243, 172.92735754027743], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.61899999997695, 5.412200000023404, 5.052899999952842], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1498.01953125, "gpu_memory_peak_mb": 1498.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 22.02, "gpu_power_peak_watts": 22.02, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1579.484375, "cpu_memory_peak_mb": 1579.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019267.8970804}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.054000000016003, 46.101299999975254], "ttft_ms": [6.447100000002592, 4.894400000011956], "tokens_processed": [3, 8], "throughput_tok_s": [149.59609055538075, 173.53089826109664], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.107100000008359, 4.633299999966312, 6.654999999966549], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1498.01953125, "gpu_memory_peak_mb": 1498.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 22.02, "gpu_power_peak_watts": 22.02, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1579.49609375, "cpu_memory_peak_mb": 1579.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019268.0200021}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.96360000001687, 54.57989999996471], "ttft_ms": [6.506800000011026, 4.773100000022623], "tokens_processed": [8, 8], "throughput_tok_s": [177.9216966612326, 146.5741051193786], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [622.2222000000102, 7.349400000009609, 6.697799999983545], "resource_metrics": {"samples": 8, "duration_s": 0.7692313194274902, "gpu_memory_mean_mb": 1594.76953125, "gpu_memory_peak_mb": 1598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.5, "gpu_power_mean_watts": 25.903375, "gpu_power_peak_watts": 26.129, "gpu_temperature_mean_c": 49.625, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1574.0126953125, "cpu_memory_peak_mb": 1587.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019268.9177146}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [58.50950000001376, 57.00540000003684], "ttft_ms": [6.850200000030782, 7.287700000006225], "tokens_processed": [8, 8], "throughput_tok_s": [136.7299327459322, 140.3375820535393], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.507200000010926, 7.003499999996166, 6.922900000006393], "resource_metrics": {"samples": 2, "duration_s": 0.10746383666992188, "gpu_memory_mean_mb": 1598.01953125, "gpu_memory_peak_mb": 1598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 28.3675, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 49.5, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1587.5859375, "cpu_memory_peak_mb": 1587.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019269.1336873}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [49.787400000013804, 47.593300000016825], "ttft_ms": [4.585899999995036, 5.158899999969435], "tokens_processed": [8, 8], "throughput_tok_s": [160.68322507296588, 168.09088674240223], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.680800000050112, 5.317100000013397, 4.818000000000211], "resource_metrics": {"samples": 2, "duration_s": 0.11138916015625, "gpu_memory_mean_mb": 1598.01953125, "gpu_memory_peak_mb": 1598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1587.58984375, "cpu_memory_peak_mb": 1587.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019269.3531692}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.61669999999185, 45.92719999999417], "ttft_ms": [6.219899999962308, 5.441300000029514], "tokens_processed": [8, 8], "throughput_tok_s": [168.0082828083712, 174.18871605499606], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.019600000011451, 4.890999999986434, 4.840500000000247], "resource_metrics": {"samples": 2, "duration_s": 0.10945987701416016, "gpu_memory_mean_mb": 1598.01953125, "gpu_memory_peak_mb": 1598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1587.6015625, "cpu_memory_peak_mb": 1587.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019269.5710056}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.18750000000682, 47.39529999994829], "ttft_ms": [5.867899999998372, 4.933900000025915], "tokens_processed": [8, 8], "throughput_tok_s": [169.5364238410351, 168.79310817757727], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.469499999980144, 7.389299999999821, 6.830499999978201], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1598.01953125, "gpu_memory_peak_mb": 1598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 31.039, "gpu_power_peak_watts": 31.039, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1587.6015625, "cpu_memory_peak_mb": 1587.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019269.7019424}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [55.60570000000098, 48.57020000002876], "ttft_ms": [7.192999999972471, 7.793499999991127], "tokens_processed": [8, 8], "throughput_tok_s": [143.87014280909798, 164.71004854818926], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [631.52290000005, 7.456199999978708, 7.0440000000076], "resource_metrics": {"samples": 8, "duration_s": 0.7775313854217529, "gpu_memory_mean_mb": 1685.51953125, "gpu_memory_peak_mb": 1698.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 30.1315, "gpu_power_peak_watts": 31.039, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1580.59619140625, "cpu_memory_peak_mb": 1595.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019270.5918267}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.1884999999852, 48.03759999998647], "ttft_ms": [4.94059999999763, 5.222899999978381], "tokens_processed": [8, 8], "throughput_tok_s": [185.2344952939496, 166.5362132996289], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.156299999986459, 5.3312000000005355, 5.224499999997079], "resource_metrics": {"samples": 2, "duration_s": 0.10793352127075195, "gpu_memory_mean_mb": 1698.01953125, "gpu_memory_peak_mb": 1698.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 29.388, "gpu_power_peak_watts": 29.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1595.69140625, "cpu_memory_peak_mb": 1595.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019270.8078198}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.1920999999611, 48.36590000002161], "ttft_ms": [6.745099999989179, 6.402600000001257], "tokens_processed": [8, 8], "throughput_tok_s": [169.51989845772056, 165.40579209725087], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.255299999997078, 5.79019999997854, 6.868300000007821], "resource_metrics": {"samples": 2, "duration_s": 0.1110527515411377, "gpu_memory_mean_mb": 1698.01953125, "gpu_memory_peak_mb": 1698.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 29.388, "gpu_power_peak_watts": 29.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1595.69140625, "cpu_memory_peak_mb": 1595.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019271.027296}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [61.25750000001062, 58.00629999998819], "ttft_ms": [4.905799999960436, 11.990199999956985], "tokens_processed": [8, 8], "throughput_tok_s": [130.5962535199545, 137.9160539458926], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.5001999999717555, 5.949299999997493, 5.02649999998539], "resource_metrics": {"samples": 2, "duration_s": 0.11078000068664551, "gpu_memory_mean_mb": 1698.01953125, "gpu_memory_peak_mb": 1698.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 30.062, "gpu_power_peak_watts": 30.062, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1595.69140625, "cpu_memory_peak_mb": 1595.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019271.2447238}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.16520000000901, 45.564200000001165], "ttft_ms": [5.136200000038116, 5.167400000004818], "tokens_processed": [8, 8], "throughput_tok_s": [181.1380906233498, 175.57643939759274], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.661800000041239, 6.869699999981549, 5.344100000002072], "resource_metrics": {"samples": 2, "duration_s": 0.10883355140686035, "gpu_memory_mean_mb": 1698.01953125, "gpu_memory_peak_mb": 1698.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.0, "gpu_power_mean_watts": 30.062, "gpu_power_peak_watts": 30.062, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1595.69921875, "cpu_memory_peak_mb": 1595.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019271.461068}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.899300000048697, 61.42649999998184], "ttft_ms": [6.505600000025424, 8.247400000016114], "tokens_processed": [12, 32], "throughput_tok_s": [463.3329858327228, 520.947799402692], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [632.4877999999785, 6.832799999983763, 6.21259999996937], "resource_metrics": {"samples": 8, "duration_s": 0.7801072597503662, "gpu_memory_mean_mb": 1785.51953125, "gpu_memory_peak_mb": 1798.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.625, "gpu_power_mean_watts": 25.68025, "gpu_power_peak_watts": 30.062, "gpu_temperature_mean_c": 49.75, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1583.77294921875, "cpu_memory_peak_mb": 1610.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019272.3485007}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.486399999981586, 61.472299999991264], "ttft_ms": [6.733199999985118, 6.290700000022298], "tokens_processed": [12, 32], "throughput_tok_s": [585.7544517343597, 520.5596667117474], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.667699999979959, 7.310300000028747, 7.747399999971094], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1798.01953125, "gpu_memory_peak_mb": 1798.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 24.685, "gpu_power_peak_watts": 24.685, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1622.8203125, "cpu_memory_peak_mb": 1622.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019272.4655898}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.37629999994806, 61.437800000021525], "ttft_ms": [8.234600000037062, 6.625899999960438], "tokens_processed": [12, 32], "throughput_tok_s": [472.8821774657677, 520.8519836320439], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.120699999982662, 6.569599999977527, 8.352799999954641], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1798.01953125, "gpu_memory_peak_mb": 1798.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 24.685, "gpu_power_peak_watts": 24.685, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1622.8203125, "cpu_memory_peak_mb": 1622.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019272.5872884}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.75249999999096, 65.37220000001298], "ttft_ms": [8.196800000007443, 6.574900000032358], "tokens_processed": [12, 32], "throughput_tok_s": [551.6607286521083, 489.5047130124678], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.774100000015551, 8.312999999986914, 8.244999999988067], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1798.01953125, "gpu_memory_peak_mb": 1798.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 27.006, "gpu_power_peak_watts": 27.006, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1622.8515625, "cpu_memory_peak_mb": 1622.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019272.7129984}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.92520000002196, 58.833700000036515], "ttft_ms": [6.447900000011941, 6.639199999995071], "tokens_processed": [12, 32], "throughput_tok_s": [573.4712213019425, 543.9059586594102], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.147999999981948, 8.328300000016498, 6.465999999988981], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1798.01953125, "gpu_memory_peak_mb": 1798.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 27.006, "gpu_power_peak_watts": 27.006, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1622.859375, "cpu_memory_peak_mb": 1622.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019272.8323615}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [63.670900000033726, 61.82369999999082], "ttft_ms": [7.774799999992865, 7.409800000004907], "tokens_processed": [32, 32], "throughput_tok_s": [502.58438313237366, 517.6008553354903], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [637.3403999999709, 10.197500000003856, 9.861600000022008], "resource_metrics": {"samples": 8, "duration_s": 0.7703413963317871, "gpu_memory_mean_mb": 1894.76953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.25, "gpu_power_mean_watts": 26.05425, "gpu_power_peak_watts": 27.196, "gpu_temperature_mean_c": 49.875, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1593.26806640625, "cpu_memory_peak_mb": 1644.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019273.724202}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [63.95559999998568, 67.5783000000365], "ttft_ms": [7.324499999981526, 7.266799999968043], "tokens_processed": [32, 32], "throughput_tok_s": [500.3471158117063, 473.52478532284346], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.025900000006914, 7.562300000017785, 7.168799999988096], "resource_metrics": {"samples": 2, "duration_s": 0.11067676544189453, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.442, "gpu_power_peak_watts": 18.442, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1644.546875, "cpu_memory_peak_mb": 1644.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019273.9422536}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [70.45590000001312, 63.776899999993475], "ttft_ms": [9.365999999999985, 7.724199999984194], "tokens_processed": [32, 32], "throughput_tok_s": [454.1848163176404, 501.74906588440757], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.12639999998055, 9.650399999998172, 25.08860000000368], "resource_metrics": {"samples": 2, "duration_s": 0.11106109619140625, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.866, "gpu_power_peak_watts": 29.29, "gpu_temperature_mean_c": 49.5, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1644.5546875, "cpu_memory_peak_mb": 1644.5546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019274.1594324}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [67.856699999993, 66.41059999998333], "ttft_ms": [7.323799999994662, 7.5726999999687905], "tokens_processed": [32, 32], "throughput_tok_s": [471.5820250616859, 481.85078888020934], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.919800000024679, 7.458899999960522, 7.489499999962845], "resource_metrics": {"samples": 2, "duration_s": 0.10877776145935059, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.29, "gpu_power_peak_watts": 29.29, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1644.55859375, "cpu_memory_peak_mb": 1644.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019274.3744388}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [66.81570000000647, 63.6119999999778], "ttft_ms": [7.176700000002256, 7.760299999972631], "tokens_processed": [32, 32], "throughput_tok_s": [478.9293534303599, 503.04973904312345], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.46089999998867, 7.8538999999864245, 7.17739999998912], "resource_metrics": {"samples": 2, "duration_s": 0.11265921592712402, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.29, "gpu_power_peak_watts": 29.29, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1644.56640625, "cpu_memory_peak_mb": 1644.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1082.9831000000354, "compile_ms": 547.7121000000125, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1766019274.5931067}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.464799999989737, 21.370900000022175], "ttft_ms": [2.5241000000164604, 2.4180999999998676], "tokens_processed": [8, 8], "throughput_tok_s": [372.703216428936, 374.34080923085594], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.5651999999781765, 3.251300000044921, 2.9871999999500076], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 30.652, "gpu_power_peak_watts": 30.652, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1651.9140625, "cpu_memory_peak_mb": 1651.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019274.7537706}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.65589999997519, 20.756100000028255], "ttft_ms": [2.416200000027402, 2.4513999999840053], "tokens_processed": [8, 8], "throughput_tok_s": [407.0024776280963, 385.4288618762248], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.376100000025417, 2.517000000011649, 2.464800000041123], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 30.652, "gpu_power_peak_watts": 30.652, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1652.0078125, "cpu_memory_peak_mb": 1652.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019274.878391}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.07029999998622, 22.20760000000155], "ttft_ms": [2.4047999999652347, 2.760099999989052], "tokens_processed": [8, 8], "throughput_tok_s": [398.5989247796741, 360.23703596964293], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.162799999984145, 2.561600000035469, 2.4388999999587213], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 30.652, "gpu_power_peak_watts": 30.652, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1652.171875, "cpu_memory_peak_mb": 1652.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019274.9988542}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.376900000007026, 25.32370000000128], "ttft_ms": [2.489900000000489, 3.1066999999893596], "tokens_processed": [8, 8], "throughput_tok_s": [374.2357404486792, 315.909602467238], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7898000000163847, 2.6020999999900596, 2.375900000004094], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 21.801, "gpu_power_peak_watts": 21.801, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1652.25, "cpu_memory_peak_mb": 1652.25, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.1362216}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.427299999994375, 23.90920000004826], "ttft_ms": [2.391400000021804, 2.590400000030968], "tokens_processed": [8, 8], "throughput_tok_s": [391.6327659554715, 334.59923376707934], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.994499999999789, 2.5337999999806016, 2.431500000000142], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 21.801, "gpu_power_peak_watts": 21.801, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1652.3359375, "cpu_memory_peak_mb": 1652.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.258713}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.58639999995603, 24.50370000002522], "ttft_ms": [2.7663999999845146, 2.6969000000462984], "tokens_processed": [3, 8], "throughput_tok_s": [349.3897326021805, 326.4813069043355], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.501299999982166, 2.783099999987826, 2.775100000008024], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 21.801, "gpu_power_peak_watts": 21.801, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1653.73046875, "cpu_memory_peak_mb": 1653.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.3817627}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.489099999962946, 25.17330000000584], "ttft_ms": [2.63599999999542, 3.0421999999816762], "tokens_processed": [3, 8], "throughput_tok_s": [353.3943527597855, 317.79703098116437], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.260000000011587, 2.702599999963695, 2.678300000013678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 21.801, "gpu_power_peak_watts": 21.801, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1653.73046875, "cpu_memory_peak_mb": 1653.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.5070603}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.402900000021418, 25.098399999990306], "ttft_ms": [2.698699999996279, 2.836699999988923], "tokens_processed": [3, 8], "throughput_tok_s": [357.0196003751506, 318.74541803473886], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.133300000001782, 2.603799999974399, 2.721900000040023], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.63, "gpu_power_peak_watts": 21.63, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1653.73046875, "cpu_memory_peak_mb": 1653.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.6316946}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.034499999984291, 24.70149999999194], "ttft_ms": [2.884499999993295, 2.9620999999906417], "tokens_processed": [3, 8], "throughput_tok_s": [332.0604349997472, 323.866971641504], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4463000000073407, 2.7184999999576576, 2.661799999998493], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.63, "gpu_power_peak_watts": 21.63, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1653.77734375, "cpu_memory_peak_mb": 1653.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.7541983}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.262399999978243, 23.47509999998465], "ttft_ms": [2.6280999999812593, 2.842899999961901], "tokens_processed": [3, 8], "throughput_tok_s": [363.0906274215603, 340.78662071749346], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3027999999717395, 2.6735000000144282, 2.648000000021966], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.63, "gpu_power_peak_watts": 21.63, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1653.77734375, "cpu_memory_peak_mb": 1653.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.8771338}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.36040000003959, 34.23269999996137], "ttft_ms": [3.2679000000257474, 4.203899999993155], "tokens_processed": [8, 8], "throughput_tok_s": [255.09878700494576, 233.69468373832703], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.366400000037629, 3.2040000000392865, 3.032500000017535], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.63, "gpu_power_peak_watts": 21.63, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1659.4921875, "cpu_memory_peak_mb": 1659.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019275.9998088}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.39440000004379, 30.661100000031638], "ttft_ms": [3.2481000000075255, 4.066799999975501], "tokens_processed": [8, 8], "throughput_tok_s": [246.9562640453037, 260.91692731153626], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.43140000004405, 3.1119000000217056, 3.0835999999681007], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1665.171875, "cpu_memory_peak_mb": 1665.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.1392884}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.269699999995737, 34.2476000000147], "ttft_ms": [3.6150999999904343, 4.278199999987464], "tokens_processed": [8, 8], "throughput_tok_s": [255.8387192714062, 233.5930108970137], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6247999999545755, 3.042300000004161, 3.2267999999930908], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1665.203125, "cpu_memory_peak_mb": 1665.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.2627857}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.38299999996252, 30.17720000002555], "ttft_ms": [3.312499999992724, 3.628100000014456], "tokens_processed": [8, 8], "throughput_tok_s": [281.85885917663967, 265.10080458071747], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6017999999558015, 3.095000000030268, 3.124500000012631], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1665.203125, "cpu_memory_peak_mb": 1665.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.3870356}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.273499999987962, 35.31309999999621], "ttft_ms": [3.2944999999813263, 3.7386999999853288], "tokens_processed": [8, 8], "throughput_tok_s": [273.28471142853743, 226.5448233092212], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.562600000009297, 3.240199999993365, 3.2252000000312364], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1665.203125, "cpu_memory_peak_mb": 1665.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.5088027}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.73019999996541, 38.11540000003788], "ttft_ms": [3.8288999999736006, 4.517299999974966], "tokens_processed": [8, 8], "throughput_tok_s": [217.80442251900436, 209.88891629084438], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.996200000017325, 3.6225999999714986, 3.72740000000249], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1667.03125, "cpu_memory_peak_mb": 1667.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.6329172}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.13679999997521, 39.55150000001595], "ttft_ms": [4.002299999967818, 4.847799999993185], "tokens_processed": [8, 8], "throughput_tok_s": [227.681519091256, 202.26792915557624], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.106200000023819, 3.756899999984853, 3.85420000003478], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1668.5625, "cpu_memory_peak_mb": 1668.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.7553203}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.2783999999815, 38.436899999965135], "ttft_ms": [4.052000000001499, 4.624900000010257], "tokens_processed": [8, 8], "throughput_tok_s": [226.76765386197204, 208.13333021152218], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.066399999999248, 3.8156999999614527, 3.848500000003696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1668.5703125, "cpu_memory_peak_mb": 1668.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019276.8785808}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.46080000000984, 42.77569999999287], "ttft_ms": [4.133599999988746, 5.42769999998427], "tokens_processed": [8, 8], "throughput_tok_s": [225.60122727061375, 187.02207094217826], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.056800000000749, 3.8712999999575004, 4.1148999999904845], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1668.578125, "cpu_memory_peak_mb": 1668.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.001233}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.157200000014655, 36.875300000019706], "ttft_ms": [4.217000000039661, 4.466100000001916], "tokens_processed": [8, 8], "throughput_tok_s": [227.54940666482727, 216.94738754656166], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.928200000018478, 3.7681000000020504, 3.880899999956], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.018, "gpu_power_peak_watts": 21.018, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1668.578125, "cpu_memory_peak_mb": 1668.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.124623}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.270599999984825, 75.80289999998513], "ttft_ms": [8.119800000031319, 9.157200000004195], "tokens_processed": [12, 32], "throughput_tok_s": [424.46923659230583, 422.1474376310969], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.492200000001503, 6.780900000023848, 7.753299999990304], "resource_metrics": {"samples": 2, "duration_s": 0.11685967445373535, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.655, "gpu_power_peak_watts": 10.655, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1684.49609375, "cpu_memory_peak_mb": 1692.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.3482285}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.14490000000069, 64.91800000003423], "ttft_ms": [7.140700000036304, 7.7974000000153865], "tokens_processed": [12, 32], "throughput_tok_s": [541.8854905644021, 492.92954188334716], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.937400000050275, 6.306800000004387, 6.744999999966694], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.655, "gpu_power_peak_watts": 10.655, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1692.28515625, "cpu_memory_peak_mb": 1692.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.4655745}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.466799999994237, 68.22299999998904], "ttft_ms": [7.860099999959402, 7.9848000000311], "tokens_processed": [12, 32], "throughput_tok_s": [511.36073090506363, 469.05002711703], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.346999999981563, 7.36869999997225, 7.537500000012187], "resource_metrics": {"samples": 2, "duration_s": 0.11466598510742188, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.655, "gpu_power_peak_watts": 10.655, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1692.36328125, "cpu_memory_peak_mb": 1692.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.6889691}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.492399999985537, 73.72450000002573], "ttft_ms": [7.445099999983995, 8.372099999974125], "tokens_processed": [12, 32], "throughput_tok_s": [489.947902206688, 434.0483828305222], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.965000000003329, 6.537999999977728, 7.065399999987676], "resource_metrics": {"samples": 2, "duration_s": 0.10892629623413086, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.655, "gpu_power_peak_watts": 10.655, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1692.390625, "cpu_memory_peak_mb": 1692.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019277.9057956}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.45500000001266, 74.54169999999749], "ttft_ms": [7.424800000023879, 8.814299999983177], "tokens_processed": [12, 32], "throughput_tok_s": [511.6179918991056, 429.2899142359388], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.428200000016204, 6.341700000007222, 7.089600000028895], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.655, "gpu_power_peak_watts": 10.655, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1692.390625, "cpu_memory_peak_mb": 1692.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019278.0357647}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [98.47550000000638, 98.25050000000601], "ttft_ms": [10.613300000045456, 12.952799999993658], "tokens_processed": [32, 32], "throughput_tok_s": [324.95392254924246, 325.69808805042254], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.460200000011355, 10.257000000024163, 10.162100000002283], "resource_metrics": {"samples": 3, "duration_s": 0.21558761596679688, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.8540000000000005, "gpu_power_peak_watts": 3.854, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1713.70703125, "cpu_memory_peak_mb": 1721.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019278.3599265}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [96.48479999998472, 99.10289999999122], "ttft_ms": [10.816599999998289, 11.578799999995226], "tokens_processed": [32, 32], "throughput_tok_s": [331.6584581198807, 322.8967063527186], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.682799999997769, 8.419800000012856, 9.260200000028362], "resource_metrics": {"samples": 3, "duration_s": 0.21665453910827637, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.8540000000000005, "gpu_power_peak_watts": 3.854, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1721.27734375, "cpu_memory_peak_mb": 1721.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019278.6835685}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [92.57780000001503, 96.95249999998623], "ttft_ms": [10.371499999962452, 12.562899999977617], "tokens_processed": [32, 32], "throughput_tok_s": [345.6552218781911, 330.0585338181537], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.946000000004005, 8.795400000053633, 9.891100000004371], "resource_metrics": {"samples": 3, "duration_s": 0.2179241180419922, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.8540000000000005, "gpu_power_peak_watts": 3.854, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1721.30078125, "cpu_memory_peak_mb": 1721.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019279.009579}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [93.05239999997639, 93.53230000004942], "ttft_ms": [10.187999999970998, 12.472100000024966], "tokens_processed": [32, 32], "throughput_tok_s": [343.8922585554819, 342.1277997010989], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.889599999998609, 9.099800000001323, 9.706499999992957], "resource_metrics": {"samples": 2, "duration_s": 0.11763262748718262, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.211, "gpu_power_peak_watts": 3.211, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1721.39453125, "cpu_memory_peak_mb": 1721.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019279.2352743}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [96.42609999997376, 99.49749999998403], "ttft_ms": [12.453800000002957, 11.323699999991277], "tokens_processed": [32, 32], "throughput_tok_s": [331.8603573099888, 321.61612100811715], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.956100000010792, 10.21680000002334, 10.953800000038427], "resource_metrics": {"samples": 3, "duration_s": 0.2215120792388916, "gpu_memory_mean_mb": 1898.01953125, "gpu_memory_peak_mb": 1898.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.211, "gpu_power_peak_watts": 3.211, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1721.39453125, "cpu_memory_peak_mb": 1721.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 332.2820000000206, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019279.565137}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.16629999997895, 97.21600000000308], "ttft_ms": [12.356000000011136, 12.43610000000217], "tokens_processed": [8, 8], "throughput_tok_s": [80.67256719270254, 82.29098090848983], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [98.4349000000293, 12.550499999974818, 12.436199999967812], "resource_metrics": {"samples": 4, "duration_s": 0.3153502941131592, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.211, "gpu_power_peak_watts": 3.211, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1839.1474609375, "cpu_memory_peak_mb": 1870.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019279.9876068}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [95.51319999997077, 94.87450000000308], "ttft_ms": [12.453999999991083, 11.586000000022523], "tokens_processed": [8, 8], "throughput_tok_s": [83.75805647808312, 84.32192001011589], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.277100000005703, 11.877700000013647, 11.985199999969609], "resource_metrics": {"samples": 3, "duration_s": 0.20997858047485352, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.099, "gpu_power_peak_watts": 7.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1870.32421875, "cpu_memory_peak_mb": 1870.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.3046944}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.001800000007734, 24.66789999999719], "ttft_ms": [3.2905000000482687, 3.4526000000028034], "tokens_processed": [8, 8], "throughput_tok_s": [333.30833520808534, 324.3081089189153], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.425300000003517, 3.026299999987714, 2.8959999999642605], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.543, "gpu_power_peak_watts": 7.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1870.3359375, "cpu_memory_peak_mb": 1870.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.4290295}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.594900000010966, 24.98859999997194], "ttft_ms": [3.260499999953481, 3.1909999999584215], "tokens_processed": [8, 8], "throughput_tok_s": [325.27068619902633, 320.1459865702354], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.49149999999554, 3.1880000000228392, 3.2013000000006286], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.543, "gpu_power_peak_watts": 7.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1870.33984375, "cpu_memory_peak_mb": 1870.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.5527263}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.13379999998233, 22.407700000030673], "ttft_ms": [2.848699999958626, 2.827700000011646], "tokens_processed": [8, 8], "throughput_tok_s": [345.8143495666994, 357.02013147217474], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.963099999988117, 2.598299999988285, 2.846300000044266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 11.51, "gpu_power_peak_watts": 11.51, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1870.34375, "cpu_memory_peak_mb": 1870.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.6776762}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.70799999998917, 24.79160000001457], "ttft_ms": [3.255499999966105, 3.260100000034072], "tokens_processed": [3, 8], "throughput_tok_s": [309.0234857852644, 322.68994336772533], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.043600000021797, 3.4006999999860454, 3.152600000021266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 11.51, "gpu_power_peak_watts": 11.51, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1871.41796875, "cpu_memory_peak_mb": 1871.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.8009393}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.79720000003681, 25.400199999978668], "ttft_ms": [3.0853000000092834, 3.0085999999869273], "tokens_processed": [3, 8], "throughput_tok_s": [306.20993753202225, 314.9581499360918], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6510999999563865, 3.1503000000157044, 3.125599999975748], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 11.51, "gpu_power_peak_watts": 11.51, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1871.98046875, "cpu_memory_peak_mb": 1871.98046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019280.9243515}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.722299999964434, 25.974500000017997], "ttft_ms": [3.041899999971065, 3.1136999999716863], "tokens_processed": [3, 8], "throughput_tok_s": [308.5689600208772, 307.994379102368], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1670000000190157, 3.0447999999978492, 2.9961000000184868], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 11.51, "gpu_power_peak_watts": 11.51, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1871.98046875, "cpu_memory_peak_mb": 1871.98046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.0478058}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.79219999999259, 25.324699999998757], "ttft_ms": [3.175999999996293, 3.1361000000060812], "tokens_processed": [3, 8], "throughput_tok_s": [306.3662915383949, 315.8971281002497], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.356999999994059, 3.201499999988755, 3.149000000007618], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 15.458, "gpu_power_peak_watts": 15.458, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1871.9921875, "cpu_memory_peak_mb": 1871.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.1741781}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.639500000048429, 24.74550000005138], "ttft_ms": [3.1060000000024957, 2.8572999999596504], "tokens_processed": [3, 8], "throughput_tok_s": [311.2194615887679, 323.29110343227615], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.292699999974502, 3.5002999999846907, 3.2638000000133616], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 15.458, "gpu_power_peak_watts": 15.458, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1872.0, "cpu_memory_peak_mb": 1872.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.2971718}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.377500000000055, 28.32300000000032], "ttft_ms": [3.2631000000264976, 3.673000000048887], "tokens_processed": [8, 8], "throughput_tok_s": [292.2107570084918, 282.45595452458815], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.758500000036747, 3.3560000000534274, 3.288499999996475], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 15.458, "gpu_power_peak_watts": 15.458, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1882.83984375, "cpu_memory_peak_mb": 1882.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.4214816}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.0088999999748, 28.66629999999759], "ttft_ms": [3.756899999984853, 3.379699999982222], "tokens_processed": [8, 8], "throughput_tok_s": [285.6234982454576, 279.07333698456625], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.588499999978012, 3.312399999970239, 3.4304999999790198], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 15.458, "gpu_power_peak_watts": 15.458, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1883.21875, "cpu_memory_peak_mb": 1883.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.5474966}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.594100000011167, 27.543100000002596], "ttft_ms": [3.274599999997463, 3.8364000000115084], "tokens_processed": [8, 8], "throughput_tok_s": [300.81860262225985, 290.4538704793304], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.421000000003005, 3.2678000000032625, 3.224900000020625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.283, "gpu_power_peak_watts": 20.283, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1883.21875, "cpu_memory_peak_mb": 1883.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.6700492}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.005000000007385, 27.54690000000437], "ttft_ms": [3.193399999986468, 3.362099999947077], "tokens_processed": [8, 8], "throughput_tok_s": [285.66327441520764, 290.413803368028], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.252299999985553, 2.7923999999757143, 3.1571999999755462], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.283, "gpu_power_peak_watts": 20.283, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1883.22265625, "cpu_memory_peak_mb": 1883.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.7951093}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.09060000000818, 26.799799999992047], "ttft_ms": [3.8288999999736006, 3.4706999999798427], "tokens_processed": [8, 8], "throughput_tok_s": [295.3053826787736, 298.50969037091227], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.475299999990966, 3.4136000000444255, 3.3136999999783256], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.283, "gpu_power_peak_watts": 20.283, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1883.22265625, "cpu_memory_peak_mb": 1883.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019281.919654}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.54320000003463, 28.229699999997138], "ttft_ms": [3.562600000009297, 3.384100000005219], "tokens_processed": [8, 8], "throughput_tok_s": [270.789894120834, 283.3894798740621], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9213999999674343, 3.731399999992391, 3.6144000000035703], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.283, "gpu_power_peak_watts": 20.283, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1886.2578125, "cpu_memory_peak_mb": 1886.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.055534}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.53680000004033, 27.015500000004522], "ttft_ms": [3.163200000017241, 3.5141999999837026], "tokens_processed": [8, 8], "throughput_tok_s": [280.3397718030296, 296.1262978659903], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.217300000017076, 3.1270999999719606, 3.130300000009356], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.924, "gpu_power_peak_watts": 20.924, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1886.2578125, "cpu_memory_peak_mb": 1886.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.1825397}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.810200000009445, 26.635200000043824], "ttft_ms": [3.632999999979347, 3.609799999992447], "tokens_processed": [8, 8], "throughput_tok_s": [277.67943297850684, 300.35441821299776], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.076600000018971, 3.5985999999752494, 3.5228000000415705], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.924, "gpu_power_peak_watts": 20.924, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1886.265625, "cpu_memory_peak_mb": 1886.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.3063219}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.630800000020827, 26.581699999951525], "ttft_ms": [3.0477000000246335, 3.2009999999900174], "tokens_processed": [8, 8], "throughput_tok_s": [300.4040434381898, 300.95893039251024], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3256000000392305, 3.130699999985609, 3.2032000000299377], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.924, "gpu_power_peak_watts": 20.924, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1886.265625, "cpu_memory_peak_mb": 1886.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.4306817}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.89050000002635, 27.426600000012513], "ttft_ms": [2.991300000019237, 3.6671999999953186], "tokens_processed": [8, 8], "throughput_tok_s": [321.4077660148061, 291.6876317150631], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6183999999934713, 3.4982000000240987, 2.9090000000451255], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 48.0, "gpu_power_mean_watts": 20.924, "gpu_power_peak_watts": 20.924, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1886.28125, "cpu_memory_peak_mb": 1886.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.5656307}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.09150000003956, 37.308900000027734], "ttft_ms": [5.1288999999883345, 4.58269999995764], "tokens_processed": [12, 32], "throughput_tok_s": [795.1495875140671, 857.704193904838], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.355600000006234, 5.0191000000268104, 4.6001999999703], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.414, "gpu_power_peak_watts": 19.414, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1894.2421875, "cpu_memory_peak_mb": 1894.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.6927702}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.104500000030384, 37.442300000009254], "ttft_ms": [4.469399999948109, 4.696500000022752], "tokens_processed": [12, 32], "throughput_tok_s": [850.7923003278493, 854.6483522644734], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.513600000028873, 4.999900000029811, 5.095700000026682], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.414, "gpu_power_peak_watts": 19.414, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1909.86328125, "cpu_memory_peak_mb": 1909.86328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.8163419}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.392000000019834, 36.92399999999907], "ttft_ms": [5.450300000006791, 4.322399999978188], "tokens_processed": [12, 32], "throughput_tok_s": [779.625779624775, 866.645000541675], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7989000000256965, 4.30460000001176, 4.913799999997082], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.414, "gpu_power_peak_watts": 19.414, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1909.875, "cpu_memory_peak_mb": 1909.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019282.9399393}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.176000000020395, 35.592099999973925], "ttft_ms": [4.832499999963602, 4.720599999984643], "tokens_processed": [12, 32], "throughput_tok_s": [846.5011286669537, 899.075918533142], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.555900000013935, 4.577299999994011, 4.789200000004712], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 19.414, "gpu_power_peak_watts": 19.414, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1909.875, "cpu_memory_peak_mb": 1909.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.0650916}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.348700000027748, 35.15069999997422], "ttft_ms": [5.437400000005255, 4.039700000021185], "tokens_processed": [12, 32], "throughput_tok_s": [836.3126973159098, 910.3659386590728], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.847100000006321, 4.58179999998265, 4.697600000042712], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 18.992, "gpu_power_peak_watts": 18.992, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1909.875, "cpu_memory_peak_mb": 1909.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.188625}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.46730000000798, 42.56820000000516], "ttft_ms": [5.7707999999934145, 4.960100000005241], "tokens_processed": [32, 32], "throughput_tok_s": [719.6299303082097, 751.7348631136886], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.25519999999824, 5.216700000005403, 5.112499999995634], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 18.992, "gpu_power_peak_watts": 18.992, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1916.0, "cpu_memory_peak_mb": 1916.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.3119712}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.80720000003657, 41.5866999999821], "ttft_ms": [5.729700000017601, 5.457999999975982], "tokens_processed": [32, 32], "throughput_tok_s": [714.1709368131434, 769.4767798361921], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.210400000043137, 6.163099999980659, 5.262999999956719], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 18.992, "gpu_power_peak_watts": 18.992, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1938.7421875, "cpu_memory_peak_mb": 1938.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.4352884}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.660799999988285, 42.43169999995189], "ttft_ms": [5.070799999998599, 4.984499999977743], "tokens_processed": [32, 32], "throughput_tok_s": [768.1081496276836, 754.1531449373059], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.78840000002856, 5.002400000023499, 5.0064000000134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 37.0, "gpu_power_mean_watts": 18.992, "gpu_power_peak_watts": 18.992, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1938.7421875, "cpu_memory_peak_mb": 1938.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.5754776}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.55809999998428, 42.349999999999], "ttft_ms": [5.431999999984782, 4.933200000039051], "tokens_processed": [32, 32], "throughput_tok_s": [734.6509604416067, 755.6080283353189], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.487000000016451, 5.387299999995321, 5.640500000026805], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 19.651, "gpu_power_peak_watts": 19.651, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1938.7421875, "cpu_memory_peak_mb": 1938.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.7015204}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.79190000002109, 44.024999999976444], "ttft_ms": [4.97139999998808, 5.681399999957648], "tokens_processed": [32, 32], "throughput_tok_s": [765.6986162386456, 726.8597387851703], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.446799999958785, 4.9776999999835425, 5.9035000000449145], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1908.01953125, "gpu_memory_peak_mb": 1908.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 19.651, "gpu_power_peak_watts": 19.651, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1938.7421875, "cpu_memory_peak_mb": 1938.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1033.904600000028, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1766019283.8259716}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [27.189000000021224, 1.6302000000223416, 1.6235999999594242], "resource_metrics": {"samples": 3, "duration_s": 0.22875761985778809, "gpu_memory_mean_mb": 2163.3658854166665, "gpu_memory_peak_mb": 2489.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 19.17866666666667, "gpu_power_peak_watts": 19.651, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2117.98828125, "cpu_memory_peak_mb": 2248.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1766019284.1634755}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1614999999997053, 1.5476000000376189, 1.5028000000256725], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 18.234, "gpu_power_peak_watts": 18.234, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2223.82421875, "cpu_memory_peak_mb": 2223.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.2943535}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.555000000029395, 1.8177999999693384, 2.0017000000507323], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 18.234, "gpu_power_peak_watts": 18.234, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2223.95703125, "cpu_memory_peak_mb": 2223.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.4181256}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.4065000000064174, 1.5190999999958876, 1.9520999999826927], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 18.234, "gpu_power_peak_watts": 18.234, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2223.98828125, "cpu_memory_peak_mb": 2223.98828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.542429}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0839999999680003, 1.8491999999810105, 1.8656999999961954], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 21.74, "gpu_power_peak_watts": 21.74, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.0, "cpu_memory_peak_mb": 2224.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.6688082}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5739999999814245, 1.6166999999995824, 1.6114999999672364], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 21.74, "gpu_power_peak_watts": 21.74, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.578125, "cpu_memory_peak_mb": 2224.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.7891912}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0614000000023225, 1.649299999996856, 1.605499999982385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 21.74, "gpu_power_peak_watts": 21.74, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.578125, "cpu_memory_peak_mb": 2224.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019284.9136455}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8107000000213702, 1.6592999999716085, 1.6264999999862084], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 21.74, "gpu_power_peak_watts": 21.74, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.58984375, "cpu_memory_peak_mb": 2224.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.0363598}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2450000000162618, 1.6646000000264394, 1.6733000000499487], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 22.871, "gpu_power_peak_watts": 22.871, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.59375, "cpu_memory_peak_mb": 2224.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.160289}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0200999999815394, 1.7260000000192122, 1.7082999999615822], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2495.0390625, "gpu_memory_peak_mb": 2495.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 22.871, "gpu_power_peak_watts": 22.871, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.59765625, "cpu_memory_peak_mb": 2224.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.2829332}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0524000000013984, 2.0282000000406697, 1.9391000000155145], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2497.0390625, "gpu_memory_peak_mb": 2497.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 22.871, "gpu_power_peak_watts": 22.871, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2226.1328125, "cpu_memory_peak_mb": 2226.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.4068115}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.283900000008998, 1.947000000029675, 2.0177999999759777], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2497.0390625, "gpu_memory_peak_mb": 2497.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 22.871, "gpu_power_peak_watts": 22.871, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2226.1328125, "cpu_memory_peak_mb": 2226.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.5291321}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7049000000261003, 1.9462999999859676, 1.9345999999700325], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2497.0390625, "gpu_memory_peak_mb": 2497.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.075, "gpu_power_peak_watts": 23.075, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2226.1484375, "cpu_memory_peak_mb": 2226.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.654054}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8550999999765736, 1.881200000013905, 1.8921999999861328], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2497.0390625, "gpu_memory_peak_mb": 2497.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.075, "gpu_power_peak_watts": 23.075, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2226.16015625, "cpu_memory_peak_mb": 2226.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.776092}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.045000000042819, 1.9527999999695567, 1.9408999999654952], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2497.0390625, "gpu_memory_peak_mb": 2497.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.075, "gpu_power_peak_watts": 23.075, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2226.171875, "cpu_memory_peak_mb": 2226.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019285.8999414}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6077999999974963, 2.431100000023889, 2.208100000018476], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2499.0390625, "gpu_memory_peak_mb": 2499.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.075, "gpu_power_peak_watts": 23.075, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2227.89453125, "cpu_memory_peak_mb": 2227.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.0298944}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.638100000012855, 2.149300000041876, 2.1553000000267275], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2499.0390625, "gpu_memory_peak_mb": 2499.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.175, "gpu_power_peak_watts": 23.175, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2228.14453125, "cpu_memory_peak_mb": 2228.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.1484742}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.578700000015033, 2.208100000018476, 2.1525999999880696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2499.0390625, "gpu_memory_peak_mb": 2499.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.175, "gpu_power_peak_watts": 23.175, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2228.1484375, "cpu_memory_peak_mb": 2228.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.2748034}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.635199999986071, 1.5457000000083099, 1.5091999999867767], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2499.0390625, "gpu_memory_peak_mb": 2499.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.175, "gpu_power_peak_watts": 23.175, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2228.1484375, "cpu_memory_peak_mb": 2228.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.3975966}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8352999999583517, 1.401599999951486, 1.2833000000114225], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2499.0390625, "gpu_memory_peak_mb": 2499.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 23.175, "gpu_power_peak_watts": 23.175, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2228.15625, "cpu_memory_peak_mb": 2228.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.5221214}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.686800000034964, 2.134599999976672, 2.0840000000248438], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2491.0390625, "gpu_memory_peak_mb": 2491.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 26.512, "gpu_power_peak_watts": 26.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2224.578125, "cpu_memory_peak_mb": 2224.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.6441104}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.938599999969483, 2.031999999985601, 2.066000000013446], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2507.0390625, "gpu_memory_peak_mb": 2507.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 26.512, "gpu_power_peak_watts": 26.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2243.16796875, "cpu_memory_peak_mb": 2243.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.7684178}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.288099999996575, 2.4584000000231754, 2.6140999999597625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2507.0390625, "gpu_memory_peak_mb": 2507.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 26.512, "gpu_power_peak_watts": 26.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2243.265625, "cpu_memory_peak_mb": 2243.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019286.8964522}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.330799999991086, 3.5603000000037355, 3.397099999972397], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2507.0390625, "gpu_memory_peak_mb": 2507.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 26.512, "gpu_power_peak_watts": 26.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2243.265625, "cpu_memory_peak_mb": 2243.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.0206752}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.098700000042754, 3.3618000000501524, 3.2860000000027867], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2507.0390625, "gpu_memory_peak_mb": 2507.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.954, "gpu_power_peak_watts": 27.954, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2243.265625, "cpu_memory_peak_mb": 2243.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.1451142}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.35159999995949, 4.602599999998347, 4.806299999984276], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.954, "gpu_power_peak_watts": 27.954, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2249.40234375, "cpu_memory_peak_mb": 2249.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.269214}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.982000000017251, 4.593499999998585, 4.465999999979431], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.954, "gpu_power_peak_watts": 27.954, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2249.40234375, "cpu_memory_peak_mb": 2249.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.3962798}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.880100000013044, 4.434699999990244, 4.401700000016717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.954, "gpu_power_peak_watts": 27.954, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2249.40625, "cpu_memory_peak_mb": 2249.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.52047}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.29410000004782, 4.838199999994686, 4.5278000000053], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 27.457, "gpu_power_peak_watts": 27.457, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2249.41015625, "cpu_memory_peak_mb": 2249.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.6444933}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.901100000016868, 4.628900000000158, 4.633800000021893], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 27.457, "gpu_power_peak_watts": 27.457, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2249.41015625, "cpu_memory_peak_mb": 2249.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 237.98490000001493, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019287.7681751}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.873099999997521, 1.6024999999899592, 1.274700000010398], "resource_metrics": {"samples": 3, "duration_s": 0.21319174766540527, "gpu_memory_mean_mb": 2664.3723958333335, "gpu_memory_peak_mb": 3011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 27.457000000000004, "gpu_power_peak_watts": 27.457, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2363.7565104166665, "cpu_memory_peak_mb": 2561.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1766019288.0922832}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1082000000092194, 1.6646999999920808, 1.6528999999536609], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 24.771, "gpu_power_peak_watts": 24.771, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2241.6953125, "cpu_memory_peak_mb": 2241.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.2311487}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.1707000000219523, 1.6889000000332999, 1.626999999984946], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 24.771, "gpu_power_peak_watts": 24.771, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2241.69921875, "cpu_memory_peak_mb": 2241.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.3436089}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.555199999960678, 1.8503000000009706, 1.68300000001409], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 24.771, "gpu_power_peak_watts": 24.771, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2241.7421875, "cpu_memory_peak_mb": 2241.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.468874}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.242599999988215, 1.6750999999999294, 1.7416999999682048], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 24.771, "gpu_power_peak_watts": 24.771, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2241.83203125, "cpu_memory_peak_mb": 2241.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.5930738}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3572000000058324, 1.6904000000295127, 1.4766000000463464], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.527, "gpu_power_peak_watts": 23.527, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.4140625, "cpu_memory_peak_mb": 2242.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.733852}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.262800000039533, 1.5966000000275926, 1.8774000000121305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.527, "gpu_power_peak_watts": 23.527, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.5390625, "cpu_memory_peak_mb": 2242.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.8594232}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.184600000020964, 1.855599999998958, 1.8335000000320179], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.527, "gpu_power_peak_watts": 23.527, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.55078125, "cpu_memory_peak_mb": 2242.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019288.9828663}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7231000000256245, 2.057200000024295, 1.8140000000244072], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.527, "gpu_power_peak_watts": 23.527, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.640625, "cpu_memory_peak_mb": 2242.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.1192255}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2819000000140477, 1.8227999999567146, 1.7138000000045395], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3015.0390625, "gpu_memory_peak_mb": 3015.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.565, "gpu_power_peak_watts": 23.565, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.7890625, "cpu_memory_peak_mb": 2242.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.2470746}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.980600000000777, 2.094100000022081, 2.124299999991308], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3017.0390625, "gpu_memory_peak_mb": 3017.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.565, "gpu_power_peak_watts": 23.565, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.36328125, "cpu_memory_peak_mb": 2244.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.3682516}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.461500000038086, 2.0480999999676897, 2.0465000000058353], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3017.0390625, "gpu_memory_peak_mb": 3017.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.565, "gpu_power_peak_watts": 23.565, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.3671875, "cpu_memory_peak_mb": 2244.3671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.4932673}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1358000000523134, 2.2111000000109016, 2.245200000004388], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3017.0390625, "gpu_memory_peak_mb": 3017.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 23.565, "gpu_power_peak_watts": 23.565, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.38671875, "cpu_memory_peak_mb": 2244.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.6157591}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2449999999594183, 1.8888999999830958, 1.9255999999927553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3017.0390625, "gpu_memory_peak_mb": 3017.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.041, "gpu_power_peak_watts": 23.041, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.40625, "cpu_memory_peak_mb": 2244.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.7401845}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5645000000054097, 2.048699999988912, 2.0305000000462314], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3017.0390625, "gpu_memory_peak_mb": 3017.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.041, "gpu_power_peak_watts": 23.041, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.4140625, "cpu_memory_peak_mb": 2244.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.8616314}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.664300000025378, 2.232800000001589, 2.378200000009656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3019.0390625, "gpu_memory_peak_mb": 3019.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.041, "gpu_power_peak_watts": 23.041, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2246.1640625, "cpu_memory_peak_mb": 2246.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019289.983573}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.941899999996167, 2.3236000000110835, 1.9019000000071173], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3019.0390625, "gpu_memory_peak_mb": 3019.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 23.041, "gpu_power_peak_watts": 23.041, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2246.16796875, "cpu_memory_peak_mb": 2246.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.1080534}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5873000000160573, 2.15349999996306, 2.1471000000019558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3019.0390625, "gpu_memory_peak_mb": 3019.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.941, "gpu_power_peak_watts": 22.941, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2246.16796875, "cpu_memory_peak_mb": 2246.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.2338388}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2327000000123007, 2.566999999999098, 2.276599999959217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3019.0390625, "gpu_memory_peak_mb": 3019.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.941, "gpu_power_peak_watts": 22.941, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2246.16796875, "cpu_memory_peak_mb": 2246.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.3581705}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.805500000027223, 6.978800000013052, 7.298999999989064], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3019.0390625, "gpu_memory_peak_mb": 3019.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.941, "gpu_power_peak_watts": 22.941, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2246.16796875, "cpu_memory_peak_mb": 2246.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.4824698}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.58580000001075, 9.912499999984448, 10.390400000005684], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3011.0390625, "gpu_memory_peak_mb": 3011.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 22.941, "gpu_power_peak_watts": 22.941, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2242.703125, "cpu_memory_peak_mb": 2242.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.6051831}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.75399999996307, 9.939600000052451, 10.534199999995053], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.699, "gpu_power_peak_watts": 15.699, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.5, "cpu_memory_peak_mb": 2260.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.7453325}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.56349999998929, 9.978500000045187, 10.538800000006177], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.699, "gpu_power_peak_watts": 15.699, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.50390625, "cpu_memory_peak_mb": 2260.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.87217}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.026100000037786, 10.382499999991524, 10.68049999997811], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.699, "gpu_power_peak_watts": 15.699, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.5078125, "cpu_memory_peak_mb": 2260.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019290.9964569}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.488699999996243, 9.949199999994107, 12.50649999997222], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.308, "gpu_power_peak_watts": 15.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.5078125, "cpu_memory_peak_mb": 2260.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.1499574}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.767400000006091, 12.695599999972274, 13.01810000001069], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3035.0390625, "gpu_memory_peak_mb": 3035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.308, "gpu_power_peak_watts": 15.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2266.8984375, "cpu_memory_peak_mb": 2266.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.2739103}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.814200000012988, 12.435499999980948, 12.837199999978566], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3035.0390625, "gpu_memory_peak_mb": 3035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.308, "gpu_power_peak_watts": 15.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2266.91015625, "cpu_memory_peak_mb": 2266.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.3975163}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.738199999977496, 12.79460000000654, 12.8093000000149], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3035.0390625, "gpu_memory_peak_mb": 3035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 15.308, "gpu_power_peak_watts": 15.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2266.91015625, "cpu_memory_peak_mb": 2266.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.5368621}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.025500000002467, 13.149699999985387, 12.638499999980013], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3035.0390625, "gpu_memory_peak_mb": 3035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.412, "gpu_power_peak_watts": 15.412, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2255.24609375, "cpu_memory_peak_mb": 2255.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.6594536}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.941199999976561, 13.211699999999382, 13.283300000011877], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3035.0390625, "gpu_memory_peak_mb": 3035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.412, "gpu_power_peak_watts": 15.412, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2266.9140625, "cpu_memory_peak_mb": 2266.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 234.28360000002613, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019291.7973173}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.461499999962598, 5.463499999962096, 5.454899999961071], "resource_metrics": {"samples": 3, "duration_s": 0.2145557403564453, "gpu_memory_mean_mb": 3253.7057291666665, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.298000000000002, "gpu_power_peak_watts": 15.412, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2341.6015625, "cpu_memory_peak_mb": 2421.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1766019292.137128}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.149600000014743, 5.34460000000081, 5.919600000027003], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.07, "gpu_power_peak_watts": 15.07, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.390625, "cpu_memory_peak_mb": 2260.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.2620687}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.24819999995907, 5.682899999953861, 6.092099999989387], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.07, "gpu_power_peak_watts": 15.07, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.4375, "cpu_memory_peak_mb": 2260.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.3851788}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.946400000027552, 5.754499999966356, 5.443999999954485], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 15.07, "gpu_power_peak_watts": 15.07, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.57421875, "cpu_memory_peak_mb": 2260.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.5098996}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.979200000012952, 6.083400000022721, 5.5828000000133216], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.85, "gpu_power_peak_watts": 14.85, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2260.578125, "cpu_memory_peak_mb": 2260.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.636172}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.016599999985829, 6.041900000013811, 5.877800000007483], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.85, "gpu_power_peak_watts": 14.85, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2261.1796875, "cpu_memory_peak_mb": 2261.1796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.7745702}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.067799999982526, 5.718199999989793, 5.744800000002215], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.85, "gpu_power_peak_watts": 14.85, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2261.18359375, "cpu_memory_peak_mb": 2261.18359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019292.8974118}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.089099999940117, 5.723600000010265, 5.8075000000599175], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.85, "gpu_power_peak_watts": 14.85, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2261.18359375, "cpu_memory_peak_mb": 2261.18359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.0203333}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.309799999939969, 5.426400000033027, 5.874800000015057], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2261.19140625, "cpu_memory_peak_mb": 2261.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.1435163}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.997199999910663, 5.743699999925411, 5.348499999968226], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3575.0390625, "gpu_memory_peak_mb": 3575.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2261.1953125, "cpu_memory_peak_mb": 2261.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.268096}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.051599999930659, 6.418300000063937, 6.769899999994777], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3577.0390625, "gpu_memory_peak_mb": 3577.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2262.80859375, "cpu_memory_peak_mb": 2262.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.3909762}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.78210000000945, 6.492900000012014, 6.63540000005014], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3577.0390625, "gpu_memory_peak_mb": 3577.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2262.80859375, "cpu_memory_peak_mb": 2262.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.5165625}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.095300000059979, 5.962199999999029, 6.1676999999917825], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3577.0390625, "gpu_memory_peak_mb": 3577.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.822, "gpu_power_peak_watts": 14.822, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2262.80859375, "cpu_memory_peak_mb": 2262.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.6559188}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.198300000027302, 6.359599999996135, 6.344000000012784], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3577.0390625, "gpu_memory_peak_mb": 3577.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.822, "gpu_power_peak_watts": 14.822, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2262.80859375, "cpu_memory_peak_mb": 2262.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.7975013}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.911999999942964, 6.096599999978025, 6.256400000097528], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3577.0390625, "gpu_memory_peak_mb": 3577.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.822, "gpu_power_peak_watts": 14.822, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2262.8125, "cpu_memory_peak_mb": 2262.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019293.9367287}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.28459999995357, 7.256800000050134, 7.1573000000171305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3579.0390625, "gpu_memory_peak_mb": 3579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.822, "gpu_power_peak_watts": 14.822, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2264.5234375, "cpu_memory_peak_mb": 2264.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.060725}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.662799999996423, 14.599999999973079, 14.28849999990689], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3579.0390625, "gpu_memory_peak_mb": 3579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.924, "gpu_power_peak_watts": 14.924, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2264.5234375, "cpu_memory_peak_mb": 2264.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.1855018}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.362699999992401, 14.224699999999757, 15.029999999910615], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3579.0390625, "gpu_memory_peak_mb": 3579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.924, "gpu_power_peak_watts": 14.924, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2264.55078125, "cpu_memory_peak_mb": 2264.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.3104646}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.504199999919365, 14.53320000007352, 16.093799999907787], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3579.0390625, "gpu_memory_peak_mb": 3579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.924, "gpu_power_peak_watts": 14.924, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2264.64453125, "cpu_memory_peak_mb": 2264.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.4349473}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.888200000024881, 6.933799999956136, 7.572600000003149], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3579.0390625, "gpu_memory_peak_mb": 3579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 14.924, "gpu_power_peak_watts": 14.924, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2264.7890625, "cpu_memory_peak_mb": 2264.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.5596492}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.876899999923808, 10.256599999934224, 10.84600000001501], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3571.0390625, "gpu_memory_peak_mb": 3571.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 10.512, "gpu_power_peak_watts": 10.512, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2261.4453125, "cpu_memory_peak_mb": 2261.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.684318}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.44520000002558, 13.103300000011586, 10.618900000054055], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3587.0390625, "gpu_memory_peak_mb": 3587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 10.512, "gpu_power_peak_watts": 10.512, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2278.34375, "cpu_memory_peak_mb": 2278.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.8098774}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.444200000028104, 10.40059999991172, 10.879400000021633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3587.0390625, "gpu_memory_peak_mb": 3587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 10.512, "gpu_power_peak_watts": 10.512, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2278.34375, "cpu_memory_peak_mb": 2278.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019294.9338155}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.197899999956462, 10.404100000073413, 12.303200000019388], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3587.0390625, "gpu_memory_peak_mb": 3587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 10.512, "gpu_power_peak_watts": 10.512, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2278.34375, "cpu_memory_peak_mb": 2278.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.059305}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.584599999991951, 10.6021999999939, 14.098099999955593], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3587.0390625, "gpu_memory_peak_mb": 3587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 13.594, "gpu_power_peak_watts": 13.594, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2278.34375, "cpu_memory_peak_mb": 2278.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.1825917}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.768299999900592, 13.595099999974991, 13.410200000066652], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 13.594, "gpu_power_peak_watts": 13.594, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2281.81640625, "cpu_memory_peak_mb": 2281.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.3073614}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.308599999935723, 13.922200000024532, 15.015299999959097], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 13.594, "gpu_power_peak_watts": 13.594, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2266.7890625, "cpu_memory_peak_mb": 2266.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.4279325}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [16.02139999999963, 13.300200000003315, 13.61650000001191], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 13.594, "gpu_power_peak_watts": 13.594, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2270.83203125, "cpu_memory_peak_mb": 2270.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.566565}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.147600000001148, 13.836999999966793, 13.284999999996217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 15.515, "gpu_power_peak_watts": 15.515, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2284.49609375, "cpu_memory_peak_mb": 2284.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.7064686}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.080700000022262, 14.075600000069244, 13.53299999993851], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 15.515, "gpu_power_peak_watts": 15.515, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2275.80078125, "cpu_memory_peak_mb": 2275.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": null, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1766019219.3180852}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019219.318992, "build_time_s": null, "file_size_mb": 174.54455947875977, "built": false, "reused": true, "error": null, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.2994013, "build_time_s": null, "file_size_mb": 332.3042411804199, "built": false, "reused": true, "error": null, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": {"batch_size": 8, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "dataset_config": "wikitext-2-raw-v1", "dataset_name": "wikitext", "samples": 512, "seed": 42, "seq_len": 128, "split": "test", "text_field": "text"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1766019220.8564398, "build_time_s": null, "file_size_mb": 174.86082077026367, "built": false, "reused": true, "error": null, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 193.8109999999824, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1766019295.8285449}
