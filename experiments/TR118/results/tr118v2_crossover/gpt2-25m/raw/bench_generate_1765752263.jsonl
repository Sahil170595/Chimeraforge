{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.121300000231713, 19.599100000050385], "ttft_ms": [2.6348999999754597, 2.4895999995351303], "tokens_processed": [8, 8], "throughput_tok_s": [378.764564676996, 408.1820083564773], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2154.9408999999287, 301.9617999998445, 2.393100003246218], "resource_metrics": {"samples": 17, "duration_s": 2.5226521492004395, "gpu_memory_mean_mb": 996.8430606617648, "gpu_memory_peak_mb": 1154.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.06188235294118, "gpu_power_peak_watts": 30.157, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1225.5882352941176, "cpu_memory_peak_mb": 1558.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752567.1193027}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.700100001500687, 19.148999999742955], "ttft_ms": [2.490799997758586, 2.3709000015514903], "tokens_processed": [8, 8], "throughput_tok_s": [406.0893091603894, 417.7763851954351], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.593900000647409, 2.4515000004612375, 2.2403000002668705], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1156.01953125, "gpu_memory_peak_mb": 1156.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.021, "gpu_power_peak_watts": 30.021, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1562.64453125, "cpu_memory_peak_mb": 1562.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752567.2367716}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.810400001209928, 19.64169999700971], "ttft_ms": [3.0643999998574145, 2.3214000029838644], "tokens_processed": [8, 8], "throughput_tok_s": [384.4231730065196, 407.2967208142847], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5171999986923765, 2.523899998777779, 2.226100001280429], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1156.01953125, "gpu_memory_peak_mb": 1156.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 31.224, "gpu_power_peak_watts": 31.224, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1562.67578125, "cpu_memory_peak_mb": 1562.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752567.3790083}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.270000000688015, 19.528199998603668], "ttft_ms": [2.092599999741651, 2.416399998764973], "tokens_processed": [8, 8], "throughput_tok_s": [415.15308768626716, 409.6639731553357], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5977000004786532, 2.457700000377372, 2.3813000007066876], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1156.01953125, "gpu_memory_peak_mb": 1156.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 31.224, "gpu_power_peak_watts": 31.224, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1562.6953125, "cpu_memory_peak_mb": 1562.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752567.5023057}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.33329999903799, 19.495399999868823], "ttft_ms": [2.3187000006146263, 2.3900000014691614], "tokens_processed": [8, 8], "throughput_tok_s": [393.4432679583981, 410.35321152958284], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6833999982045498, 2.1857000028830953, 2.3579000007885043], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1156.01953125, "gpu_memory_peak_mb": 1156.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 31.224, "gpu_power_peak_watts": 31.224, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1562.7421875, "cpu_memory_peak_mb": 1562.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752567.6275158}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.703999998862855, 53.35239999840269], "ttft_ms": [7.312199999432778, 6.309399999736343], "tokens_processed": [3, 8], "throughput_tok_s": [138.2233689714882, 149.94639416857558], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [802.5539999980538, 6.7816000009770505, 5.8352999985800125], "resource_metrics": {"samples": 9, "duration_s": 0.8651084899902344, "gpu_memory_mean_mb": 1244.908420138889, "gpu_memory_peak_mb": 1256.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.11111111111111, "gpu_power_mean_watts": 35.50888888888889, "gpu_power_peak_watts": 36.105, "gpu_temperature_mean_c": 49.55555555555556, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1559.1783854166667, "cpu_memory_peak_mb": 1563.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752568.601009}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.90989999831072, 51.15059999661753], "ttft_ms": [6.9345000010798685, 6.313199999567587], "tokens_processed": [3, 8], "throughput_tok_s": [150.67880804296047, 156.40090244354946], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.38009999966016, 6.2499999985448085, 12.263299999176525], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1256.01953125, "gpu_memory_peak_mb": 1256.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 35.984, "gpu_power_peak_watts": 35.984, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1571.7734375, "cpu_memory_peak_mb": 1571.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752568.7266204}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [18.971700003021397, 51.260699998238124], "ttft_ms": [6.096600001910701, 6.577800002560252], "tokens_processed": [3, 8], "throughput_tok_s": [158.13026768935973, 156.0649776588101], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.910300002549775, 6.517300000268733, 6.321700002445141], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1256.01953125, "gpu_memory_peak_mb": 1256.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.815, "gpu_power_peak_watts": 31.815, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1571.83203125, "cpu_memory_peak_mb": 1571.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752568.8506942}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.184500001050765, 53.93809999804944], "ttft_ms": [6.649899998592446, 6.73550000283285], "tokens_processed": [3, 8], "throughput_tok_s": [148.62889840441062, 148.31816471639348], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.23269999778131, 6.078000002162298, 6.9627999982913025], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1256.01953125, "gpu_memory_peak_mb": 1256.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.815, "gpu_power_peak_watts": 31.815, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1571.89453125, "cpu_memory_peak_mb": 1571.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752568.9759676}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.806699998298427, 52.55589999796939], "ttft_ms": [6.862199999886798, 6.649799997830996], "tokens_processed": [3, 8], "throughput_tok_s": [151.46389859278563, 152.21887552699312], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.3746000014361925, 6.120899997767992, 7.712099999480415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1256.01953125, "gpu_memory_peak_mb": 1256.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.815, "gpu_power_peak_watts": 31.815, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1571.9375, "cpu_memory_peak_mb": 1571.9375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752569.1008594}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [56.50160000004689, 58.318199997302145], "ttft_ms": [6.821999999374384, 7.0470999999088235], "tokens_processed": [8, 8], "throughput_tok_s": [141.58891075639204, 137.17844515725943], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [787.8660999995191, 7.474699999875156, 7.042699999146862], "resource_metrics": {"samples": 9, "duration_s": 0.9294943809509277, "gpu_memory_mean_mb": 1344.908420138889, "gpu_memory_peak_mb": 1356.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.111111111111111, "gpu_power_mean_watts": 33.431000000000004, "gpu_power_peak_watts": 33.67, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1565.8645833333333, "cpu_memory_peak_mb": 1580.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752570.1370845}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.72699999882025, 56.12750000000233], "ttft_ms": [6.593999998585787, 7.044099998893216], "tokens_processed": [8, 8], "throughput_tok_s": [146.18013046891767, 142.5326266090538], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.758100000297418, 8.09290000324836, 6.947600002604304], "resource_metrics": {"samples": 2, "duration_s": 0.11084461212158203, "gpu_memory_mean_mb": 1356.01953125, "gpu_memory_peak_mb": 1356.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.5, "gpu_power_mean_watts": 32.61, "gpu_power_peak_watts": 33.596, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1580.37109375, "cpu_memory_peak_mb": 1580.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752570.3572547}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.53990000023623, 57.568000000173924], "ttft_ms": [6.390700000338256, 7.049799998640083], "tokens_processed": [8, 8], "throughput_tok_s": [146.68160374267921, 138.9660922730654], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.066199999826495, 6.221200001164107, 9.272399998735636], "resource_metrics": {"samples": 2, "duration_s": 0.11838459968566895, "gpu_memory_mean_mb": 1356.01953125, "gpu_memory_peak_mb": 1356.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 31.624, "gpu_power_peak_watts": 31.624, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1580.39453125, "cpu_memory_peak_mb": 1580.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752570.5862596}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.87110000103712, 56.78249999982654], "ttft_ms": [6.734599999617785, 7.078700000420213], "tokens_processed": [8, 8], "throughput_tok_s": [145.7962388187733, 140.88847796459189], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.712599999649683, 7.624199999554548, 7.003699996857904], "resource_metrics": {"samples": 2, "duration_s": 0.11127567291259766, "gpu_memory_mean_mb": 1356.01953125, "gpu_memory_peak_mb": 1356.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 32.583999999999996, "gpu_power_peak_watts": 33.544, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1580.453125, "cpu_memory_peak_mb": 1580.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752570.8045576}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [56.39119999977993, 58.220900002197595], "ttft_ms": [7.131800000934163, 7.242499999847496], "tokens_processed": [8, 8], "throughput_tok_s": [141.8661067689856, 137.40770066587828], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.725200000801124, 6.333799999993062, 7.377999998425366], "resource_metrics": {"samples": 2, "duration_s": 0.12274360656738281, "gpu_memory_mean_mb": 1356.01953125, "gpu_memory_peak_mb": 1356.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 33.544, "gpu_power_peak_watts": 33.544, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1580.46484375, "cpu_memory_peak_mb": 1580.46484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752571.0361266}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [59.57739999939804, 59.30150000131107], "ttft_ms": [6.764300000213552, 7.071599997289013], "tokens_processed": [8, 8], "throughput_tok_s": [134.279105836791, 134.90383885438195], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [798.8052000000607, 7.339699997828575, 6.921100000909064], "resource_metrics": {"samples": 10, "duration_s": 0.962660551071167, "gpu_memory_mean_mb": 1446.01953125, "gpu_memory_peak_mb": 1456.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 33.826299999999996, "gpu_power_peak_watts": 35.119, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1572.828515625, "cpu_memory_peak_mb": 1588.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752572.1087875}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [57.938499998272164, 58.67020000005141], "ttft_ms": [6.7616999986057635, 6.741700002748985], "tokens_processed": [8, 8], "throughput_tok_s": [138.07744419062584, 136.3554240482049], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.082000001100823, 6.7726000015682075, 6.652299998677336], "resource_metrics": {"samples": 2, "duration_s": 0.10781741142272949, "gpu_memory_mean_mb": 1456.01953125, "gpu_memory_peak_mb": 1456.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 30.203, "gpu_power_peak_watts": 32.281, "gpu_temperature_mean_c": 48.5, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1588.890625, "cpu_memory_peak_mb": 1588.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752572.3282447}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [58.23360000067623, 59.91390000053798], "ttft_ms": [6.940600000234554, 6.958699999813689], "tokens_processed": [8, 8], "throughput_tok_s": [137.37773381530766, 133.52494162336563], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.040700002107769, 6.570900000951951, 9.446100000786828], "resource_metrics": {"samples": 2, "duration_s": 0.12284564971923828, "gpu_memory_mean_mb": 1456.01953125, "gpu_memory_peak_mb": 1456.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 28.125, "gpu_power_peak_watts": 28.125, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1588.890625, "cpu_memory_peak_mb": 1588.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752572.5596175}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [59.44950000048266, 60.10969999988447], "ttft_ms": [7.198300001618918, 7.1763999985705595], "tokens_processed": [8, 8], "throughput_tok_s": [134.56799468347168, 133.09000044943454], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.433300001139287, 7.072700002026977, 7.651199997781077], "resource_metrics": {"samples": 2, "duration_s": 0.12258625030517578, "gpu_memory_mean_mb": 1456.01953125, "gpu_memory_peak_mb": 1456.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 25.394, "gpu_power_peak_watts": 28.125, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1588.890625, "cpu_memory_peak_mb": 1588.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752572.790207}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [59.779499999422114, 61.36469999910332], "ttft_ms": [7.336099999520229, 6.857700002001366], "tokens_processed": [8, 8], "throughput_tok_s": [133.82514072679322, 130.3681106583573], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.408299999951851, 7.892000001447741, 7.143700000597164], "resource_metrics": {"samples": 2, "duration_s": 0.11138153076171875, "gpu_memory_mean_mb": 1456.01953125, "gpu_memory_peak_mb": 1456.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 22.663, "gpu_power_peak_watts": 22.663, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1588.890625, "cpu_memory_peak_mb": 1588.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752573.012327}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.44700000042212, 115.99809999825084], "ttft_ms": [13.540699997975025, 12.357200001133606], "tokens_processed": [12, 32], "throughput_tok_s": [264.0438312735393, 275.866587474127], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [811.3301000012143, 13.919500001065899, 13.114600002154475], "resource_metrics": {"samples": 11, "duration_s": 1.079416036605835, "gpu_memory_mean_mb": 1546.928622159091, "gpu_memory_peak_mb": 1556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.636363636363637, "gpu_power_mean_watts": 17.271, "gpu_power_peak_watts": 22.663, "gpu_temperature_mean_c": 47.54545454545455, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1580.434659090909, "cpu_memory_peak_mb": 1616.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752574.2013135}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.74839999945834, 117.53640000097221], "ttft_ms": [12.849399998231092, 13.206599996919977], "tokens_processed": [12, 32], "throughput_tok_s": [274.2957456763807, 272.25608407042677], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.546399997721892, 13.95570000022417, 13.476899999659508], "resource_metrics": {"samples": 2, "duration_s": 0.12102890014648438, "gpu_memory_mean_mb": 1556.01953125, "gpu_memory_peak_mb": 1556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 12.474, "gpu_power_peak_watts": 12.474, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1608.7265625, "cpu_memory_peak_mb": 1616.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752574.43143}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.37669999949867, 113.35979999785195], "ttft_ms": [13.044200000877026, 13.819200001307763], "tokens_processed": [12, 32], "throughput_tok_s": [276.6462179035909, 282.2870188603576], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.914000002638204, 14.898100002028514, 13.333099999726983], "resource_metrics": {"samples": 2, "duration_s": 0.12160229682922363, "gpu_memory_mean_mb": 1556.01953125, "gpu_memory_peak_mb": 1556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 12.474, "gpu_power_peak_watts": 12.474, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1608.75, "cpu_memory_peak_mb": 1616.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752574.6669607}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.02719999817782, 75.01100000081351], "ttft_ms": [8.117900000797817, 8.324500002345303], "tokens_processed": [12, 32], "throughput_tok_s": [428.15550610764456, 426.60409806099045], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.741100002225721, 8.333399997354718, 8.201600001484621], "resource_metrics": {"samples": 2, "duration_s": 0.10937237739562988, "gpu_memory_mean_mb": 1556.01953125, "gpu_memory_peak_mb": 1556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 13.726, "gpu_power_peak_watts": 13.726, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1616.0625, "cpu_memory_peak_mb": 1616.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752574.8843975}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.813799999421462, 76.79909999933443], "ttft_ms": [8.54070000059437, 9.05140000031679], "tokens_processed": [12, 32], "throughput_tok_s": [431.44050795826547, 416.6715495399988], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.137900000496302, 9.12869999956456, 8.463500002108049], "resource_metrics": {"samples": 2, "duration_s": 0.11124110221862793, "gpu_memory_mean_mb": 1556.01953125, "gpu_memory_peak_mb": 1556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 13.726, "gpu_power_peak_watts": 13.726, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1616.07421875, "cpu_memory_peak_mb": 1616.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752575.102775}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [75.68870000250172, 75.71160000225063], "ttft_ms": [9.47950000045239, 9.732999998959713], "tokens_processed": [32, 32], "throughput_tok_s": [422.78437863171536, 422.65650176523485], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [850.66469999947, 11.160199999721954, 8.963200001744553], "resource_metrics": {"samples": 10, "duration_s": 1.0134358406066895, "gpu_memory_mean_mb": 1646.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.7, "gpu_power_mean_watts": 19.8187, "gpu_power_peak_watts": 21.561, "gpu_temperature_mean_c": 47.9, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1583.0734375, "cpu_memory_peak_mb": 1637.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752576.223257}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [74.35029999760445, 76.16650000272784], "ttft_ms": [8.998799999972107, 9.128400000918191], "tokens_processed": [32, 32], "throughput_tok_s": [430.39503540713395, 420.13221033989936], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.205700000165962, 10.435600001073908, 8.263600000645965], "resource_metrics": {"samples": 2, "duration_s": 0.11320757865905762, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.163, "gpu_power_peak_watts": 21.163, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1637.89453125, "cpu_memory_peak_mb": 1637.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752576.444523}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [127.3823999981687, 76.38379999843892], "ttft_ms": [15.450099999725353, 9.17939999999362], "tokens_processed": [32, 32], "throughput_tok_s": [251.21209837826927, 418.9369997388713], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.207600001303945, 15.31750000140164, 15.41930000166758], "resource_metrics": {"samples": 3, "duration_s": 0.213623046875, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.59, "gpu_power_peak_watts": 22.444, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1637.89453125, "cpu_memory_peak_mb": 1637.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752576.7761412}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [76.818400000775, 78.42140000138897], "ttft_ms": [9.49130000299192, 10.186600000452017], "tokens_processed": [32, 32], "throughput_tok_s": [416.5668641845855, 408.0518837897975], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.273200001189252, 12.14320000144653, 9.320199998910539], "resource_metrics": {"samples": 2, "duration_s": 0.11554360389709473, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 22.444, "gpu_power_peak_watts": 22.444, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1637.9296875, "cpu_memory_peak_mb": 1637.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752576.9997923}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [74.68840000001364, 76.76480000009178], "ttft_ms": [8.053399997152155, 11.628699998254888], "tokens_processed": [32, 32], "throughput_tok_s": [428.4467199725011, 416.85772645746147], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.302000002615387, 9.161599999060854, 9.267299999919487], "resource_metrics": {"samples": 2, "duration_s": 0.11084604263305664, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 22.444, "gpu_power_peak_watts": 22.444, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1637.9296875, "cpu_memory_peak_mb": 1637.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2189.5963000024494, "compile_ms": 893.0329000031634, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765752577.2189336}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.507399999100016, 28.763300000719028], "ttft_ms": [3.391600002942141, 3.7936000007903203], "tokens_processed": [8, 8], "throughput_tok_s": [253.9086056046679, 278.13220318252826], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.654799999319948, 3.1796000002941582, 3.8122000005387235], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 25.307, "gpu_power_peak_watts": 25.307, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1641.921875, "cpu_memory_peak_mb": 1641.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.3386893}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.808600000455044, 32.509699998627184], "ttft_ms": [3.3538000025146175, 4.104100000404287], "tokens_processed": [8, 8], "throughput_tok_s": [259.6677551035049, 246.08040062928367], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.874300000665244, 3.3775999982026406, 3.9873000023362692], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 25.307, "gpu_power_peak_watts": 25.307, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1645.08203125, "cpu_memory_peak_mb": 1645.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.4637911}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.72109999973327, 30.252600001404062], "ttft_ms": [3.444999998464482, 3.7728000024799258], "tokens_processed": [8, 8], "throughput_tok_s": [269.1690415251049, 264.44008117083195], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.703700000391109, 3.6952999980712775, 4.1189999974449165], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 25.307, "gpu_power_peak_watts": 25.307, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1645.10546875, "cpu_memory_peak_mb": 1645.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.605294}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.84669999993639, 31.12139999939245], "ttft_ms": [4.535300002316944, 3.335600002174033], "tokens_processed": [8, 8], "throughput_tok_s": [243.55566921533952, 257.05784444646366], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.591200002323603, 3.4578999984660186, 3.8558999985980336], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 25.307, "gpu_power_peak_watts": 25.307, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1645.10546875, "cpu_memory_peak_mb": 1645.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.727885}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.606699997908436, 28.3389000032912], "ttft_ms": [3.2907000022532884, 3.8267999989329837], "tokens_processed": [8, 8], "throughput_tok_s": [279.6547662115839, 282.29747799212043], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.677700002503116, 3.4187000019301195, 3.96069999987958], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.604, "gpu_power_peak_watts": 21.604, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1645.12890625, "cpu_memory_peak_mb": 1645.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.8525722}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [11.364699999830918, 33.00399999716319], "ttft_ms": [3.413799997360911, 4.230800001096213], "tokens_processed": [3, 8], "throughput_tok_s": [263.97529191660436, 242.39486124977662], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.663199997594347, 3.2934000009845477, 4.101800001080846], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.604, "gpu_power_peak_watts": 21.604, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1646.0625, "cpu_memory_peak_mb": 1646.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752577.9780538}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.60869999937131, 32.995800000207964], "ttft_ms": [5.067599999165395, 4.631700001482386], "tokens_processed": [3, 8], "throughput_tok_s": [205.35708174780137, 242.45510034457652], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.888000003120396, 3.5698000028787646, 4.285099999833619], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.604, "gpu_power_peak_watts": 21.604, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1646.6953125, "cpu_memory_peak_mb": 1646.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.1056361}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [12.504599999374477, 32.43409999777214], "ttft_ms": [4.19280000278377, 4.139199998462573], "tokens_processed": [3, 8], "throughput_tok_s": [239.91171250180494, 246.65398455790393], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.875599999650149, 3.9008999992802273, 4.1568999986338895], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 21.604, "gpu_power_peak_watts": 21.604, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1646.6953125, "cpu_memory_peak_mb": 1646.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.2279088}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [11.139299997012131, 33.084900001995265], "ttft_ms": [3.4047999979520682, 4.364899999927729], "tokens_processed": [3, 8], "throughput_tok_s": [269.31674349417676, 241.80215142005991], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.56339999800548, 3.946599998016609, 4.224100001010811], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1646.6953125, "cpu_memory_peak_mb": 1646.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.3545384}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [13.39640000151121, 34.13149999687448], "ttft_ms": [4.654899999877671, 4.5066999991831835], "tokens_processed": [3, 8], "throughput_tok_s": [223.94076017897183, 234.3875891986166], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.123899998579873, 3.6485999989963602, 4.26560000050813], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1646.6953125, "cpu_memory_peak_mb": 1646.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.4778016}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.87309999825084, 37.27350000190199], "ttft_ms": [4.661899998609442, 4.6648999996250495], "tokens_processed": [8, 8], "throughput_tok_s": [211.2317185646139, 214.6296966904577], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2040999980818015, 4.4899999993504025, 4.4569000019691885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1652.28125, "cpu_memory_peak_mb": 1652.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.6036766}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.96640000291518, 36.62919999987935], "ttft_ms": [4.864200000156416, 4.139199998462573], "tokens_processed": [8, 8], "throughput_tok_s": [210.7126300988699, 218.40498837065377], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.212500000197906, 3.9921000025060493, 4.782500000146683], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1658.0703125, "cpu_memory_peak_mb": 1658.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.7283754}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.083899999037385, 37.92830000020331], "ttft_ms": [4.60430000021006, 3.974000002926914], "tokens_processed": [8, 8], "throughput_tok_s": [210.06251986278215, 210.92429663225394], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.39040000148816, 4.097599998203805, 5.064200002379948], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1658.12890625, "cpu_memory_peak_mb": 1658.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.8535047}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.080400001083035, 33.058100001653656], "ttft_ms": [4.231900002196198, 3.8218999980017543], "tokens_processed": [8, 8], "throughput_tok_s": [221.72703184443247, 241.99817895159788], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.158800002391217, 3.741100001207087, 4.501700001128484], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1658.12890625, "cpu_memory_peak_mb": 1658.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752578.9804106}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.57279999990715, 35.97830000217073], "ttft_ms": [4.9332999988109805, 3.695499999594176], "tokens_processed": [8, 8], "throughput_tok_s": [212.91998467028728, 222.356253617245], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.105600001115818, 4.56809999741381, 5.336499998520594], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1658.12890625, "cpu_memory_peak_mb": 1658.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.105852}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.03860000113491, 41.427899999689544], "ttft_ms": [5.288100001052953, 5.164300000615185], "tokens_processed": [8, 8], "throughput_tok_s": [177.62541463985139, 193.10657793564124], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.848500000865897, 5.117000000609551, 4.45890000264626], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.512, "gpu_power_peak_watts": 21.512, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1659.8984375, "cpu_memory_peak_mb": 1659.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.230959}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.5849999988277, 43.37889999806066], "ttft_ms": [4.925400000502123, 5.658199999743374], "tokens_processed": [8, 8], "throughput_tok_s": [197.11716151856797, 184.42145836703227], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.3173000014794525, 4.856600000493927, 5.199299997912021], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1661.4296875, "cpu_memory_peak_mb": 1661.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.3578136}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [44.60259999905247, 42.20340000028955], "ttft_ms": [5.180200001632329, 4.548700002487749], "tokens_processed": [8, 8], "throughput_tok_s": [179.36174124759432, 189.55818725375477], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.424999999377178, 4.731299999548355, 6.089900001825299], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1661.4296875, "cpu_memory_peak_mb": 1661.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.482384}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.649399999092566, 38.83680000217282], "ttft_ms": [4.879100000835024, 4.370599999674596], "tokens_processed": [8, 8], "throughput_tok_s": [175.24874368905236, 205.99019485519972], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.3809000019100495, 4.518099998676917, 5.920999999943888], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1661.4296875, "cpu_memory_peak_mb": 1661.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.6060898}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.05260000223643, 40.96849999768892], "ttft_ms": [5.238899997493718, 4.892700002528727], "tokens_processed": [8, 8], "throughput_tok_s": [177.5702179142353, 195.27197726183016], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.53800000125193, 4.935900000418769, 5.643100001179846], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1661.4296875, "cpu_memory_peak_mb": 1661.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.7341187}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.809300001332304, 60.892100002092775], "ttft_ms": [7.310799999686424, 7.47639999826788], "tokens_processed": [12, 32], "throughput_tok_s": [447.60586809068695, 525.5197307844566], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.78779999766266, 7.253100000525592, 7.256899996718857], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1669.64453125, "cpu_memory_peak_mb": 1669.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.8572667}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.10750000126427, 66.91370000044117], "ttft_ms": [7.7954000007594, 8.136099997500423], "tokens_processed": [12, 32], "throughput_tok_s": [497.7704033753265, 478.2279264155027], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.454899998469045, 7.540200000221375, 7.637899998371722], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1685.27734375, "cpu_memory_peak_mb": 1685.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752579.9853606}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.11120000074152, 66.67780000134371], "ttft_ms": [8.226800000556977, 8.49000000016531], "tokens_processed": [12, 32], "throughput_tok_s": [459.57290356855367, 479.9198533748133], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.84659999771975, 7.769799998641247, 8.173700000043027], "resource_metrics": {"samples": 2, "duration_s": 0.11589980125427246, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.323, "gpu_power_peak_watts": 17.323, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1685.27734375, "cpu_memory_peak_mb": 1685.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752580.214599}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.591000001237262, 64.91440000172588], "ttft_ms": [8.015300001716241, 8.26969999980065], "tokens_processed": [12, 32], "throughput_tok_s": [487.9834085395566, 492.9568785839385], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.936300000641495, 8.391499999561347, 8.573300001444295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.41, "gpu_power_peak_watts": 13.41, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1685.27734375, "cpu_memory_peak_mb": 1685.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752580.3431385}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.210600000311388, 64.50860000040848], "ttft_ms": [7.608799998706672, 8.442199999990407], "tokens_processed": [12, 32], "throughput_tok_s": [517.0051614279256, 496.05788995261673], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.470100001228275, 7.874200000514975, 7.500100000470411], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.41, "gpu_power_peak_watts": 13.41, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1685.5703125, "cpu_memory_peak_mb": 1685.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752580.4695785}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [74.49840000117547, 84.66259999840986], "ttft_ms": [9.0076999986195, 10.586700002022553], "tokens_processed": [32, 32], "throughput_tok_s": [429.53942634331867, 377.97091042090636], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.427699999127071, 8.053300000028685, 8.700700000190409], "resource_metrics": {"samples": 2, "duration_s": 0.11225366592407227, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.41, "gpu_power_peak_watts": 13.41, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1703.1171875, "cpu_memory_peak_mb": 1714.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752580.6948566}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [83.33879999918281, 80.9795999994094], "ttft_ms": [10.767600000690436, 10.086099999170983], "tokens_processed": [32, 32], "throughput_tok_s": [383.97481125614695, 395.16125049065914], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.740299999772105, 10.162200000195298, 12.174399998912122], "resource_metrics": {"samples": 2, "duration_s": 0.12023663520812988, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.41, "gpu_power_peak_watts": 13.41, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1714.53515625, "cpu_memory_peak_mb": 1714.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752580.9283442}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [76.89169999866863, 75.50130000163335], "ttft_ms": [9.653800003434299, 10.17890000002808], "tokens_processed": [32, 32], "throughput_tok_s": [416.16975565053286, 423.8337617936079], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.834299998852657, 9.458299999096198, 9.51580000037211], "resource_metrics": {"samples": 2, "duration_s": 0.12071633338928223, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.41, "gpu_power_peak_watts": 13.41, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1714.53515625, "cpu_memory_peak_mb": 1714.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752581.1624086}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [81.20549999875948, 80.26210000025458], "ttft_ms": [10.768399999506073, 10.839999999006977], "tokens_processed": [32, 32], "throughput_tok_s": [394.0619785665853, 398.69377950363247], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.123399999225512, 10.794199999509146, 10.81510000221897], "resource_metrics": {"samples": 2, "duration_s": 0.10935759544372559, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.776, "gpu_power_peak_watts": 6.776, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1714.53515625, "cpu_memory_peak_mb": 1714.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752581.380924}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [77.32589999795891, 77.84460000038962], "ttft_ms": [9.94870000067749, 9.522200001811143], "tokens_processed": [32, 32], "throughput_tok_s": [413.83288136115675, 411.0753989337711], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.503999997628853, 8.137199998600408, 9.3949000001885], "resource_metrics": {"samples": 2, "duration_s": 0.1100764274597168, "gpu_memory_mean_mb": 1656.01953125, "gpu_memory_peak_mb": 1656.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.776, "gpu_power_peak_watts": 6.776, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1714.53515625, "cpu_memory_peak_mb": 1714.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 472.8778999997303, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752581.5994985}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.00129999834462, 103.1105000001844], "ttft_ms": [13.063999998848885, 12.851999999838881], "tokens_processed": [8, 8], "throughput_tok_s": [76.92211539785883, 77.58666673118347], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [119.94930000219028, 16.175000000657747, 12.806700000510318], "resource_metrics": {"samples": 4, "duration_s": 0.3115215301513672, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.9395000000000002, "gpu_power_peak_watts": 6.776, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1826.865234375, "cpu_memory_peak_mb": 1863.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752582.0226185}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.03099999946426, 52.82850000003236], "ttft_ms": [6.333199999062344, 6.383100000675768], "tokens_processed": [8, 8], "throughput_tok_s": [150.85516019084724, 151.43341188932297], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.881999997858657, 6.898499999806518, 6.644599998253398], "resource_metrics": {"samples": 2, "duration_s": 0.11456847190856934, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.5, "gpu_power_mean_watts": 3.5635000000000003, "gpu_power_peak_watts": 4.133, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1863.140625, "cpu_memory_peak_mb": 1863.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752582.2657285}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [53.19779999990715, 52.84400000164169], "ttft_ms": [6.724300001224037, 6.280699999479111], "tokens_processed": [8, 8], "throughput_tok_s": [150.38215866095896, 151.3889940154316], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.556900000054156, 6.6653000030783005, 6.912700002430938], "resource_metrics": {"samples": 2, "duration_s": 0.12098908424377441, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 4.133, "gpu_power_peak_watts": 4.133, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1863.140625, "cpu_memory_peak_mb": 1863.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752582.4977548}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [52.52900000050431, 57.43410000286531], "ttft_ms": [6.5610999990894925, 6.73090000054799], "tokens_processed": [8, 8], "throughput_tok_s": [152.29682651341534, 139.29007331186335], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.948300000658492, 6.783900000300491, 6.711499998345971], "resource_metrics": {"samples": 2, "duration_s": 0.10837745666503906, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 4.133, "gpu_power_peak_watts": 4.133, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1863.14453125, "cpu_memory_peak_mb": 1863.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752582.7160463}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [54.635599997709505, 52.50969999906374], "ttft_ms": [6.278400000155671, 6.115699998190394], "tokens_processed": [8, 8], "throughput_tok_s": [146.42467549245154, 152.3528033895193], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first time of the first", "Test , and the first time of the first"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.43499999953201, 7.1380000008502975, 6.897300001583062], "resource_metrics": {"samples": 2, "duration_s": 0.11921834945678711, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 11.197, "gpu_power_peak_watts": 11.197, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1863.14453125, "cpu_memory_peak_mb": 1863.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752582.9461088}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.075899999937974, 51.33719999867026], "ttft_ms": [6.481500000518281, 6.280799996602582], "tokens_processed": [3, 8], "throughput_tok_s": [149.43290213685407, 155.83241782191504], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.7129999990575016, 8.049700001720339, 6.528600002638996], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 11.197, "gpu_power_peak_watts": 11.197, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1864.13671875, "cpu_memory_peak_mb": 1864.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.070418}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [19.786000000749482, 52.187199999025324], "ttft_ms": [6.819700000050943, 6.676500001049135], "tokens_processed": [3, 8], "throughput_tok_s": [151.62235923816647, 153.29429438922594], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.985500000155298, 6.500100000266684, 6.332000000838889], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 61.0, "gpu_power_mean_watts": 11.197, "gpu_power_peak_watts": 11.197, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1864.7109375, "cpu_memory_peak_mb": 1864.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.1875768}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.369199999549892, 21.091700000397395], "ttft_ms": [6.896200000483077, 4.780000002938323], "tokens_processed": [3, 8], "throughput_tok_s": [147.28118924976397, 379.2961212158939], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.20770000043558, 6.57629999841447, 6.90779999786173], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 16.762, "gpu_power_peak_watts": 16.762, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1864.72265625, "cpu_memory_peak_mb": 1864.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.315374}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [7.364599998254562, 18.950900001073023], "ttft_ms": [2.504600000975188, 2.482600000803359], "tokens_processed": [3, 8], "throughput_tok_s": [407.3540994366308, 422.14353933306757], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3583000004000496, 2.4277000011352357, 2.1931000010226853], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 16.762, "gpu_power_peak_watts": 16.762, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1864.72265625, "cpu_memory_peak_mb": 1864.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.437957}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [7.19300000127987, 17.900500002724584], "ttft_ms": [2.2083000003476627, 2.188800001022173], "tokens_processed": [3, 8], "throughput_tok_s": [417.0721534083417, 446.9148905774891], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9618000007758383, 2.4677000001247507, 2.5671000003057998], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 16.762, "gpu_power_peak_watts": 16.762, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1864.72265625, "cpu_memory_peak_mb": 1864.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.5637107}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [20.57010000135051, 18.90780000030645], "ttft_ms": [2.637400000821799, 2.491399998689303], "tokens_processed": [8, 8], "throughput_tok_s": [388.91400622625883, 423.1058081781243], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.283999998733634, 2.853599999070866, 2.4258000012196135], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 16.762, "gpu_power_peak_watts": 16.762, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1870.234375, "cpu_memory_peak_mb": 1870.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.6922035}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.493099998129765, 19.296900001791073], "ttft_ms": [6.022300000040559, 2.7461999998195097], "tokens_processed": [8, 8], "throughput_tok_s": [313.8104036224272, 414.5743616465581], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.119100002251798, 6.02699999944889, 4.988999997294741], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 31.222, "gpu_power_peak_watts": 31.222, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1875.9453125, "cpu_memory_peak_mb": 1875.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.8141577}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.97610000075656, 18.890700001065852], "ttft_ms": [4.75189999997383, 2.5956999998015817], "tokens_processed": [8, 8], "throughput_tok_s": [364.03183457140204, 423.48880663758484], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.760600000736304, 3.556299998308532, 3.297200000815792], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 31.222, "gpu_power_peak_watts": 31.222, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1876.05859375, "cpu_memory_peak_mb": 1876.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752583.9372077}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.99540000100387, 21.476099998835707], "ttft_ms": [6.886600000143517, 3.0133000000205357], "tokens_processed": [8, 8], "throughput_tok_s": [235.32595585766788, 372.50711257787526], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.961099999694852, 6.824200001574354, 6.135999999969499], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 31.222, "gpu_power_peak_watts": 31.222, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1876.0625, "cpu_memory_peak_mb": 1876.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.0627863}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.14539999840781, 20.970699999452336], "ttft_ms": [2.3707000000285916, 2.9782999990857206], "tokens_processed": [8, 8], "throughput_tok_s": [361.2488372562779, 381.48464286880863], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.661600000370527, 4.4087000023864675, 5.1105999991705175], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1666.01953125, "gpu_memory_peak_mb": 1666.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 59.0, "gpu_power_mean_watts": 31.222, "gpu_power_peak_watts": 31.222, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1876.0625, "cpu_memory_peak_mb": 1876.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.1881738}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [48.54469999918365, 26.148499997361796], "ttft_ms": [5.323800000041956, 5.355799999961164], "tokens_processed": [8, 8], "throughput_tok_s": [164.79656893820606, 305.94489170725456], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.763700001320103, 6.965900000068359, 7.0357000004150905], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 24.832, "gpu_power_peak_watts": 24.832, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1884.08203125, "cpu_memory_peak_mb": 1884.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.3128712}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [21.72960000098101, 21.55510000011418], "ttft_ms": [2.1640000013576355, 2.7907000003324356], "tokens_processed": [8, 8], "throughput_tok_s": [368.16140194199755, 371.14186433640407], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.86169999971753, 4.2995000003429595, 3.2195000021602027], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 24.832, "gpu_power_peak_watts": 24.832, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1887.16015625, "cpu_memory_peak_mb": 1887.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.4385612}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.907999999210006, 22.981800000707153], "ttft_ms": [3.2252999990305398, 2.35870000324212], "tokens_processed": [8, 8], "throughput_tok_s": [334.6160281188031, 348.1015412088626], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.645099998218939, 5.38320000123349, 3.3935000028577633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 24.832, "gpu_power_peak_watts": 24.832, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1887.16015625, "cpu_memory_peak_mb": 1887.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.5654695}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [51.574799999798415, 52.748300000530435], "ttft_ms": [5.864599999767961, 7.038499999907799], "tokens_processed": [8, 8], "throughput_tok_s": [155.1145132900422, 151.66365550964775], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.861599998548627, 6.820399998105131, 5.929599999944912], "resource_metrics": {"samples": 2, "duration_s": 0.11180329322814941, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 25.219, "gpu_power_peak_watts": 25.606, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1887.162109375, "cpu_memory_peak_mb": 1887.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.795402}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [52.39859999710461, 30.87220000088564], "ttft_ms": [6.940600000234554, 5.196499998419313], "tokens_processed": [8, 8], "throughput_tok_s": [152.67583485898584, 259.1328120370593], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.S. , and the same time .", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.com.com.com.com."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.72149999809335, 5.5032999989634845, 6.936199999472592], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 25.606, "gpu_power_peak_watts": 25.606, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1887.171875, "cpu_memory_peak_mb": 1887.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752584.9235363}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.971800002793316, 45.82250000021304], "ttft_ms": [10.245699999359204, 8.836100001644809], "tokens_processed": [12, 32], "throughput_tok_s": [375.3307601996629, 698.3468819870418], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.625299997424008, 8.77770000079181, 9.551700000884011], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 25.606, "gpu_power_peak_watts": 25.606, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1895.12890625, "cpu_memory_peak_mb": 1895.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.0486877}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [13.709599999856437, 38.92460000133724], "ttft_ms": [4.408699998748489, 5.158700001629768], "tokens_processed": [12, 32], "throughput_tok_s": [875.2990605215076, 822.1022181063043], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.211200001824182, 4.765099998621736, 5.6464000008418225], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 25.606, "gpu_power_peak_watts": 25.606, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1910.72265625, "cpu_memory_peak_mb": 1910.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.1856658}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.858700000331737, 38.09710000132327], "ttft_ms": [5.023099998652469, 4.732999997941079], "tokens_processed": [12, 32], "throughput_tok_s": [807.6076641787025, 839.9589469772898], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.603499998571351, 9.30299999890849, 7.007000000157859], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 23.948, "gpu_power_peak_watts": 23.948, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1910.72265625, "cpu_memory_peak_mb": 1910.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.3085842}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.018699999927776, 38.01989999919897], "ttft_ms": [4.717899999377551, 4.4170999972266145], "tokens_processed": [12, 32], "throughput_tok_s": [799.0039084646279, 841.6644967681187], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.236999997578096, 4.6314999999594875, 4.655699998693308], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 23.948, "gpu_power_peak_watts": 23.948, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1910.72265625, "cpu_memory_peak_mb": 1910.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.433654}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [14.335299998492701, 40.043499997409526], "ttft_ms": [4.977900000085356, 4.797000001417473], "tokens_processed": [12, 32], "throughput_tok_s": [837.0944452687946, 799.1309451489037], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. \n<|endoftext|>", "List two ways to improve throughput on local LLMs.S. , the first time of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.403700000897516, 4.732100002001971, 4.670899998018285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 23.948, "gpu_power_peak_watts": 23.948, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1910.72265625, "cpu_memory_peak_mb": 1910.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.560304}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [56.97580000196467, 51.737399997364264], "ttft_ms": [8.566700002120342, 7.247800000186544], "tokens_processed": [32, 32], "throughput_tok_s": [561.641960251485, 618.508081226158], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.13650000054622, 6.556199998158263, 6.58349999866914], "resource_metrics": {"samples": 2, "duration_s": 0.11432242393493652, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 22.2285, "gpu_power_peak_watts": 23.948, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1928.203125, "cpu_memory_peak_mb": 1939.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752585.7820702}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [48.16890000074636, 48.477700001967605], "ttft_ms": [6.158799998956965, 5.912000000535045], "tokens_processed": [32, 32], "throughput_tok_s": [664.3290587807521, 660.0973230722825], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.83330000154092, 5.885999999009073, 6.182400000398047], "resource_metrics": {"samples": 2, "duration_s": 0.11005830764770508, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 20.509, "gpu_power_peak_watts": 20.509, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1939.55859375, "cpu_memory_peak_mb": 1939.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752586.0024185}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [48.35760000059963, 48.57120000087889], "ttft_ms": [6.005499999446329, 6.261499998799991], "tokens_processed": [32, 32], "throughput_tok_s": [661.7367280345427, 658.826629760454], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.966300000087358, 7.843799998227041, 5.932700001721969], "resource_metrics": {"samples": 2, "duration_s": 0.11933207511901855, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 20.509, "gpu_power_peak_watts": 20.509, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1939.5703125, "cpu_memory_peak_mb": 1939.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752586.2325153}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.611800002807286, 38.76319999835687], "ttft_ms": [5.221999999776017, 5.796299999929033], "tokens_processed": [32, 32], "throughput_tok_s": [787.9483302337745, 825.5252404692194], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.00600000002305, 5.63970000075642, 4.042399999889312], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 73.0, "gpu_power_mean_watts": 18.336, "gpu_power_peak_watts": 18.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1939.5703125, "cpu_memory_peak_mb": 1939.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752586.36606}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.206099998613354, 38.33749999830616], "ttft_ms": [5.023300000175368, 5.414100000052713], "tokens_processed": [32, 32], "throughput_tok_s": [795.8991297614947, 834.6918813541268], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.S. , and the first time of", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.S. , and the first time of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.385900000168476, 3.640599999926053, 4.981100002623862], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 1922.01953125, "gpu_memory_peak_mb": 1922.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 73.0, "gpu_power_mean_watts": 18.336, "gpu_power_peak_watts": 18.336, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1939.58203125, "cpu_memory_peak_mb": 1939.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2043.0715999973472, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx"}, "started_at": 1765752586.4905343}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [33.1488999981957, 1.4755000011064112, 1.211999999213731], "resource_metrics": {"samples": 4, "duration_s": 0.31841611862182617, "gpu_memory_mean_mb": 2116.7841796875, "gpu_memory_peak_mb": 2503.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 73.0, "gpu_power_mean_watts": 18.552, "gpu_power_peak_watts": 18.768, "gpu_temperature_mean_c": 47.5, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2095.052734375, "cpu_memory_peak_mb": 2249.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765752586.9163003}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.5911000009509735, 1.4860999981465284, 1.450499999918975], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 73.0, "gpu_power_mean_watts": 18.768, "gpu_power_peak_watts": 18.768, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2225.7578125, "cpu_memory_peak_mb": 2225.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.0351405}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.65909999870928, 1.2945999988005497, 1.4590999999199994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 73.0, "gpu_power_mean_watts": 18.768, "gpu_power_peak_watts": 18.768, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2225.765625, "cpu_memory_peak_mb": 2225.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.1594558}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8428000003041234, 1.406199997290969, 1.1230999989493284], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 23.672, "gpu_power_peak_watts": 23.672, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2225.765625, "cpu_memory_peak_mb": 2225.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.2841547}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.577200000610901, 1.4506000006804243, 1.177900001493981], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 23.672, "gpu_power_peak_watts": 23.672, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2225.765625, "cpu_memory_peak_mb": 2225.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.4071705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0079000023542903, 1.5592999989166856, 1.099200002499856], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 23.672, "gpu_power_peak_watts": 23.672, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.33984375, "cpu_memory_peak_mb": 2226.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.5328634}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3992999995243736, 1.259199998457916, 1.3471999991452321], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 23.672, "gpu_power_peak_watts": 23.672, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.33984375, "cpu_memory_peak_mb": 2226.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.656807}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5322999972559046, 1.2497999996412545, 1.5404000005219132], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 28.422, "gpu_power_peak_watts": 28.422, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.33984375, "cpu_memory_peak_mb": 2226.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.781964}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.076400000078138, 1.3307000008353498, 1.7540000008011702], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 28.422, "gpu_power_peak_watts": 28.422, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.33984375, "cpu_memory_peak_mb": 2226.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752587.9037604}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.6246999985014554, 1.5767999975651037, 1.1560000020836014], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2509.0390625, "gpu_memory_peak_mb": 2509.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 28.422, "gpu_power_peak_watts": 28.422, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.33984375, "cpu_memory_peak_mb": 2226.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.0281086}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9361000015342142, 1.5122999975574203, 2.0019999974465463], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2511.0390625, "gpu_memory_peak_mb": 2511.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 28.422, "gpu_power_peak_watts": 28.422, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2227.91796875, "cpu_memory_peak_mb": 2227.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.153565}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.420100001472747, 1.4435000011872035, 1.836600000387989], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2511.0390625, "gpu_memory_peak_mb": 2511.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.612, "gpu_power_peak_watts": 30.612, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2227.91796875, "cpu_memory_peak_mb": 2227.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.2771044}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.873500001442153, 1.4098999999987427, 1.9119999997201376], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2511.0390625, "gpu_memory_peak_mb": 2511.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.612, "gpu_power_peak_watts": 30.612, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2228.00390625, "cpu_memory_peak_mb": 2228.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.403434}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3684999978286214, 1.6973000019788742, 1.6198000012082048], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2511.0390625, "gpu_memory_peak_mb": 2511.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.612, "gpu_power_peak_watts": 30.612, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2228.00390625, "cpu_memory_peak_mb": 2228.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.5248842}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8286000015214086, 1.398299998982111, 1.8906000004790258], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2511.0390625, "gpu_memory_peak_mb": 2511.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.612, "gpu_power_peak_watts": 30.612, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2228.015625, "cpu_memory_peak_mb": 2228.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.6503484}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7399999999033753, 2.110800000082236, 1.6543999990972225], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.177, "gpu_power_peak_watts": 31.177, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2229.55078125, "cpu_memory_peak_mb": 2229.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.7735384}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5879999993776437, 2.223399998911191, 1.6672999990987591], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.177, "gpu_power_peak_watts": 31.177, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2229.55078125, "cpu_memory_peak_mb": 2229.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752588.8956628}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.888600000005681, 1.7369000015605707, 2.202499999839347], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.177, "gpu_power_peak_watts": 31.177, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2229.5625, "cpu_memory_peak_mb": 2229.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.021167}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.705999999510823, 2.03479999981937, 1.6346000011253636], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.177, "gpu_power_peak_watts": 31.177, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2229.5625, "cpu_memory_peak_mb": 2229.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.1482646}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.527699998609023, 2.2253999995882623, 1.5908999994280748], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2513.0390625, "gpu_memory_peak_mb": 2513.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.465, "gpu_power_peak_watts": 31.465, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2229.5625, "cpu_memory_peak_mb": 2229.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.269461}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.132399998430628, 3.5250999972049613, 2.1634000004269183], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2505.0390625, "gpu_memory_peak_mb": 2505.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.465, "gpu_power_peak_watts": 31.465, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2226.41015625, "cpu_memory_peak_mb": 2226.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.3941202}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.444400001579197, 3.5669999997480772, 2.1947000022919383], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.465, "gpu_power_peak_watts": 31.465, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.85546875, "cpu_memory_peak_mb": 2243.85546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.5199149}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.368400001520058, 2.836100000422448, 3.3702000000630505], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.465, "gpu_power_peak_watts": 31.465, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.96484375, "cpu_memory_peak_mb": 2243.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.64336}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.065900000772672, 3.2819000007293653, 2.1035999998275656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.596, "gpu_power_peak_watts": 31.596, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2243.98828125, "cpu_memory_peak_mb": 2243.98828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.7663352}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.872199999226723, 3.074899999774061, 3.6706999999296386], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2521.0390625, "gpu_memory_peak_mb": 2521.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.596, "gpu_power_peak_watts": 31.596, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2244.0078125, "cpu_memory_peak_mb": 2244.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752589.8899274}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.335300000704592, 3.2945999992080033, 3.74549999833107], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2527.0390625, "gpu_memory_peak_mb": 2527.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.596, "gpu_power_peak_watts": 31.596, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2250.14453125, "cpu_memory_peak_mb": 2250.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.0166423}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.7209000008006115, 2.7379999992263038, 4.3667999998433515], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2527.0390625, "gpu_memory_peak_mb": 2527.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.596, "gpu_power_peak_watts": 31.596, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2250.16015625, "cpu_memory_peak_mb": 2250.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.138926}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.528099999035476, 2.8203000001667533, 4.597400002239738], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2527.0390625, "gpu_memory_peak_mb": 2527.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.661, "gpu_power_peak_watts": 31.661, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2250.1640625, "cpu_memory_peak_mb": 2250.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.264977}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.632900000113295, 2.7659999977913685, 4.794600001332583], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2527.0390625, "gpu_memory_peak_mb": 2527.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.661, "gpu_power_peak_watts": 31.661, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2250.203125, "cpu_memory_peak_mb": 2250.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.3893137}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.553499999427004, 2.6629999993019737, 4.906999998638639], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2527.0390625, "gpu_memory_peak_mb": 2527.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.661, "gpu_power_peak_watts": 31.661, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2250.21875, "cpu_memory_peak_mb": 2250.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 332.9889999986335, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.5144687}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.65519999852404, 1.1386999976821244, 1.1579999991226941], "resource_metrics": {"samples": 3, "duration_s": 0.21726465225219727, "gpu_memory_mean_mb": 2678.3723958333335, "gpu_memory_peak_mb": 3025.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.636333333333337, "gpu_power_peak_watts": 31.661, "gpu_temperature_mean_c": 48.666666666666664, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2379.6940104166665, "cpu_memory_peak_mb": 2561.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765752590.840327}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8978999978571665, 1.063899999280693, 1.05249999978696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.587, "gpu_power_peak_watts": 31.587, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.42578125, "cpu_memory_peak_mb": 2243.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752590.9626563}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.8202999999630265, 1.3453999999910593, 1.0436000011395663], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.587, "gpu_power_peak_watts": 31.587, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.44140625, "cpu_memory_peak_mb": 2243.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.086213}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.7949000030057505, 1.924799998960225, 1.5077999996719882], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.587, "gpu_power_peak_watts": 31.587, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.56640625, "cpu_memory_peak_mb": 2243.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.2086027}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5969999987864867, 2.1344999986467883, 1.6902000024856534], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.754, "gpu_power_peak_watts": 31.754, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2243.56640625, "cpu_memory_peak_mb": 2243.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.3333242}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6270999987900723, 1.250399996933993, 1.1704999997164123], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.754, "gpu_power_peak_watts": 31.754, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2244.16015625, "cpu_memory_peak_mb": 2244.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.461423}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.294000001711538, 1.2532000000646804, 1.262099998712074], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.754, "gpu_power_peak_watts": 31.754, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2244.16015625, "cpu_memory_peak_mb": 2244.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.582678}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.9754000022658147, 1.5679999996791594, 1.0910999990301207], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.754, "gpu_power_peak_watts": 31.754, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2244.2265625, "cpu_memory_peak_mb": 2244.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.706917}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.861500000813976, 1.5978000010363758, 1.3275999990582932], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.456, "gpu_power_peak_watts": 31.456, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2244.2265625, "cpu_memory_peak_mb": 2244.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.8324342}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3751999979140237, 2.080400001432281, 1.2153999996371567], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3029.0390625, "gpu_memory_peak_mb": 3029.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.456, "gpu_power_peak_watts": 31.456, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2244.2265625, "cpu_memory_peak_mb": 2244.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752591.9567232}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.925599997979589, 1.474100001360057, 1.7487000004621223], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3031.0390625, "gpu_memory_peak_mb": 3031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.456, "gpu_power_peak_watts": 31.456, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2245.83203125, "cpu_memory_peak_mb": 2245.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.0839918}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4567999973660335, 3.1032999977469444, 1.990299999306444], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3031.0390625, "gpu_memory_peak_mb": 3031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.456, "gpu_power_peak_watts": 31.456, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2245.83203125, "cpu_memory_peak_mb": 2245.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.204559}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2356000008585397, 1.5396999988297466, 1.521300000604242], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3031.0390625, "gpu_memory_peak_mb": 3031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.218, "gpu_power_peak_watts": 31.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2245.84375, "cpu_memory_peak_mb": 2245.84375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.329081}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.4976000022434164, 1.5464999996765982, 1.7619999998714775], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3031.0390625, "gpu_memory_peak_mb": 3031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.218, "gpu_power_peak_watts": 31.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2245.84765625, "cpu_memory_peak_mb": 2245.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.4539714}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [1.9930999987991527, 1.8192000025010202, 1.2687999987974763], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3031.0390625, "gpu_memory_peak_mb": 3031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.218, "gpu_power_peak_watts": 31.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2245.859375, "cpu_memory_peak_mb": 2245.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.5777836}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0984999975771643, 1.9969999993918464, 1.8087000025843736], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3033.0390625, "gpu_memory_peak_mb": 3033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.218, "gpu_power_peak_watts": 31.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2247.390625, "cpu_memory_peak_mb": 2247.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.704448}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.388099998119287, 1.647400000365451, 2.080100002785912], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3033.0390625, "gpu_memory_peak_mb": 3033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.261, "gpu_power_peak_watts": 31.261, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2247.39453125, "cpu_memory_peak_mb": 2247.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.823579}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.109499997663079, 1.7554000005475245, 2.2309999985736795], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3033.0390625, "gpu_memory_peak_mb": 3033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.261, "gpu_power_peak_watts": 31.261, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2247.40625, "cpu_memory_peak_mb": 2247.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752592.9479809}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.879399999888847, 6.744599999365164, 6.652199997915886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3033.0390625, "gpu_memory_peak_mb": 3033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.261, "gpu_power_peak_watts": 31.261, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2247.4140625, "cpu_memory_peak_mb": 2247.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.0721252}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.936800000403309, 6.649999999353895, 6.739099997503217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3033.0390625, "gpu_memory_peak_mb": 3033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.261, "gpu_power_peak_watts": 31.261, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2247.42578125, "cpu_memory_peak_mb": 2247.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.1978264}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.403000000631437, 10.063800000352785, 9.902400001010392], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3025.0390625, "gpu_memory_peak_mb": 3025.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 28.368, "gpu_power_peak_watts": 28.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2243.96875, "cpu_memory_peak_mb": 2243.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.3199563}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.7683999997098, 10.295499996573199, 9.954799999832176], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3043.0390625, "gpu_memory_peak_mb": 3043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 28.368, "gpu_power_peak_watts": 28.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2260.73046875, "cpu_memory_peak_mb": 2260.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.4449522}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.133699997822987, 10.05309999891324, 9.917800001858268], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3043.0390625, "gpu_memory_peak_mb": 3043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 28.368, "gpu_power_peak_watts": 28.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2256.66796875, "cpu_memory_peak_mb": 2256.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.571032}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.402700001577614, 9.915999999066116, 9.99719999890658], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3043.0390625, "gpu_memory_peak_mb": 3043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 28.368, "gpu_power_peak_watts": 28.368, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2260.75390625, "cpu_memory_peak_mb": 2260.75390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.6981146}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.559399997873697, 9.943099998054095, 10.039299999334617], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3043.0390625, "gpu_memory_peak_mb": 3043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 20.258, "gpu_power_peak_watts": 20.258, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2254.68359375, "cpu_memory_peak_mb": 2254.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.82029}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.082600002235267, 12.43649999742047, 12.452299997676164], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3049.0390625, "gpu_memory_peak_mb": 3049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 20.258, "gpu_power_peak_watts": 20.258, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2250.24609375, "cpu_memory_peak_mb": 2250.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752593.942478}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.524100002541672, 12.773700000252575, 12.513199999375502], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3049.0390625, "gpu_memory_peak_mb": 3049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 20.258, "gpu_power_peak_watts": 20.258, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2261.94921875, "cpu_memory_peak_mb": 2261.94921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752594.06573}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.879099999030586, 13.141999999788823, 12.998700000025565], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3049.0390625, "gpu_memory_peak_mb": 3049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 20.258, "gpu_power_peak_watts": 20.258, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2267.0625, "cpu_memory_peak_mb": 2267.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752594.1914363}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.772500002232846, 13.167500001145527, 13.092900000629015], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3049.0390625, "gpu_memory_peak_mb": 3049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2267.0625, "cpu_memory_peak_mb": 2267.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752594.318867}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.009300001111114, 13.259300001664087, 12.819300001865486], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3049.0390625, "gpu_memory_peak_mb": 3049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 14.616, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2251.53515625, "cpu_memory_peak_mb": 2251.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 237.89799999940442, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752594.44042}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.625599999912083, 5.866700001206482, 5.405799998698058], "resource_metrics": {"samples": 3, "duration_s": 0.21373867988586426, "gpu_memory_mean_mb": 3267.7057291666665, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 14.176, "gpu_power_peak_watts": 14.616, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2328.9479166666665, "cpu_memory_peak_mb": 2421.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765752594.7652535}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.9351999989303295, 7.808999998815125, 5.6101000009221025], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 13.296, "gpu_power_peak_watts": 13.296, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2260.41015625, "cpu_memory_peak_mb": 2260.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752594.893482}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.84290000188048, 8.320700002514059, 5.3963000027579255], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 13.296, "gpu_power_peak_watts": 13.296, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2260.41015625, "cpu_memory_peak_mb": 2260.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.0177717}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.994699997245334, 6.047299997590017, 5.61569999990752], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 13.296, "gpu_power_peak_watts": 13.296, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2260.41015625, "cpu_memory_peak_mb": 2260.41015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.1555908}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.109099998866441, 5.79469999865978, 5.333199998858618], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.942, "gpu_power_peak_watts": 11.942, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2260.4140625, "cpu_memory_peak_mb": 2260.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.2810578}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.144300001527881, 5.483000000822358, 5.921099997067358], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.942, "gpu_power_peak_watts": 11.942, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2260.99609375, "cpu_memory_peak_mb": 2260.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.4045}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.422500002372544, 6.001299996569287, 5.673899999237619], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.942, "gpu_power_peak_watts": 11.942, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.0, "cpu_memory_peak_mb": 2261.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.5284934}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.749399999534944, 5.882100002054358, 6.187200000567827], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.942, "gpu_power_peak_watts": 11.942, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.0, "cpu_memory_peak_mb": 2261.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.6529078}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.67539999994915, 5.601499997283099, 6.083800002670614], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.664, "gpu_power_peak_watts": 11.664, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.0, "cpu_memory_peak_mb": 2261.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.778036}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.709700002829777, 5.505000000994187, 5.917899998166831], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3589.0390625, "gpu_memory_peak_mb": 3589.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.664, "gpu_power_peak_watts": 11.664, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.0, "cpu_memory_peak_mb": 2261.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752595.9015353}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.093599997664569, 6.5687999995134305, 6.268400000408292], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3591.0390625, "gpu_memory_peak_mb": 3591.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.664, "gpu_power_peak_watts": 11.664, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2262.54296875, "cpu_memory_peak_mb": 2262.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.0244706}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.31889999951818, 6.969999998545973, 8.500299998559058], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3591.0390625, "gpu_memory_peak_mb": 3591.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 11.664, "gpu_power_peak_watts": 11.664, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.49609375, "cpu_memory_peak_mb": 2261.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.149389}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.067700000334298, 6.892800000059651, 6.248000001505716], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3591.0390625, "gpu_memory_peak_mb": 3591.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 11.359, "gpu_power_peak_watts": 11.359, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2262.6171875, "cpu_memory_peak_mb": 2262.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.273664}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.206799997220514, 6.46739999865531, 6.609200001548743], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3591.0390625, "gpu_memory_peak_mb": 3591.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 11.359, "gpu_power_peak_watts": 11.359, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2262.6171875, "cpu_memory_peak_mb": 2262.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.3986723}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.192000000941334, 6.495800000266172, 7.006300002103671], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3591.0390625, "gpu_memory_peak_mb": 3591.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 11.359, "gpu_power_peak_watts": 11.359, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2262.62890625, "cpu_memory_peak_mb": 2262.62890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.521266}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.205499999865424, 14.797299998463131, 14.121799998974893], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 11.359, "gpu_power_peak_watts": 11.359, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2264.25390625, "cpu_memory_peak_mb": 2264.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.6475613}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.273799999500625, 14.387399998668116, 14.815899998211535], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.104, "gpu_power_peak_watts": 10.104, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2260.55859375, "cpu_memory_peak_mb": 2260.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.773229}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.238299998396542, 14.711800002260134, 15.705499998148298], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.104, "gpu_power_peak_watts": 10.104, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2259.59765625, "cpu_memory_peak_mb": 2259.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752596.896655}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.044400002603652, 14.500500001304317, 15.553500001260545], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.104, "gpu_power_peak_watts": 10.104, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2260.7265625, "cpu_memory_peak_mb": 2260.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.0201902}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.423000000533648, 14.505900002404815, 14.962299999751849], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3593.0390625, "gpu_memory_peak_mb": 3593.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.104, "gpu_power_peak_watts": 10.104, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2264.3984375, "cpu_memory_peak_mb": 2264.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.1601512}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [23.811099999875296, 21.37389999916195, 21.57919999808655], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3585.0390625, "gpu_memory_peak_mb": 3585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 6.848, "gpu_power_peak_watts": 6.848, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2261.25390625, "cpu_memory_peak_mb": 2261.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.2841969}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [20.973500002583023, 21.98099999804981, 21.970300000248244], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3601.0390625, "gpu_memory_peak_mb": 3601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 6.848, "gpu_power_peak_watts": 6.848, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2263.98828125, "cpu_memory_peak_mb": 2263.98828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.407875}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [20.32869999675313, 10.484999998880085, 10.81010000052629], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3601.0390625, "gpu_memory_peak_mb": 3601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 6.848, "gpu_power_peak_watts": 6.848, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2265.33203125, "cpu_memory_peak_mb": 2265.33203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.5332193}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.20710000031977, 10.56599999719765, 11.222800003451994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3601.0390625, "gpu_memory_peak_mb": 3601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 6.848, "gpu_power_peak_watts": 6.848, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2278.5703125, "cpu_memory_peak_mb": 2278.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.6576703}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.971799998515053, 10.64550000228337, 10.930899999948451], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3601.0390625, "gpu_memory_peak_mb": 3601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 5.667, "gpu_power_peak_watts": 5.667, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2278.57421875, "cpu_memory_peak_mb": 2278.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.78328}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.593800002330681, 13.37710000007064, 13.254399997094879], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3607.0390625, "gpu_memory_peak_mb": 3607.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 5.667, "gpu_power_peak_watts": 5.667, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2272.078125, "cpu_memory_peak_mb": 2272.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752597.9070923}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.232800000172574, 12.992399999347981, 13.307900000654627], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3607.0390625, "gpu_memory_peak_mb": 3607.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 5.667, "gpu_power_peak_watts": 5.667, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2278.03515625, "cpu_memory_peak_mb": 2278.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752598.0314302}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.142700001684716, 13.437000001431443, 13.229100000899052], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3607.0390625, "gpu_memory_peak_mb": 3607.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 41.0, "gpu_power_mean_watts": 5.667, "gpu_power_peak_watts": 5.667, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2266.30859375, "cpu_memory_peak_mb": 2266.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752598.1542213}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.012600000569364, 13.282100000651553, 13.313800001924392], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3607.0390625, "gpu_memory_peak_mb": 3607.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 9.132, "gpu_power_peak_watts": 9.132, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2283.21484375, "cpu_memory_peak_mb": 2283.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752598.2788026}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.379700001882156, 13.351500001590466, 13.26320000225678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3607.0390625, "gpu_memory_peak_mb": 3607.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 9.132, "gpu_power_peak_watts": 9.132, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2267.1875, "cpu_memory_peak_mb": 2267.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "export_time_s": 5.091383599999972, "file_size_mb": 169.1706199645996, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "3d2e663ac2a9fc311176f4d1248b13f9a72966bbf490ae5aaed52655ad02575a", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "exists": true, "onnx_file_size_bytes": 177388252, "onnx_file_size_mb": 169.1706199645996, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 177388252, "total_artifact_size_mb": 169.1706199645996, "initializer_count": 41, "initializer_numel": 44314752, "initializer_bytes_est": 177259008, "initializer_bytes_est_mb": 169.04736328125, "initializer_dtype_counts": {"FLOAT": 41}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-25m\\model.safetensors", "name": "model.safetensors", "size_bytes": 100068208, "size_mb": 95.43247985839844}], "total_size_bytes": 100068208, "total_size_mb": 95.43247985839844}, "timestamp": 1765752283.8598948, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 35.87899710000056, "file_size_mb": 174.54455947875977, "engine_sha256": "b6870b6efb0df3e26fcf8f669972d72b3c408f5722e23bf6415620a6ebf52ca0", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp32.plan", "exists": true, "file_size_bytes": 183023236, "file_size_mb": 174.54455947875977, "deserialize_error": null, "num_layers": 244, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 68, "Float": 213}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752321.1788826, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 119.06865459999972, "file_size_mb": 332.3042411804199, "engine_sha256": "394e87205dba18409ed4d771d986fe5913a8b39eb2e24a3c4a10fff3b302a104", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_fp16.plan", "exists": true, "file_size_bytes": 348446252, "file_size_mb": 332.3042411804199, "deserialize_error": null, "num_layers": 236, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 67, "Float": 174, "Half": 30, "Bool": 2}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752447.0537574, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\onnx\\gpt2-25m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 48.36450599999807, "file_size_mb": 174.86082077026367, "engine_sha256": "d0796a8a33e4937a982460e41caaab4a59f1bcfb48d3a8db753dae3cb94f087f", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "exists": true, "file_size_bytes": 183354860, "file_size_mb": 174.86082077026367, "deserialize_error": null, "num_layers": 279, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 69, "Float": 256}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765752501.5640306, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 195.47329999841168, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-25m\\tensorrt\\gpt2-25m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765752598.4040847}
