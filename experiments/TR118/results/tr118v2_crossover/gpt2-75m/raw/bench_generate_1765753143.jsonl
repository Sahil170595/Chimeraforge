{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.04719999950612, 33.0017999986012], "ttft_ms": [4.709199998615077, 3.926199999114033], "tokens_processed": [8, 8], "throughput_tok_s": [215.94074586221492, 242.41102001524416], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2542.4463000017568, 318.3337999980722, 4.244799998559756], "resource_metrics": {"samples": 22, "duration_s": 3.0584471225738525, "gpu_memory_mean_mb": 1686.2922585227273, "gpu_memory_peak_mb": 2046.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.2727272727272727, "gpu_power_mean_watts": 30.152727272727272, "gpu_power_peak_watts": 30.33, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1498.953125, "cpu_memory_peak_mb": 1833.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753559.114888}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.60959999918123, 33.30609999829903], "ttft_ms": [4.086299999471521, 3.968100001657149], "tokens_processed": [8, 8], "throughput_tok_s": [238.0272303209467, 240.19624034061528], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.740799999126466, 4.521299997577444, 4.275999999663327], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2046.01953125, "gpu_memory_peak_mb": 2046.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.129, "gpu_power_peak_watts": 30.129, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1839.140625, "cpu_memory_peak_mb": 1839.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753559.2391243}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [35.17849999843747, 33.09350000199629], "ttft_ms": [4.433599999174476, 3.9300999997067265], "tokens_processed": [8, 8], "throughput_tok_s": [227.41162927229234, 241.73931435228727], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.251799997291528, 3.991500001575332, 4.686499996751081], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2046.01953125, "gpu_memory_peak_mb": 2046.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 36.675, "gpu_power_peak_watts": 36.675, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1839.16796875, "cpu_memory_peak_mb": 1839.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753559.3627405}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.90399999989313, 33.290500003204215], "ttft_ms": [4.192399999737972, 3.8339000020641834], "tokens_processed": [8, 8], "throughput_tok_s": [235.96035866048894, 240.30879678076326], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1498000027786475, 4.6441999984381255, 4.539699999440927], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2046.01953125, "gpu_memory_peak_mb": 2046.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 36.675, "gpu_power_peak_watts": 36.675, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1839.17578125, "cpu_memory_peak_mb": 1839.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753559.4849536}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.44510000231094, 33.88219999760622], "ttft_ms": [4.015599999547703, 3.9133999998739455], "tokens_processed": [8, 8], "throughput_tok_s": [219.5082466365226, 236.11217691192425], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.240300000674324, 3.906400001142174, 3.9544999999634456], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 2046.01953125, "gpu_memory_peak_mb": 2046.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 60.0, "gpu_power_mean_watts": 36.675, "gpu_power_peak_watts": 36.675, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1839.21484375, "cpu_memory_peak_mb": 1839.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753559.6111836}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [78.46319999953266, 70.50559999697725], "ttft_ms": [10.325899998861132, 9.289099998568418], "tokens_processed": [8, 8], "throughput_tok_s": [101.95862519050522, 113.46616439464354], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1034.1603000015311, 8.900799999537412, 8.428400000411784], "resource_metrics": {"samples": 13, "duration_s": 1.2952911853790283, "gpu_memory_mean_mb": 2309.250300480769, "gpu_memory_peak_mb": 2338.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.692307692307693, "gpu_power_mean_watts": 44.54346153846154, "gpu_power_peak_watts": 49.345, "gpu_temperature_mean_c": 48.46153846153846, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1852.6108774038462, "cpu_memory_peak_mb": 2035.375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753561.0180078}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [70.6620999990264, 71.9000999997661], "ttft_ms": [9.227499998814892, 8.56750000093598], "tokens_processed": [8, 8], "throughput_tok_s": [113.21486341490314, 111.26549198159704], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.702900002390379, 8.726500000193482, 8.73660000070231], "resource_metrics": {"samples": 2, "duration_s": 0.11003994941711426, "gpu_memory_mean_mb": 2338.01953125, "gpu_memory_peak_mb": 2338.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.255, "gpu_power_peak_watts": 34.255, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1849.72265625, "cpu_memory_peak_mb": 1849.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753561.235583}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [71.28329999977723, 81.81619999959366], "ttft_ms": [8.5575000011886, 8.877300002495758], "tokens_processed": [8, 8], "throughput_tok_s": [112.2282498148234, 97.78014623069431], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.001999998872634, 8.224500001233537, 10.16459999664221], "resource_metrics": {"samples": 2, "duration_s": 0.12239861488342285, "gpu_memory_mean_mb": 2338.01953125, "gpu_memory_peak_mb": 2338.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 39.22, "gpu_power_peak_watts": 39.22, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1849.732421875, "cpu_memory_peak_mb": 1849.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753561.46958}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [77.83969999945839, 74.41929999913555], "ttft_ms": [9.238200000254437, 8.340599997609388], "tokens_processed": [8, 8], "throughput_tok_s": [102.7753190217288, 107.49899555750898], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [22.833999999420485, 16.04149999911897, 8.924099998694146], "resource_metrics": {"samples": 2, "duration_s": 0.11901092529296875, "gpu_memory_mean_mb": 2338.01953125, "gpu_memory_peak_mb": 2338.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 39.22, "gpu_power_peak_watts": 39.22, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1849.7421875, "cpu_memory_peak_mb": 1849.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753561.7001452}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [73.32940000196686, 74.91929999741842], "ttft_ms": [9.009999997942941, 12.309300000197254], "tokens_processed": [8, 8], "throughput_tok_s": [109.09676064150834, 106.7815636328111], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.145699999062344, 12.420600000041304, 8.336599999893224], "resource_metrics": {"samples": 2, "duration_s": 0.11236143112182617, "gpu_memory_mean_mb": 2338.01953125, "gpu_memory_peak_mb": 2338.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 40.916, "gpu_power_peak_watts": 42.612, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1849.748046875, "cpu_memory_peak_mb": 1849.75, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753561.9193447}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [78.0680999996548, 74.01410000238684], "ttft_ms": [9.370200001285411, 8.50469999932102], "tokens_processed": [8, 8], "throughput_tok_s": [102.47463432612518, 108.08751305145928], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1037.4991000026057, 9.392799998749979, 8.704399999260204], "resource_metrics": {"samples": 14, "duration_s": 1.4044291973114014, "gpu_memory_mean_mb": 2621.01953125, "gpu_memory_peak_mb": 2654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.928571428571429, "gpu_power_mean_watts": 33.90378571428572, "gpu_power_peak_watts": 42.612, "gpu_temperature_mean_c": 47.357142857142854, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1858.0811941964287, "cpu_memory_peak_mb": 2029.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753563.4371252}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [74.24379999793018, 77.23849999820231], "ttft_ms": [8.759599997574696, 8.861099999194266], "tokens_processed": [8, 8], "throughput_tok_s": [107.75310531280766, 103.57528952771216], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.953599998174468, 10.346600000048056, 8.639699997729622], "resource_metrics": {"samples": 2, "duration_s": 0.1157529354095459, "gpu_memory_mean_mb": 2654.01953125, "gpu_memory_peak_mb": 2654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 18.452, "gpu_power_peak_watts": 18.452, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1859.66796875, "cpu_memory_peak_mb": 1859.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753563.6626132}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [74.98699999996461, 74.57730000169249], "ttft_ms": [8.732300000701798, 10.752899997896748], "tokens_processed": [8, 8], "throughput_tok_s": [106.68515876090223, 107.27124741467503], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.467800000304123, 8.893100002751453, 8.599700002378086], "resource_metrics": {"samples": 2, "duration_s": 0.11485600471496582, "gpu_memory_mean_mb": 2654.01953125, "gpu_memory_peak_mb": 2654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 18.239, "gpu_power_peak_watts": 18.452, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1859.671875, "cpu_memory_peak_mb": 1859.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753563.8901155}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [73.26839999950607, 75.90100000015809], "ttft_ms": [8.541100000002189, 9.325400002126116], "tokens_processed": [8, 8], "throughput_tok_s": [109.18758973928638, 105.40045585675205], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.01139999993029, 9.666199999628589, 9.081000000151107], "resource_metrics": {"samples": 2, "duration_s": 0.11437058448791504, "gpu_memory_mean_mb": 2654.01953125, "gpu_memory_peak_mb": 2654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 18.026, "gpu_power_peak_watts": 18.026, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1859.671875, "cpu_memory_peak_mb": 1859.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753564.1219318}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [75.21840000117663, 78.03419999981998], "ttft_ms": [8.977099998446647, 9.583200000633951], "tokens_processed": [8, 8], "throughput_tok_s": [106.35695521142243, 102.51915185929317], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.86950000131037, 10.569999998551793, 8.56230000135838], "resource_metrics": {"samples": 2, "duration_s": 0.11801934242248535, "gpu_memory_mean_mb": 2654.01953125, "gpu_memory_peak_mb": 2654.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 22.5, "gpu_power_mean_watts": 18.961, "gpu_power_peak_watts": 19.896, "gpu_temperature_mean_c": 46.5, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1859.671875, "cpu_memory_peak_mb": 1859.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753564.3479755}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [87.5077999990026, 85.4235000006156], "ttft_ms": [9.510799998679431, 10.443300001497846], "tokens_processed": [8, 8], "throughput_tok_s": [91.42042195199951, 93.65104450113081], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1077.1033000019088, 9.254700002202298, 9.963600001356099], "resource_metrics": {"samples": 15, "duration_s": 1.4816012382507324, "gpu_memory_mean_mb": 2936.9528645833334, "gpu_memory_peak_mb": 2966.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 17.75586666666667, "gpu_power_peak_watts": 19.896, "gpu_temperature_mean_c": 46.266666666666666, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1862.546875, "cpu_memory_peak_mb": 2024.3515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753565.9370353}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [79.38199999989592, 82.53500000137137], "ttft_ms": [8.762500001466833, 10.823000000527827], "tokens_processed": [8, 8], "throughput_tok_s": [100.7785140209429, 96.92857575412945], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.621199998946395, 9.411399998498382, 10.445400002936367], "resource_metrics": {"samples": 2, "duration_s": 0.11333203315734863, "gpu_memory_mean_mb": 2966.01953125, "gpu_memory_peak_mb": 2966.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.314, "gpu_power_peak_watts": 15.314, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1869.76171875, "cpu_memory_peak_mb": 1869.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753566.1607168}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [83.75359999990906, 81.39149999988149], "ttft_ms": [9.560900001815753, 9.630200001993217], "tokens_processed": [8, 8], "throughput_tok_s": [95.51828219931664, 98.29036201583271], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.542499997536652, 10.499899999558693, 9.585299998434493], "resource_metrics": {"samples": 2, "duration_s": 0.11171197891235352, "gpu_memory_mean_mb": 2966.01953125, "gpu_memory_peak_mb": 2966.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.5, "gpu_power_mean_watts": 16.689, "gpu_power_peak_watts": 18.064, "gpu_temperature_mean_c": 46.5, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1869.765625, "cpu_memory_peak_mb": 1869.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753566.3811848}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [83.36829999825568, 82.60060000247904], "ttft_ms": [9.437199998501455, 9.016200001497054], "tokens_processed": [8, 8], "throughput_tok_s": [95.95973529707796, 96.85159671672967], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.177699997962918, 9.51830000121845, 9.929299998475472], "resource_metrics": {"samples": 2, "duration_s": 0.11022186279296875, "gpu_memory_mean_mb": 2966.01953125, "gpu_memory_peak_mb": 2966.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 18.064, "gpu_power_peak_watts": 18.064, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1869.765625, "cpu_memory_peak_mb": 1869.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753566.60102}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [90.1162000009208, 82.36840000245138], "ttft_ms": [9.428900000784779, 9.872400001768256], "tokens_processed": [8, 8], "throughput_tok_s": [88.77427143974398, 97.12462546027251], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.857699999585748, 13.20069999928819, 8.98339999912423], "resource_metrics": {"samples": 2, "duration_s": 0.12182855606079102, "gpu_memory_mean_mb": 2966.01953125, "gpu_memory_peak_mb": 2966.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 18.064, "gpu_power_peak_watts": 18.064, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1869.765625, "cpu_memory_peak_mb": 1869.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753566.8320138}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.15640000251005, 108.15829999773996], "ttft_ms": [14.440500002820045, 15.324199997849064], "tokens_processed": [32, 32], "throughput_tok_s": [243.98351890862807, 295.8626383797514], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1264.2588000016985, 15.655100000003586, 18.34660000167787], "resource_metrics": {"samples": 17, "duration_s": 1.6975328922271729, "gpu_memory_mean_mb": 3235.784237132353, "gpu_memory_peak_mb": 3262.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.176470588235293, "gpu_power_mean_watts": 18.252058823529413, "gpu_power_peak_watts": 21.391, "gpu_temperature_mean_c": 46.23529411764706, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1870.6953125, "cpu_memory_peak_mb": 2033.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753568.636751}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [105.21440000229632, 106.25829999844427], "ttft_ms": [11.882300001161639, 11.815699999715434], "tokens_processed": [32, 32], "throughput_tok_s": [304.140878048077, 301.1529452331584], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [26.21309999813093, 24.94270000170218, 20.87530000062543], "resource_metrics": {"samples": 3, "duration_s": 0.21321678161621094, "gpu_memory_mean_mb": 3262.01953125, "gpu_memory_peak_mb": 3262.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.861666666666665, "gpu_power_peak_watts": 17.874, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1889.1940104166667, "cpu_memory_peak_mb": 1898.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753568.9609406}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [102.65049999725306, 102.60589999961667], "ttft_ms": [11.591499998758081, 11.63059999817051], "tokens_processed": [32, 32], "throughput_tok_s": [311.73740021584234, 311.8729039959647], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.898299999302253, 12.547199999971781, 11.385699999664212], "resource_metrics": {"samples": 3, "duration_s": 0.21785998344421387, "gpu_memory_mean_mb": 3262.01953125, "gpu_memory_peak_mb": 3262.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.874, "gpu_power_peak_watts": 17.874, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1888.91015625, "cpu_memory_peak_mb": 1898.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753569.2860584}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [102.76079999675858, 102.30339999907301], "ttft_ms": [11.421100000006845, 11.530100000527455], "tokens_processed": [32, 32], "throughput_tok_s": [311.40279173585054, 312.7950781722793], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.684099998092279, 14.584299999114592, 11.40760000271257], "resource_metrics": {"samples": 3, "duration_s": 0.2167530059814453, "gpu_memory_mean_mb": 3262.01953125, "gpu_memory_peak_mb": 3262.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 21.81, "gpu_power_peak_watts": 21.81, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1898.28515625, "cpu_memory_peak_mb": 1898.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753569.6098444}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [100.81730000092648, 100.15369999746326], "ttft_ms": [10.47630000175559, 10.768099997221725], "tokens_processed": [32, 32], "throughput_tok_s": [317.40584204998476, 319.5089148060482], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [23.869200002081925, 11.533200002304511, 11.760800000047311], "resource_metrics": {"samples": 3, "duration_s": 0.21737194061279297, "gpu_memory_mean_mb": 3262.01953125, "gpu_memory_peak_mb": 3262.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 49.0, "gpu_power_mean_watts": 21.98, "gpu_power_peak_watts": 22.32, "gpu_temperature_mean_c": 46.333333333333336, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1898.28515625, "cpu_memory_peak_mb": 1898.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753569.9357312}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [188.60039999708533, 128.4546999995655], "ttft_ms": [22.8279000002658, 22.403500002837973], "tokens_processed": [32, 32], "throughput_tok_s": [169.67090207918187, 249.11505768265576], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1455.5741000003763, 23.829900001146598, 23.489100000006147], "resource_metrics": {"samples": 17, "duration_s": 1.9824795722961426, "gpu_memory_mean_mb": 3550.254825367647, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.352941176470589, "gpu_power_mean_watts": 18.022117647058824, "gpu_power_peak_watts": 22.32, "gpu_temperature_mean_c": 46.1764705882353, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1881.5252757352941, "cpu_memory_peak_mb": 2040.62890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753572.0325906}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [93.81749999738531, 94.49779999704333], "ttft_ms": [11.928399999305839, 11.026999996829545], "tokens_processed": [32, 32], "throughput_tok_s": [341.0877501627291, 338.6322221364013], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.65649999913876, 11.565400000108639, 11.33539999864297], "resource_metrics": {"samples": 3, "duration_s": 0.21825170516967773, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 18.284333333333333, "gpu_power_peak_watts": 24.743, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1920.60546875, "cpu_memory_peak_mb": 1920.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753572.3615706}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [97.38840000136406, 96.10210000028019], "ttft_ms": [11.048599997593556, 12.046100000588922], "tokens_processed": [32, 32], "throughput_tok_s": [328.58122732842713, 332.97919608319387], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.371700002404395, 14.261399999668356, 11.54089999909047], "resource_metrics": {"samples": 3, "duration_s": 0.21786785125732422, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 24.743, "gpu_power_peak_watts": 24.743, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1920.60546875, "cpu_memory_peak_mb": 1920.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753572.6868453}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [131.71149999834597, 130.37220000114758], "ttft_ms": [17.563600002176827, 16.637299999274546], "tokens_processed": [32, 32], "throughput_tok_s": [242.9552468873398, 245.45110076932295], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.246099999378202, 13.4037999996508, 13.57310000094003], "resource_metrics": {"samples": 3, "duration_s": 0.21526598930358887, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 33.967, "gpu_power_peak_watts": 38.579, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1920.60546875, "cpu_memory_peak_mb": 1920.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753573.014703}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [95.16179999991436, 96.94160000071861], "ttft_ms": [11.023899998690467, 10.601299996778835], "tokens_processed": [32, 32], "throughput_tok_s": [336.26938540495024, 330.0956452107536], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.641400001797592, 11.284899999736808, 11.357399998814799], "resource_metrics": {"samples": 3, "duration_s": 0.21390485763549805, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 38.579, "gpu_power_peak_watts": 38.579, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1920.60546875, "cpu_memory_peak_mb": 1920.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 3088.6233000019274, "compile_ms": 1163.3450999979686, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765753573.3361974}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [88.56709999963641, 85.3222999976424], "ttft_ms": [10.1859999995213, 10.313000002497574], "tokens_processed": [8, 8], "throughput_tok_s": [90.3269950131916, 93.7621231521074], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.401299999008188, 11.198599997442216, 10.705400000006193], "resource_metrics": {"samples": 2, "duration_s": 0.12183785438537598, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 47.423, "gpu_power_peak_watts": 47.423, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1926.375, "cpu_memory_peak_mb": 1927.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753573.567631}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [87.86770000006072, 90.70779999819933], "ttft_ms": [11.380299998563714, 11.915099999896483], "tokens_processed": [8, 8], "throughput_tok_s": [91.04597024839015, 88.19528199514055], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.243900000408757, 11.227099999814527, 11.189799999556271], "resource_metrics": {"samples": 3, "duration_s": 0.21033453941345215, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 41.886, "gpu_power_peak_watts": 47.423, "gpu_temperature_mean_c": 48.333333333333336, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1927.91015625, "cpu_memory_peak_mb": 1927.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753573.8900232}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [87.14249999684398, 87.19980000023497], "ttft_ms": [10.273399999277899, 11.369500000000698], "tokens_processed": [8, 8], "throughput_tok_s": [91.80365493633686, 91.74332968628876], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.867199998756405, 10.056800001621014, 9.93929999822285], "resource_metrics": {"samples": 2, "duration_s": 0.11412644386291504, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 30.812, "gpu_power_peak_watts": 30.812, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1927.91015625, "cpu_memory_peak_mb": 1927.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753574.1161911}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [81.60359999965294, 84.11820000037551], "ttft_ms": [10.62639999872772, 10.533100001339335], "tokens_processed": [8, 8], "throughput_tok_s": [98.03489061798773, 95.10426994353526], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.138300000311574, 10.971799998515053, 10.260899998684181], "resource_metrics": {"samples": 2, "duration_s": 0.1089773178100586, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 30.812, "gpu_power_peak_watts": 30.812, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1927.91015625, "cpu_memory_peak_mb": 1927.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753574.3344753}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [85.24279999983264, 82.63979999901494], "ttft_ms": [10.052300000097603, 10.317000000213739], "tokens_processed": [8, 8], "throughput_tok_s": [93.84956852679295, 96.80565538754159], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.806199999933597, 10.047899999335641, 9.935399997630157], "resource_metrics": {"samples": 2, "duration_s": 0.11077332496643066, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.17, "gpu_power_peak_watts": 18.17, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1927.91015625, "cpu_memory_peak_mb": 1927.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753574.5530097}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [92.72500000224682, 97.55529999893042], "ttft_ms": [11.573399999178946, 11.881599999469472], "tokens_processed": [8, 8], "throughput_tok_s": [86.27662442497872, 82.00477062843034], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.463800001365598, 10.756499999843072, 12.155299998994451], "resource_metrics": {"samples": 3, "duration_s": 0.21346473693847656, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.17, "gpu_power_peak_watts": 18.17, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1929.03125, "cpu_memory_peak_mb": 1929.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753574.8762362}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [92.08779999971739, 91.32599999793456], "ttft_ms": [11.207899999135407, 12.1553999997559], "tokens_processed": [8, 8], "throughput_tok_s": [86.87361409464175, 87.59827431597715], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.43700000102399, 10.678099999495316, 10.860299997148104], "resource_metrics": {"samples": 3, "duration_s": 0.21749472618103027, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.17, "gpu_power_peak_watts": 18.17, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1929.2265625, "cpu_memory_peak_mb": 1929.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753575.203494}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [97.29750000042259, 94.04209999775048], "ttft_ms": [12.776300001860363, 11.86030000098981], "tokens_processed": [8, 8], "throughput_tok_s": [82.22205092592569, 85.06828324964418], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.910900000861147, 11.55750000179978, 11.57729999977164], "resource_metrics": {"samples": 3, "duration_s": 0.22437405586242676, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.088, "gpu_power_peak_watts": 18.17, "gpu_temperature_mean_c": 46.333333333333336, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1929.2265625, "cpu_memory_peak_mb": 1929.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753575.5371397}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [96.29249999852618, 96.58810000109952], "ttft_ms": [11.8798000003153, 13.144500000635162], "tokens_processed": [8, 8], "throughput_tok_s": [83.08019835524516, 82.82593818398882], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.423899999499554, 11.730599999282276, 11.590899997827364], "resource_metrics": {"samples": 3, "duration_s": 0.2153012752532959, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.047000000000002, "gpu_power_peak_watts": 15.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1929.2265625, "cpu_memory_peak_mb": 1929.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753575.8625696}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [93.23030000086874, 92.2738000008394], "ttft_ms": [10.162399998080218, 11.48980000289157], "tokens_processed": [8, 8], "throughput_tok_s": [85.80901273433052, 86.69849946493181], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.04439999855822, 12.863799998740433, 10.36230000318028], "resource_metrics": {"samples": 3, "duration_s": 0.21894454956054688, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.047000000000002, "gpu_power_peak_watts": 15.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1929.2265625, "cpu_memory_peak_mb": 1929.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753576.190324}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.27139999956125, 102.54520000307821], "ttft_ms": [12.532699998700991, 12.686499998380896], "tokens_processed": [8, 8], "throughput_tok_s": [76.72285976819782, 78.01437804753276], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.366099999984726, 12.827400001697242, 13.3626999995613], "resource_metrics": {"samples": 3, "duration_s": 0.21770596504211426, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.319, "gpu_power_peak_watts": 15.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1938.5052083333333, "cpu_memory_peak_mb": 1940.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753576.516415}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [100.66310000183876, 102.44880000027479], "ttft_ms": [12.629000000742963, 13.200200002756901], "tokens_processed": [8, 8], "throughput_tok_s": [79.47301443978844, 78.08778628913704], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.900399997102795, 13.170700000046054, 13.621999998576939], "resource_metrics": {"samples": 3, "duration_s": 0.22171521186828613, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.455, "gpu_power_peak_watts": 12.455, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1940.3984375, "cpu_memory_peak_mb": 1940.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753576.8492117}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [103.40910000013537, 103.25060000104713], "ttft_ms": [12.582699997437885, 13.015699998504715], "tokens_processed": [8, 8], "throughput_tok_s": [77.36263056142572, 77.48138993786831], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.228799998614704, 12.803000001440523, 12.163600000349106], "resource_metrics": {"samples": 3, "duration_s": 0.21629905700683594, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 12.455, "gpu_power_peak_watts": 12.455, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1940.3984375, "cpu_memory_peak_mb": 1940.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753577.1784363}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.92430000056629, 100.30360000018845], "ttft_ms": [12.435600001481362, 10.922800000116695], "tokens_processed": [8, 8], "throughput_tok_s": [80.06060587819641, 79.7578551516094], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.733999999705702, 10.978399997839006, 12.34870000189403], "resource_metrics": {"samples": 3, "duration_s": 0.21611332893371582, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.700333333333333, "gpu_power_peak_watts": 12.455, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1940.3984375, "cpu_memory_peak_mb": 1940.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753577.5081546}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [99.9919999994745, 98.8961000002746], "ttft_ms": [12.513100002252031, 12.015500000416068], "tokens_processed": [8, 8], "throughput_tok_s": [80.00640051246143, 80.8929775792755], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.979300001461525, 11.762099999032216, 12.61289999820292], "resource_metrics": {"samples": 3, "duration_s": 0.21408462524414062, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.323, "gpu_power_peak_watts": 8.323, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1940.3984375, "cpu_memory_peak_mb": 1940.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753577.8354263}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [114.56560000078753, 109.6934000015608], "ttft_ms": [14.925299998139963, 14.496100000542356], "tokens_processed": [8, 8], "throughput_tok_s": [69.8289888059331, 72.93055005940349], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.665499998955056, 13.886100001400337, 14.576300000044284], "resource_metrics": {"samples": 3, "duration_s": 0.21565842628479004, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.323, "gpu_power_peak_watts": 8.323, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1943.0677083333333, "cpu_memory_peak_mb": 1943.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753578.1623154}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.07469999801833, 107.72180000276421], "ttft_ms": [14.622300001065014, 13.574500000686385], "tokens_processed": [8, 8], "throughput_tok_s": [73.34423106499806, 74.26537618007418], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.971299998956965, 13.721300001634518, 14.728999998624204], "resource_metrics": {"samples": 3, "duration_s": 0.21871232986450195, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 4.832333333333334, "gpu_power_peak_watts": 8.323, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1943.578125, "cpu_memory_peak_mb": 1943.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753578.4928079}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [109.83150000174646, 108.42240000056336], "ttft_ms": [13.46430000194232, 14.076399998884881], "tokens_processed": [8, 8], "throughput_tok_s": [72.83884859874253, 73.78549082070155], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.399499999650288, 14.182599999912782, 14.100399999733781], "resource_metrics": {"samples": 3, "duration_s": 0.21818208694458008, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.087, "gpu_power_peak_watts": 3.087, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1943.578125, "cpu_memory_peak_mb": 1943.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753578.820708}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [114.9727999982133, 114.20749999888358], "ttft_ms": [13.966200000140816, 14.039099998626625], "tokens_processed": [8, 8], "throughput_tok_s": [69.58167497116119, 70.04793905897776], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.062800000829156, 13.385999998718034, 13.955900001747068], "resource_metrics": {"samples": 3, "duration_s": 0.21978211402893066, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.087, "gpu_power_peak_watts": 3.087, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1943.578125, "cpu_memory_peak_mb": 1943.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753579.1523733}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.17699999926845, 112.54940000071656], "ttft_ms": [13.948699997854419, 13.942599998699734], "tokens_processed": [8, 8], "throughput_tok_s": [70.68574003597648, 71.07989913717059], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.66010000128881, 14.191099999152357, 14.410600000701379], "resource_metrics": {"samples": 3, "duration_s": 0.2159423828125, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.3443333333333336, "gpu_power_peak_watts": 3.087, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1943.578125, "cpu_memory_peak_mb": 1943.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753579.4820461}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [168.87089999727323, 164.79489999983343], "ttft_ms": [19.862200002535246, 20.318200000474462], "tokens_processed": [32, 32], "throughput_tok_s": [189.49386780384725, 194.1807665166358], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [22.507599998789374, 22.93439999994007, 20.89479999995092], "resource_metrics": {"samples": 4, "duration_s": 0.3159925937652588, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.973, "gpu_power_peak_watts": 1.973, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1961.1591796875, "cpu_memory_peak_mb": 1967.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753579.911335}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [170.66459999841754, 166.1048000023584], "ttft_ms": [19.540699999197386, 20.72720000069239], "tokens_processed": [32, 32], "throughput_tok_s": [187.50227053704583, 192.64945985634165], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.488899997872068, 20.701700002973666, 20.377400000143098], "resource_metrics": {"samples": 4, "duration_s": 0.3085770606994629, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.973, "gpu_power_peak_watts": 1.973, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1967.01953125, "cpu_memory_peak_mb": 1967.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753580.3324597}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [172.22440000114148, 174.45090000182972], "ttft_ms": [22.229700000025332, 22.38030000080471], "tokens_processed": [32, 32], "throughput_tok_s": [185.80410208883242, 183.43270226559088], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.011000000522472, 21.47749999858206, 20.175000001472654], "resource_metrics": {"samples": 4, "duration_s": 0.3141906261444092, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.952, "gpu_power_peak_watts": 1.952, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1967.01953125, "cpu_memory_peak_mb": 1967.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753580.7569187}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [172.65480000060052, 174.7974999998405], "ttft_ms": [21.969900000840425, 21.016800001234515], "tokens_processed": [32, 32], "throughput_tok_s": [185.34092304348735, 183.06897981967245], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.353600001020823, 21.53869999892777, 20.24909999818192], "resource_metrics": {"samples": 5, "duration_s": 0.4113142490386963, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.952, "gpu_power_peak_watts": 1.952, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1967.01953125, "cpu_memory_peak_mb": 1967.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753581.282198}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [169.23379999934696, 173.65049999716575], "ttft_ms": [22.398599998268764, 21.628599999530707], "tokens_processed": [32, 32], "throughput_tok_s": [189.08752270600485, 184.27819096704178], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.706799998355564, 22.29100000113249, 21.476499998243526], "resource_metrics": {"samples": 4, "duration_s": 0.3160543441772461, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.945, "gpu_power_peak_watts": 1.945, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1967.01953125, "cpu_memory_peak_mb": 1967.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753581.709862}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [218.66429999863612, 206.84909999908996], "ttft_ms": [29.961200001707766, 25.609100001020124], "tokens_processed": [32, 32], "throughput_tok_s": [146.34304731133338, 154.70214760490032], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [26.919800002360716, 29.461399997671833, 28.064500002074055], "resource_metrics": {"samples": 6, "duration_s": 0.5127341747283936, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.945, "gpu_power_peak_watts": 1.945, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1987.2747395833333, "cpu_memory_peak_mb": 1995.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753582.3332438}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [229.61930000019493, 229.80009999810136], "ttft_ms": [30.028500001208158, 29.10150000025169], "tokens_processed": [32, 32], "throughput_tok_s": [139.36110771164635, 139.25146246787702], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [28.31960000185063, 32.5273999987985, 28.56229999815696], "resource_metrics": {"samples": 6, "duration_s": 0.5131845474243164, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.934, "gpu_power_peak_watts": 1.934, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1995.8671875, "cpu_memory_peak_mb": 1995.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753582.957336}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [237.92619999949238, 214.44370000244817], "ttft_ms": [30.198200001905207, 27.979499998764368], "tokens_processed": [32, 32], "throughput_tok_s": [134.4954864158225, 149.2233159548855], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [27.034700000513112, 30.043300001125317, 27.812999996967847], "resource_metrics": {"samples": 6, "duration_s": 0.5128581523895264, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.9240000000000002, "gpu_power_peak_watts": 1.934, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1995.8671875, "cpu_memory_peak_mb": 1995.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753583.581185}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [218.35859999919194, 230.86630000034347], "ttft_ms": [27.951300002314383, 27.878000000782777], "tokens_processed": [32, 32], "throughput_tok_s": [146.54792620999777, 138.60836336854877], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [26.533899999776622, 29.372900000453228, 26.883999998972286], "resource_metrics": {"samples": 6, "duration_s": 0.515627384185791, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.914, "gpu_power_peak_watts": 1.914, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1995.8671875, "cpu_memory_peak_mb": 1995.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753584.2073166}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [233.66519999763113, 230.3001000000222], "ttft_ms": [30.878399997163797, 28.703199997835327], "tokens_processed": [32, 32], "throughput_tok_s": [136.9480778495232, 138.94913636597167], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [27.982499999779975, 30.215400001907256, 26.949099999910686], "resource_metrics": {"samples": 6, "duration_s": 0.513211727142334, "gpu_memory_mean_mb": 3576.01953125, "gpu_memory_peak_mb": 3576.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8998333333333335, "gpu_power_peak_watts": 1.914, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 1995.87109375, "cpu_memory_peak_mb": 1995.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 949.9810000015714, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753584.831734}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.857799998892, 43.05009999734466], "ttft_ms": [27.995199998258613, 5.614800000330433], "tokens_processed": [8, 8], "throughput_tok_s": [70.88566319810009, 185.8299980834758], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [163.31750000244938, 30.085599999438273, 28.55719999934081], "resource_metrics": {"samples": 4, "duration_s": 0.31653857231140137, "gpu_memory_mean_mb": 3970.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.897, "gpu_power_peak_watts": 1.897, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2124.3076171875, "cpu_memory_peak_mb": 2165.06640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.2565296}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.36030000151368, 22.830699999758508], "ttft_ms": [3.107399999862537, 2.5647000002209097], "tokens_processed": [8, 8], "throughput_tok_s": [342.4613553542388, 350.40537522216226], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9891999986139126, 7.38170000113314, 3.3505999999761116], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 3.881, "gpu_power_peak_watts": 3.881, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2165.12109375, "cpu_memory_peak_mb": 2165.12109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.3753018}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [22.778700000344543, 23.18639999793959], "ttft_ms": [3.104600000369828, 2.7373999982955866], "tokens_processed": [8, 8], "throughput_tok_s": [351.20529265844823, 345.0298451122599], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.011000001512002, 5.577699997957097, 3.1869999984337483], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 3.881, "gpu_power_peak_watts": 3.881, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2165.12109375, "cpu_memory_peak_mb": 2165.12109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.5002503}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.428899999998976, 23.329999999987194], "ttft_ms": [2.9238999995868653, 2.9666000009456184], "tokens_processed": [8, 8], "throughput_tok_s": [341.4586258851397, 342.9061294472521], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1870999991951976, 3.1171000009635463, 3.0793000005360227], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 3.881, "gpu_power_peak_watts": 3.881, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2165.12109375, "cpu_memory_peak_mb": 2165.12109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.6412046}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [23.61160000145901, 23.801800001820084], "ttft_ms": [3.1392000018968247, 2.9912999998487066], "tokens_processed": [8, 8], "throughput_tok_s": [338.81651389595214, 336.1090337448535], "predicted_tokens": ["", ""], "outputs": ["Hello , and the first of the first of", "Test , the first of the first of the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.320499999972526, 3.0095000001892913, 2.912399999331683], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 3.881, "gpu_power_peak_watts": 3.881, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2165.12109375, "cpu_memory_peak_mb": 2165.12109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.7682376}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.551899998186855, 24.489299998094793], "ttft_ms": [3.1477999982598703, 3.1601000009686686], "tokens_processed": [8, 8], "throughput_tok_s": [325.8403626843868, 326.6732818260375], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1829000001598615, 3.1042000009620097, 3.1262000011338387], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 16.46, "gpu_power_peak_watts": 16.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2166.0703125, "cpu_memory_peak_mb": 2166.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753585.8929968}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [24.397100001806393, 25.40150000277208], "ttft_ms": [3.08969999969122, 3.170199997839518], "tokens_processed": [8, 8], "throughput_tok_s": [327.90782508608277, 314.9420309480525], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.688299999339506, 3.4366999971098267, 3.0821000000287313], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 16.46, "gpu_power_peak_watts": 16.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2166.6328125, "cpu_memory_peak_mb": 2166.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.0169473}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.287100001150975, 26.462900001206435], "ttft_ms": [3.503899999486748, 3.5018999988096766], "tokens_processed": [8, 8], "throughput_tok_s": [316.3668431586014, 302.3100264761338], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.563500002201181, 3.1553000007988885, 3.281799999967916], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 16.46, "gpu_power_peak_watts": 16.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2166.63671875, "cpu_memory_peak_mb": 2166.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.1393948}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.50849999897764, 24.44439999817405], "ttft_ms": [3.1740999984322116, 2.950300000520656], "tokens_processed": [8, 8], "throughput_tok_s": [313.6209498920216, 327.2733223395782], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.243300001689931, 3.3473999974376056, 2.960099998745136], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 63.0, "gpu_power_mean_watts": 16.46, "gpu_power_peak_watts": 16.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2166.63671875, "cpu_memory_peak_mb": 2166.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.2663481}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [25.577200001862366, 24.578500000643544], "ttft_ms": [3.3858000024338253, 3.0421000010392163], "tokens_processed": [8, 8], "throughput_tok_s": [312.77856838971786, 325.4877230014254], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.556100000423612, 3.4063000020978507, 3.131299999949988], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 36.011, "gpu_power_peak_watts": 36.011, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2166.63671875, "cpu_memory_peak_mb": 2166.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.3900852}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.800899999623653, 28.315899999142857], "ttft_ms": [3.465699999651406, 3.4525999981269706], "tokens_processed": [8, 8], "throughput_tok_s": [277.76909749711075, 282.52677824975245], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.1640999990922865, 3.5232999980507884, 3.5720999985642266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 36.011, "gpu_power_peak_watts": 36.011, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2172.08984375, "cpu_memory_peak_mb": 2172.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.5119114}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.13869999954477, 28.348199997708434], "ttft_ms": [3.4890999995695893, 3.6982000019634143], "tokens_processed": [8, 8], "throughput_tok_s": [284.3059558589922, 282.20486664573735], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.833200000372017, 3.531699996528914, 3.332699998281896], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 36.011, "gpu_power_peak_watts": 36.011, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2177.80859375, "cpu_memory_peak_mb": 2177.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.639694}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.48140000080457, 28.59080000052927], "ttft_ms": [3.8340000028256327, 3.6059999983990565], "tokens_processed": [8, 8], "throughput_tok_s": [271.35753389532636, 279.8102886191329], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.6757999991532415, 3.7298000024748035, 4.256299998814939], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 36.011, "gpu_power_peak_watts": 36.011, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2177.80859375, "cpu_memory_peak_mb": 2177.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.7624762}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.21239999725367, 27.789499999926193], "ttft_ms": [3.7144000016269274, 3.3962000015890226], "tokens_processed": [8, 8], "throughput_tok_s": [264.7919397574243, 287.8785152673221], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.7235000017972197, 3.8228000012168195, 3.6712000000989065], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 33.882, "gpu_power_peak_watts": 33.882, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2177.8125, "cpu_memory_peak_mb": 2177.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753586.891732}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [28.445399999327492, 28.433200001018122], "ttft_ms": [3.642499999841675, 3.598199997213669], "tokens_processed": [8, 8], "throughput_tok_s": [281.24055208185285, 281.3612255994239], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.57520000054501, 3.6196000000927597, 3.5930000012740493], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 33.882, "gpu_power_peak_watts": 33.882, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2177.8125, "cpu_memory_peak_mb": 2177.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.0125387}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.018499998026527, 33.40340000067954], "ttft_ms": [3.6481999995885417, 4.231300001265481], "tokens_processed": [8, 8], "throughput_tok_s": [257.9106017540816, 239.4965781877669], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.3244000007689465, 3.7863000034121796, 4.22199999957229], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 33.882, "gpu_power_peak_watts": 33.882, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2179.375, "cpu_memory_peak_mb": 2179.375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.1354308}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.0757000008598, 28.60549999968498], "ttft_ms": [3.8727999999537133, 3.858399999444373], "tokens_processed": [8, 8], "throughput_tok_s": [249.4099894869187, 279.6664977045708], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8509000005433336, 3.63880000077188, 3.6498000008577947], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 27.0, "gpu_power_mean_watts": 33.882, "gpu_power_peak_watts": 33.882, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2180.875, "cpu_memory_peak_mb": 2180.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.2608929}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.626100000721635, 28.97049999955925], "ttft_ms": [3.681099999084836, 3.910900002665585], "tokens_processed": [8, 8], "throughput_tok_s": [252.95562841505776, 276.1429730284845], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.018000003270572, 3.7913000014668796, 3.6820999994233716], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 38.252, "gpu_power_peak_watts": 38.252, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2180.875, "cpu_memory_peak_mb": 2180.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.3863583}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.688299997564172, 32.758800000010524], "ttft_ms": [3.763000000617467, 3.7764000007882714], "tokens_processed": [8, 8], "throughput_tok_s": [260.6856685002097, 244.20918959172587], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.285299997718539, 3.969199999119155, 3.865599999699043], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 38.252, "gpu_power_peak_watts": 38.252, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2180.875, "cpu_memory_peak_mb": 2180.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.509879}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.01199999966775, 33.27480000007199], "ttft_ms": [3.848700001981342, 4.206000001431676], "tokens_processed": [8, 8], "throughput_tok_s": [249.9062851456651, 240.42218134993124], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. , and the other other , and the", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. and that the same time , and the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.312799999752315, 3.7612999985867646, 3.8688999993610196], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 38.252, "gpu_power_peak_watts": 38.252, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2180.87890625, "cpu_memory_peak_mb": 2180.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.660014}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [42.60980000253767, 40.01889999926789], "ttft_ms": [4.472399999940535, 5.353700002160622], "tokens_processed": [32, 32], "throughput_tok_s": [751.0009434002086, 799.6221785352774], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.327200000669109, 6.071399999200366, 3.9622000003873836], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 38.252, "gpu_power_peak_watts": 38.252, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2188.921875, "cpu_memory_peak_mb": 2188.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.785123}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [39.04730000067502, 39.53460000047926], "ttft_ms": [4.6689000009791926, 4.1069000035349745], "tokens_processed": [32, 32], "throughput_tok_s": [819.518891176773, 809.4175734574798], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.3049000018509105, 5.847200001880992, 5.041100001108134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 36.062, "gpu_power_peak_watts": 36.062, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2204.5, "cpu_memory_peak_mb": 2204.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753587.9084373}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.33160000067437, 38.59059999740566], "ttft_ms": [5.671300001267809, 4.932699997880263], "tokens_processed": [32, 32], "throughput_tok_s": [834.8203570797207, 829.217477887135], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.725900002289563, 4.898999999568332, 4.756900001666509], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 36.062, "gpu_power_peak_watts": 36.062, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2204.5, "cpu_memory_peak_mb": 2204.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.032691}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [38.91449999719043, 39.06170000118436], "ttft_ms": [4.778200000146171, 5.657999998220475], "tokens_processed": [32, 32], "throughput_tok_s": [822.3155893641278, 819.2167775347655], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.991899997548899, 5.783599997812416, 4.946900000504684], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 36.062, "gpu_power_peak_watts": 36.062, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2204.50390625, "cpu_memory_peak_mb": 2204.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.1581156}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.92900000169175, 37.885000001551816], "ttft_ms": [3.79379999867524, 5.056300000433112], "tokens_processed": [32, 32], "throughput_tok_s": [866.5276611479882, 844.6614754834167], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.@. @-@ 5 @-", "List two ways to improve throughput on local LLMs.@ 5 % of the other other ,"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.280999997921754, 4.735499998787418, 5.783600001450395], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 29.0, "gpu_power_mean_watts": 36.062, "gpu_power_peak_watts": 36.062, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2204.50390625, "cpu_memory_peak_mb": 2204.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.28171}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [50.4317999984778, 47.28550000072573], "ttft_ms": [5.9425999970699195, 6.900100001075771], "tokens_processed": [32, 32], "throughput_tok_s": [634.520282856568, 676.7402269090708], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.885899998655077, 5.973900002572918, 5.454199999803677], "resource_metrics": {"samples": 2, "duration_s": 0.11645317077636719, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 42.439, "gpu_power_peak_watts": 42.439, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2222.080078125, "cpu_memory_peak_mb": 2233.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.506267}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.245299999805866, 46.186499999748776], "ttft_ms": [5.721599998651072, 4.649400001653703], "tokens_processed": [32, 32], "throughput_tok_s": [707.2557812665028, 692.843146810736], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.170000000769505, 6.026200000633253, 5.647800000588177], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 42.439, "gpu_power_peak_watts": 42.439, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2233.45703125, "cpu_memory_peak_mb": 2233.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.638563}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [49.842300002637785, 92.37189999839757], "ttft_ms": [6.198699997185031, 8.986799999547657], "tokens_processed": [32, 32], "throughput_tok_s": [642.0249466478568, 346.4256987304053], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.189899999299087, 6.940699997358024, 4.714700000477023], "resource_metrics": {"samples": 2, "duration_s": 0.1165311336517334, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 43.411500000000004, "gpu_power_peak_watts": 44.384, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2233.45703125, "cpu_memory_peak_mb": 2233.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753588.864892}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [55.259799999475945, 47.08369999934803], "ttft_ms": [11.534299999766517, 6.572099999175407], "tokens_processed": [32, 32], "throughput_tok_s": [579.082805227371, 679.6407249311993], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.4325999992433935, 6.553999999596272, 6.119699999544537], "resource_metrics": {"samples": 2, "duration_s": 0.12067198753356934, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 44.384, "gpu_power_peak_watts": 44.384, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2233.45703125, "cpu_memory_peak_mb": 2233.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753589.0976036}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [46.07969999779016, 45.598700002301484], "ttft_ms": [6.3098999999056105, 5.2740999999514315], "tokens_processed": [32, 32], "throughput_tok_s": [694.4489656298679, 701.7743926555993], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. , and the other other other other other", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.@ 5 % of the time . The"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.748999999923399, 6.936900001164759, 4.228900001180591], "resource_metrics": {"samples": 2, "duration_s": 0.10989117622375488, "gpu_memory_mean_mb": 4098.01953125, "gpu_memory_peak_mb": 4098.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 38.0, "gpu_power_mean_watts": 44.384, "gpu_power_peak_watts": 44.384, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2233.45703125, "cpu_memory_peak_mb": 2233.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1439.5485000022745, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx"}, "started_at": 1765753589.315457}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.123399998614332, 1.9864999994751997, 1.6299999988405034], "resource_metrics": {"samples": 5, "duration_s": 0.4141557216644287, "gpu_memory_mean_mb": 4302.43515625, "gpu_memory_peak_mb": 4731.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 51.622, "gpu_power_peak_watts": 51.622, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2611.12421875, "cpu_memory_peak_mb": 2845.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765753589.8371847}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.469400002155453, 1.6127999988384545, 1.8963000002258923], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 31.557, "gpu_power_peak_watts": 31.557, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.34375, "cpu_memory_peak_mb": 2426.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753589.9617257}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2285999984887894, 1.9400999990466516, 1.6439999999420252], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 31.557, "gpu_power_peak_watts": 31.557, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.35546875, "cpu_memory_peak_mb": 2426.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.0863101}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3419999997713603, 1.6228999993472826, 1.9080000020039733], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 31.557, "gpu_power_peak_watts": 31.557, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.375, "cpu_memory_peak_mb": 2426.375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.2123592}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5143000020761974, 1.6637000007904135, 1.9003000015800353], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 50.0, "gpu_power_mean_watts": 31.557, "gpu_power_peak_watts": 31.557, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.375, "cpu_memory_peak_mb": 2426.375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.3353674}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.900199997384334, 2.175999998144107, 1.761299998179311], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.467, "gpu_power_peak_watts": 32.467, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.9609375, "cpu_memory_peak_mb": 2426.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.458497}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.5261999983049463, 2.25240000145277, 1.6771999980846886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.467, "gpu_power_peak_watts": 32.467, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.9609375, "cpu_memory_peak_mb": 2426.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.583326}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5517999965813942, 1.8495999975129962, 2.0676000021921936], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.467, "gpu_power_peak_watts": 32.467, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.9609375, "cpu_memory_peak_mb": 2426.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.7080088}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6066999998874962, 1.6957999978330918, 2.0520000034593977], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.467, "gpu_power_peak_watts": 32.467, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.96484375, "cpu_memory_peak_mb": 2426.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.8308613}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.616500001749955, 2.097299999149982, 1.7680999990261625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4959.0390625, "gpu_memory_peak_mb": 4959.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.949, "gpu_power_peak_watts": 31.949, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2426.96875, "cpu_memory_peak_mb": 2426.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753590.9544053}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.66310000026715, 2.493699998012744, 1.9090999994659796], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4961.0390625, "gpu_memory_peak_mb": 4961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.949, "gpu_power_peak_watts": 31.949, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2428.5078125, "cpu_memory_peak_mb": 2428.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.077602}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6889000000664964, 2.3290999997698236, 1.9819000008283183], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4961.0390625, "gpu_memory_peak_mb": 4961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.949, "gpu_power_peak_watts": 31.949, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2428.5078125, "cpu_memory_peak_mb": 2428.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.2012055}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.125499999441672, 2.1237000000837725, 1.9725999991351273], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4961.0390625, "gpu_memory_peak_mb": 4961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.949, "gpu_power_peak_watts": 31.949, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2428.5078125, "cpu_memory_peak_mb": 2428.5078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.325683}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1722999992780387, 2.0828999986406416, 2.012600001762621], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4961.0390625, "gpu_memory_peak_mb": 4961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.208, "gpu_power_peak_watts": 32.208, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2428.515625, "cpu_memory_peak_mb": 2428.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.4514627}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.90080000195303, 2.502500003174646, 1.9279000007372815], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4961.0390625, "gpu_memory_peak_mb": 4961.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.208, "gpu_power_peak_watts": 32.208, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2428.515625, "cpu_memory_peak_mb": 2428.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.5745168}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.552599999238737, 2.5760999997146428, 2.827399999659974], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4963.0390625, "gpu_memory_peak_mb": 4963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.208, "gpu_power_peak_watts": 32.208, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2430.046875, "cpu_memory_peak_mb": 2430.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.6967854}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.3784000006562565, 2.7167000007466413, 2.6499999985389877], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4963.0390625, "gpu_memory_peak_mb": 4963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.208, "gpu_power_peak_watts": 32.208, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2430.046875, "cpu_memory_peak_mb": 2430.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.8241503}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.697299998748349, 2.730100000917446, 2.674700001080055], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4963.0390625, "gpu_memory_peak_mb": 4963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.445, "gpu_power_peak_watts": 32.445, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2430.046875, "cpu_memory_peak_mb": 2430.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753591.9448757}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0430000006163027, 2.2559000026376452, 2.6354000001447275], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4963.0390625, "gpu_memory_peak_mb": 4963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.445, "gpu_power_peak_watts": 32.445, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2430.046875, "cpu_memory_peak_mb": 2430.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.0676608}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4466999968572054, 2.7319999971950892, 2.5180000011459924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4963.0390625, "gpu_memory_peak_mb": 4963.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.445, "gpu_power_peak_watts": 32.445, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2430.046875, "cpu_memory_peak_mb": 2430.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.1935332}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.08250000065891, 4.136299998208415, 4.249599998729536], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4955.0390625, "gpu_memory_peak_mb": 4955.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.445, "gpu_power_peak_watts": 32.445, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2427.64453125, "cpu_memory_peak_mb": 2427.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.3178027}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.503700002009282, 4.416200001287507, 4.680400001234375], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4971.0390625, "gpu_memory_peak_mb": 4971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.634, "gpu_power_peak_watts": 32.634, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.01953125, "cpu_memory_peak_mb": 2447.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.4441469}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.116900000051828, 4.013499998109182, 4.192699998384342], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4971.0390625, "gpu_memory_peak_mb": 4971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.634, "gpu_power_peak_watts": 32.634, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.0234375, "cpu_memory_peak_mb": 2447.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.5694804}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.7291000011900906, 4.466400001547299, 2.7729000030376483], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4971.0390625, "gpu_memory_peak_mb": 4971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.634, "gpu_power_peak_watts": 32.634, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.0234375, "cpu_memory_peak_mb": 2447.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.6946456}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.612299999484094, 3.822599999693921, 3.9026000013109297], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4971.0390625, "gpu_memory_peak_mb": 4971.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.634, "gpu_power_peak_watts": 32.634, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.03125, "cpu_memory_peak_mb": 2447.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.816833}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.890000000770669, 5.106699998577824, 5.575699997280026], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4977.0390625, "gpu_memory_peak_mb": 4977.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.998, "gpu_power_peak_watts": 32.998, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2453.1640625, "cpu_memory_peak_mb": 2453.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753592.9441242}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.916599999385653, 4.83890000032261, 3.9479000006394926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4977.0390625, "gpu_memory_peak_mb": 4977.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.998, "gpu_power_peak_watts": 32.998, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2453.16796875, "cpu_memory_peak_mb": 2453.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753593.069279}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.162400001107017, 4.080400001839735, 5.200699997658376], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4977.0390625, "gpu_memory_peak_mb": 4977.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.998, "gpu_power_peak_watts": 32.998, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2453.171875, "cpu_memory_peak_mb": 2453.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753593.1916902}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.595099999889499, 5.24550000045565, 4.082399998878827], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4977.0390625, "gpu_memory_peak_mb": 4977.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.998, "gpu_power_peak_watts": 32.998, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2453.171875, "cpu_memory_peak_mb": 2453.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753593.3157063}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.854600000428036, 5.285100000037346, 3.8761999967391603], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 4977.0390625, "gpu_memory_peak_mb": 4977.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 33.128, "gpu_power_peak_watts": 33.128, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2453.171875, "cpu_memory_peak_mb": 2453.171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 493.8785000013013, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753593.4401355}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.451900000683963, 1.9406999999773689, 1.6027999990910757], "resource_metrics": {"samples": 5, "duration_s": 0.4177818298339844, "gpu_memory_mean_mb": 5251.8390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.95399999999999, "gpu_power_peak_watts": 33.128, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2847.1953125, "cpu_memory_peak_mb": 3086.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765753593.9709039}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2797999990871176, 1.6323999989253934, 1.9336999976076186], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.693, "gpu_power_peak_watts": 32.693, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2446.6875, "cpu_memory_peak_mb": 2446.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.0987842}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5209000014001504, 1.7943999991985038, 1.8646000025910325], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.693, "gpu_power_peak_watts": 32.693, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2446.69140625, "cpu_memory_peak_mb": 2446.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.2204213}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.153000001271721, 2.0661999988078605, 1.580899999680696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 32.693, "gpu_power_peak_watts": 32.693, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2446.6953125, "cpu_memory_peak_mb": 2446.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.3470569}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.35890000112704, 1.6613000007055234, 1.8880999996326864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.466, "gpu_power_peak_watts": 32.466, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2446.6953125, "cpu_memory_peak_mb": 2446.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.4717417}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9130999973858707, 2.084600000671344, 1.6474999974889215], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.466, "gpu_power_peak_watts": 32.466, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.27734375, "cpu_memory_peak_mb": 2447.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.5971313}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.722200002608588, 1.8209000008937437, 1.9655000032798853], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.466, "gpu_power_peak_watts": 32.466, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.27734375, "cpu_memory_peak_mb": 2447.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.721792}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.834199996868847, 1.8421000022499356, 1.9873999990522861], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.466, "gpu_power_peak_watts": 32.466, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.28515625, "cpu_memory_peak_mb": 2447.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.8474593}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.546499999880325, 1.746000001730863, 2.0481999999901745], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.418, "gpu_power_peak_watts": 32.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.28515625, "cpu_memory_peak_mb": 2447.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753594.9700773}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.515699998184573, 1.743600001645973, 1.9689999971888028], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5799.0390625, "gpu_memory_peak_mb": 5799.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.418, "gpu_power_peak_watts": 32.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2447.28515625, "cpu_memory_peak_mb": 2447.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.093894}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.090999998676125, 2.3330000003625173, 2.0437000021047425], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5801.0390625, "gpu_memory_peak_mb": 5801.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.418, "gpu_power_peak_watts": 32.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2448.8203125, "cpu_memory_peak_mb": 2448.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.2162755}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1265999969036784, 2.115100000082748, 1.9410999993851874], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5801.0390625, "gpu_memory_peak_mb": 5801.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.418, "gpu_power_peak_watts": 32.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2448.82421875, "cpu_memory_peak_mb": 2448.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.344675}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.386199997999938, 2.2723000001860783, 2.0248000000719912], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5801.0390625, "gpu_memory_peak_mb": 5801.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.242, "gpu_power_peak_watts": 32.242, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2448.82421875, "cpu_memory_peak_mb": 2448.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.4678988}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1060000001161825, 2.2605000012845267, 1.8898999987868592], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5801.0390625, "gpu_memory_peak_mb": 5801.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.242, "gpu_power_peak_watts": 32.242, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2448.82421875, "cpu_memory_peak_mb": 2448.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.5923905}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8800000000046566, 2.359699999942677, 1.8686999974306673], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5801.0390625, "gpu_memory_peak_mb": 5801.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.242, "gpu_power_peak_watts": 32.242, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2448.82421875, "cpu_memory_peak_mb": 2448.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.7181988}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.023499997856561, 2.5628000003052875, 2.748700000665849], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5803.0390625, "gpu_memory_peak_mb": 5803.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.242, "gpu_power_peak_watts": 32.242, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2450.35546875, "cpu_memory_peak_mb": 2450.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.8417451}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.3380999993823934, 2.3660999977437314, 2.2513999974762555], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5803.0390625, "gpu_memory_peak_mb": 5803.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.281, "gpu_power_peak_watts": 32.281, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2450.359375, "cpu_memory_peak_mb": 2450.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753595.966284}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6278000006859656, 2.694599999813363, 2.151400000002468], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5803.0390625, "gpu_memory_peak_mb": 5803.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.281, "gpu_power_peak_watts": 32.281, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2450.359375, "cpu_memory_peak_mb": 2450.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.0934138}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.842400001507485, 3.2992000014928635, 3.375899999809917], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5803.0390625, "gpu_memory_peak_mb": 5803.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.281, "gpu_power_peak_watts": 32.281, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2450.359375, "cpu_memory_peak_mb": 2450.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.2185354}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.327500002546003, 3.2930999987001996, 3.7874999979976565], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5803.0390625, "gpu_memory_peak_mb": 5803.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.281, "gpu_power_peak_watts": 32.281, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2450.359375, "cpu_memory_peak_mb": 2450.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.3411999}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.167599997657817, 5.4832000023452565, 5.650600000080885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5795.0390625, "gpu_memory_peak_mb": 5795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 30.18, "gpu_power_peak_watts": 30.18, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2448.0, "cpu_memory_peak_mb": 2448.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.4657483}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.296799998584902, 5.792799998744158, 5.228199999692151], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5813.0390625, "gpu_memory_peak_mb": 5813.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 30.18, "gpu_power_peak_watts": 30.18, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2466.7265625, "cpu_memory_peak_mb": 2466.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.5870953}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.553100000222912, 5.356399997253902, 5.985699997836491], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5813.0390625, "gpu_memory_peak_mb": 5813.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 30.18, "gpu_power_peak_watts": 30.18, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2466.73046875, "cpu_memory_peak_mb": 2466.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.7129908}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.870800002128817, 18.951099998957943, 17.78560000093421], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5813.0390625, "gpu_memory_peak_mb": 5813.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 30.18, "gpu_power_peak_watts": 30.18, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2452.1640625, "cpu_memory_peak_mb": 2452.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.8337011}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.565400001331, 18.722999997407896, 17.2314000010374], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5813.0390625, "gpu_memory_peak_mb": 5813.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 23.193, "gpu_power_peak_watts": 23.193, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2457.21875, "cpu_memory_peak_mb": 2457.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753596.961781}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.858100000827108, 20.09360000010929, 20.063699997990625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5819.0390625, "gpu_memory_peak_mb": 5819.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 23.193, "gpu_power_peak_watts": 23.193, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2452.1640625, "cpu_memory_peak_mb": 2452.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753597.0846395}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [20.375300002342556, 19.91740000084974, 19.97549999941839], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5819.0390625, "gpu_memory_peak_mb": 5819.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 23.193, "gpu_power_peak_watts": 23.193, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2452.16796875, "cpu_memory_peak_mb": 2452.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753597.2094426}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [20.644100000936305, 20.044000000780215, 19.956500000262167], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5819.0390625, "gpu_memory_peak_mb": 5819.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 23.193, "gpu_power_peak_watts": 23.193, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2452.17578125, "cpu_memory_peak_mb": 2452.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753597.3350875}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.264299998700153, 5.577300002187258, 5.334400000720052], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5819.0390625, "gpu_memory_peak_mb": 5819.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 16.269, "gpu_power_peak_watts": 16.269, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2472.87890625, "cpu_memory_peak_mb": 2472.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753597.4628065}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.165999999619089, 3.8090000016381964, 4.834499999560649], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5819.0390625, "gpu_memory_peak_mb": 5819.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 16.269, "gpu_power_peak_watts": 16.269, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2472.87890625, "cpu_memory_peak_mb": 2472.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 406.99300000051153, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753597.5836606}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.145600000512786, 2.2241000006033573, 1.9055999982811045], "resource_metrics": {"samples": 5, "duration_s": 0.4156532287597656, "gpu_memory_mean_mb": 6068.6390625, "gpu_memory_peak_mb": 6579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 16.677, "gpu_power_peak_watts": 16.949, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2825.675, "cpu_memory_peak_mb": 3039.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765753598.1122952}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.3603000008733943, 1.8242000005557202, 2.0798000005015638], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 16.949, "gpu_power_peak_watts": 16.949, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2469.19921875, "cpu_memory_peak_mb": 2469.19921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.2314382}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.459799998177914, 2.1295000005920883, 1.8228999979328364], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 19.484, "gpu_power_peak_watts": 19.484, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.20703125, "cpu_memory_peak_mb": 2469.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.3545866}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1134000018937513, 1.8545000020822044, 1.831300000048941], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 19.484, "gpu_power_peak_watts": 19.484, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.2109375, "cpu_memory_peak_mb": 2469.2109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.4790998}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5305000017397106, 2.028399998380337, 1.7516000007162802], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 19.484, "gpu_power_peak_watts": 19.484, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.21484375, "cpu_memory_peak_mb": 2469.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.6033216}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.298499999800697, 1.9809000004897825, 2.089599998726044], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 19.484, "gpu_power_peak_watts": 19.484, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.9140625, "cpu_memory_peak_mb": 2469.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.7291918}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.731399999902351, 1.7129999978351407, 2.0368000004964415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 21.578, "gpu_power_peak_watts": 21.578, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.9140625, "cpu_memory_peak_mb": 2469.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.856049}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.0594000015989877, 2.1211000021139625, 1.7468999976699706], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 21.578, "gpu_power_peak_watts": 21.578, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.91796875, "cpu_memory_peak_mb": 2469.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753598.9786503}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.5351999975100625, 1.9442999982857145, 2.081000002362998], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 21.578, "gpu_power_peak_watts": 21.578, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.91796875, "cpu_memory_peak_mb": 2469.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.102638}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.254099998244783, 12.099299998226343, 12.170599999080878], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6583.0390625, "gpu_memory_peak_mb": 6583.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 21.578, "gpu_power_peak_watts": 21.578, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2469.91796875, "cpu_memory_peak_mb": 2469.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.2275903}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.52509999924223, 12.765999999828637, 12.95140000001993], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6585.0390625, "gpu_memory_peak_mb": 6585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 22.308, "gpu_power_peak_watts": 22.308, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2471.453125, "cpu_memory_peak_mb": 2471.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.351919}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.964300000021467, 12.93690000238712, 12.815499998396263], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6585.0390625, "gpu_memory_peak_mb": 6585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 22.308, "gpu_power_peak_watts": 22.308, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2471.453125, "cpu_memory_peak_mb": 2471.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.4771338}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.957099999766797, 12.94400000188034, 12.763500002620276], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6585.0390625, "gpu_memory_peak_mb": 6585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 22.308, "gpu_power_peak_watts": 22.308, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2471.453125, "cpu_memory_peak_mb": 2471.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.6001074}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.758400000166148, 13.034300001891097, 12.87389999924926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6585.0390625, "gpu_memory_peak_mb": 6585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 22.308, "gpu_power_peak_watts": 22.308, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2471.45703125, "cpu_memory_peak_mb": 2471.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.7252493}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.735000000451691, 12.96849999926053, 13.303100000484847], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6585.0390625, "gpu_memory_peak_mb": 6585.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 19.443, "gpu_power_peak_watts": 19.443, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2471.45703125, "cpu_memory_peak_mb": 2471.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.8523543}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.191200000117533, 14.145900000585243, 14.630300000135321], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6587.0390625, "gpu_memory_peak_mb": 6587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 19.443, "gpu_power_peak_watts": 19.443, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2466.30078125, "cpu_memory_peak_mb": 2466.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753599.9724643}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.02560000133235, 13.678100000106497, 14.205199997377349], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6587.0390625, "gpu_memory_peak_mb": 6587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 19.443, "gpu_power_peak_watts": 19.443, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2472.9453125, "cpu_memory_peak_mb": 2472.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.098478}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.412399999855552, 14.24820000102045, 13.721899998927256], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6587.0390625, "gpu_memory_peak_mb": 6587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 19.443, "gpu_power_peak_watts": 19.443, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2466.23828125, "cpu_memory_peak_mb": 2466.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.2213988}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.465299998846604, 14.260899999499088, 13.98479999988922], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6587.0390625, "gpu_memory_peak_mb": 6587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 36.0, "gpu_power_mean_watts": 19.443, "gpu_power_peak_watts": 19.443, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2472.9453125, "cpu_memory_peak_mb": 2472.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.3505096}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [14.47810000172467, 14.35969999874942, 14.2431000022043], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6587.0390625, "gpu_memory_peak_mb": 6587.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 15.39, "gpu_power_peak_watts": 15.39, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2466.23828125, "cpu_memory_peak_mb": 2466.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.470433}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [22.47440000064671, 17.849199997726828, 17.6525999995647], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6579.0390625, "gpu_memory_peak_mb": 6579.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 15.39, "gpu_power_peak_watts": 15.39, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2470.078125, "cpu_memory_peak_mb": 2470.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.5959694}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.958099997485988, 17.735599998559337, 17.266599999857135], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6595.0390625, "gpu_memory_peak_mb": 6595.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 15.39, "gpu_power_peak_watts": 15.39, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2476.9921875, "cpu_memory_peak_mb": 2476.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.7216945}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [17.714800000248943, 17.543099998874823, 17.861199998151278], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6595.0390625, "gpu_memory_peak_mb": 6595.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 15.39, "gpu_power_peak_watts": 15.39, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2475.37109375, "cpu_memory_peak_mb": 2475.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.8483176}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.25520000056713, 18.210300000646384, 17.23839999976917], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6595.0390625, "gpu_memory_peak_mb": 6595.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 14.894, "gpu_power_peak_watts": 14.894, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2473.91796875, "cpu_memory_peak_mb": 2473.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753600.9705787}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [18.285299996932736, 20.364200001495192, 17.367500000545988], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6595.0390625, "gpu_memory_peak_mb": 6595.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 14.894, "gpu_power_peak_watts": 14.894, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2477.15625, "cpu_memory_peak_mb": 2477.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.095764}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.69539999886183, 20.267399999283953, 20.20760000232258], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6601.0390625, "gpu_memory_peak_mb": 6601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 14.894, "gpu_power_peak_watts": 14.894, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2473.93359375, "cpu_memory_peak_mb": 2473.93359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.2196128}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [21.016399998188717, 20.126299998082686, 20.145299997238908], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6601.0390625, "gpu_memory_peak_mb": 6601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 40.0, "gpu_power_mean_watts": 14.894, "gpu_power_peak_watts": 14.894, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2473.93359375, "cpu_memory_peak_mb": 2473.93359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.3434682}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.318999996845378, 5.745200000092154, 4.33089999933145], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6601.0390625, "gpu_memory_peak_mb": 6601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 15.378, "gpu_power_peak_watts": 15.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2494.640625, "cpu_memory_peak_mb": 2494.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.468822}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.650399999169167, 6.323900001007132, 5.226100001891609], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6601.0390625, "gpu_memory_peak_mb": 6601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 15.378, "gpu_power_peak_watts": 15.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2494.640625, "cpu_memory_peak_mb": 2494.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.5918832}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.695100001204992, 4.008600000815932, 5.157600000529783], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 6601.0390625, "gpu_memory_peak_mb": 6601.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 58.0, "gpu_power_mean_watts": 15.378, "gpu_power_peak_watts": 15.378, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2494.640625, "cpu_memory_peak_mb": 2494.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "export_time_s": 8.35722320000059, "file_size_mb": 432.862398147583, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "onnx_sanitization": {"changed": false, "constant_of_shape_scalar_rewrites": 0}, "valid": true, "onnx_sha256": "c14459446b17a5fe32d31cc24bd7c8ae9ca4e11b4d34b4519568cb338c685b5b", "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "exists": true, "onnx_file_size_bytes": 453889122, "onnx_file_size_mb": 432.862398147583, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 453889122, "total_artifact_size_mb": 432.862398147583, "initializer_count": 65, "initializer_numel": 113422080, "initializer_bytes_est": 453688320, "initializer_bytes_est_mb": 432.6708984375, "initializer_dtype_counts": {"FLOAT": 65}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m", "is_local_dir": true, "weight_files": [{"path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\models\\gpt2-75m\\model.safetensors", "name": "model.safetensors", "size_bytes": 299305224, "size_mb": 285.43970489501953}], "total_size_bytes": 299305224, "total_size_mb": 285.43970489501953}, "timestamp": 1765753168.5283976, "reused": false}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.28244249999989, "file_size_mb": 438.8343086242676, "engine_sha256": "8a54fbd9181d37d8ddc681e3ea30e1d8e8c799fbd0d41735dd97cddde10780ab", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp32.plan", "exists": true, "file_size_bytes": 460151124, "file_size_mb": 438.8343086242676, "deserialize_error": null, "num_layers": 390, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 339}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753238.0784807, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 149.4209805999999, "file_size_mb": 654.3703880310059, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_fp16.plan", "exists": true, "file_size_bytes": 686157084, "file_size_mb": 654.3703880310059, "deserialize_error": null, "num_layers": 382, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 108, "Float": 208, "Half": 123}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753394.673086, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\onnx\\gpt2-75m.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 79.88098290000198, "file_size_mb": 587.5064277648926, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "exists": true, "file_size_bytes": 616045140, "file_size_mb": 587.5064277648926, "deserialize_error": null, "num_layers": 444, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 109, "Float": 405}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tensorrt\\calib\\gpt2_wikitext2_test_512x8x128.calib", "cache_hit_before": true, "cache_size_bytes_before": 27442, "cache_sha256_before": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5", "cache_size_bytes_after": 27442, "cache_sha256_after": "23b9c1599ffc55be49127dd3fb5331b9086b53eac70f77438b2c7c78600540b5"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765753482.5191367, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 426.3933999973233, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2_crossover\\gpt2-75m\\tensorrt\\gpt2-75m_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765753601.7158966}
