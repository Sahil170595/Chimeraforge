{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [305.9397000033641, 41.88350000185892], "ttft_ms": [268.5831999988295, 4.842400005145464], "tokens_processed": [8, 8], "throughput_tok_s": [26.14894372947359, 191.00600474279693], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1914.348099999188], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1475.4114000024856, "compile_ms": 434.51659999846015, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765600956.9366086}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.616599999542814, 41.10980000405107], "ttft_ms": [4.5926000020699576, 5.011299996112939], "tokens_processed": [8, 8], "throughput_tok_s": [192.23098475338892, 194.60080076311874], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.721799996332265], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1475.4114000024856, "compile_ms": 434.51659999846015, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765600957.0261292}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [42.11140000552405, 41.14589999517193], "ttft_ms": [4.540999994787853, 5.153199999767821], "tokens_processed": [8, 8], "throughput_tok_s": [189.97231151067368, 194.43006474372226], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.4539999982807785], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1475.4114000024856, "compile_ms": 434.51659999846015, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765600957.1163287}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [43.72489999514073, 42.648900001950096], "ttft_ms": [5.008700005419087, 5.432000005384907], "tokens_processed": [8, 8], "throughput_tok_s": [182.96211085420578, 187.57810868824762], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [67.12939999852097], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2220.888700001524, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765600957.2717578}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.07930000079796, 41.557700002158526], "ttft_ms": [5.051000000094064, 5.419900000561029], "tokens_processed": [8, 8], "throughput_tok_s": [199.6042845019929, 192.50343497316925], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.367199999454897], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2220.888700001524, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765600957.3601604}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.70019999926444, 43.01310000300873], "ttft_ms": [4.822900002181996, 5.21630000002915], "tokens_processed": [8, 8], "throughput_tok_s": [196.5592306707235, 185.98984959094804], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8937999997870065], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2220.888700001524, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765600957.4497015}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.37129999656463, 31.16309999313671], "ttft_ms": [4.750300002342556, 3.6676999952760525], "tokens_processed": [8, 8], "throughput_tok_s": [232.75232536446367, 256.713869986038], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.580600002256688], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765600957.6777925}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.59210000053281, 33.19619999820134], "ttft_ms": [4.726699997263495, 4.451700006029569], "tokens_processed": [8, 8], "throughput_tok_s": [238.1512319823146, 240.99143879219497], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.029299995338079], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 145.61509999475675, "engine_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765600957.755205}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 128, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [32.804499998746905, 32.48329999769339], "ttft_ms": [3.998799998953473, 3.1344000017270446], "tokens_processed": [8, 8], "throughput_tok_s": [243.86898139906387, 246.28039640578612], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.357099995715544], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765600935.8612463}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 4, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765600935.8623188, "build_time_s": null, "file_size_mb": 2.966472625732422, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 145.61509999475675, "engine_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tr118\\sweeps\\baseline\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765600957.8312745}
