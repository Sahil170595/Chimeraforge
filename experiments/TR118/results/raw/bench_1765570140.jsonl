{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.2360000002663583, 1.823099999455735], "tokens_processed": [8, 8], "throughput_tok_s": [3577.8175308797045, 4388.130109367728], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [84.14679999987129, 2.4358999980904628, 1.9885999972757418], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.5532146}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.1368999987316784, 1.8442000000504777], "tokens_processed": [8, 8], "throughput_tok_s": [3743.740935349463, 4337.924303102175], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7202999988512602, 1.8197999997937586, 1.717099999950733], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.565255}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.9696000017574988, 1.8202999999630265], "tokens_processed": [8, 8], "throughput_tok_s": [4061.738420421151, 4394.879964930228], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1439000011014286, 1.8955000014102552, 1.835800001572352], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.5773628}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.8982000001415145, 1.8455000026733615], "tokens_processed": [8, 8], "throughput_tok_s": [4214.519017702868, 4334.868593016164], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.178099999582628, 1.913200001581572, 2.2325999998429324], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.5883634}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.0659000001614913, 1.695599999948172], "tokens_processed": [8, 8], "throughput_tok_s": [3872.4042787040225, 4718.093890212626], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1679999990737997, 2.1486000005097594, 2.0620000032067765], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.602106}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.425400001811795, 2.0904999983031303], "tokens_processed": [11, 11], "throughput_tok_s": [4535.334374446649, 5261.899071479913], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4735000006330665, 2.8510999982245266, 2.192700001614867], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.6170988}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.261899997392902, 2.554200000304263], "tokens_processed": [11, 11], "throughput_tok_s": [4863.1681385909, 4306.632213095941], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.174699999159202, 2.0137999999860767, 2.4293000024044886], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.6310341}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4859000004653353, 2.074300002277596], "tokens_processed": [11, 11], "throughput_tok_s": [4424.956755276122, 5302.993775211841], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0846999977948144, 2.1496999979717657, 1.9329999995534308], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.6450677}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.965100000234088, 2.4075000001175795], "tokens_processed": [11, 11], "throughput_tok_s": [5597.679506737393, 4569.055036121608], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4190999974962324, 2.013299999816809, 2.0178000013402198], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.6581166}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.470899999025278, 2.841400000761496], "tokens_processed": [11, 11], "throughput_tok_s": [4451.819176955477, 3871.3310329598075], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1830000005138572, 2.4962999996205326, 2.129599997715559], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.6734169}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.5831999994115904, 3.5158999999111984], "tokens_processed": [19, 19], "throughput_tok_s": [5302.522885443194, 5404.021729992288], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.416000000172062, 3.0976999987615272, 3.0848000023979694], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.697219}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.7436000020534266, 3.4439000010024756], "tokens_processed": [19, 19], "throughput_tok_s": [5075.328557959768, 5517.001072757438], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8500000007625204, 3.0358000003616326, 3.3215000003110617], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.7172403}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.3172000003105495, 3.351300001668278], "tokens_processed": [19, 19], "throughput_tok_s": [5727.722174792372, 5669.44170636523], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1065000002854504, 3.6271999997552484, 3.296099999715807], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.7382634}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.5654999992402736, 2.500899998267414], "tokens_processed": [19, 19], "throughput_tok_s": [5328.845885303173, 7597.264989868813], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.043400000227848, 4.9262000029557385, 5.717599997296929], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.7622907}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.514699997846037, 2.3648999995202757], "tokens_processed": [19, 19], "throughput_tok_s": [7555.573235882779, 8034.1663511582665], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5540999995428137, 2.0834000024478883, 2.2762999979022425], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.7773075}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.8258000020287, 2.8109999984735623], "tokens_processed": [27, 27], "throughput_tok_s": [9554.816328337512, 9605.122737339601], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.253499999118503, 2.336300000024494, 2.7539000002434477], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.7951639}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.001699999003904, 2.6108000020030886], "tokens_processed": [27, 27], "throughput_tok_s": [8994.902891348165, 10341.657721497144], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0307000015454832, 2.427499999612337, 2.7069999996456318], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.8115654}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.2198999979300424, 2.885399997467175], "tokens_processed": [27, 27], "throughput_tok_s": [8385.353587800033, 9357.454780515975], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9084999987389892, 2.673099999810802, 2.4831999980960973], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.8296556}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.122799997072434, 2.3980000005394686], "tokens_processed": [27, 27], "throughput_tok_s": [8646.08685324452, 11259.382816482868], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.776799999992363, 2.8929000000061933, 2.721400000154972], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.8476121}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.422300000645919, 5.656100001942832], "tokens_processed": [27, 27], "throughput_tok_s": [4979.436769781032, 4773.607254243328], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.642600000806851, 7.040399999823421, 5.56210000286228], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.8797324}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.70900000052643, 3.7219000005279668], "tokens_processed": [44, 44], "throughput_tok_s": [11863.035857038269, 11821.918910706472], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.834100000560284, 6.651300001976779, 5.25759999800357], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.9104905}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.634700002905447, 3.2384999976784457], "tokens_processed": [44, 44], "throughput_tok_s": [6631.799475595228, 13586.536986735182], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.150200001982739, 4.181899999821326, 7.107100002031075], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.9384868}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.0774999983550515, 6.397400000423659], "tokens_processed": [44, 44], "throughput_tok_s": [7239.819006484431, 6877.794103399219], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.851899998058798, 6.776199999876553, 6.649299997661728], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570168.9766052}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.450500000937609, 6.467300001531839], "tokens_processed": [44, 44], "throughput_tok_s": [6821.176651981149, 6803.457391736612], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.734300001175143, 7.24640000044019, 7.812199997715652], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.0171626}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.027399999060435, 6.758399998943787], "tokens_processed": [44, 44], "throughput_tok_s": [6261.206136819138, 6510.416667684124], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.489700001111487, 5.844199997227406, 6.397299999662209], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.055197}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9094000021577813, 6.3759000004210975], "tokens_processed": [76, 76], "throughput_tok_s": [19440.32331254209, 11919.885819253841], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.550500002660556, 6.248500001674984, 7.540900001913542], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.0939357}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.13829999990412, 5.762299999332754], "tokens_processed": [76, 76], "throughput_tok_s": [8316.645327992886, 13189.177933950059], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.765499998029554, 8.3178000022599, 8.614799997303635], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.1350584}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.036399998876732, 8.165999999619089], "tokens_processed": [76, 76], "throughput_tok_s": [8410.428932920982, 9306.882194898983], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.8068000002531335, 7.262900002388051, 8.055999998759944], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.180995}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.776600002514897, 4.064800003106939], "tokens_processed": [76, 76], "throughput_tok_s": [15910.898957414422, 18697.106854435453], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.040700002311496, 6.113200000982033, 4.272300000593532], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.2117555}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.858100001001731, 4.661099999793805], "tokens_processed": [76, 76], "throughput_tok_s": [15643.976036789887, 16305.164017798812], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.712500001915032, 3.703099999256665, 4.314499998145038], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 923.4870000000228, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765570169.237752}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5808000023534987, 0.540299999556737], "tokens_processed": [8, 8], "throughput_tok_s": [13774.104627380617, 14806.588944222123], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.601300002221251, 0.809000001027016, 0.6419000019377563], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2438204}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5090000013296958, 0.5357999980333261], "tokens_processed": [8, 8], "throughput_tok_s": [15717.092296858642, 14930.944437036764], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.656899999739835, 0.5520000013348181, 0.46999999904073775], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2487535}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5825999978696927, 0.7501000000047497], "tokens_processed": [8, 8], "throughput_tok_s": [13731.548282273287, 10665.24463398126], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5543000006582588, 0.490999998874031, 0.515899999300018], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2537978}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9295999989262782, 0.7635000001755543], "tokens_processed": [8, 8], "throughput_tok_s": [8605.851989286028, 10478.061556202398], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8602999987488147, 0.7212999989860691, 0.7626999977219384], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2607546}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7621000004292, 0.7829000023775734], "tokens_processed": [8, 8], "throughput_tok_s": [10497.310058384142, 10218.418668674109], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8291999984066933, 0.7769999974698294, 0.8875000021362212], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2667537}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0420999969937839, 0.8936999984143768], "tokens_processed": [11, 11], "throughput_tok_s": [10555.608897161925, 12308.380910279126], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2040999972668942, 1.9699999975273386, 0.9430999998585321], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2767515}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6821999995736405, 0.8525999983248767], "tokens_processed": [11, 11], "throughput_tok_s": [16124.303733325638, 12901.712434449872], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9329000022262335, 0.9391999992658384, 0.7030999986454844], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.283756}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6852000005892478, 0.6680999977106694], "tokens_processed": [11, 11], "throughput_tok_s": [16053.706933071204, 16464.601164036692], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.870699997904012, 1.009299998258939, 0.8699999998498242], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.290761}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7207000016933307, 0.7073000015225261], "tokens_processed": [11, 11], "throughput_tok_s": [15262.938773629523, 15552.099499959737], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8464000020467211, 0.8290000005217735, 0.6790000006731134], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.2972677}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6300999993982259, 0.6820000016887207], "tokens_processed": [11, 11], "throughput_tok_s": [17457.54643787573, 16129.032218126935], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6388000001606997, 0.7650000006833579, 0.7675999986531679], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3022702}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9828000002016779, 1.125899998442037], "tokens_processed": [19, 19], "throughput_tok_s": [19332.519328552156, 16875.38860137777], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.036099998804275, 1.2357999985397328, 1.1627000021690037], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3122673}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.6985000002023298, 1.9528000011632685], "tokens_processed": [19, 19], "throughput_tok_s": [11186.340887687176, 9729.61900280717], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.092499998776475, 1.3270999988890253, 1.306099999055732], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.323267}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5389000000141095, 1.5438999980688095], "tokens_processed": [19, 19], "throughput_tok_s": [12346.48125272974, 12306.496550143267], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4069999997445848, 1.6168000001925975, 1.299499999731779], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3362684}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.346900000498863, 1.7310000002908055], "tokens_processed": [19, 19], "throughput_tok_s": [14106.466696089396, 10976.314267364545], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4007999998284504, 1.1897000003955327, 1.430399999662768], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3462682}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3975999972899444, 1.613500000530621], "tokens_processed": [19, 19], "throughput_tok_s": [13594.733855783117, 11775.64300821295], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.888800001324853, 1.3820999993185978, 1.5134000022953842], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3582692}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.141799999662908, 1.7363000006298535], "tokens_processed": [27, 27], "throughput_tok_s": [12606.219070057643, 15550.30812083487], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4070000001520384, 1.8233000009786338, 1.8874999987019692], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3752697}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.0474000011745375, 1.7275999998673797], "tokens_processed": [27, 27], "throughput_tok_s": [13187.457255304698, 15628.617736786682], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.833700000133831, 1.7332999996142462, 1.8600999974296428], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.3882742}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.012299999478273, 1.774100001057377], "tokens_processed": [27, 27], "throughput_tok_s": [13417.48248620994, 15218.98426464562], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.380400001129601, 1.8364999996265396, 2.2552000009454787], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.4037812}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.646100001380546, 1.913200001581572], "tokens_processed": [27, 27], "throughput_tok_s": [16402.405672410987, 14112.481694375963], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8091999991156626, 2.078500001516659, 1.719699997920543], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.4167814}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5569999995932449, 1.7116999988502357], "tokens_processed": [27, 27], "throughput_tok_s": [17341.04046695797, 15773.79214706791], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7470999991928693, 2.007200000662124, 1.7608000016480219], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.430781}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.938900001026923, 2.520199999707984], "tokens_processed": [44, 44], "throughput_tok_s": [14971.588003887622, 17458.93183283005], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.024399997637374, 2.5471000008110423, 2.3155999988375697], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.450782}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6801999993040226, 2.6692999999795575], "tokens_processed": [44, 44], "throughput_tok_s": [16416.68532625388, 16483.722324331087], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.719499996601371, 2.567899999121437, 3.5807999993267003], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.4707823}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2137999987753574, 2.9428000016196165], "tokens_processed": [44, 44], "throughput_tok_s": [13690.957749942912, 14951.746627628077], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9393000004347414, 2.683699996850919, 2.7928000017709564], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.4907842}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.614299999549985, 3.165499998431187], "tokens_processed": [44, 44], "throughput_tok_s": [16830.509125798104, 13899.857849251706], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7432999995653518, 3.1573999985994305, 2.762699998129392], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.5112934}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7406000008340925, 2.967800002807053], "tokens_processed": [44, 44], "throughput_tok_s": [16054.878488874241, 14825.796872559878], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6658999995561317, 2.69299999854411, 3.3818000010796823], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.530296}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.620799998519942, 5.00359999932698], "tokens_processed": [76, 76], "throughput_tok_s": [16447.36842632078, 15189.063876053751], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.032299999787938, 4.567399999359623, 5.0498999989940785], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.563294}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.912499996862607, 4.80480000260286], "tokens_processed": [76, 76], "throughput_tok_s": [15470.73792336647, 15817.515808947139], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.874700000073062, 5.009600001358194, 4.782699998031603], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.59381}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.046599999332102, 4.948000001604669], "tokens_processed": [76, 76], "throughput_tok_s": [15059.644118824219, 15359.741304638785], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.0306000011914875, 4.551400001219008, 5.50189999921713], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.62581}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.136899999342859, 4.802899999049259], "tokens_processed": [76, 76], "throughput_tok_s": [14794.915223135033, 15823.773140195362], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.103999999846565, 4.962099999829661, 4.85090000074706], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.6588128}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.452599998330697, 4.687900000135414], "tokens_processed": [76, 76], "throughput_tok_s": [17068.678980481694, 16211.949913139075], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.62849999894388, 4.724299997178605, 4.300900000089314], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 85.8501000002434, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.6893241}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.4438000002410263, 2.984200000355486], "tokens_processed": [8, 8], "throughput_tok_s": [2323.015273662841, 2680.7854698234096], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [31.777899999724468, 3.5801000012725126, 3.52049999855808], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.7378402}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.007299997989321, 3.2620999991195276], "tokens_processed": [8, 8], "throughput_tok_s": [2660.193530857844, 2452.4079587257525], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.653899999335408, 3.936299999622861, 2.6787999995576683], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.7578425}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.976499999931548, 3.1215999988489784], "tokens_processed": [8, 8], "throughput_tok_s": [2687.720477132196, 2562.7883146302615], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2178000001295004, 2.767199999652803, 2.50909999886062], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.7748358}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.6109999996842816, 1.5969999985827599], "tokens_processed": [8, 8], "throughput_tok_s": [4965.859715436259, 5009.392615591429], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.036699999938719, 2.98800000018673, 1.7079000026569702], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.7879882}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.897499998449348, 1.8003999975917395], "tokens_processed": [8, 8], "throughput_tok_s": [4216.073784736582, 4443.4570154971125], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5491999984078575, 2.0453000033739954, 1.4953000027162489], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.798659}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.2934999979042914, 1.8030999999609776], "tokens_processed": [11, 11], "throughput_tok_s": [4796.163073926907, 6100.604514579369], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.065500000753673, 2.079099998809397, 1.677600001130486], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.810655}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.227500001026783, 1.7374000017298386], "tokens_processed": [11, 11], "throughput_tok_s": [4938.271602661937, 6331.299636841184], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3427999985869974, 1.865199999883771, 1.684499999100808], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.823719}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.9613000004028436, 1.6990000003715977], "tokens_processed": [11, 11], "throughput_tok_s": [5608.524956784093, 6474.396702527445], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6265999986208044, 1.706800001556985, 1.5591999981552362], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.8347323}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.0314999967231415, 3.249800000048708], "tokens_processed": [11, 11], "throughput_tok_s": [3628.5667200693715, 3384.8236814065885], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.635799999552546, 1.974099999642931, 2.440500000375323], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.8511622}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4018000005744398, 3.819199999270495], "tokens_processed": [11, 11], "throughput_tok_s": [3233.58222063099, 2880.1843323473786], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.048900001682341, 2.1918000020377804, 3.5535999995772727], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.8701532}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.440799999021692, 2.220499998657033], "tokens_processed": [19, 19], "throughput_tok_s": [7784.333008692017, 8556.631394501812], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.757700000482146, 4.29699999949662, 3.5017999980482273], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.8903062}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3358000034932047, 2.239599998574704], "tokens_processed": [19, 19], "throughput_tok_s": [8134.258057875405, 8483.657801434061], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.258399999846006, 3.0929999993531965, 2.3485000019718427], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.9060674}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.2486999987449963, 2.9042999994999263], "tokens_processed": [19, 19], "throughput_tok_s": [8449.326282120308, 6542.023896729503], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.067699999519391, 2.2544000021298416, 2.851000001101056], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.9220743}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.7924999994866084, 2.9830999992555007], "tokens_processed": [19, 19], "throughput_tok_s": [6803.939123900836, 6369.213236144237], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.867700000933837, 2.4902000004658476, 1.8841999990399927], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.9380865}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.0236000020522624, 2.4234000011347234], "tokens_processed": [19, 19], "throughput_tok_s": [6283.8999825055525, 7840.224474335031], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.330800001800526, 2.007199997024145, 2.4951999985205475], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.9540792}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.3747000015864614, 3.11620000138646], "tokens_processed": [27, 27], "throughput_tok_s": [8000.711170565437, 8664.398943581014], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.549500001303386, 3.543599999829894, 2.933900002972223], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.974956}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.283400001237169, 3.4487000011722557], "tokens_processed": [27, 27], "throughput_tok_s": [8223.18328252011, 7829.037025784315], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.325300000142306, 3.429399999731686, 3.215100001398241], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570169.9956074}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.184600001986837, 3.098400000453694], "tokens_processed": [27, 27], "throughput_tok_s": [8478.30182225554, 8714.175056818498], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.371599999809405, 3.220099999452941, 3.3894999978656415], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.0167232}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.8415000015229452, 2.996399998664856], "tokens_processed": [27, 27], "throughput_tok_s": [9502.023574002793, 9010.812979585748], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.414799997699447, 3.2155000008060597, 3.150900000036927], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.0356843}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.673499999422347, 2.684600000065984], "tokens_processed": [27, 27], "throughput_tok_s": [7349.93875166618, 10057.364225335758], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4641999991436023, 2.645799999299925, 2.977600001031533], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.0556848}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.940700000588549, 4.195600002276478], "tokens_processed": [44, 44], "throughput_tok_s": [8905.620659979073, 10487.177036925867], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.48679999721935, 4.0422000020043924, 4.607799997756956], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.0837717}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.50020000062068, 4.919099999824539], "tokens_processed": [44, 44], "throughput_tok_s": [9777.343227841297, 8944.72566151724], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.941399998642737, 3.5930000012740493, 4.35039999865694], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.1099327}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.858700001728721, 4.661399998440174], "tokens_processed": [44, 44], "throughput_tok_s": [11402.804048070006, 9439.22427054609], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.029200001445133, 4.593899997416884, 4.955899999913527], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.1380792}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.423900001711445, 4.942100000334904], "tokens_processed": [44, 44], "throughput_tok_s": [9945.975266841026, 8903.097872770344], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.322599997976795, 4.724700000224402, 4.8357999985455535], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.1650445}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.620600000635022, 4.883800000243355], "tokens_processed": [44, 44], "throughput_tok_s": [9522.572824731194, 9009.377942955798], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.695999999763444, 4.38410000060685, 4.3031999994127546], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.1910489}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [12.063900001521688, 10.972899999615038], "tokens_processed": [76, 76], "throughput_tok_s": [6299.786966935542, 6926.154435260169], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.733200000075158, 7.592000001750421, 10.722399998485344], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.2468395}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.51670000035665, 11.345800001436146], "tokens_processed": [76, 76], "throughput_tok_s": [6599.112592812735, 6698.513986706971], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.06910000089556, 11.359600001014769, 11.103699998784577], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.3108714}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.119700000155717, 7.79310000143596], "tokens_processed": [76, 76], "throughput_tok_s": [8333.60746501555, 9752.21670272372], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.269500002323184, 7.719400000496535, 8.296899999550078], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.361335}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.4601999986043666, 7.331999997404637], "tokens_processed": [76, 76], "throughput_tok_s": [10187.39444173318, 10365.521007488038], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.20200000089244, 7.859299999836367, 8.242399999289773], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.4068503}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.9311000008601695, 7.95510000170907], "tokens_processed": [76, 76], "throughput_tok_s": [9582.5295345863, 9553.619688460509], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.044199999858392, 7.2093000017048325, 7.670099999813829], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 234.58360000222456, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765570170.4518502}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6515000022773165, 0.5660999995598104], "tokens_processed": [8, 8], "throughput_tok_s": [12279.35529092252, 14131.77884864982], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0077000008313917, 0.5396000015025493, 0.6981000005907845], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.458864}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.032899999700021, 0.9776000006240793], "tokens_processed": [8, 8], "throughput_tok_s": [7745.183466282692, 8183.306050422431], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6350999976566527, 0.9310000023106113, 0.8197999995900318], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.4678621}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.4721000004792586, 0.6265000010898802], "tokens_processed": [8, 8], "throughput_tok_s": [16945.562363649, 12769.353529262464], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8298000029753894, 0.5974000014248304, 0.4487999976845458], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.4739733}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.0701000028348062, 1.144699999713339], "tokens_processed": [8, 8], "throughput_tok_s": [7475.936808529266, 6988.730673541886], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1892000002262648, 1.6018000023905188, 0.9815999983402435], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.4839191}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7092000014381483, 0.7666000019526109], "tokens_processed": [8, 8], "throughput_tok_s": [11280.315825969024, 10435.690033424416], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1212999997951556, 0.9551999974064529, 0.8573999984946568], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.4920354}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9563999992678873, 1.2448000015865546], "tokens_processed": [11, 11], "throughput_tok_s": [11501.46383147257, 8836.760914187014], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.220800000941381, 1.163000000815373, 1.0293999985151459], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5027769}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1354000016581267, 1.603400000021793], "tokens_processed": [11, 11], "throughput_tok_s": [9688.215592686023, 6860.421603998061], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5069000000949018, 1.6130000003613532, 1.025000001391163], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5137854}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1030000023311004, 1.0182000005443115], "tokens_processed": [11, 11], "throughput_tok_s": [9972.801429512601, 10803.378505322724], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.279600000998471, 1.1215000013180543, 1.203799998620525], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5226667}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2072999998054001, 1.1092000022472348], "tokens_processed": [11, 11], "throughput_tok_s": [9111.239958397287, 9917.057318530511], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4945999973861035, 1.2864000018453225, 1.2141000006522518], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5337846}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.120599998102989, 0.9427999975741841], "tokens_processed": [11, 11], "throughput_tok_s": [9816.169925594666, 11667.373810249153], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5982999975676648, 1.0947000009764452, 1.396999999997206], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5446675}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4628999997512437, 1.4269999992393423], "tokens_processed": [19, 19], "throughput_tok_s": [12987.900747303864, 13314.646117819122], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.191399998991983, 1.575900001625996, 1.5184000003500842], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5566666}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7791999996697996, 0.7546999986516312], "tokens_processed": [19, 19], "throughput_tok_s": [24383.98358322844, 25175.566495224524], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.059099999110913, 1.0269999984302558, 0.973300000623567], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.564785}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7264000014401972, 0.5827999993925914], "tokens_processed": [19, 19], "throughput_tok_s": [26156.387613339266, 32601.2354492146], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6660000001138542, 0.8675999997649342, 0.8825000004435424], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5716784}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.1659000010695308, 1.1360999997123145], "tokens_processed": [19, 19], "throughput_tok_s": [16296.423348975446, 16723.87994438097], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5313999974750914, 0.8667000001878478, 0.880300001881551], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5808632}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.999800002318807, 1.2062000023433939], "tokens_processed": [19, 19], "throughput_tok_s": [19003.80071607707, 15751.948236682956], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5840999985812232, 1.8650999991223216, 1.4278000016929582], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.5919685}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2088000003132038, 1.073999999789521], "tokens_processed": [27, 27], "throughput_tok_s": [22336.201185476686, 25139.66480939606], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.101600002788473, 0.876300000527408, 1.5291999989131], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.6024833}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0323000024072826, 1.1586000000534113], "tokens_processed": [27, 27], "throughput_tok_s": [26155.18738451717, 23303.987570132318], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5896000006468967, 1.6160000013769604, 1.9876000005751848], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.6154578}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5180999980657361, 1.2067999996361323], "tokens_processed": [27, 27], "throughput_tok_s": [17785.389654437546, 22373.218435648734], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8282999990333337, 1.2117000005673617, 0.8178999996744096], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.625465}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [0.8635000012873206, 1.1617999989539385], "tokens_processed": [27, 27], "throughput_tok_s": [31268.094915747464, 23239.800330788657], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.305900001374539, 1.1115000015706755, 1.1749000004783738], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.63646}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0823000011441763, 0.9234000026481226], "tokens_processed": [27, 27], "throughput_tok_s": [24946.872374994346, 29239.76599801767], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.774600001226645, 1.880299998447299, 1.0452999995322898], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.6474493}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.5878999984124675, 2.2280999983195215], "tokens_processed": [44, 44], "throughput_tok_s": [27709.55352603427, 19747.767170766885], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [38.85719999743742, 2.3705000021436717, 1.6069999983301386], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.7262528}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4940000005008187, 1.6379999979108106], "tokens_processed": [44, 44], "throughput_tok_s": [12593.016598080476, 26862.026896288073], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.29459999941173, 2.9036000014457386, 3.1132000003708526], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.7473342}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3641000009083655, 3.2272999997076113], "tokens_processed": [44, 44], "throughput_tok_s": [13079.278258113383, 13633.68760387517], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.531999998813262, 3.3777999997255392, 2.2714999977324624], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.7673204}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.467500002239831, 1.524999999674037], "tokens_processed": [44, 44], "throughput_tok_s": [17831.813560307906, 28852.459022560546], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8335999995761085, 2.3832000006223097, 1.7483999981777743], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.7824628}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6084000017144717, 1.645799999096198], "tokens_processed": [44, 44], "throughput_tok_s": [27356.378981035974, 26734.71869252819], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3284999990428332, 1.6068000004452188, 2.262699999846518], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.797246}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.391300000657793, 3.064199998334516], "tokens_processed": [76, 76], "throughput_tok_s": [22410.285137044397, 24802.5585932081], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.4087000023864675, 2.996200000779936, 2.022099997702753], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.8178189}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.084500000521075, 2.683999999135267], "tokens_processed": [76, 76], "throughput_tok_s": [14947.389122275797, 28315.946357856086], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.293300000834279, 5.916999998589745, 4.989799999748357], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.848704}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.1468999990902375, 5.680899997969391], "tokens_processed": [76, 76], "throughput_tok_s": [14766.169930139251, 13378.161915746768], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.955500000913162, 5.19469999926514, 5.221300001721829], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.8837295}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.10589999955846, 4.994099999748869], "tokens_processed": [76, 76], "throughput_tok_s": [18509.949099630503, 15217.957190248833], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.95590000032098, 4.353899999841815, 5.238699999608798], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9162996}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.813300001434982, 3.5031999977945816], "tokens_processed": [76, 76], "throughput_tok_s": [27014.538073164833, 21694.45080150872], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9192000003822614, 3.0242000029829796, 3.707100000610808], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 42.98459999699844, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9382968}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.4833000020880718, 0.49959999887505546], "tokens_processed": [8, 8], "throughput_tok_s": [16552.865643361118, 16012.81028425445], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9180999990785494, 0.7191999975475483, 0.5399000001489185], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9483495}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.8864999981597066, 1.3208000018494204], "tokens_processed": [8, 8], "throughput_tok_s": [9024.252697808543, 6056.935182312372], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.541099998576101, 1.5574999997625127, 1.0872000020754058], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9583397}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.060999999026535, 0.9630999993532896], "tokens_processed": [8, 8], "throughput_tok_s": [7540.056557342112, 8306.510232968441], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8319000007759314, 1.3153999971109442, 0.9671999978309032], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.967298}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9033000023919158, 0.7516000005125534], "tokens_processed": [8, 8], "throughput_tok_s": [8856.415342429094, 10643.959545695054], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8146999973396305, 0.973300000623567, 0.8931000011216383], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.976297}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.0269000013067853, 0.945200001297053], "tokens_processed": [8, 8], "throughput_tok_s": [7790.4372283762505, 8463.817169934386], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2855000022682361, 0.9816000019782223, 1.2968000010005198], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9863052}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2968000010005198, 1.0885000010603108], "tokens_processed": [11, 11], "throughput_tok_s": [8482.41825378869, 10105.649967188672], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8878000009863172, 1.182100000733044, 0.9783999994397163], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570170.9968166}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.3115000001562294, 1.227099997777259], "tokens_processed": [11, 11], "throughput_tok_s": [8387.342736324552, 8964.224610810163], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9246999981987756, 1.0494000016478822, 1.0399000020697713], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0068133}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.095399999030633, 1.3149000005796552], "tokens_processed": [11, 11], "throughput_tok_s": [10041.993801108616, 8365.65517921576], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6937000000325497, 1.4985999987402465, 1.0332999991078395], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0178146}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7277000004251022, 0.5421999994723592], "tokens_processed": [11, 11], "throughput_tok_s": [15116.119271092626, 20287.716729444168], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4334000006783754, 0.9069000007002614, 1.1190999975951854], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0258133}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6160000011732336, 0.6668999994872138], "tokens_processed": [11, 11], "throughput_tok_s": [17857.142823132144, 16494.22703322539], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0222000018984545, 0.9275999982492067, 0.7446000017807819], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.032814}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.7785999989428092, 1.3531999975384679], "tokens_processed": [19, 19], "throughput_tok_s": [10682.559322665862, 14040.792221816333], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6450999976077583, 1.5973000008671079, 2.160200001526391], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0468128}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.1887999973841943, 1.6647999982524198], "tokens_processed": [19, 19], "throughput_tok_s": [8680.555565929571, 11412.782328174408], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.955600000655977, 2.0612000007531606, 1.6233999995165505], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0618136}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5806999981577974, 2.040700001089135], "tokens_processed": [19, 19], "throughput_tok_s": [12019.991157172935, 9310.530695280822], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1118000004207715, 1.6942999973252881, 1.9791999984590802], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0758128}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4330999983940274, 2.1124999984749593], "tokens_processed": [19, 19], "throughput_tok_s": [13257.972242894384, 8994.082846729629], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.263699999981327, 1.094899998861365, 1.9008999988727737], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.0878193}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4955000006011687, 2.1034999990661163], "tokens_processed": [19, 19], "throughput_tok_s": [12704.781004588622, 9032.564777007543], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8997999977727886, 1.555999999254709, 1.77590000021155], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1013303}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.3211000006995164, 2.035400000750087], "tokens_processed": [27, 27], "throughput_tok_s": [11632.415661480736, 13265.20585145423], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.331900002900511, 2.482899999449728, 2.0475999990594573], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1173291}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0886999989452306, 1.2977000005776063], "tokens_processed": [27, 27], "throughput_tok_s": [24800.22047043126, 20806.041448703323], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2592000022996217, 1.5901000006124377, 1.5292999996745493], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1293333}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7157999973278493, 2.455900001223199], "tokens_processed": [27, 27], "throughput_tok_s": [15736.099803036035, 10993.932972251407], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.114099999947939, 2.8101000025344547, 2.0172000004095025], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1463282}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0228999999526422, 1.4709999995830003], "tokens_processed": [27, 27], "throughput_tok_s": [26395.542087447488, 18354.860644224318], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6287999971827958, 1.2846999998146202, 0.9178999971481971], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1583292}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.00070000209962, 2.5152999987767544], "tokens_processed": [27, 27], "throughput_tok_s": [13495.27663900887, 10734.306052212736], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2110000029206276, 2.5152999987767544, 2.5647000002209097], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.1773286}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.7364000013913028, 1.7731000007188413], "tokens_processed": [44, 44], "throughput_tok_s": [25339.78343972857, 24815.29523555453], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.265899999154499, 1.4211999987310264, 2.206299999670591], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.2204509}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4550000016461127, 3.221200000552926], "tokens_processed": [44, 44], "throughput_tok_s": [17922.60691262622, 13659.505771900938], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.770700001041405, 3.0230999982450157, 3.6756999979843386], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.2424889}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.110599998763064, 2.473099997587269], "tokens_processed": [44, 44], "throughput_tok_s": [14145.180999645305, 17791.43586710038], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.250699999829521, 3.1453000010515098, 3.0636000010417774], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.2644875}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6415999998571351, 2.088100001856219], "tokens_processed": [44, 44], "throughput_tok_s": [26803.118910714682, 21071.787730897056], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.431799999612849, 2.2314999987429474, 1.6495999989274424], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.278488}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.6489000012807082, 1.8975999992107973], "tokens_processed": [44, 44], "throughput_tok_s": [12058.428563281173, 23187.183820773287], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.332799999247072, 2.3805000018910505, 3.397700002096826], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.3000093}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.4918999994697515, 5.201299998589093], "tokens_processed": [76, 76], "throughput_tok_s": [13838.562247553284, 14611.731686427585], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.891299999551848, 5.622600001515821, 5.194800000026589], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.3340087}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.142199999681907, 5.149000000528758], "tokens_processed": [76, 76], "throughput_tok_s": [14779.66629160696, 14760.147599960274], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.374000000505475, 5.559799999900861, 4.538799999863841], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.3670082}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.801499999302905, 5.364500000723638], "tokens_processed": [76, 76], "throughput_tok_s": [15828.386964705589, 14167.210362521777], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.552999999257736, 5.108800000016345, 5.493799999385374], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.4015274}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.530599999066908, 2.5696999982756097], "tokens_processed": [76, 76], "throughput_tok_s": [21526.08622332913, 29575.43684126536], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.171500000869855, 3.5144000030413736, 2.7541000017663464], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.4255283}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.525900000066031, 4.549699999188306], "tokens_processed": [76, 76], "throughput_tok_s": [13753.41573301939, 16704.39809516207], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.193199998961063, 5.464099998789607, 5.020900000090478], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 40.25360000014189, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765570171.457525}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.459526}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.459526}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4605253}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4605253}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4605253}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4605253}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4615276}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4615276}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4615276}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4615276}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4625266}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4625266}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4625266}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.463525}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.463525}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.463525}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4645252}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4645252}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4645252}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4645252}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4645252}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4655297}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4655297}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4655297}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4655297}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4655297}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4665248}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4665248}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4665248}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "int8", "success": false, "error": "Engine build failed (returned None)"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765570171.4665248}
