{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.8710000005958136, 2.935099999376689], "tokens_processed": [1, 1], "throughput_tok_s": [348.31069306599505, 340.70389431786464], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [124.29760000122769, 3.0709000002389075, 2.936200000476674], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.3440247}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.740300000368734, 2.7727000015147496], "tokens_processed": [1, 1], "throughput_tok_s": [364.9235484674818, 360.65928497626555], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8453000013541896, 2.7394999997341074, 2.9381000003922964], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.360782}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.683900000192807, 2.8466999992815545], "tokens_processed": [1, 1], "throughput_tok_s": [372.59212337574485, 351.2839428996306], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7699999991455115, 2.7914000002056127, 2.7853000010509277], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.377301}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.6634999994712416, 2.691400000912836], "tokens_processed": [1, 1], "throughput_tok_s": [375.4458420118341, 371.55383802512904], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.693300000828458, 2.769599999737693, 2.8904999999213032], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.3931117}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.9559000013250625, 2.7893000005860813], "tokens_processed": [1, 1], "throughput_tok_s": [338.3064378198595, 358.51288846301304], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7331000001140637, 3.066599998419406, 3.0523000004905043], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.4107676}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.584699999919394, 3.725000000486034], "tokens_processed": [11, 11], "throughput_tok_s": [3068.5970932706637, 2953.020133842881], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.947299999315874, 4.625800000212621, 3.6770999995496823], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.4417849}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.5880999985238304, 4.099800000403775], "tokens_processed": [11, 11], "throughput_tok_s": [3065.68936331916, 2683.0577098679564], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.98979999954463, 3.5148000006302027, 3.4124999983760063], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.4629123}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3660999997664476, 3.330100000312086], "tokens_processed": [11, 11], "throughput_tok_s": [3267.876771564487, 3303.20410767518], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3325000003969762, 3.540199999406468, 3.7871000004088273], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.48326}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3929000001080567, 3.5574000012275064], "tokens_processed": [11, 11], "throughput_tok_s": [3242.064310663348, 3092.1459482218393], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8715999999112682, 3.9164000008895528, 3.5801000012725126], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.5053074}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.855999999359483, 3.863699999783421], "tokens_processed": [11, 11], "throughput_tok_s": [2852.697095909544, 2847.011931727775], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8316000009217532, 3.8907999987713993, 3.3534000012878096], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.526349}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.395100000692764, 4.362499999842839], "tokens_processed": [19, 19], "throughput_tok_s": [4322.9960631169215, 4355.3008597557555], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.052099999782513, 4.537500000878936, 4.4543000003614], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.5544581}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.4340999993437435, 4.436199998963275], "tokens_processed": [19, 19], "throughput_tok_s": [4284.973275932442, 4282.944863721256], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9342000000033295, 3.922600000805687, 4.2424000002938556], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.5785985}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.092200000741286, 3.773399999772664], "tokens_processed": [19, 19], "throughput_tok_s": [4642.979325682572, 5035.246727392986], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.486799998630886, 4.4613999998546205, 3.976100000727456], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.6026337}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.8985000010143267, 4.0793999996822095], "tokens_processed": [19, 19], "throughput_tok_s": [4873.6693587422105, 4657.547678943012], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.485400000703521, 3.7675000003218884, 3.829000001132954], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.6260242}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.882299999531824, 4.290000000764849], "tokens_processed": [19, 19], "throughput_tok_s": [4894.006130976806, 4428.904428114815], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.378999999971711, 3.855200000543846, 4.009500000393018], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.649148}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.558599999654689, 4.215699998894706], "tokens_processed": [27, 27], "throughput_tok_s": [5922.871057352089, 6404.630312185164], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.0575999994180165, 4.418500000610948, 4.305899999963003], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.6763816}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.592500001308508, 4.748800000015763], "tokens_processed": [27, 27], "throughput_tok_s": [5879.150787655326, 5685.646900250669], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.550800000288291, 4.447700001037447, 4.287800000383868], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.7026448}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.536600001301849, 4.886299999270705], "tokens_processed": [27, 27], "throughput_tok_s": [5951.5937028285325, 5525.65335817077], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.750699999931385, 4.211199999190285, 4.695399999036454], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.7291954}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.3513000000530155, 4.526300001089112], "tokens_processed": [27, 27], "throughput_tok_s": [6205.042171229526, 5965.137086252193], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.014300000562798, 4.755699999805074, 4.179399998974986], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.7551656}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.308700001274701, 4.262300000846153], "tokens_processed": [27, 27], "throughput_tok_s": [6266.391253049, 6334.608074194673], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.078199999843491, 3.952999999455642, 4.746399999930873], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.7804875}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.053200000678771, 5.460200000015902], "tokens_processed": [44, 44], "throughput_tok_s": [7268.882573690956, 8058.312882288534], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.196800000907388, 5.986399999528658, 5.036500000642263], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.814124}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.0546000004251255, 5.477400000017951], "tokens_processed": [44, 44], "throughput_tok_s": [7267.201796470539, 8033.008361605104], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.012100000589271, 5.565999999816995, 5.490900000950205], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.8452568}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.1768999997439096, 5.809899999803747], "tokens_processed": [44, 44], "throughput_tok_s": [13849.979540919401, 7573.28009113518], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.674100000760518, 6.006100000377046, 5.447499999718275], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.876458}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.577899999683723, 6.149800001367112], "tokens_processed": [44, 44], "throughput_tok_s": [6689.064899453564, 7154.704216432847], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.626799999139621, 5.630800000290037, 5.728500000259373], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.9117548}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.961999999271939, 5.383700001402758], "tokens_processed": [44, 44], "throughput_tok_s": [7380.07380163924, 8172.817948350672], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.458100000600098, 5.8364999986224575, 5.7238999997935025], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.9448998}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.3313000011694385, 9.062299999641255], "tokens_processed": [76, 76], "throughput_tok_s": [10366.510712680834, 8386.391975879034], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.457500000280561, 7.658700000320096, 8.45360000130313], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567368.9913871}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.256299999426119, 7.366599998931633], "tokens_processed": [76, 76], "throughput_tok_s": [10473.657374420935, 10316.835447970863], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.362099999227212, 7.608500000060303, 7.109999998647254], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567369.0321825}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.662900001378148, 7.369400000243331], "tokens_processed": [76, 76], "throughput_tok_s": [9917.916191824459, 10312.915569448061], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.465099999331869, 6.601499999305815, 7.68430000061926], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567369.072962}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.433999999193475, 6.770100000721868], "tokens_processed": [76, 76], "throughput_tok_s": [10223.29836000072, 11225.831227293014], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.025999999314081, 7.251600000017788, 7.1446000001742505], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567369.1128268}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.634699999471195, 7.64319999871077], "tokens_processed": [76, 76], "throughput_tok_s": [9954.549622809544, 9943.479172705074], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.982900000366499, 7.828699999663513, 6.868600001325831], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1013.6051999998017, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567369.154309}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.25040000036824495, 0.2616000001580687], "tokens_processed": [1, 1], "throughput_tok_s": [3993.6102177690623, 3822.629967109181], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.059099999110913, 0.27489999956742395, 0.26869999965128954], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1578236}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.25010000172187574, 0.2583999994385522], "tokens_processed": [1, 1], "throughput_tok_s": [3998.4006122161177, 3869.9690486562913], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.27580000096349977, 0.25770000138436444, 0.2550999997765757], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1598287}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.26450000041222665, 0.3605999991123099], "tokens_processed": [1, 1], "throughput_tok_s": [3780.7183305916337, 2773.1558581855325], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.25039999854925554, 0.24899999880290125, 0.24790000134089496], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1628304}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.24230000053648837, 0.24370000028284267], "tokens_processed": [1, 1], "throughput_tok_s": [4127.115137374539, 4103.405822073786], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.25149999964924064, 0.24750000011408702, 0.24669999947946053], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1648214}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.24389999998675194, 0.23919999875943176], "tokens_processed": [1, 1], "throughput_tok_s": [4100.041000632708, 4180.602028370911], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.24990000019897707, 0.2502999996067956, 0.2426999999443069], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.16735}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.3061999998171814, 1.0851999995793449], "tokens_processed": [11, 11], "throughput_tok_s": [8421.374982039186, 10136.380394640546], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6407000002800487, 1.198800000565825, 1.6190999995160382], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1778657}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0517999999137828, 1.0428000005049398], "tokens_processed": [11, 11], "throughput_tok_s": [10458.262027858606, 10548.523201643298], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1486000003060326, 1.0094999997818377, 1.0770999997475883], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.1858776}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9996000007959083, 1.1394000011932803], "tokens_processed": [11, 11], "throughput_tok_s": [11004.401751942283, 9654.20395688944], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0008999997808132, 1.0765000006358605, 2.0863999998255167], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.196398}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9874999996100087, 1.1814999998023268], "tokens_processed": [11, 11], "throughput_tok_s": [11139.24051072831, 9310.198901261429], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1687000005622394, 1.0690999988582917, 0.9906999985105358], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.204917}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0247000009258045, 0.9893999995256308], "tokens_processed": [11, 11], "throughput_tok_s": [10734.849214464359, 11117.849206866753], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3180999994801823, 1.3906999993196223, 1.0726000000431668], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2134285}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5989000003173715, 1.4772000013181241], "tokens_processed": [19, 19], "throughput_tok_s": [11883.169676795686, 12862.17166466698], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4740999997447943, 1.4156999986880692, 1.4718000002176268], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2259412}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5002000000094995, 1.5424000011989847], "tokens_processed": [19, 19], "throughput_tok_s": [12664.978002852746, 12318.464720714697], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.743200000419165, 1.34030000117491, 1.6398999996454222], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2384787}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.9730000003619352, 1.8957000011141645], "tokens_processed": [19, 19], "throughput_tok_s": [9630.005066657153, 10022.682908072524], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.765299999533454, 1.6285000001516892, 1.756300000124611], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2529984}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.73960000029183, 1.316699999733828], "tokens_processed": [19, 19], "throughput_tok_s": [10922.05104438527, 14430.01443293147], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.653400000577676, 1.9076000007771654, 1.6292999989673262], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2670214}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.356599999780883, 1.5390999997180188], "tokens_processed": [19, 19], "throughput_tok_s": [14005.602243158532, 12344.876878358147], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.945500000147149, 1.7291999993176432, 1.3496999999915715], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.2795453}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.4728999997023493, 2.068899999358109], "tokens_processed": [27, 27], "throughput_tok_s": [10918.354969165699, 13050.413267135647], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.559600000400678, 2.619099999719765, 2.0629999999073334], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3015747}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.8946000000141794, 2.334599999812781], "tokens_processed": [27, 27], "throughput_tok_s": [14251.029240894082, 11565.150347881958], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.17999999949825, 2.3753999994369224, 2.0850000000791624], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3186042}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.179300001444062, 2.021099999183207], "tokens_processed": [27, 27], "throughput_tok_s": [12389.299308084743, 13359.061902385627], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.369699999690056, 2.028799999607145, 2.5383000011061085], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3356388}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.0469000010052696, 2.6474999995116377], "tokens_processed": [27, 27], "throughput_tok_s": [13190.678580653579, 10198.300285167314], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.55019999895012, 2.2360000002663583, 2.274099999340251], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3536675}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7593999982636888, 1.4515999991999706], "tokens_processed": [27, 27], "throughput_tok_s": [15346.140744939, 18600.1653450542], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.187000000049011, 2.166499998565996, 1.8387000000075204], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3686893}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8770999997504987, 3.4272000011696946], "tokens_processed": [44, 44], "throughput_tok_s": [15293.177158880702, 12838.468716439926], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.550000001472654, 3.568400001313421, 2.80410000050324], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.3937218}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.56860000101733, 3.3225000006495975], "tokens_processed": [44, 44], "throughput_tok_s": [12329.765170502875, 13243.03987701952], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.611399999499554, 3.0871999988448806, 3.431199998885859], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.4172502}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.6925999993400183, 2.751299998635659], "tokens_processed": [44, 44], "throughput_tok_s": [11915.723340698738, 15992.439945414582], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.04869999854418, 4.056300000229385, 3.8937999997870065], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.441801}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.410400000575464, 3.8638000005448703], "tokens_processed": [44, 44], "throughput_tok_s": [12901.712406924562, 11387.752987679267], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.055299999687122, 3.500200000416953, 3.1662999990658136], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.4658353}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2582999992882833, 3.3108999996329658], "tokens_processed": [44, 44], "throughput_tok_s": [13503.97446816162, 13289.437918655858], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5182999999960884, 3.4446000008756528, 3.0858999998599757], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.488906}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.483799999637995, 6.021499999405933], "tokens_processed": [76, 76], "throughput_tok_s": [13859.00288212864, 12621.43984181649], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.602900000871159, 6.021900000632741, 6.596999999601394], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.5309587}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.154000000606175, 6.066599999030586], "tokens_processed": [76, 76], "throughput_tok_s": [12349.691256502101, 12527.610195520463], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.353900000045542, 5.989999999655993, 6.191000000399072], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.5715306}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.469300000186195, 5.725600000005215], "tokens_processed": [76, 76], "throughput_tok_s": [13895.745341709668, 13273.718038272107], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.392500001311419, 6.093500000133645, 6.0260000009293435], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.613591}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.781600000773324, 6.232300000192481], "tokens_processed": [76, 76], "throughput_tok_s": [13145.150129693258, 12194.534922525036], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.792899999505607, 5.796699999336852, 6.08260000080918], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.6541705}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.648100001053535, 6.0493000000860775], "tokens_processed": [76, 76], "throughput_tok_s": [13455.85240803523, 12563.437091716161], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.622299999435199, 5.487800000992138, 6.052799999451963], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 104.39599999881466, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.6962292}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.5696999998908723, 1.3995000008435454], "tokens_processed": [1, 1], "throughput_tok_s": [637.0644072558587, 714.5409070362646], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [36.55170000092767, 1.4179999998304993, 1.2768999986292329], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.7406158}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.5360999987024115, 2.069899999696645], "tokens_processed": [1, 1], "throughput_tok_s": [650.9992844507058, 483.11512640540866], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3366999992285855, 1.184099999591126, 1.300799998716684], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.7502654}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.8319999999221181, 1.732699998683529], "tokens_processed": [1, 1], "throughput_tok_s": [545.8515284074847, 577.1339532289376], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.532900000005611, 1.989599999433267, 1.9226000003982335], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.7627423}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.740700001391815, 1.5478999994229525], "tokens_processed": [1, 1], "throughput_tok_s": [574.4815299594577, 646.0365659104554], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1295000005920883, 1.9018999992113095, 1.909100001284969], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.7742612}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.5077000007295283, 1.3354000002436806], "tokens_processed": [1, 1], "throughput_tok_s": [663.2619218121189, 748.8392989497697], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6142000004037982, 1.4336000003822846, 1.5407999999297317], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.7837837}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.578100000595441, 3.9800999984436203], "tokens_processed": [11, 11], "throughput_tok_s": [3074.2572868755656, 2763.749655612031], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.1872999993065605, 3.130299999611452, 3.8437000002886634], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.8073413}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.8794000010966556, 3.437000001213164], "tokens_processed": [11, 11], "throughput_tok_s": [2835.4900234289953, 3200.465521128109], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3177000004798174, 3.6409000003914116, 3.5681999997905223], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.8293846}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3745999990060227, 3.4244999988004565], "tokens_processed": [11, 11], "throughput_tok_s": [3259.645588585318, 3212.147759922065], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4517000003688736, 3.355599999849801, 3.304300000309013], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.8499475}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.6958999990019947, 3.0774000006204005], "tokens_processed": [11, 11], "throughput_tok_s": [2976.2710038070118, 3574.44596015546], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.873300000122981, 3.8468000002467306, 3.717399999004556], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.8726735}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2427999994979473, 3.3928000011655968], "tokens_processed": [11, 11], "throughput_tok_s": [3392.1302583270717, 3242.1598668418264], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1079000000318047, 3.2976000002236106, 3.786900000704918], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.8937192}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.743899999084533, 5.3091999998287065], "tokens_processed": [19, 19], "throughput_tok_s": [4005.143448147426, 3578.693588603369], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.902899998545763, 5.198200000450015, 5.192099999476341], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.92591}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.2174000011291355, 5.280100000163657], "tokens_processed": [19, 19], "throughput_tok_s": [3641.6605964442197, 3598.4166965419395], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.808399999295943, 3.973000000769389, 4.97929999983171], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.955835}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.945999999108608, 5.10989999929734], "tokens_processed": [19, 19], "throughput_tok_s": [3841.488071860953, 3718.2723737475644], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.777599999215454, 5.246100001386367, 5.280400000629015], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567369.9855108}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.840400000830414, 4.176899999947636], "tokens_processed": [19, 19], "throughput_tok_s": [3925.295429456322, 4548.8280782968695], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.964400000972091, 4.703099999460392, 4.683799999838811], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.0137844}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.351100000349106, 5.12440000056813], "tokens_processed": [19, 19], "throughput_tok_s": [4366.711865614569, 3707.751150943235], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7481000001425855, 4.528400000708643, 4.605600001013954], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.0417764}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.742899998949724, 5.566600000747712], "tokens_processed": [27, 27], "throughput_tok_s": [4701.457452669875, 4850.3574886597435], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.128499999656924, 6.214199998794356, 5.094199999803095], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.0782845}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.750500000431202, 5.865799999810406], "tokens_processed": [27, 27], "throughput_tok_s": [4695.243891483419, 4602.952709071686], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.787699999928009, 5.761099999290309, 5.549600000449573], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.1130424}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.103099998654216, 5.606799999441137], "tokens_processed": [27, 27], "throughput_tok_s": [4423.981256403094, 4815.581080596999], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.62530000024708, 6.297600000834791, 5.20420000066224], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.146374}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.140199999208562, 5.928399999902467], "tokens_processed": [27, 27], "throughput_tok_s": [4397.250904446134, 4554.348559551346], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.821499999001389, 5.032099999880302, 5.379499998525716], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.1808727}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.669100000886829, 5.546700000195415], "tokens_processed": [27, 27], "throughput_tok_s": [4762.660739054936, 4867.7592080063405], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.637700000079349, 5.989699999190634, 5.0253999997948995], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.2147336}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.570500000132597, 8.227199999964796], "tokens_processed": [44, 44], "throughput_tok_s": [5133.889504616914, 5348.113574507521], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.612000000444823, 7.644399998753215, 8.41240000045218], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.2676086}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.880800000042655, 8.676800000102958], "tokens_processed": [44, 44], "throughput_tok_s": [4954.508602804777, 5070.9939147471305], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.40049999897019, 8.720600000742706, 8.492599999954109], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.317498}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.43400000121619, 8.405799999309238], "tokens_processed": [44, 44], "throughput_tok_s": [5216.978894196723, 5234.480954057411], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.318800000779447, 7.508400000006077, 8.218500001021312], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.3650327}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.597400001235656, 8.569200001147692], "tokens_processed": [44, 44], "throughput_tok_s": [5117.826318849435, 5134.668346415882], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.454400000118767, 8.494200001223362, 8.629699999801232], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.4141257}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.750000000873115, 8.696900000359165], "tokens_processed": [44, 44], "throughput_tok_s": [5028.571428069655, 5059.273993972897], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.015400000862428, 8.420000000114669, 8.302099999127677], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.4640052}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [12.26909999968484, 11.37610000114364], "tokens_processed": [76, 76], "throughput_tok_s": [6194.423388997745, 6680.672637578758], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.07659999858879, 12.528799999927287, 12.805700000171782], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.537299}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [12.68759999948088, 12.256099998921854], "tokens_processed": [76, 76], "throughput_tok_s": [5990.100570880984, 6200.993791392496], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.559999999211868, 12.314300000070943, 12.45050000034098], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.6100528}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.713899999449495, 11.617000000114786], "tokens_processed": [76, 76], "throughput_tok_s": [6488.01850823139, 6542.136523994926], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.881799999173381, 12.545799998406437, 12.33219999994617], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.6793613}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.961399999563582, 12.38299999931769], "tokens_processed": [76, 76], "throughput_tok_s": [6353.771297906006, 6137.446499570996], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.673499999436899, 12.522900000476511, 11.380099998859805], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.750732}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.739999999917927, 12.243000001035398], "tokens_processed": [76, 76], "throughput_tok_s": [6473.594548597215, 6207.6288486133], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.69359999948938, 12.117400001443457, 12.812900000426453], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1949.2804000001343, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567370.8207045}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8207045}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8207045}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.821712}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.821712}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.821712}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.821712}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8226655}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8226655}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8226655}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8226655}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8226655}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8237057}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8237057}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8237057}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8237057}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.824664}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.824664}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.824664}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.824664}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.825705}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8272588}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8272588}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8272588}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567370.8272588}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8272588}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8282657}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8293037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8293037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8293037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8293037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8293037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8302763}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8302763}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8302763}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8302763}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8312685}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8312685}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8312685}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8312685}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.832266}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8332675}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8347735}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8347735}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8347735}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8347735}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8347735}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8358161}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8373592}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8373592}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8373592}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8373592}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8373592}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.838409}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.838409}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.838409}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.838409}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.838409}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8394122}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8394122}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567370.8394122}
