{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8608568}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8618557}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8618557}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8628478}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8628478}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8628478}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8638518}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8638518}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8638518}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8648727}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8648727}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8648727}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8648727}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8664932}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8664932}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8675961}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8675961}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8685532}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8685532}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.869588}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.869588}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.869588}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8705943}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8705943}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8705943}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8715956}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8715956}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8715956}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8726153}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1036.648100000093, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566973.8726153}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8726153}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8735886}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8735886}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8735886}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8745944}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8745944}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8745944}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8755884}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8755884}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8755884}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8766303}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8766303}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8766303}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8777773}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8777773}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.878769}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.878769}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.878769}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8798556}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8798556}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.880805}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.880805}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.880805}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8818378}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8818378}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8818378}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8828444}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8828444}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8828444}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 100.58140000001004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.883832}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.883832}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.883832}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8848348}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8864307}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8864307}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8864307}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8874967}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8874967}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8874967}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8885329}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8885329}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8895311}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8895311}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8895311}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8905241}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8905241}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8915284}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8915284}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8915284}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8924482}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8924482}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8924482}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.8924482}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.893536}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1998.160299999654, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566973.893536}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.893536}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8945618}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8945618}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8945618}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8955333}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8955333}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8955333}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.896527}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.896527}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8971422}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8971422}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8971422}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8982286}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8982286}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8982286}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8991406}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.8991406}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9001412}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9001412}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9001412}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.901244}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.901244}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.901244}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.902215}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.902215}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.902215}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9032154}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9032154}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9032154}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566973.9032154}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9042232}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9042232}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9042232}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9052014}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9052014}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9052014}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9062366}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9062366}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.906854}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.906854}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.906854}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9078655}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9078655}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9078655}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9089417}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9089417}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9099538}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9099538}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9109826}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9109826}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9109826}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9119263}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9119263}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9119263}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.912949}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.912949}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.912949}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.912949}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9143507}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566973.9143507}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9143507}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9153526}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9153526}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9153526}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9163513}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9163513}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9169555}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9169555}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9169555}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9179583}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9179583}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9179583}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9190645}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9190645}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9190645}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9200387}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9200387}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9210665}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9210665}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9210665}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9220607}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9220607}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9220607}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9230442}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9230442}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9230442}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9240355}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9240355}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9240355}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "NVML Shared Library Not Found", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:NVMLError_LibraryNotFound"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566973.9250484}
