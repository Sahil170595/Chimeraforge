{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 67, "duration_s": 7.378677606582642, "gpu_memory_mean_mb": 497.3031133395522, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.83616417910448, "gpu_power_peak_watts": 31.168, "gpu_temperature_mean_c": 50.26865671641791, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 985.8187383395523, "cpu_memory_peak_mb": 999.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589660.16155}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 54, "duration_s": 6.209102630615234, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.5740740740740741, "gpu_power_mean_watts": 16.12611111111111, "gpu_power_peak_watts": 30.943, "gpu_temperature_mean_c": 49.75925925925926, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1003.3335503472222, "cpu_memory_peak_mb": 1004.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589666.4816756}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 48, "duration_s": 5.432100296020508, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.875, "gpu_power_mean_watts": 1.9478125000000002, "gpu_power_peak_watts": 1.994, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1005.2396647135416, "cpu_memory_peak_mb": 1005.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589672.031971}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 50, "duration_s": 5.621959447860718, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.9379400000000002, "gpu_power_peak_watts": 1.961, "gpu_temperature_mean_c": 48.3, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1006.080703125, "cpu_memory_peak_mb": 1006.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589677.767984}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 59, "duration_s": 6.5204081535339355, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.9461525423728814, "gpu_power_peak_watts": 1.978, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1006.9755693855932, "cpu_memory_peak_mb": 1008.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589684.4070256}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 133, "duration_s": 15.095956563949585, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8617894736842104, "gpu_power_peak_watts": 1.986, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1014.003436325188, "cpu_memory_peak_mb": 1022.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589699.617657}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 147, "duration_s": 16.87393093109131, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.862986394557823, "gpu_power_peak_watts": 1.958, "gpu_temperature_mean_c": 47.38095238095238, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1027.8949032738096, "cpu_memory_peak_mb": 1031.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589716.6054122}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 122, "duration_s": 13.768414974212646, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8683934426229507, "gpu_power_peak_watts": 1.953, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1033.3150294569673, "cpu_memory_peak_mb": 1034.43359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589730.4893072}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 104, "duration_s": 12.201568841934204, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.25961538461538464, "gpu_power_mean_watts": 1.8567788461538461, "gpu_power_peak_watts": 1.916, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1036.802509014423, "cpu_memory_peak_mb": 1041.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589742.8163443}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 100, "duration_s": 11.284237384796143, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8515100000000002, "gpu_power_peak_watts": 1.934, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1043.9711328125, "cpu_memory_peak_mb": 1046.1015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589754.2168815}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 112, "duration_s": 13.183186531066895, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8446517857142857, "gpu_power_peak_watts": 1.918, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1048.9296177455358, "cpu_memory_peak_mb": 1052.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589767.5237224}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 105, "duration_s": 11.859345197677612, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8510666666666666, "gpu_power_peak_watts": 1.933, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1054.7904389880953, "cpu_memory_peak_mb": 1059.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589779.4935973}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 103, "duration_s": 11.60183310508728, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.856009708737864, "gpu_power_peak_watts": 1.923, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1062.138349514563, "cpu_memory_peak_mb": 1064.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589791.2148306}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 110, "duration_s": 12.321915864944458, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.09090909090909091, "gpu_power_mean_watts": 1.857290909090909, "gpu_power_peak_watts": 1.922, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1069.2318892045455, "cpu_memory_peak_mb": 1071.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589803.6503878}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 129, "duration_s": 14.58054256439209, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.854093023255814, "gpu_power_peak_watts": 1.976, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1073.5572008236434, "cpu_memory_peak_mb": 1075.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589818.3423343}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 144, "duration_s": 15.865219116210938, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.4375, "gpu_power_mean_watts": 1.8586319444444444, "gpu_power_peak_watts": 1.949, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1077.843017578125, "cpu_memory_peak_mb": 1084.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589834.3168564}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 134, "duration_s": 14.84476375579834, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.6791044776119403, "gpu_power_mean_watts": 1.8654626865671642, "gpu_power_peak_watts": 1.948, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1086.2103836287313, "cpu_memory_peak_mb": 1089.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589849.3002532}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 133, "duration_s": 14.986252307891846, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.06766917293233082, "gpu_power_mean_watts": 1.8488571428571428, "gpu_power_peak_watts": 1.932, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1089.710820018797, "cpu_memory_peak_mb": 1093.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589864.401209}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 123, "duration_s": 13.978046417236328, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8463170731707317, "gpu_power_peak_watts": 1.943, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1094.4051067073171, "cpu_memory_peak_mb": 1098.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589878.4921234}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 109, "duration_s": 12.336591482162476, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.23853211009174313, "gpu_power_mean_watts": 1.8571467889908257, "gpu_power_peak_watts": 1.928, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1099.3924168577983, "cpu_memory_peak_mb": 1103.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589890.988798}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 136, "duration_s": 16.35700011253357, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.27941176470588236, "gpu_power_mean_watts": 1.807360294117647, "gpu_power_peak_watts": 1.919, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1106.8311408547795, "cpu_memory_peak_mb": 1112.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589907.4596074}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 167, "duration_s": 18.813318014144897, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.16167664670658682, "gpu_power_mean_watts": 1.987065868263473, "gpu_power_peak_watts": 2.898, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1116.0789436751497, "cpu_memory_peak_mb": 1120.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589926.3916597}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 137, "duration_s": 15.605260848999023, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.4517737226277374, "gpu_power_peak_watts": 2.906, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1126.508953010949, "cpu_memory_peak_mb": 1132.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589942.1163921}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 151, "duration_s": 17.184862852096558, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.5034900662251656, "gpu_power_peak_watts": 2.907, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1134.7109633692053, "cpu_memory_peak_mb": 1137.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589959.4098828}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 137, "duration_s": 15.668592929840088, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.5484306569343067, "gpu_power_peak_watts": 2.874, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1146.8566662864964, "cpu_memory_peak_mb": 1153.18359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589975.1895413}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 140, "duration_s": 16.025083303451538, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.441842857142857, "gpu_power_peak_watts": 2.892, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1158.2590401785715, "cpu_memory_peak_mb": 1163.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589991.3293178}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 135, "duration_s": 15.68589472770691, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.06666666666666667, "gpu_power_mean_watts": 2.4909407407407405, "gpu_power_peak_watts": 2.927, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1164.6065393518518, "cpu_memory_peak_mb": 1166.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765590007.1424356}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 136, "duration_s": 16.00986623764038, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.19852941176470587, "gpu_power_mean_watts": 2.486360294117647, "gpu_power_peak_watts": 2.924, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1171.1567670036766, "cpu_memory_peak_mb": 1180.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765590023.2689042}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 177, "duration_s": 20.307761430740356, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.392395480225989, "gpu_power_peak_watts": 2.975, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1181.4607168079096, "cpu_memory_peak_mb": 1186.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765590043.6954212}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n", "Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 132, "duration_s": 14.179624557495117, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.535462121212121, "gpu_power_peak_watts": 2.864, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1187.8947088068182, "cpu_memory_peak_mb": 1195.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2665.331399999559, "compile_ms": 1424.5013000036124, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765590057.9877946}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.2736999958870001, 0.3102999980910681], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [29229.083376760016, 25781.501931083247], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4943999995011836, 0.3448999996180646, 0.28359999851090834], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.194, "gpu_power_peak_watts": 2.194, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1197.98046875, "cpu_memory_peak_mb": 1197.98046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.1157656}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.1832999987527728, 0.22370000078808516], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [43644.29926041657, 35762.1813670825], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8680999962962233, 0.23979999969014898, 0.17239999579032883], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.194, "gpu_power_peak_watts": 2.194, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1197.98046875, "cpu_memory_peak_mb": 1197.98046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.2402625}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.1768000001902692, 0.17800000205170363], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [45248.868729584465, 44943.81970667754], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8868000004440546, 0.2899000028264709, 0.2027000009547919], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.194, "gpu_power_peak_watts": 2.194, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1198.078125, "cpu_memory_peak_mb": 1198.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.3638418}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.3164999943692237, 0.29399999766610563], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [25276.461745106164, 27210.884569752823], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9720000016386621, 0.32449999707750976, 0.27630000113276765], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1198.078125, "cpu_memory_peak_mb": 1198.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.5076532}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.2860000022337772, 0.3369999976712279], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [27972.027753554972, 23738.872567603634], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5705999938072637, 0.30220000189729035, 0.31510000553680584], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1198.08984375, "cpu_memory_peak_mb": 1198.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.627819}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.429300001997035, 0.5173999961698428], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [25623.107264919072, 21260.14704567009], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7766000019037165, 0.5705999938072637, 0.4206000012345612], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1200.24609375, "cpu_memory_peak_mb": 1200.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.7546751}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.42070000199601054, 0.45510000200010836], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [26146.897903043777, 24170.511869163605], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7225999943329953, 0.37310000334400684, 0.5014999987906776], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1200.24609375, "cpu_memory_peak_mb": 1200.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590058.881058}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.3405999959795736, 0.3499999947962351], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [32295.94870770254, 31428.571895848283], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.647900000330992, 0.3804000007221475, 0.3392999933566898], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1200.2578125, "cpu_memory_peak_mb": 1200.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.006758}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.371000001905486, 0.39709999691694975], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [29649.59553504882, 27700.83123999762], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.658800003293436, 0.3938000008929521, 0.3775000004679896], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1200.28125, "cpu_memory_peak_mb": 1200.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.1298044}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.35260000004200265, 0.4050999996252358], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [31196.82359242669, 27153.789212975236], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6541000038851053, 0.32359999750042334, 0.5448000010801479], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1200.38671875, "cpu_memory_peak_mb": 1200.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.2546353}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.46190000284696, 0.4906000031041913], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [41134.4444314611, 38728.087810396675], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6232999987551011, 0.6955000062589534, 0.5022999976063147], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.779, "gpu_power_peak_watts": 2.779, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1201.98828125, "cpu_memory_peak_mb": 1201.98828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.3809276}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.42440000106580555, 0.42720000055851415], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [44769.08565571362, 44475.655372564885], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9266000051866286, 0.450699997600168, 0.43820000428240746], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1202.02734375, "cpu_memory_peak_mb": 1202.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.5067635}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.6391999995685183, 0.5068000027677044], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [29724.655839839874, 37490.13397047827], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.785599993832875, 0.584999994316604, 0.494699997943826], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1202.04296875, "cpu_memory_peak_mb": 1202.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.6308725}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.4343000036897138, 0.4231999992043711], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [43748.56053092409, 44896.03033015259], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9324999991804361, 0.4351999959908426, 0.4270999997970648], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1202.0546875, "cpu_memory_peak_mb": 1202.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.7564032}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.4239000045345165, 0.48019999667303637], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [44821.89147618399, 39566.84742115257], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8106000022962689, 0.5984000017633662, 0.4427999956533313], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1202.14453125, "cpu_memory_peak_mb": 1202.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590059.880311}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.5010000022593886, 0.501599999552127], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [53892.215325821446, 53827.751244234445], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3835000029066578, 0.5631000021821819, 0.5103000003146008], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1207.33984375, "cpu_memory_peak_mb": 1207.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.0063233}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.4948999994667247, 0.5314000009093434], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [54556.47611455571, 50809.18320247837], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9602000063750893, 0.5571000001509674, 0.6665000037173741], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1207.3984375, "cpu_memory_peak_mb": 1207.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.1337388}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.48100000276463106, 0.4861999987042509], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [56133.05581042164, 55532.70273952375], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8417999997618608, 0.5491999982041307, 0.4728999992948957], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1207.40625, "cpu_memory_peak_mb": 1207.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.2572157}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.6609999982174486, 0.5622000026050955], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [40847.20132044211, 48025.6134380802], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1324000006425194, 0.5530999987968244, 0.5629000006592833], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.076, "gpu_power_peak_watts": 2.076, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1207.40625, "cpu_memory_peak_mb": 1207.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.3808932}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.39760000072419643, 0.39480000123148784], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [67907.4445443201, 68389.05753743593], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7417999950121157, 0.4507000048761256, 0.41449999844189733], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1207.40625, "cpu_memory_peak_mb": 1207.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.505264}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.4791000028490089, 0.5067999954917468], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [91838.86399154719, 86819.2588622794], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.452200002153404, 0.6880000000819564, 0.450999999884516], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1216.4609375, "cpu_memory_peak_mb": 1216.4609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.631135}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.6217999980435707, 0.592199998209253], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [70762.3032139618, 74299.22346006604], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4276000001700595, 0.666200001433026, 0.6743999983882532], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1216.5859375, "cpu_memory_peak_mb": 1216.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.7562163}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.6584000002476387, 0.553100006072782], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [66828.67555202101, 79551.61727879294], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2253999957465567, 0.7175999999162741, 0.7706999967922457], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1216.5859375, "cpu_memory_peak_mb": 1216.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590060.8840578}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.4884000009042211, 0.5215999990468845], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [90090.0899232978, 84355.82837500163], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9352999986731447, 0.5454000056488439, 0.5048000020906329], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1216.5859375, "cpu_memory_peak_mb": 1216.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.006041}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.6065999987185933, 0.4996999996365048], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [72535.4436085516, 88052.8317630714], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1577999975997955, 0.629599999228958, 0.5709000033675693], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1216.5859375, "cpu_memory_peak_mb": 1216.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.129453}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.9237999984179623, 1.0843000054592267], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [82268.88951088167, 70091.30279199086], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.359000005526468, 1.1860000013257377, 0.7904999947641045], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.75, "cpu_memory_peak_mb": 1222.75, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.2557745}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.8417999997618608, 0.9061000018846244], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [90282.72751425499, 83875.95170723468], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.615599998331163, 0.8574000021326356, 0.9716999993543141], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.692, "gpu_power_peak_watts": 1.692, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.76171875, "cpu_memory_peak_mb": 1222.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.380869}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.8123000006889924, 0.8017000000108965], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [93561.4919802251, 94798.55307342776], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6489999979967251, 0.9321000034105964, 0.9920000011334196], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.7734375, "cpu_memory_peak_mb": 1222.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.5046365}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.7718000051681884, 0.7907000035629608], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [98471.1058448857, 96117.36392758013], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2266000048839487, 0.9462999951210804, 0.7215000005089678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.83203125, "cpu_memory_peak_mb": 1222.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.6271734}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [0.7533000025432557, 0.7371000028797425], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [100889.41954521759, 103106.76937061328], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3260999985504895, 0.8460000026389025, 0.763599993661046], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.84375, "cpu_memory_peak_mb": 1222.84375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 126.51129999721888, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765590061.753746}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.953125, "cpu_memory_peak_mb": 1222.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590061.876293}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.97265625, "cpu_memory_peak_mb": 1222.97265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.000673}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.984375, "cpu_memory_peak_mb": 1222.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.1261177}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.99609375, "cpu_memory_peak_mb": 1222.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.2505417}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.698, "gpu_power_peak_watts": 1.698, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1222.99609375, "cpu_memory_peak_mb": 1222.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.375805}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.0234375, "cpu_memory_peak_mb": 1223.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.5009549}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.05078125, "cpu_memory_peak_mb": 1223.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.626077}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.05859375, "cpu_memory_peak_mb": 1223.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.7531598}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.05859375, "cpu_memory_peak_mb": 1223.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.8739944}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.05859375, "cpu_memory_peak_mb": 1223.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590062.9979506}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.0703125, "cpu_memory_peak_mb": 1223.0703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.1214411}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.078125, "cpu_memory_peak_mb": 1223.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.2461283}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7, "gpu_power_peak_watts": 1.7, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.078125, "cpu_memory_peak_mb": 1223.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.373391}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.078125, "cpu_memory_peak_mb": 1223.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.4981158}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.08984375, "cpu_memory_peak_mb": 1223.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.622799}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.08984375, "cpu_memory_peak_mb": 1223.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.7521744}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.08984375, "cpu_memory_peak_mb": 1223.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.8748887}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.1015625, "cpu_memory_peak_mb": 1223.1015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590063.9965644}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.1015625, "cpu_memory_peak_mb": 1223.1015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.1247628}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.1015625, "cpu_memory_peak_mb": 1223.1015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.2464168}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.598, "gpu_power_peak_watts": 2.598, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.371567}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.495696}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.6191804}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.7452881}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.8721588}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.11328125, "cpu_memory_peak_mb": 1223.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590064.9947555}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.203125, "cpu_memory_peak_mb": 1223.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590065.1194143}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.203125, "cpu_memory_peak_mb": 1223.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590065.2441404}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.728, "gpu_power_peak_watts": 1.728, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1223.21484375, "cpu_memory_peak_mb": 1223.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590065.3675783}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.729, "gpu_power_peak_watts": 1.729, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1223.21875, "cpu_memory_peak_mb": 1223.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 57.63229999865871, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765590065.493361}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.198599999246653, 1.5800999972270802], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3638.6791607119017, 5062.9707069421], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.749700001615565, 2.427300001727417, 2.416700001049321], "resource_metrics": {"samples": 291, "duration_s": 52.29677081108093, "gpu_memory_mean_mb": 1121.5235314647766, "gpu_memory_peak_mb": 1467.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.738831615120274, "gpu_power_mean_watts": 8.452154639175257, "gpu_power_peak_watts": 32.962, "gpu_temperature_mean_c": 49.175257731958766, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 5136.906156035223, "cpu_memory_peak_mb": 5426.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765590117.9041834}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.5162000019918196, 2.140600001439452], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3179.3975016561535, 3737.269921807147], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.027799993811641, 2.0769999973708764, 2.4549000008846633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 737.0390625, "gpu_memory_peak_mb": 737.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.892, "gpu_power_peak_watts": 9.892, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2664.2578125, "cpu_memory_peak_mb": 2664.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.037461}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.4441000059596263, 2.4913000015658326], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3273.188486761188, 3211.1748865940826], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.569800002675038, 2.2100999995018356, 2.1591999975498766], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 737.0390625, "gpu_memory_peak_mb": 737.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.892, "gpu_power_peak_watts": 9.892, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2664.2734375, "cpu_memory_peak_mb": 2664.2734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.1638806}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.3024999973131344, 2.244899995275773], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3474.484260297708, 3563.633131469291], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5863999981083907, 2.2690999976475723, 1.7904000051203184], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 737.0390625, "gpu_memory_peak_mb": 737.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.892, "gpu_power_peak_watts": 9.892, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2664.4921875, "cpu_memory_peak_mb": 2664.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.301111}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.410100001725368, 2.351099996303674], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3319.364339352257, 3402.6625888211265], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2828999935882166, 2.1694999959436245, 2.516799999284558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 737.0390625, "gpu_memory_peak_mb": 737.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2664.51171875, "cpu_memory_peak_mb": 2664.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.4285133}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.4161000037565827, 2.503600000636652], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4552.791682006979, 4393.6731096032745], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0906000029062852, 2.638199999637436, 1.9572999954107217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.3125, "cpu_memory_peak_mb": 2665.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.5524223}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.476499998010695, 2.9682000022148713], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4441.752476816475, 3705.949731080048], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6514999990467913, 2.3135000010370277, 2.1873000005143695], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.5234375, "cpu_memory_peak_mb": 2665.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.6759784}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.0327999993460253, 2.507199998944998], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3627.0113434357604, 4387.364392401356], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.391300000657793, 2.2855999995954335, 2.875499994843267], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.546875, "cpu_memory_peak_mb": 2665.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.8040378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.6010000001406297, 2.013900004385505], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4229.142637218476, 5462.038818236359], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4999999988940544, 2.9455999974743463, 2.6500000021769665], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.105, "gpu_power_peak_watts": 3.105, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.546875, "cpu_memory_peak_mb": 2665.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590118.9273512}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.1645999988541007, 2.6150000048801303], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3475.9527283015523, 4206.500948172745], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.131900004518684, 2.6437999986228533, 2.6159000044572167], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.105, "gpu_power_peak_watts": 3.105, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.5625, "cpu_memory_peak_mb": 2665.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.0521998}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.679800000099931, 3.8883000015630387], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [5163.324093560526, 4886.454232534085], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9619000017410144, 3.662600000097882, 3.528300003381446], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.105, "gpu_power_peak_watts": 3.105, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2667.296875, "cpu_memory_peak_mb": 2667.296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.1784863}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.177499999466818, 3.9365000047837384], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [3075.677863478737, 4826.622628454388], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.79139999859035, 4.026499998872168, 3.773600001295563], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.105, "gpu_power_peak_watts": 3.105, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2667.30078125, "cpu_memory_peak_mb": 2667.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.29983}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [5.191800002648961, 3.5862000004271977], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [3659.617086618479, 5298.087111074862], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.227699995681178, 3.79850000172155, 3.7584000019705854], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.153, "gpu_power_peak_watts": 3.153, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2667.30078125, "cpu_memory_peak_mb": 2667.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.424138}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.874900001392234, 3.9245000007213093], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4903.352342814882, 4841.381066762101], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.240800000843592, 3.791099996306002, 5.203699998673983], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.153, "gpu_power_peak_watts": 3.153, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2667.30078125, "cpu_memory_peak_mb": 2667.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.54837}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.847499996481929, 3.718399995705113], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4938.271609453721, 5109.724618638578], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6811000027228147, 6.153100002848078, 3.5688999996636994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 741.0390625, "gpu_memory_peak_mb": 741.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.153, "gpu_power_peak_watts": 3.153, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2667.3203125, "cpu_memory_peak_mb": 2667.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.6719925}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.786199999216478, 7.563899998785928], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5641.218504120183, 3569.5871183296626], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.038199997215997, 4.203000004054047, 4.808600002434105], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 743.0390625, "gpu_memory_peak_mb": 743.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.153, "gpu_power_peak_watts": 3.153, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2669.07421875, "cpu_memory_peak_mb": 2669.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.796684}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.4797000009566545, 4.566700001305435], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [6027.189319426315, 5912.365601480674], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.994800001441035, 4.892899996775668, 4.3817000041599385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 743.0390625, "gpu_memory_peak_mb": 743.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.198, "gpu_power_peak_watts": 3.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2669.08984375, "cpu_memory_peak_mb": 2669.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590119.9200485}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.838300003029872, 4.887299997790251], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5580.472476508668, 5524.522745116487], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.915599995001685, 4.562200003420003, 6.750900000042748], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 743.0390625, "gpu_memory_peak_mb": 743.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.198, "gpu_power_peak_watts": 3.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2669.26953125, "cpu_memory_peak_mb": 2669.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.0476472}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.793100000824779, 4.393800001707859], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5633.097576798718, 6145.022529360728], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.067800004326273, 7.265299995196983, 4.3917000002693385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 743.0390625, "gpu_memory_peak_mb": 743.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.198, "gpu_power_peak_watts": 3.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2669.26953125, "cpu_memory_peak_mb": 2669.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.1726973}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.580499997653533, 4.99860000127228], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [4103.0316859855075, 5401.512422103742], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.217499998456333, 5.0436000019544736, 5.033399997046217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 743.0390625, "gpu_memory_peak_mb": 743.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.198, "gpu_power_peak_watts": 3.198, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2669.28125, "cpu_memory_peak_mb": 2669.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.2981913}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.965900000068359, 6.841399997938424], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6316.48458915118, 6431.432164945608], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.000199999718461, 6.777399998100009, 7.09880000067642], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 737.0390625, "gpu_memory_peak_mb": 737.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2665.11328125, "cpu_memory_peak_mb": 2665.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.4225938}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.915999998454936, 6.429499997466337], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6362.058995059252, 6843.455947949143], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.661599993298296, 8.654999997816049, 7.092300002113916], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 747.0390625, "gpu_memory_peak_mb": 747.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.4765625, "cpu_memory_peak_mb": 2674.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.550531}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.927999995241407, 7.074100001773331], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6351.039265332276, 6219.872491054707], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.226099998864811, 7.080399998812936, 6.704000006720889], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 747.0390625, "gpu_memory_peak_mb": 747.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.68359375, "cpu_memory_peak_mb": 2674.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.6777081}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.851199999800883, 6.7196000018157065], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6422.232601774693, 6548.008808278876], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.532900002843235, 9.969099999580067, 7.167100004153326], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 747.0390625, "gpu_memory_peak_mb": 747.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.73046875, "cpu_memory_peak_mb": 2674.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.8140445}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.1779999998398125, 7.081399999151472], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6129.84118152437, 6213.4606158771285], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.11829999636393, 7.099399997969158, 6.797699999879114], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 747.0390625, "gpu_memory_peak_mb": 747.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.35, "gpu_power_peak_watts": 3.35, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.73828125, "cpu_memory_peak_mb": 2674.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590120.9386117}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.975299999699928, 10.957200000120793], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6924.639873359079, 6936.07856013965], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.892399998032488, 13.75039999402361, 11.270700000750367], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 753.0390625, "gpu_memory_peak_mb": 753.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.35, "gpu_power_peak_watts": 3.35, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2680.76953125, "cpu_memory_peak_mb": 2680.76953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590121.0623345}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.923099995125085, 10.82989999849815], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6957.731782545097, 7017.608658486172], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.994499996944796, 10.781800003314856, 11.119000002508983], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 753.0390625, "gpu_memory_peak_mb": 753.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.35, "gpu_power_peak_watts": 3.35, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2678.9765625, "cpu_memory_peak_mb": 2678.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590121.1873035}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.8369000008679, 11.27950000227429], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [7013.075694517192, 6737.88731634169], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.575799999875017, 11.239899999054614, 10.6143000011798], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 753.0390625, "gpu_memory_peak_mb": 753.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.35, "gpu_power_peak_watts": 3.35, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2672.40234375, "cpu_memory_peak_mb": 2672.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590121.312152}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.540600000240374, 10.9050999963074], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [7210.215737080133, 6969.216240633697], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.515199999848846, 10.634799997205846, 10.959600003843661], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 753.0390625, "gpu_memory_peak_mb": 753.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 3.533, "gpu_power_peak_watts": 3.533, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.37890625, "cpu_memory_peak_mb": 2674.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590121.4335682}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [13.23489999776939, 10.871999998926185], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [5742.393218899201, 6990.4341434424605], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.249800001678523, 10.571599996183068, 10.832400002982467], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 753.0390625, "gpu_memory_peak_mb": 753.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 53.0, "gpu_power_mean_watts": 3.533, "gpu_power_peak_watts": 3.533, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2674.83984375, "cpu_memory_peak_mb": 2674.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 75.8614000005764, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590121.5569816}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.30349999765167, 1.738300001306925], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3472.9759097702163, 4602.197545869685], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.5306000029086135, 2.538799999456387, 2.776999994239304], "resource_metrics": {"samples": 480, "duration_s": 55.88586974143982, "gpu_memory_mean_mb": 1123.8140625, "gpu_memory_peak_mb": 1427.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.708333333333334, "gpu_power_mean_watts": 7.246839583333334, "gpu_power_peak_watts": 31.613, "gpu_temperature_mean_c": 49.44583333333333, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 5179.176814778646, "cpu_memory_peak_mb": 5326.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765590177.5567832}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.133299996785354, 2.158499999495689], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3750.0586003164635, 3706.2775083943097], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.916400000685826, 2.2907000020495616, 1.7114000002038665], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 751.0390625, "gpu_memory_peak_mb": 751.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.12, "gpu_power_peak_watts": 2.12, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2808.64453125, "cpu_memory_peak_mb": 2808.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590177.6845317}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [1.7337999961455353, 2.1220999988145195], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [4614.142356549227, 3769.8506217751683], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.351899995119311, 2.2210000024642795, 2.2914000001037493], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 751.0390625, "gpu_memory_peak_mb": 751.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.12, "gpu_power_peak_watts": 2.12, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2808.65234375, "cpu_memory_peak_mb": 2808.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590177.8077595}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.2217000005184673, 2.285899994603824], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3600.8461980164193, 3499.715656365144], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8920999975525774, 2.3060000021359883, 1.7693999980110675], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 751.0390625, "gpu_memory_peak_mb": 751.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.317, "gpu_power_peak_watts": 2.317, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2808.65625, "cpu_memory_peak_mb": 2808.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590177.9330575}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.592299999378156, 2.5575000036042184], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3086.0625706588935, 3128.0547365496805], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.798099994834047, 2.2926999954506755, 2.2073999934946187], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 751.0390625, "gpu_memory_peak_mb": 751.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.317, "gpu_power_peak_watts": 2.317, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2808.65625, "cpu_memory_peak_mb": 2808.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.0576808}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.9264999975566752, 2.6283999977749772], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3758.756196543264, 4185.0555506436785], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.948800003854558, 2.5976999968406744, 3.1023000046843663], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.317, "gpu_power_peak_watts": 2.317, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2809.234375, "cpu_memory_peak_mb": 2809.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.1805599}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.0947999985073693, 2.295300000696443], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3554.349232682348, 4792.401863225881], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3914000014192425, 2.5217000002157874, 3.0937999981688336], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.317, "gpu_power_peak_watts": 2.317, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2809.234375, "cpu_memory_peak_mb": 2809.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.304011}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.435399997921195, 3.2898999997996725], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4516.711837640372, 3343.5666739626763], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3689000047161244, 2.8624999977182597, 2.1913000018685125], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2809.24609375, "cpu_memory_peak_mb": 2809.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.4277694}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.6079999952344224, 2.67869999515824], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4217.791418750081, 4106.469563550431], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4522999994806014, 2.8103000004193746, 2.0975000006728806], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2809.26171875, "cpu_memory_peak_mb": 2809.26171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.5505211}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.716299997700844, 2.9633999947691336], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4049.626333361824, 3711.9524935603454], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.221400002075825, 2.8550999995786697, 2.043300002696924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2809.265625, "cpu_memory_peak_mb": 2809.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.6746066}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [5.572100002609659, 3.584500002034474], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [3409.845478563103, 5300.599801706254], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.307099996367469, 6.445600003644358, 3.8472000014735386], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2810.80078125, "cpu_memory_peak_mb": 2810.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.800156}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.012800003692973, 4.072700001415797], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4734.848480491011, 4665.209810051075], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.709900000307243, 6.731800000125077, 3.983199996582698], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.337, "gpu_power_peak_watts": 2.337, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2810.8046875, "cpu_memory_peak_mb": 2810.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590178.925988}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.95849999767961, 6.777899994631298], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4799.797906059721, 2803.228140729385], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.937500005122274, 6.436000003304798, 3.5165000008419156], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.337, "gpu_power_peak_watts": 2.337, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2810.8125, "cpu_memory_peak_mb": 2810.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.0473826}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.929699996660929, 3.4192000020993873], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4834.974684109302, 5556.855401361139], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.160100004810374, 6.520700000692159, 3.8419000047724694], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.337, "gpu_power_peak_watts": 2.337, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2810.82421875, "cpu_memory_peak_mb": 2810.82421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.1706405}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.5354999999981374, 3.8335999997798353], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [5374.063074532601, 4956.176961887306], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.376400000182912, 3.46469999931287, 3.2642000005580485], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 755.0390625, "gpu_memory_peak_mb": 755.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.337, "gpu_power_peak_watts": 2.337, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2810.83203125, "cpu_memory_peak_mb": 2810.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.294919}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.8753000010037795, 4.842200003622565], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5538.120729891688, 5575.977857131192], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.3879000042798, 6.550999998580664, 4.505000004428439], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 757.0390625, "gpu_memory_peak_mb": 757.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.435, "gpu_power_peak_watts": 2.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.37109375, "cpu_memory_peak_mb": 2812.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.4199297}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.949100002704654, 4.35740000102669], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5455.537367449569, 6196.355623453955], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.847299998800736, 6.728100001055282, 4.596600003424101], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 757.0390625, "gpu_memory_peak_mb": 757.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.435, "gpu_power_peak_watts": 2.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.390625, "cpu_memory_peak_mb": 2812.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.5429993}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.828699995414354, 4.939799997373484], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5591.567093760422, 5465.808335227343], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.092899998999201, 6.39940000110073, 5.025500002375338], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 757.0390625, "gpu_memory_peak_mb": 757.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.435, "gpu_power_peak_watts": 2.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.3984375, "cpu_memory_peak_mb": 2812.3984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.6707957}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.498099995951634, 4.810799997358117], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [4155.060712642343, 5612.372165716145], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.133300001034513, 6.335199999739416, 4.586499999277294], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 757.0390625, "gpu_memory_peak_mb": 757.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.435, "gpu_power_peak_watts": 2.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.40625, "cpu_memory_peak_mb": 2812.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.7931879}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [5.073899999842979, 4.589800002577249], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5321.350440654243, 5882.609260717036], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.127999997057486, 6.686900000204332, 4.850900004385039], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 757.0390625, "gpu_memory_peak_mb": 757.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.543, "gpu_power_peak_watts": 2.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.40625, "cpu_memory_peak_mb": 2812.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590179.918692}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.0024999949964695, 7.221100000606384], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6283.470193707895, 6093.254489801436], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.2171000035014, 7.122200004232582, 7.165600000007544], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 751.0390625, "gpu_memory_peak_mb": 751.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.543, "gpu_power_peak_watts": 2.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2808.015625, "cpu_memory_peak_mb": 2808.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.04313}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.075800000166055, 6.805400000303052], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6218.37813377532, 6465.4539039645915], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.128500005113892, 6.815299995651003, 7.125900003302377], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.543, "gpu_power_peak_watts": 2.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2816.80078125, "cpu_memory_peak_mb": 2816.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.167459}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [8.04960000095889, 6.983499995840248], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [5466.11011662177, 6300.565622711934], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.023399997910019, 6.838900000730064, 7.07019999390468], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 16.0, "gpu_power_mean_watts": 2.543, "gpu_power_peak_watts": 2.543, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2816.80859375, "cpu_memory_peak_mb": 2816.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.2925253}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.2109000029740855, 7.1858000010252], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6101.873550021843, 6123.187396493433], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.536299999628682, 6.904299996676855, 7.1667999945930205], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.616, "gpu_power_peak_watts": 2.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2816.80859375, "cpu_memory_peak_mb": 2816.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.417284}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.0877000034670345, 7.382399999187328], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6207.937691843174, 5960.121370400361], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.9417000015382655, 7.061000003886875, 6.97309999668505], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.616, "gpu_power_peak_watts": 2.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2816.81640625, "cpu_memory_peak_mb": 2816.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.539477}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [11.141900002257898, 11.271399998804554], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6821.0987340219035, 6742.729386594439], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.575100001413375, 11.344300000928342, 11.183299997355789], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.616, "gpu_power_peak_watts": 2.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2821.3828125, "cpu_memory_peak_mb": 2821.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.6653466}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [11.370399995939806, 11.307799999485724], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6684.021672688597, 6721.024425923386], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.321000001975335, 11.228799994569272, 10.982700005115476], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.616, "gpu_power_peak_watts": 2.616, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2812.2109375, "cpu_memory_peak_mb": 2812.2109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.7875082}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [11.386799997126218, 11.2068000016734], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6674.394915092981, 6781.596886591326], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.403499997162726, 11.16829999955371, 11.29390000278363], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.821, "gpu_power_peak_watts": 2.821, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2822.96484375, "cpu_memory_peak_mb": 2822.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590180.9159975}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [11.285699998552445, 10.95319999876665], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6734.185740339377, 6938.611548091675], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.93290000082925, 11.280600003374275, 10.797000002639834], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.821, "gpu_power_peak_watts": 2.821, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2822.96875, "cpu_memory_peak_mb": 2822.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590181.053894}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [11.231300006329548, 11.236899998039007], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6766.8034828710115, 6763.431196616775], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.146799999754876, 11.02060000266647, 11.19759999710368], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 2.821, "gpu_power_peak_watts": 2.821, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2819.08984375, "cpu_memory_peak_mb": 2819.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 59.05279999569757, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590181.1792305}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.795100001094397, 2.5771000000531785], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [2862.1516213615505, 3104.2644832699234], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.654599998204503, 2.24280000111321, 2.0660000009229407], "resource_metrics": {"samples": 305, "duration_s": 37.3943817615509, "gpu_memory_mean_mb": 1057.0456198770491, "gpu_memory_peak_mb": 1535.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.285245901639344, "gpu_power_mean_watts": 9.148773770491804, "gpu_power_peak_watts": 32.76, "gpu_temperature_mean_c": 47.42622950819672, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 4971.99752817623, "cpu_memory_peak_mb": 5432.46484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765590218.6869464}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.197499998146668, 2.4571999965701252], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [3640.5005718985467, 3255.7382431901246], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7229000043007545, 2.2229999958653934, 4.1805000000749715], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.092, "gpu_power_peak_watts": 10.092, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2868.48046875, "cpu_memory_peak_mb": 2868.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590218.82179}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.671800000825897, 2.191299994592555], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [2994.2360945905643, 3650.8009034552574], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0815999998594634, 2.192699997976888, 1.9834000049741007], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.238, "gpu_power_peak_watts": 8.238, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2868.48046875, "cpu_memory_peak_mb": 2868.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590218.9447296}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.929700000095181, 2.322600004845299], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [2730.6550157832176, 3444.4157337943584], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8531999996630475, 2.3941000035847537, 2.2686000011162832], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.238, "gpu_power_peak_watts": 8.238, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2868.48046875, "cpu_memory_peak_mb": 2868.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.0702722}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [1.956599997356534, 2.3340999978245236], "ttft_ms": [], "tokens_processed": [8, 8], "throughput_tok_s": [4088.7253453993694, 3427.445271177896], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.775200002361089, 2.4362000040127896, 5.530099995667115], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.238, "gpu_power_peak_watts": 8.238, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2868.48046875, "cpu_memory_peak_mb": 2868.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.1960466}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.577699997345917, 2.6526000001467764], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4267.370140561724, 4146.874764152656], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.759199993510265, 2.6746000003186055, 2.2399999943445437], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 8.238, "gpu_power_peak_watts": 8.238, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2869.0546875, "cpu_memory_peak_mb": 2869.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.3209968}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.526100004615728, 2.6299999954062514], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4354.53860888351, 4182.509513008897], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.0092999988701195, 2.605900001071859, 2.66389999887906], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 4.114, "gpu_power_peak_watts": 4.114, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2869.05859375, "cpu_memory_peak_mb": 2869.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.4502103}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.846199997293297, 2.769600003375672], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3864.8021960722617, 3971.6926583596437], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4410000007483177, 2.838799999153707, 2.6989999969373457], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 4.114, "gpu_power_peak_watts": 4.114, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2869.0625, "cpu_memory_peak_mb": 2869.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.5851457}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.4594999995315447, 2.930200003902428], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [4472.453751614208, 3754.009960190515], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5719000006793067, 2.722400000493508, 2.44320000638254], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 4.114, "gpu_power_peak_watts": 4.114, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2869.0625, "cpu_memory_peak_mb": 2869.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.7113106}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [2.9433000017888844, 2.298999999766238], "ttft_ms": [], "tokens_processed": [11, 11], "throughput_tok_s": [3737.3016659240984, 4784.6889957018175], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.307799997855909, 2.5462000048719347, 2.0973999999114312], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 4.114, "gpu_power_peak_watts": 4.114, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2869.0625, "cpu_memory_peak_mb": 2869.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.8361986}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.036099999211729, 7.031199995253701], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4707.514680932286, 2702.241439985443], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7450000056414865, 6.6614999959710985, 4.1917000053217635], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.315, "gpu_power_peak_watts": 2.315, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2870.59765625, "cpu_memory_peak_mb": 2870.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590219.9589674}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [3.851600005873479, 6.852899998193607], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4933.014843448448, 2772.5488486638233], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.637699996237643, 4.620100000465754, 3.362600000400562], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.315, "gpu_power_peak_watts": 2.315, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2870.59765625, "cpu_memory_peak_mb": 2870.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.0822742}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.82929999998305, 3.886300000885967], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [3934.317602979042, 4888.968941066962], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.254500003298745, 6.85689999954775, 3.944500000216067], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.315, "gpu_power_peak_watts": 2.315, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2870.59765625, "cpu_memory_peak_mb": 2870.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.2098634}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.015800004708581, 3.828699998848606], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4731.311314737347, 4962.519916868341], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.319300001952797, 6.160500000987668, 3.5571999978856184], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 2.315, "gpu_power_peak_watts": 2.315, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2870.59765625, "cpu_memory_peak_mb": 2870.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.3330674}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.007999996247236, 4.188599996268749], "ttft_ms": [], "tokens_processed": [19, 19], "throughput_tok_s": [4740.5189665144835, 4536.121858598436], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.186500002106186, 6.408900000678841, 3.544800005329307], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 765.0390625, "gpu_memory_peak_mb": 765.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2870.59765625, "cpu_memory_peak_mb": 2870.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.4584475}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.860200002440251, 6.886299997859169], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5555.32693848887, 3920.8283125036423], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.152799996722024, 5.309000000124797, 4.249300000083167], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2872.1328125, "cpu_memory_peak_mb": 2872.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.5835195}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.918900005577598, 4.86559999990277], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5489.032094448838, 5549.161460156927], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.301500001223758, 6.294899998465553, 4.30190000042785], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2872.1328125, "cpu_memory_peak_mb": 2872.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.7085555}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [5.0824999998440035, 5.24050000240095], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5312.34628643949, 5152.18013312277], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.400200003350619, 6.2279999983729795, 5.292999994708225], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.37, "gpu_power_peak_watts": 2.37, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2872.1328125, "cpu_memory_peak_mb": 2872.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.8337336}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.866399998718407, 6.773000000976026], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5548.249220596457, 3986.416653788447], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.172500001208391, 6.323999994492624, 4.891899996437132], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.437, "gpu_power_peak_watts": 2.437, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2872.14453125, "cpu_memory_peak_mb": 2872.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590220.958424}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [4.761900003359187, 4.598500003339723], "ttft_ms": [], "tokens_processed": [27, 27], "throughput_tok_s": [5670.005666005877, 5871.47982611523], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.998799995519221, 6.760699994629249, 4.31850000313716], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 767.0390625, "gpu_memory_peak_mb": 767.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.437, "gpu_power_peak_watts": 2.437, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2872.14453125, "cpu_memory_peak_mb": 2872.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.095783}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.740700002410449, 7.073499997204635], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6527.511977133794, 6220.400087281867], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.204100003349595, 7.156499996199273, 6.680399994365871], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 761.0390625, "gpu_memory_peak_mb": 761.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.437, "gpu_power_peak_watts": 2.437, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2867.9140625, "cpu_memory_peak_mb": 2867.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.2227674}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [7.000799996603746, 6.593500002054498], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6284.996003506091, 6673.238793704382], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.260399994265754, 7.161000001360662, 7.093100000929553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 771.0390625, "gpu_memory_peak_mb": 771.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 2.437, "gpu_power_peak_watts": 2.437, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2877.62109375, "cpu_memory_peak_mb": 2877.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.346574}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.812400002672803, 6.590099997993093], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6458.810402022324, 6676.681691233742], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.6759000003221445, 6.69200000265846, 6.9418999992194586], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 771.0390625, "gpu_memory_peak_mb": 771.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2874.1875, "cpu_memory_peak_mb": 2874.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.4704535}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [8.83579999936046, 7.053400004224386], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [4979.741506505889, 6238.1262899662215], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.331100001465529, 6.346199996187352, 7.0360000026994385], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 771.0390625, "gpu_memory_peak_mb": 771.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2877.62109375, "cpu_memory_peak_mb": 2877.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.5938334}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [6.317800005490426, 7.117400004062802], "ttft_ms": [], "tokens_processed": [44, 44], "throughput_tok_s": [6964.449644142297, 6182.0327612447845], "predicted_tokens": [" stairs", " stairs"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.294399998907465, 6.918999999470543, 6.655199998931494], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 771.0390625, "gpu_memory_peak_mb": 771.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2877.62109375, "cpu_memory_peak_mb": 2877.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.7179823}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [12.136999997892417, 10.971199997584336], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6261.84394934476, 6927.227652101307], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.188500004413072, 10.532300002523698, 11.1174999983632], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 777.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.063, "gpu_power_peak_watts": 3.063, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2883.7578125, "cpu_memory_peak_mb": 2883.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.843057}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.961699998006225, 11.154200001328718], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [6933.231160661513, 6813.576947781704], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.321300004259683, 10.975500001222827, 11.415099994337652], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 777.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.223, "gpu_power_peak_watts": 3.223, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2883.7578125, "cpu_memory_peak_mb": 2883.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590221.983813}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.685000001103617, 10.676799996872433], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [7112.774917374845, 7118.237676294654], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.01059999584686, 10.999900005117524, 12.289599995710887], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 777.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.223, "gpu_power_peak_watts": 3.223, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2881.21484375, "cpu_memory_peak_mb": 2881.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590222.1100547}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [13.530700001865625, 11.243000000831671], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [5616.856481151829, 6759.761628958294], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.897699994733557, 10.779999996884726, 11.097200003860053], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 777.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.223, "gpu_power_peak_watts": 3.223, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2877.90234375, "cpu_memory_peak_mb": 2877.90234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590222.2332213}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "prefill"}, "status": "ok", "error": null, "latencies_ms": [10.641699998814147, 10.961299994960427], "ttft_ms": [], "tokens_processed": [76, 76], "throughput_tok_s": [7141.716079993706, 6933.484170211726], "predicted_tokens": [" factors", " factors"], "outputs": [], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.821000000054482, 10.724599997047335, 10.63609999982873], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 777.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 3.223, "gpu_power_peak_watts": 3.223, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2883.203125, "cpu_memory_peak_mb": 2883.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 66.53509999887319, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765590222.35762}
