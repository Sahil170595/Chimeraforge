{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.341899999417365, 4.241299997374881], "tokens_processed": [8, 8], "throughput_tok_s": [1842.5113432076998, 1886.2141336268446], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [110.79510000126902, 4.271599998901365, 4.136799998377683], "resource_metrics": {"samples": 2, "duration_s": 0.12283468246459961, "gpu_memory_mean_mb": 538.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.046, "gpu_power_peak_watts": 30.046, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 717.4296875, "cpu_memory_peak_mb": 763.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577846.6607006}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.661799997847993, 5.950099999608938], "tokens_processed": [8, 8], "throughput_tok_s": [1716.075336499422, 1344.5152183199928], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8094999979657587, 4.1918999995687045, 3.7072000013722572], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.266, "gpu_power_peak_watts": 30.266, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 763.62109375, "cpu_memory_peak_mb": 763.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577846.792909}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.949100002500927, 3.443000001425389], "tokens_processed": [8, 8], "throughput_tok_s": [2025.778024089964, 2323.5550382480483], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.384800002299016, 4.174099998635938, 5.067099998996127], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.266, "gpu_power_peak_watts": 30.266, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 763.7265625, "cpu_memory_peak_mb": 763.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577846.9162927}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.136999999900581, 3.681099999084836], "tokens_processed": [8, 8], "throughput_tok_s": [1933.7684312768317, 2173.2634272334067], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.71399999858113, 3.8353000018105377, 4.742500001157168], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.266, "gpu_power_peak_watts": 30.266, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 763.73828125, "cpu_memory_peak_mb": 763.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.0370657}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.687200002081227, 4.107100001419894], "tokens_processed": [8, 8], "throughput_tok_s": [1706.775899566439, 1947.8464116369857], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.474699999263976, 3.744499997992534, 4.007700001238845], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.266, "gpu_power_peak_watts": 30.266, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 763.84765625, "cpu_memory_peak_mb": 763.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.1652086}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.7226999997510575, 3.983200000220677], "tokens_processed": [11, 11], "throughput_tok_s": [1922.1696053398762, 2761.598714448328], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.190600000787526, 3.83720000172616, 4.461600001377519], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.418, "gpu_power_peak_watts": 30.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 766.140625, "cpu_memory_peak_mb": 766.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.2960284}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.9032999993651174, 3.7979000007908326], "tokens_processed": [11, 11], "throughput_tok_s": [2818.1282509131197, 2896.337449040123], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3745000000635628, 5.662400002620416, 3.666499997052597], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.418, "gpu_power_peak_watts": 30.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 766.21484375, "cpu_memory_peak_mb": 766.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.4148417}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.274900002201321, 4.314400001021568], "tokens_processed": [11, 11], "throughput_tok_s": [2573.159604747632, 2549.6013344602748], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.296099999919534, 4.28979999924195, 4.511600000114413], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.418, "gpu_power_peak_watts": 30.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 766.3046875, "cpu_memory_peak_mb": 766.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.5378358}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.426999999850523, 4.062699998030439], "tokens_processed": [11, 11], "throughput_tok_s": [2484.752654251505, 2707.559013791986], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.527799999777926, 4.2557000015222, 4.402699996717274], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.418, "gpu_power_peak_watts": 30.418, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 766.359375, "cpu_memory_peak_mb": 766.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.6627011}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.034199999296106, 4.0100999976857565], "tokens_processed": [11, 11], "throughput_tok_s": [2726.686828099573, 2743.073740392544], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.129799999645911, 4.282900001271628, 4.741900000226451], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.515, "gpu_power_peak_watts": 30.515, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 766.36328125, "cpu_memory_peak_mb": 766.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.7862449}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.325000001699664, 4.358900001534494], "tokens_processed": [19, 19], "throughput_tok_s": [4393.063582088617, 4358.8978855471105], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.88250000186963, 3.7075000000186265, 4.63089999902877], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.515, "gpu_power_peak_watts": 30.515, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 770.46875, "cpu_memory_peak_mb": 770.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577847.909195}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.888099996605888, 4.233599996950943], "tokens_processed": [19, 19], "throughput_tok_s": [3886.9908580415463, 4487.906276852769], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.798300000402378, 4.779599999892525, 4.8634000013407785], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.515, "gpu_power_peak_watts": 30.515, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 770.54296875, "cpu_memory_peak_mb": 770.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.0319262}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.81160000001546, 4.7558000005665235], "tokens_processed": [19, 19], "throughput_tok_s": [3269.3234221125776, 3995.121745602563], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.34780000068713, 3.548599997884594, 3.2203999980993103], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.515, "gpu_power_peak_watts": 30.515, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 770.5703125, "cpu_memory_peak_mb": 770.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.1617022}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.656000000977656, 4.4304000002739485], "tokens_processed": [19, 19], "throughput_tok_s": [4080.756012888837, 4288.551823497914], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.702099999121856, 5.695299998478731, 4.919999999401625], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.496, "gpu_power_peak_watts": 30.496, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 770.609375, "cpu_memory_peak_mb": 770.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.284859}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.1517000028979965, 4.765099998621736], "tokens_processed": [19, 19], "throughput_tok_s": [3688.1029542310093, 3987.324506410272], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.293199999869103, 4.806299999472685, 5.163600002560997], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.496, "gpu_power_peak_watts": 30.496, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 770.625, "cpu_memory_peak_mb": 770.625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.4084098}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.748799998196773, 4.5365000005404], "tokens_processed": [27, 27], "throughput_tok_s": [5685.646902428511, 5951.724897340172], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.521499999304069, 4.99620000118739, 4.992099999071797], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.496, "gpu_power_peak_watts": 30.496, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.28515625, "cpu_memory_peak_mb": 768.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.5328946}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.004600003303494, 5.402099999628263], "tokens_processed": [27, 27], "throughput_tok_s": [5395.036562797732, 4998.056311778376], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.868500000156928, 4.770600000483682, 5.502300002262928], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.496, "gpu_power_peak_watts": 30.496, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.3046875, "cpu_memory_peak_mb": 768.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.6581395}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.890199998044409, 5.03269999899203], "tokens_processed": [27, 27], "throughput_tok_s": [5521.246576990165, 5364.913467007307], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.743599998822901, 4.667599998356309, 5.100099999253871], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.496, "gpu_power_peak_watts": 30.496, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.31640625, "cpu_memory_peak_mb": 768.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.7832458}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.813399998965906, 4.872199999226723], "tokens_processed": [27, 27], "throughput_tok_s": [5609.340592055633, 5541.644432553103], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.563299997447757, 5.8136000006925315, 4.736200000479585], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.512, "gpu_power_peak_watts": 30.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.32421875, "cpu_memory_peak_mb": 768.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577848.9083438}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.458200000954093, 5.03230000322219], "tokens_processed": [27, 27], "throughput_tok_s": [6056.255886730467, 5365.339900783311], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.076699999335688, 5.646199999318924, 6.173500001750654], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.512, "gpu_power_peak_watts": 30.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 765.14453125, "cpu_memory_peak_mb": 765.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.0317564}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.7430999986536335, 6.444399998144945], "tokens_processed": [44, 44], "throughput_tok_s": [7661.367555904478, 6827.633295988088], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.256199998460943, 4.454599999007769, 7.667199999559671], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.512, "gpu_power_peak_watts": 30.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 769.0625, "cpu_memory_peak_mb": 769.0625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.1570854}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.768300001567695, 6.587600000784732], "tokens_processed": [44, 44], "throughput_tok_s": [6500.893871401767, 6679.215494984304], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.145400002627866, 8.008199998585042, 5.702599999494851], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.512, "gpu_power_peak_watts": 30.512, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 759.875, "cpu_memory_peak_mb": 759.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.2810383}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.84789999993518, 6.78650000190828], "tokens_processed": [44, 44], "throughput_tok_s": [7524.068469106467, 6483.459808093678], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.118099998275284, 5.791300001874333, 6.654200002230937], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.529, "gpu_power_peak_watts": 30.529, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.31640625, "cpu_memory_peak_mb": 768.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.402488}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.560000001627486, 6.227300000318792], "tokens_processed": [44, 44], "throughput_tok_s": [6707.317071506697, 7065.662485787986], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.553300001542084, 6.002300000545802, 6.204900000739144], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.529, "gpu_power_peak_watts": 30.529, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.31640625, "cpu_memory_peak_mb": 768.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.5277452}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.786499998066574, 6.700499998260057], "tokens_processed": [44, 44], "throughput_tok_s": [7603.905644984288, 6566.674130501551], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.90609999926528, 6.804099997680169, 6.485199999588076], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 552.01953125, "gpu_memory_peak_mb": 552.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.529, "gpu_power_peak_watts": 30.529, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 768.31640625, "cpu_memory_peak_mb": 768.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.650047}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.740799999941373, 7.690900001762202], "tokens_processed": [76, 76], "throughput_tok_s": [8694.85630611726, 9881.80836866768], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.213700002874248, 9.115100001508836, 8.196399998269044], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.529, "gpu_power_peak_watts": 30.529, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 759.88671875, "cpu_memory_peak_mb": 759.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.77272}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.5956000000587665, 7.675799999560695], "tokens_processed": [76, 76], "throughput_tok_s": [10005.79282734899, 9901.248078942868], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.371600000828039, 8.063899997068802, 7.5906000020040665], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.59, "gpu_power_peak_watts": 30.59, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 774.51171875, "cpu_memory_peak_mb": 774.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577849.8964906}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.294399998500012, 7.4190999985148665], "tokens_processed": [76, 76], "throughput_tok_s": [10418.951526599625, 10243.830116215371], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.956299999932526, 10.17629999842029, 7.7118999979575165], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.59, "gpu_power_peak_watts": 30.59, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 759.88671875, "cpu_memory_peak_mb": 759.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577850.0214264}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.007899999327492, 4.888200001005316], "tokens_processed": [76, 76], "throughput_tok_s": [15176.021887459014, 15547.645346829038], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.376000001386274, 9.088299997529248, 6.164099999296013], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.59, "gpu_power_peak_watts": 30.59, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 774.51171875, "cpu_memory_peak_mb": 774.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577850.1453474}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.80929999766522, 7.03119999889168], "tokens_processed": [76, 76], "throughput_tok_s": [8627.246208000945, 10808.965754349158], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.232399999338668, 11.064999998779967, 7.225100001960527], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.59, "gpu_power_peak_watts": 30.59, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 759.890625, "cpu_memory_peak_mb": 759.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 994.9233000006643, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577850.269444}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9420999995199963, 0.7994000006874558], "tokens_processed": [8, 8], "throughput_tok_s": [8491.667555541908, 10007.505620615815], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.613699998415541, 0.6941999999980908, 0.761799998144852], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.671, "gpu_power_peak_watts": 30.671, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 776.76953125, "cpu_memory_peak_mb": 776.76953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577850.394333}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5992000005790032, 0.7076000001688953], "tokens_processed": [8, 8], "throughput_tok_s": [13351.13483356083, 11305.822495888213], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0160999991057906, 0.6415999996534083, 0.5536999997275416], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.671, "gpu_power_peak_watts": 30.671, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 776.80859375, "cpu_memory_peak_mb": 776.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577850.5167196}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6884999966132455, 0.5682999981218018], "tokens_processed": [8, 8], "throughput_tok_s": [11619.462657011283, 14077.07201555434], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9372999993502162, 0.9583999999449588, 0.7734999999229331], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.671, "gpu_power_peak_watts": 30.671, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 776.87890625, "cpu_memory_peak_mb": 776.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577850.6396954}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7231000017782208, 0.6003999988024589], "tokens_processed": [8, 8], "throughput_tok_s": [11063.476670345313, 13324.450392998962], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0290000027453061, 0.7762999994156417, 0.6522999974549748], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.671, "gpu_power_peak_watts": 30.671, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 776.87890625, "cpu_memory_peak_mb": 776.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577850.7742367}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.8725999978196342, 0.7564000006823335], "tokens_processed": [8, 8], "throughput_tok_s": [9168.003690109561, 10576.414585911367], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.119299999118084, 0.8422999999311287, 0.8286000011139549], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.088, "gpu_power_peak_watts": 30.088, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 776.91015625, "cpu_memory_peak_mb": 776.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577850.9060934}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8124999985739123, 0.9592999995220453], "tokens_processed": [11, 11], "throughput_tok_s": [13538.461562224042, 11466.694470426937], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4628999997512437, 0.7253000003402121, 0.6394999982148875], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.088, "gpu_power_peak_watts": 30.088, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 777.52734375, "cpu_memory_peak_mb": 777.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.0302901}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.262400000996422, 1.0153000002901535], "tokens_processed": [11, 11], "throughput_tok_s": [8713.56146333778, 10834.236183252642], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0938000013993587, 1.0083999986818526, 1.2234999994689133], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.088, "gpu_power_peak_watts": 30.088, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 777.53125, "cpu_memory_peak_mb": 777.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.1560512}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8748000000196043, 0.8170000000973232], "tokens_processed": [11, 11], "throughput_tok_s": [12574.302697477697, 13463.892287257835], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.208599998790305, 0.8039000022108667, 1.100500001484761], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.088, "gpu_power_peak_watts": 30.088, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 777.609375, "cpu_memory_peak_mb": 777.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.2766771}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8353000011993572, 0.7783000000927132], "tokens_processed": [11, 11], "throughput_tok_s": [13168.921326715861, 14133.367594359053], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5299000006052665, 0.7922000004327856, 0.6505000019387808], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.313, "gpu_power_peak_watts": 30.313, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 777.65234375, "cpu_memory_peak_mb": 777.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.40305}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6689000001642853, 0.7541999984823633], "tokens_processed": [11, 11], "throughput_tok_s": [16444.909548958505, 14584.990747990874], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.546699997561518, 0.7355999987339601, 0.6926999994902872], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.313, "gpu_power_peak_watts": 30.313, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 777.671875, "cpu_memory_peak_mb": 777.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.527322}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.05729999995674, 1.2524000012490433], "tokens_processed": [19, 19], "throughput_tok_s": [17970.30171264295, 15170.871910772057], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.223800001956988, 1.112400001147762, 1.1134000014862977], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.313, "gpu_power_peak_watts": 30.313, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 779.27734375, "cpu_memory_peak_mb": 779.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.6655629}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4682000000902917, 1.3628999986394774], "tokens_processed": [19, 19], "throughput_tok_s": [12941.016209529718, 13940.86141240506], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3385999991442077, 1.1874999981955625, 1.7963000027521048], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.89, "gpu_power_peak_watts": 29.89, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 779.28125, "cpu_memory_peak_mb": 779.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.7893138}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.494600001227809, 1.0425000000395812], "tokens_processed": [19, 19], "throughput_tok_s": [7616.451531567566, 18225.41966357661], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8251000001328066, 1.0742000013124198, 1.2040000001434237], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.89, "gpu_power_peak_watts": 29.89, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 779.28515625, "cpu_memory_peak_mb": 779.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577851.9162347}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0842000010597985, 1.1879000012413599], "tokens_processed": [19, 19], "throughput_tok_s": [17524.44196774361, 15994.612324391725], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9109999993816018, 1.1952000022574794, 1.4711999974679202], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.89, "gpu_power_peak_watts": 29.89, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 779.28515625, "cpu_memory_peak_mb": 779.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.0399134}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.527899999928195, 1.2472000016714446], "tokens_processed": [19, 19], "throughput_tok_s": [12435.368807443498, 15234.124418326655], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3393000008363742, 1.7226999989361502, 1.1912000009033363], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.89, "gpu_power_peak_watts": 29.89, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 779.29296875, "cpu_memory_peak_mb": 779.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.1652586}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6480999984196387, 1.6267999999399763], "tokens_processed": [27, 27], "throughput_tok_s": [16382.501077537934, 16597.000246493863], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0258999977377243, 2.050899998721434, 1.7177000008814503], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.936, "gpu_power_peak_watts": 29.936, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 784.73046875, "cpu_memory_peak_mb": 784.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.2898338}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.781999999366235, 1.6992000018944964], "tokens_processed": [27, 27], "throughput_tok_s": [15151.51515690376, 15889.830490758459], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2306999999273103, 1.7203999996127095, 1.7626999979256652], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.936, "gpu_power_peak_watts": 29.936, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 784.734375, "cpu_memory_peak_mb": 784.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.4152737}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4378999985638075, 1.7202999988512602], "tokens_processed": [27, 27], "throughput_tok_s": [18777.38370329504, 15694.936940085683], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0463000000745524, 1.561799999763025, 2.3515999964729417], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.936, "gpu_power_peak_watts": 29.936, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 784.734375, "cpu_memory_peak_mb": 784.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.5400221}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5404000005219132, 1.9553000020096079], "tokens_processed": [27, 27], "throughput_tok_s": [17527.914821378832, 13808.62270354937], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0724999994854443, 2.6073000008182134, 1.8163000022468623], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.936, "gpu_power_peak_watts": 29.936, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 784.734375, "cpu_memory_peak_mb": 784.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.665247}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.728999999613734, 1.6097999978228472], "tokens_processed": [27, 27], "throughput_tok_s": [15615.96298787271, 16772.269869869422], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.280799999833107, 1.6838999981700908, 1.6114999998535495], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.935, "gpu_power_peak_watts": 29.935, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 784.75, "cpu_memory_peak_mb": 784.75, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.789965}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.501000002666842, 2.9971000003570225], "tokens_processed": [44, 44], "throughput_tok_s": [17592.96279611449, 14680.858161141972], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.287499999918509, 3.3842000011645723, 2.397000000200933], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.935, "gpu_power_peak_watts": 29.935, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 793.87109375, "cpu_memory_peak_mb": 793.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577852.9112775}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6327000014134683, 2.6794000004883856], "tokens_processed": [44, 44], "throughput_tok_s": [16712.880304013703, 16421.586919452093], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8057999988959637, 3.009399999427842, 2.5984999992942903], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.935, "gpu_power_peak_watts": 29.935, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 793.98828125, "cpu_memory_peak_mb": 793.98828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.0383084}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.74789999841596, 2.829800003382843], "tokens_processed": [44, 44], "throughput_tok_s": [11739.90768659689, 15548.802016891952], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.909499999077525, 2.333200001885416, 2.384400002483744], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.935, "gpu_power_peak_watts": 29.935, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 794.0546875, "cpu_memory_peak_mb": 794.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.1651747}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.735099998972146, 2.7842999988934025], "tokens_processed": [44, 44], "throughput_tok_s": [16087.1631810666, 15802.894809283283], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8477000014390796, 2.401300000201445, 2.5913999998010695], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.972, "gpu_power_peak_watts": 29.972, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 794.0546875, "cpu_memory_peak_mb": 794.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.2873833}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.620899998873938, 2.3786000019754283], "tokens_processed": [44, 44], "throughput_tok_s": [16788.12622339825, 18498.27628161859], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.248199998779455, 5.029600000852952, 2.14849999974831], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.972, "gpu_power_peak_watts": 29.972, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 794.0546875, "cpu_memory_peak_mb": 794.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.4122262}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.1629999977885745, 4.27289999788627], "tokens_processed": [76, 76], "throughput_tok_s": [18256.065347194795, 17786.51502202155], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.0570999994524755, 5.286999999952968, 3.811999999015825], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.972, "gpu_power_peak_watts": 29.972, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 800.1953125, "cpu_memory_peak_mb": 800.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.538026}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.4723000026133377, 4.257799999322742], "tokens_processed": [76, 76], "throughput_tok_s": [21887.509703309202, 17849.593689719757], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.042599997977959, 4.332399999839254, 5.590100001427345], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.972, "gpu_power_peak_watts": 29.972, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 800.1953125, "cpu_memory_peak_mb": 800.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.662201}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.254400002537295, 4.554499999358086], "tokens_processed": [76, 76], "throughput_tok_s": [17863.858582802302, 16686.79328372192], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.829100002301857, 4.949300000589574, 4.909399998723529], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.974, "gpu_power_peak_watts": 29.974, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 800.2421875, "cpu_memory_peak_mb": 800.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.7878532}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.590600001392886, 6.849900000815978], "tokens_processed": [76, 76], "throughput_tok_s": [16555.570072962135, 11095.05248119632], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.9932000001717824, 5.0049000019498635, 4.840400000830414], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.974, "gpu_power_peak_watts": 29.974, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 800.2421875, "cpu_memory_peak_mb": 800.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577853.9124932}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.496099998505088, 4.255299998476403], "tokens_processed": [76, 76], "throughput_tok_s": [16903.538627981874, 17860.080376756414], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.434799997601658, 4.4023000009474345, 5.904900001041824], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 568.01953125, "gpu_memory_peak_mb": 568.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.974, "gpu_power_peak_watts": 29.974, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 800.2421875, "cpu_memory_peak_mb": 800.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 103.59710000193445, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.037659}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.3388999981980305, 2.931500002887333], "tokens_processed": [8, 8], "throughput_tok_s": [2395.9986834938204, 2728.978336046574], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [39.1721999985748, 2.643499999976484, 3.1328000004577916], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 586.01953125, "gpu_memory_peak_mb": 586.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.974, "gpu_power_peak_watts": 29.974, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 811.4921875, "cpu_memory_peak_mb": 811.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.159575}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.7090000003227033, 2.4601999975857325], "tokens_processed": [8, 8], "throughput_tok_s": [2953.1192318372164, 3251.768152122038], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6460000008228235, 2.4468000010529067, 2.444699999614386], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.974, "gpu_power_peak_watts": 29.974, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 849.1484375, "cpu_memory_peak_mb": 849.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.2844014}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.3132000023906585, 2.5483999997959472], "tokens_processed": [8, 8], "throughput_tok_s": [3458.4125850476034, 3139.224611772315], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3493000009912066, 3.0256999998528045, 2.504099997167941], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.076, "gpu_power_peak_watts": 30.076, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 849.1484375, "cpu_memory_peak_mb": 849.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.4091597}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.388900000572903, 2.4229000009654555], "tokens_processed": [8, 8], "throughput_tok_s": [2360.6479974763424, 3301.828386153878], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.089400001044851, 2.6127999990421813, 2.6700999987951946], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.076, "gpu_power_peak_watts": 30.076, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 849.15234375, "cpu_memory_peak_mb": 849.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.535441}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.7259999988018535, 2.9031000012764707], "tokens_processed": [8, 8], "throughput_tok_s": [2934.7028626251667, 2755.6749669258593], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3581999996386003, 3.0619999997725245, 2.508300000044983], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.076, "gpu_power_peak_watts": 30.076, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 849.15234375, "cpu_memory_peak_mb": 849.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.657813}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.141900000628084, 3.1249000021489337], "tokens_processed": [11, 11], "throughput_tok_s": [3501.0662331076855, 3520.1126411838814], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.119999997783452, 3.783200001635123, 3.1784000020707026], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.076, "gpu_power_peak_watts": 30.076, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 851.4140625, "cpu_memory_peak_mb": 851.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.7804594}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.983899998071138, 2.9758999990008306], "tokens_processed": [11, 11], "throughput_tok_s": [3686.4506207013155, 3696.3607660517123], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.919299997302005, 2.966199997899821, 3.378000001248438], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.257, "gpu_power_peak_watts": 30.257, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 851.41796875, "cpu_memory_peak_mb": 851.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577854.9195502}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.7886000027356204, 3.5819000004266854], "tokens_processed": [11, 11], "throughput_tok_s": [2903.4471815597503, 3070.9958398307185], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6571999989973847, 3.5229000022809487, 3.9332999986072537], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.257, "gpu_power_peak_watts": 30.257, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 851.41796875, "cpu_memory_peak_mb": 851.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.0448525}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4133999979530927, 2.932600000349339], "tokens_processed": [11, 11], "throughput_tok_s": [3222.5933106569255, 3750.937733986787], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.465999998297775, 3.4143999982916284, 3.6832000005233567], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.257, "gpu_power_peak_watts": 30.257, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 851.41796875, "cpu_memory_peak_mb": 851.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.1693168}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.847300002234988, 3.2318999983544927], "tokens_processed": [11, 11], "throughput_tok_s": [2859.14797224283, 3403.570656765556], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5988999989058357, 3.5702999994100537, 3.6776000015379395], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.698, "gpu_power_peak_watts": 30.698, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 851.44921875, "cpu_memory_peak_mb": 851.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.293152}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.260300000169082, 4.1135000028589275], "tokens_processed": [19, 19], "throughput_tok_s": [4459.779827534665, 4618.937641131589], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.532099999778438, 3.598200000851648, 4.069199996592943], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.698, "gpu_power_peak_watts": 30.698, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 853.015625, "cpu_memory_peak_mb": 853.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.4165647}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.349700000602752, 4.288899999664864], "tokens_processed": [19, 19], "throughput_tok_s": [4368.117340820541, 4430.040337029231], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.016600000089966, 4.4592999984161, 3.868200001306832], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.698, "gpu_power_peak_watts": 30.698, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 853.015625, "cpu_memory_peak_mb": 853.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.5412755}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.4017000034509692, 4.595000002154848], "tokens_processed": [19, 19], "throughput_tok_s": [5585.4425671648905, 4134.929269007586], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.370099999505328, 4.366700002719881, 4.82949999786797], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.698, "gpu_power_peak_watts": 30.698, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 853.015625, "cpu_memory_peak_mb": 853.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.6799026}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9108000019041356, 3.8717999996151775], "tokens_processed": [19, 19], "throughput_tok_s": [4858.341002032592, 4907.278268993345], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.66719999894849, 4.962299997714581, 3.9557999989483505], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.283, "gpu_power_peak_watts": 30.283, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 853.015625, "cpu_memory_peak_mb": 853.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.8087523}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.8992999980109744, 4.036999998788815], "tokens_processed": [19, 19], "throughput_tok_s": [4872.669455977192, 4706.465198340451], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.490700001042569, 4.640900002414128, 4.528900000877911], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.283, "gpu_power_peak_watts": 30.283, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 853.015625, "cpu_memory_peak_mb": 853.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577855.93256}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.334099998435704, 5.558599998039426], "tokens_processed": [27, 27], "throughput_tok_s": [5061.772371706213, 4857.338180391316], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.526999997731764, 5.118500001117354, 5.8572999987518415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.283, "gpu_power_peak_watts": 30.283, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 858.77734375, "cpu_memory_peak_mb": 858.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.0573406}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.648800000722986, 5.384799998864764], "tokens_processed": [27, 27], "throughput_tok_s": [5807.950437919664, 5014.113802869596], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.778999999165535, 5.153199999767821, 4.54850000096485], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.283, "gpu_power_peak_watts": 30.283, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 858.77734375, "cpu_memory_peak_mb": 858.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.1831284}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.734300000767689, 5.807699999422766], "tokens_processed": [27, 27], "throughput_tok_s": [4708.508448526469, 4649.000465362115], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.536100001540035, 5.963300001894822, 6.037799998011906], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 858.77734375, "cpu_memory_peak_mb": 858.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.307058}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.290000001172302, 6.1887999981991015], "tokens_processed": [27, 27], "throughput_tok_s": [4292.527821139564, 4362.719753079243], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.5775000000721775, 6.324100002530031, 5.370400001993403], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 858.77734375, "cpu_memory_peak_mb": 858.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.4462824}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.710499997599982, 5.170000000362052], "tokens_processed": [27, 27], "throughput_tok_s": [5731.875599990788, 5222.437136965031], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.607800001394935, 5.710699999326607, 6.333400000585243], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 858.78515625, "cpu_memory_peak_mb": 858.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.5701513}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.749500000092667, 5.907700000534533], "tokens_processed": [44, 44], "throughput_tok_s": [7652.839377213816, 7447.906968197242], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.733099999721162, 7.487800001399592, 6.589500000700355], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 22.982, "gpu_power_peak_watts": 22.982, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 868.54296875, "cpu_memory_peak_mb": 868.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.6956072}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.377099999052007, 8.322699999553151], "tokens_processed": [44, 44], "throughput_tok_s": [5252.414320585794, 5286.745888036619], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.587800002307631, 8.161999998264946, 7.349600000452483], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.657, "gpu_power_peak_watts": 14.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 868.59375, "cpu_memory_peak_mb": 868.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.819089}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.972899998596404, 8.050999997067265], "tokens_processed": [44, 44], "throughput_tok_s": [7366.605838092006, 5465.1596094929655], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.692200000747107, 7.015899998805253, 6.009099997754674], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.657, "gpu_power_peak_watts": 14.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 868.62890625, "cpu_memory_peak_mb": 868.62890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577856.944192}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.680800001253374, 7.356099999014987], "tokens_processed": [44, 44], "throughput_tok_s": [5728.569939696381, 5981.430378310761], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.803499996953178, 7.3345999990124255, 7.87329999729991], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.657, "gpu_power_peak_watts": 14.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 868.65625, "cpu_memory_peak_mb": 868.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.0670893}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [10.790000000270084, 9.847899997112108], "tokens_processed": [44, 44], "throughput_tok_s": [4077.849860880319, 4467.957636948281], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.65050000033807, 9.775499998795567, 9.83980000091833], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.657, "gpu_power_peak_watts": 14.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 868.65625, "cpu_memory_peak_mb": 868.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.2073412}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.44799999849056, 16.34399999966263], "tokens_processed": [76, 76], "throughput_tok_s": [4620.622568517422, 4650.024473909006], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.48130000103265, 16.250200002104975, 16.136800000822404], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.43, "gpu_power_peak_watts": 12.43, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 868.66796875, "cpu_memory_peak_mb": 868.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.329981}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.93840000007185, 16.347099997801706], "tokens_processed": [76, 76], "throughput_tok_s": [4486.846455372267, 4649.14266201468], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.826200000650715, 16.457999998237938, 16.468000001623295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.43, "gpu_power_peak_watts": 12.43, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 874.79296875, "cpu_memory_peak_mb": 874.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.4527986}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.69229999970412, 17.29420000265236], "tokens_processed": [76, 76], "throughput_tok_s": [4552.997489941299, 4394.536896089099], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.25830000214046, 16.64610000079847, 16.968200001429068], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.43, "gpu_power_peak_watts": 12.43, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 874.79296875, "cpu_memory_peak_mb": 874.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.5941825}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [17.086899999412708, 16.4210999973875], "tokens_processed": [76, 76], "throughput_tok_s": [4447.851863276088, 4628.191778388241], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.234499999176478, 17.583400000148686, 16.49810000162688], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.43, "gpu_power_peak_watts": 12.43, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 874.79296875, "cpu_memory_peak_mb": 874.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.7179883}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.69659999970463, 16.310399998474168], "tokens_processed": [76, 76], "throughput_tok_s": [4551.824922519822, 4659.603688880087], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.220699999597855, 17.21940000061295, 17.50059999903897], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 8.113, "gpu_power_peak_watts": 8.113, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 874.79296875, "cpu_memory_peak_mb": 874.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1840.8483999992313, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577857.8483014}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.46860000293236226, 0.47480000284849666], "tokens_processed": [8, 8], "throughput_tok_s": [17072.129641353673, 16849.199561931575], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9681000012496952, 0.7869999972172081, 0.5357999980333261], "resource_metrics": {"samples": 3, "duration_s": 0.20833992958068848, "gpu_memory_mean_mb": 617.0260416666666, "gpu_memory_peak_mb": 623.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 8.113, "gpu_power_peak_watts": 8.113, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 918.2265625, "cpu_memory_peak_mb": 974.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765577858.1684268}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7485000023734756, 0.8161999976437073], "tokens_processed": [8, 8], "throughput_tok_s": [10688.042718279481, 9801.519263777564], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5358000018750317, 0.9828000002016779, 0.7049999985611066], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 6.145, "gpu_power_peak_watts": 6.145, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1047.41796875, "cpu_memory_peak_mb": 1047.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.2918649}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.8526000019628555, 1.0330000004614703], "tokens_processed": [8, 8], "throughput_tok_s": [9383.063548654003, 7744.433684826887], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6232000016316306, 0.7404999996651895, 0.7941999974718783], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 6.145, "gpu_power_peak_watts": 6.145, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1047.4375, "cpu_memory_peak_mb": 1047.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.416556}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6460999975388404, 0.7880000011937227], "tokens_processed": [8, 8], "throughput_tok_s": [12381.984260136263, 10152.284248579934], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1422000025049783, 0.9842999970715027, 0.780099999246886], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 6.145, "gpu_power_peak_watts": 6.145, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1047.51953125, "cpu_memory_peak_mb": 1047.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.5414293}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.0918000007222872, 1.1215999984415248], "tokens_processed": [8, 8], "throughput_tok_s": [7327.349326531919, 7132.667627599933], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.189800001156982, 0.8491000007779803, 0.9030000001075678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 6.145, "gpu_power_peak_watts": 6.145, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1047.5234375, "cpu_memory_peak_mb": 1047.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.6642709}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2371000011626165, 1.0454000002937391], "tokens_processed": [11, 11], "throughput_tok_s": [8891.762985742696, 10522.288116423562], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.852199999120785, 1.0414999997010455, 0.9863999985100236], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 30.625, "gpu_power_peak_watts": 30.625, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1048.09765625, "cpu_memory_peak_mb": 1048.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.7874067}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2277999994694255, 1.046899997163564], "tokens_processed": [11, 11], "throughput_tok_s": [8959.113866064079, 10507.21179654507], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7428999999538064, 0.9573999996064231, 0.8997999975690618], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 30.625, "gpu_power_peak_watts": 30.625, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1048.09765625, "cpu_memory_peak_mb": 1048.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577858.9118989}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7928999984869733, 0.9973000014724676], "tokens_processed": [11, 11], "throughput_tok_s": [13873.124001753571, 11029.780390814205], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0834000022441614, 0.8683999985805713, 0.8373999989998993], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 30.625, "gpu_power_peak_watts": 30.625, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1048.09765625, "cpu_memory_peak_mb": 1048.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.036195}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1156999971717596, 1.066600001649931], "tokens_processed": [11, 11], "throughput_tok_s": [9859.281193765722, 10313.144555582245], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0575999986031093, 0.827799998660339, 0.9715000014693942], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 30.625, "gpu_power_peak_watts": 30.625, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1048.09765625, "cpu_memory_peak_mb": 1048.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.1740005}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.4417999991565011, 1.1641999990388285], "tokens_processed": [11, 11], "throughput_tok_s": [7629.352203104002, 9448.548367189207], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6178999976546038, 0.9967000005417503, 1.0005000003729947], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.626, "gpu_power_peak_watts": 30.626, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1048.09765625, "cpu_memory_peak_mb": 1048.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.2999783}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.257299998542294, 1.1617999989539385], "tokens_processed": [19, 19], "throughput_tok_s": [15111.747412732431, 16353.933566110536], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.305100002558902, 1.713400000880938, 1.1100999981863424], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.626, "gpu_power_peak_watts": 30.626, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.6328125, "cpu_memory_peak_mb": 1049.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.4245698}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.8108999975083862, 1.3773000027867965], "tokens_processed": [19, 19], "throughput_tok_s": [10492.02055670775, 13795.106339617982], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0427000017662067, 1.5510999983234797, 1.3605000021925662], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.626, "gpu_power_peak_watts": 30.626, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.68359375, "cpu_memory_peak_mb": 1049.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.5478742}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3408000013441779, 1.9981000004918315], "tokens_processed": [19, 19], "throughput_tok_s": [14170.64437720177, 9509.033579562163], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2463999994215555, 1.4424000000872184, 1.9890999974450096], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.626, "gpu_power_peak_watts": 30.626, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.7578125, "cpu_memory_peak_mb": 1049.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.6729333}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2419999984558672, 1.308200000494253], "tokens_processed": [19, 19], "throughput_tok_s": [15297.906621273753, 14523.773117888384], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5189999978465494, 1.3479999979608692, 1.8249000022478867], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.389, "gpu_power_peak_watts": 30.389, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.77734375, "cpu_memory_peak_mb": 1049.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.7999835}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4212999994924758, 1.3184999988880008], "tokens_processed": [19, 19], "throughput_tok_s": [13368.043345377195, 14410.31476376508], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5010999997903127, 1.4490999965346418, 1.9611999996413942], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.389, "gpu_power_peak_watts": 30.389, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.78515625, "cpu_memory_peak_mb": 1049.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577859.922131}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.2921999989193864, 1.8406999988656025], "tokens_processed": [27, 27], "throughput_tok_s": [11779.076874936145, 14668.332708556374], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.11639999927138, 1.8718999999691732, 2.0847999985562637], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.389, "gpu_power_peak_watts": 30.389, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1051.36328125, "cpu_memory_peak_mb": 1051.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.047591}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.132300000084797, 1.8508000030124094], "tokens_processed": [27, 27], "throughput_tok_s": [12662.383341427692, 14588.286122786962], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3245999982464127, 1.8428000003041234, 1.7016000019793864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.389, "gpu_power_peak_watts": 30.389, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1051.42578125, "cpu_memory_peak_mb": 1051.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.167409}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.3784000002488028, 1.9250000004831236], "tokens_processed": [27, 27], "throughput_tok_s": [19587.928028965805, 14025.974022453882], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.647500001330627, 2.3432000016327947, 1.597900001797825], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.394, "gpu_power_peak_watts": 30.394, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1051.42578125, "cpu_memory_peak_mb": 1051.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.2952964}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4556999994965736, 1.7205000003741588], "tokens_processed": [27, 27], "throughput_tok_s": [18547.777707863876, 15693.11246389322], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9610999990836717, 1.9237000014982186, 2.4627000020700507], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.394, "gpu_power_peak_watts": 30.394, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1051.42578125, "cpu_memory_peak_mb": 1051.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.4200838}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.717899998970097, 2.018900002440205], "tokens_processed": [27, 27], "throughput_tok_s": [9934.140332694802, 13373.619281472897], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2888999994611368, 1.9296999998914544, 2.3290999997698236], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.394, "gpu_power_peak_watts": 30.394, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1051.42578125, "cpu_memory_peak_mb": 1051.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.5461574}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6757000014185905, 2.6537000012467615], "tokens_processed": [44, 44], "throughput_tok_s": [16444.29494213562, 16580.623272912504], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [55.8002999969176, 3.735000002052402, 2.0102999988012016], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.394, "gpu_power_peak_watts": 30.394, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1049.58203125, "cpu_memory_peak_mb": 1049.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.6915405}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7728999993996695, 2.727200000663288], "tokens_processed": [44, 44], "throughput_tok_s": [15867.863972565172, 16133.763563104529], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.915400000551017, 1.8419999978505075, 2.9630999997607432], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.452, "gpu_power_peak_watts": 30.452, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.4140625, "cpu_memory_peak_mb": 1151.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.8241782}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.854099999240134, 1.979399999981979], "tokens_processed": [44, 44], "throughput_tok_s": [15416.418489791673, 22228.958270385265], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1290000006265473, 3.2542999979341403, 3.4433000000717584], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.452, "gpu_power_peak_watts": 30.452, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.41796875, "cpu_memory_peak_mb": 1151.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577860.9486845}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.727700000832556, 3.27839999954449], "tokens_processed": [44, 44], "throughput_tok_s": [16130.806168775965, 13421.181065798402], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8163999997777864, 2.522099999623606, 2.601799998956267], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.452, "gpu_power_peak_watts": 30.452, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.41796875, "cpu_memory_peak_mb": 1151.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.0742788}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6819999984581955, 2.9107000009389594], "tokens_processed": [44, 44], "throughput_tok_s": [16405.66742180997, 15116.638604392789], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0827000009594485, 3.23249999928521, 3.3712000004015863], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.452, "gpu_power_peak_watts": 30.452, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.42578125, "cpu_memory_peak_mb": 1151.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.1959896}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.900500000076136, 4.8271000014210586], "tokens_processed": [76, 76], "throughput_tok_s": [15508.621568986684, 15744.44282853602], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.019399999582674, 4.821200000151293, 4.841900001338217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.521, "gpu_power_peak_watts": 30.521, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1157.5703125, "cpu_memory_peak_mb": 1157.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.335029}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.258000001049368, 5.21409999782918], "tokens_processed": [76, 76], "throughput_tok_s": [14454.165078895448, 14575.861612098266], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.020500000886386, 4.423599999427097, 4.6795000016572885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.521, "gpu_power_peak_watts": 30.521, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1157.57421875, "cpu_memory_peak_mb": 1157.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.4745018}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.296600000088802, 4.109299999981886], "tokens_processed": [76, 76], "throughput_tok_s": [17688.404784813396, 18494.634122681484], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.7970000016212, 4.547799999272684, 4.46649999867077], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.521, "gpu_power_peak_watts": 30.521, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1157.57421875, "cpu_memory_peak_mb": 1157.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.6161067}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.7037999973108526, 4.915699999401113], "tokens_processed": [76, 76], "throughput_tok_s": [20519.466508769336, 15460.666844856112], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.7716999981494155, 4.305400001612725, 4.985600000509294], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.521, "gpu_power_peak_watts": 30.521, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1157.57421875, "cpu_memory_peak_mb": 1157.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.754416}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.054400000517489, 5.040100000769598], "tokens_processed": [76, 76], "throughput_tok_s": [15036.403923753327, 15079.065889247271], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.967299999610987, 5.046700000093551, 3.9796999990358017], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.714, "gpu_power_peak_watts": 30.714, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1157.57421875, "cpu_memory_peak_mb": 1157.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 295.9928000018408, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577861.8803387}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.674899998557521, 0.7430000005115289], "tokens_processed": [8, 8], "throughput_tok_s": [11853.607967252305, 10767.160154094598], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.564999998867279, 0.9585999978298787, 0.821699999505654], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.714, "gpu_power_peak_watts": 30.714, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1145.58984375, "cpu_memory_peak_mb": 1145.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765577862.0054228}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.856700000440469, 0.7526000008510891], "tokens_processed": [8, 8], "throughput_tok_s": [9338.15804352379, 10629.816623642146], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8321999994223006, 0.8581000001868233, 1.0672999997041188], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.714, "gpu_power_peak_watts": 30.714, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.17578125, "cpu_memory_peak_mb": 1149.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.1285274}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9619999982533045, 0.7659000002604444], "tokens_processed": [8, 8], "throughput_tok_s": [8316.008331107623, 10445.227832980283], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0731999973359052, 0.7791999996697996, 1.065000000380678], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 30.714, "gpu_power_peak_watts": 30.714, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.203125, "cpu_memory_peak_mb": 1149.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.2516484}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7440000008500647, 0.884999997651903], "tokens_processed": [8, 8], "throughput_tok_s": [10752.68815975742, 9039.548046582753], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1622999991232064, 0.7622999983141199, 0.8125999993353616], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.741, "gpu_power_peak_watts": 30.741, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.21484375, "cpu_memory_peak_mb": 1149.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.3772743}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.8327000032295473, 0.68710000050487], "tokens_processed": [8, 8], "throughput_tok_s": [9607.301511916376, 11643.137817088822], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.014100002066698, 0.9291999995184597, 0.994199999695411], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.741, "gpu_power_peak_watts": 30.741, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.22265625, "cpu_memory_peak_mb": 1149.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.5021346}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9926000020641368, 0.8272000013676006], "tokens_processed": [11, 11], "throughput_tok_s": [11082.006827649831, 13297.872318440306], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9298000006529037, 1.2447000008251052, 0.9234999997715931], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.741, "gpu_power_peak_watts": 30.741, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.8046875, "cpu_memory_peak_mb": 1149.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.6248007}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0852000013983343, 0.8641000022180378], "tokens_processed": [11, 11], "throughput_tok_s": [10136.380377650159, 12730.00806823789], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.404700000421144, 0.9457000014663208, 1.1493999991216697], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.741, "gpu_power_peak_watts": 30.741, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.8046875, "cpu_memory_peak_mb": 1149.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.7511566}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8576000000175554, 0.9448999990127049], "tokens_processed": [11, 11], "throughput_tok_s": [12826.49253705087, 11641.4435511626], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.092300000891555, 1.065199998265598, 0.8596000006946269], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.533, "gpu_power_peak_watts": 30.533, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.8046875, "cpu_memory_peak_mb": 1149.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577862.8760552}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.862000000779517, 1.0456999989401083], "tokens_processed": [11, 11], "throughput_tok_s": [12761.02087013059, 10519.269399588109], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2243999990459997, 0.9246999979950488, 1.250199999049073], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.533, "gpu_power_peak_watts": 30.533, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.80859375, "cpu_memory_peak_mb": 1149.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.0021641}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0354000005463604, 0.954500002990244], "tokens_processed": [11, 11], "throughput_tok_s": [10623.913457789757, 11524.358266672978], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.280399999814108, 0.9539999991829973, 1.2821999989682809], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.533, "gpu_power_peak_watts": 30.533, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1149.81640625, "cpu_memory_peak_mb": 1149.81640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.1262438}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2621999994735233, 1.2987999980396125], "tokens_processed": [19, 19], "throughput_tok_s": [15053.081926735142, 14628.888226577063], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.416399998764973, 1.3739999994868413, 1.6590999985055532], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.533, "gpu_power_peak_watts": 30.533, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.40625, "cpu_memory_peak_mb": 1151.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.2532046}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.9886000009137206, 1.0970999974233564], "tokens_processed": [19, 19], "throughput_tok_s": [9554.460420029112, 17318.384873414736], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.341700001124991, 1.3763000024482608, 1.6587000027357135], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.458, "gpu_power_peak_watts": 30.458, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.40625, "cpu_memory_peak_mb": 1151.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.378486}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.8836999988707248, 1.347399997030152], "tokens_processed": [19, 19], "throughput_tok_s": [10086.53183170912, 14101.232033455926], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1493999993253965, 1.2915999977849424, 1.2821999989682809], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.458, "gpu_power_peak_watts": 30.458, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.40625, "cpu_memory_peak_mb": 1151.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.5016198}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2190999987069517, 1.8055000000458676], "tokens_processed": [19, 19], "throughput_tok_s": [15585.267837053978, 10523.400719754814], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8453000011504628, 1.3385999991442077, 1.8038999987766147], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.458, "gpu_power_peak_watts": 30.458, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.4140625, "cpu_memory_peak_mb": 1151.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.6270387}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4177999983076006, 1.2549000020953827], "tokens_processed": [19, 19], "throughput_tok_s": [13401.043886782281, 15140.648631982267], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.398900000116555, 1.383699996949872, 1.711499997327337], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.458, "gpu_power_peak_watts": 30.458, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.41796875, "cpu_memory_peak_mb": 1151.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.7503564}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.3395000025629997, 1.7154000015580095], "tokens_processed": [27, 27], "throughput_tok_s": [11540.927535978031, 15739.769135756844], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.542199999879813, 2.52820000241627, 1.5846999995119404], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.495, "gpu_power_peak_watts": 30.495, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1152.953125, "cpu_memory_peak_mb": 1152.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.874037}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7659000004641712, 2.5153999995382037], "tokens_processed": [27, 27], "throughput_tok_s": [15289.653996773874, 10733.879305461105], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.541699999710545, 1.7353000002913177, 2.4268999986816198], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.495, "gpu_power_peak_watts": 30.495, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1152.95703125, "cpu_memory_peak_mb": 1152.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577863.9971635}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6341000009560958, 2.614599998196354], "tokens_processed": [27, 27], "throughput_tok_s": [16522.856608654653, 10326.627407108383], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.258699998492375, 1.7372000002069399, 2.0919000016874634], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.495, "gpu_power_peak_watts": 30.495, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1152.9609375, "cpu_memory_peak_mb": 1152.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.133385}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.8180000006395858, 1.6370999983337242], "tokens_processed": [27, 27], "throughput_tok_s": [14851.48514328999, 16492.578356533617], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.802399998472538, 1.8477999983588234, 2.6073000008182134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.495, "gpu_power_peak_watts": 30.495, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1152.9609375, "cpu_memory_peak_mb": 1152.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.2729719}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.1066999979666434, 1.789699999790173], "tokens_processed": [27, 27], "throughput_tok_s": [12816.25291976077, 15086.327319196243], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.427800001896685, 2.1779999988211785, 1.7638999997870997], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.524, "gpu_power_peak_watts": 30.524, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1152.9609375, "cpu_memory_peak_mb": 1152.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.3983188}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8708999998343643, 3.427799998462433], "tokens_processed": [44, 44], "throughput_tok_s": [15326.204327053734, 12836.221488924835], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.342899999959627, 3.2780000001366716, 2.457700000377372], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.524, "gpu_power_peak_watts": 30.524, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1151.48828125, "cpu_memory_peak_mb": 1151.48828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.5451276}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.485299999738345, 2.3977000018930994], "tokens_processed": [44, 44], "throughput_tok_s": [12624.451267696684, 18350.91961682441], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.59530000059749, 2.5113999981840607, 2.921999999671243], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.524, "gpu_power_peak_watts": 30.524, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1159.92578125, "cpu_memory_peak_mb": 1159.92578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.6769423}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.274700000474695, 2.2456000006059185], "tokens_processed": [44, 44], "throughput_tok_s": [13436.345312126861, 19593.872456415975], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4614999967743643, 2.5323000008938834, 3.2843000008142553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1159.96484375, "cpu_memory_peak_mb": 1159.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.8016443}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.5599000000511296, 3.299299998616334], "tokens_processed": [44, 44], "throughput_tok_s": [17188.171412602514, 13336.162221820627], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5233000016887672, 3.241800000978401, 2.848600001016166], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1159.96875, "cpu_memory_peak_mb": 1159.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577864.9254725}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.890899999329122, 2.994599999510683], "tokens_processed": [44, 44], "throughput_tok_s": [15220.173651876883, 14693.11427475776], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6274999984016176, 2.3953000018082093, 2.093900002364535], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1159.96875, "cpu_memory_peak_mb": 1159.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.051733}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.8866999970632605, 5.44860000081826], "tokens_processed": [76, 76], "throughput_tok_s": [12910.459177113604, 13948.537236828997], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.020099998044316, 5.989000001136446, 5.439799999294337], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1166.10546875, "cpu_memory_peak_mb": 1166.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.1754951}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.4079000001365785, 5.452099998365156], "tokens_processed": [76, 76], "throughput_tok_s": [14053.51430279417, 13939.582917185862], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.121099999494618, 6.057000002329005, 5.876100000023143], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 27.641, "gpu_power_peak_watts": 27.641, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.13671875, "cpu_memory_peak_mb": 1166.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.2997503}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.225600001926068, 5.407299999205861], "tokens_processed": [76, 76], "throughput_tok_s": [12207.658695786304, 14055.073698733504], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.840500001999317, 5.864099999598693, 6.084199998440454], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 27.641, "gpu_power_peak_watts": 27.641, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.14453125, "cpu_memory_peak_mb": 1166.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.42511}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.806400000437861, 6.102200000896119], "tokens_processed": [76, 76], "throughput_tok_s": [13089.005234615051, 12454.524595857112], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.754199999704724, 5.891900000278838, 6.0970999984419905], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 27.641, "gpu_power_peak_watts": 27.641, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.1484375, "cpu_memory_peak_mb": 1166.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.550974}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.646500001603272, 5.883400001039263], "tokens_processed": [76, 76], "throughput_tok_s": [13459.665275554857, 12917.700647002603], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.921400003193412, 5.9012999990954995, 5.645400000503287], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 27.641, "gpu_power_peak_watts": 27.641, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.1484375, "cpu_memory_peak_mb": 1166.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 33.08110000216402, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.6720774}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9811999989324249, 1.2064000002283137], "tokens_processed": [8, 8], "throughput_tok_s": [8153.281704753608, 6631.299733493023], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.619599999889033, 1.346400000329595, 1.1514999969222117], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 19.776, "gpu_power_peak_watts": 19.776, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1154.27734375, "cpu_memory_peak_mb": 1154.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765577865.7978477}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.2475000003178138, 1.1359000018273946], "tokens_processed": [8, 8], "throughput_tok_s": [6412.82564966887, 7042.873481054575], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.22900000133086, 1.0083999986818526, 1.0451999987708405], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 19.776, "gpu_power_peak_watts": 19.776, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1157.5859375, "cpu_memory_peak_mb": 1157.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577865.92239}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.211800001328811, 1.0178999982599635], "tokens_processed": [8, 8], "throughput_tok_s": [6601.749456368643, 7859.318217580804], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3695999987248797, 1.2863000010838732, 1.1579000019992236], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 19.776, "gpu_power_peak_watts": 19.776, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1157.5859375, "cpu_memory_peak_mb": 1157.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.0481486}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.06629999956931, 1.9302000000607222], "tokens_processed": [8, 8], "throughput_tok_s": [3871.654649212352, 4144.648222851688], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.508400000806432, 1.8381000008957926, 1.7015999983414076], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 26.0, "gpu_power_mean_watts": 19.776, "gpu_power_peak_watts": 19.776, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1157.5859375, "cpu_memory_peak_mb": 1157.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.1857233}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.330999999481719, 1.3311000002431683], "tokens_processed": [8, 8], "throughput_tok_s": [6010.518409553071, 6010.066860895908], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9654999996419065, 1.4055999999982305, 1.854100002674386], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 14.153, "gpu_power_peak_watts": 14.153, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1157.64453125, "cpu_memory_peak_mb": 1157.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.3123648}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.7712000008032192, 1.933600000484148], "tokens_processed": [11, 11], "throughput_tok_s": [6210.478768638, 5688.870499196186], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7163999984622933, 1.7549000003782567, 4.262299997208174], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 14.153, "gpu_power_peak_watts": 14.153, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1158.22265625, "cpu_memory_peak_mb": 1158.22265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.435931}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.840299999457784, 1.7072000009648036], "tokens_processed": [11, 11], "throughput_tok_s": [5977.28631377546, 6443.298965430812], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2716000021318905, 1.725799997075228, 1.8262000012327917], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 14.153, "gpu_power_peak_watts": 14.153, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1158.2265625, "cpu_memory_peak_mb": 1158.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.5608141}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.54280000081053, 2.3872999990999233], "tokens_processed": [11, 11], "throughput_tok_s": [4325.93990738308, 4607.715831335525], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2212999976763967, 2.3750999971525744, 2.101800000673393], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 14.153, "gpu_power_peak_watts": 14.153, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1158.2265625, "cpu_memory_peak_mb": 1158.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.6835756}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.2910999978194013, 2.7397999983804766], "tokens_processed": [11, 11], "throughput_tok_s": [4801.18720722337, 4014.891600300099], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0393999986699782, 2.7633999998215586, 2.1215999986452516], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 11.008, "gpu_power_peak_watts": 11.008, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1158.2265625, "cpu_memory_peak_mb": 1158.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.806981}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.236500000435626, 2.7546000019356143], "tokens_processed": [11, 11], "throughput_tok_s": [4918.3992836384605, 3993.320261479152], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2591999988653697, 2.4345000019820873, 2.1197000023676082], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 11.008, "gpu_power_peak_watts": 11.008, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1158.2265625, "cpu_memory_peak_mb": 1158.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577866.9316208}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.6963999991712626, 3.7556999996013474], "tokens_processed": [19, 19], "throughput_tok_s": [5140.136350032416, 5058.9770221308345], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9829000015743077, 3.430199998547323, 3.388100001757266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 11.008, "gpu_power_peak_watts": 11.008, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.76171875, "cpu_memory_peak_mb": 1159.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.055084}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.489799997623777, 3.73810000019148], "tokens_processed": [19, 19], "throughput_tok_s": [5444.438080387758, 5082.796072610884], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9877999988675583, 3.4106999992218334, 3.5750000024563633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 11.008, "gpu_power_peak_watts": 11.008, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.76171875, "cpu_memory_peak_mb": 1159.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.1957936}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.7212999995972496, 6.511700001283316], "tokens_processed": [19, 19], "throughput_tok_s": [5105.7426173800395, 2917.8248377928203], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1865999992296565, 4.0470000021741726, 3.2326000000466593], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 6.081, "gpu_power_peak_watts": 6.081, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.76171875, "cpu_memory_peak_mb": 1159.76171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.321564}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.680300000269199, 3.720400000020163], "tokens_processed": [19, 19], "throughput_tok_s": [5162.622611909417, 5106.977744300889], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.0157000003091525, 6.52789999730885, 3.543599999829894], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 6.081, "gpu_power_peak_watts": 6.081, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.765625, "cpu_memory_peak_mb": 1159.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.446274}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.836700001556892, 6.623799999943003], "tokens_processed": [19, 19], "throughput_tok_s": [4952.17243784763, 2868.444095558968], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.005200000392506, 3.77459999799612, 3.775000001041917], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 6.081, "gpu_power_peak_watts": 6.081, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.765625, "cpu_memory_peak_mb": 1159.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.5841165}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.71560000005411, 4.88749999931315], "tokens_processed": [27, 27], "throughput_tok_s": [5725.67647800708, 5524.296675968157], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.070799998065922, 6.226700003026053, 4.840900000999682], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 6.081, "gpu_power_peak_watts": 6.081, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1161.3046875, "cpu_memory_peak_mb": 1161.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.7095828}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.814200001419522, 8.119900001474889], "tokens_processed": [27, 27], "throughput_tok_s": [5608.408456657127, 3325.1641024022156], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2896999986842275, 6.342799999401905, 5.348599999706494], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.089, "gpu_power_peak_watts": 3.089, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1161.30859375, "cpu_memory_peak_mb": 1161.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.8356302}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.365099998220103, 4.213699998217635], "tokens_processed": [27, 27], "throughput_tok_s": [4241.881511295991, 6407.67022128315], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.796599998371676, 6.790800001908792, 4.330599997047102], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.089, "gpu_power_peak_watts": 3.089, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1161.37109375, "cpu_memory_peak_mb": 1161.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577867.9588304}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.470000000059372, 5.341299998690374], "tokens_processed": [27, 27], "throughput_tok_s": [4936.014625174943, 5054.94917091721], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.214100001467159, 6.386000000929926, 4.635399996914202], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.089, "gpu_power_peak_watts": 3.089, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1161.37109375, "cpu_memory_peak_mb": 1161.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.0855076}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.836399999476271, 4.786699999385746], "tokens_processed": [27, 27], "throughput_tok_s": [5582.664792598587, 5640.629244252779], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.337799997505499, 6.111200000304962, 4.925100001855753], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 15.0, "gpu_power_mean_watts": 3.089, "gpu_power_peak_watts": 3.089, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1161.37109375, "cpu_memory_peak_mb": 1161.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.2087588}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.033899997622939, 7.562599999801023], "tokens_processed": [44, 44], "throughput_tok_s": [6255.420181530803, 5818.1048847165885], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.7342000004136935, 6.742499997926643, 6.612700002733618], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.215, "gpu_power_peak_watts": 3.215, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1159.36328125, "cpu_memory_peak_mb": 1159.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.3575325}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.709899997280445, 7.172300000092946], "tokens_processed": [44, 44], "throughput_tok_s": [5706.948211458042, 6134.7127141126], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.805599998391699, 6.635700003243983, 8.582900001783855], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.215, "gpu_power_peak_watts": 3.215, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.96484375, "cpu_memory_peak_mb": 1167.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.491137}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.911599997692974, 7.031200002529658], "tokens_processed": [44, 44], "throughput_tok_s": [6366.109151960006, 6257.822275595894], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.907100000011269, 6.73820000156411, 7.1563000019523315], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.215, "gpu_power_peak_watts": 3.215, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.03125, "cpu_memory_peak_mb": 1168.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.6199303}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.278000000951579, 7.069699997373391], "tokens_processed": [44, 44], "throughput_tok_s": [6045.616926936949, 6223.743584076742], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.424200000968995, 6.9101000008231495, 6.7432000032567885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.215, "gpu_power_peak_watts": 3.215, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.03125, "cpu_memory_peak_mb": 1168.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.7562032}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.8125999971234705, 6.956400000490248], "tokens_processed": [44, 44], "throughput_tok_s": [5631.927913396361, 6325.110688991307], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.678100002522115, 6.949399998120498, 8.504900000843918], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.173, "gpu_power_peak_watts": 3.173, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.03125, "cpu_memory_peak_mb": 1168.03125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577868.8804045}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.36640000186162, 11.428599998907885], "tokens_processed": [76, 76], "throughput_tok_s": [6686.373872778761, 6649.983375677034], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.318000000959728, 10.986299999785842, 11.317299999063835], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.173, "gpu_power_peak_watts": 3.173, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1169.64453125, "cpu_memory_peak_mb": 1169.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577869.00413}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [10.536499998124782, 11.35249999788357], "tokens_processed": [76, 76], "throughput_tok_s": [7213.021403077491, 6694.560670704124], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.435299999197014, 10.928699997748481, 10.935199999948964], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.173, "gpu_power_peak_watts": 3.173, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.66015625, "cpu_memory_peak_mb": 1167.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577869.1285799}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.256999998295214, 11.217499999474967], "tokens_processed": [76, 76], "throughput_tok_s": [6751.354713645697, 6775.128148300171], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.857500001497101, 11.379499999748077, 11.218300001928583], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.173, "gpu_power_peak_watts": 3.173, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.71875, "cpu_memory_peak_mb": 1168.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577869.2524261}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.440499998570886, 11.256499998125946], "tokens_processed": [76, 76], "throughput_tok_s": [6643.066300379678, 6751.654600688755], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.263299999176525, 11.273300002358155, 11.157400000229245], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 3.319, "gpu_power_peak_watts": 3.319, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.7265625, "cpu_memory_peak_mb": 1168.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577869.3786643}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.212400000658818, 11.39790000161156], "tokens_processed": [76, 76], "throughput_tok_s": [6778.20983870843, 6667.894962164459], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.132100000599166, 11.230299998715054, 11.224900001252536], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 31.0, "gpu_power_mean_watts": 3.319, "gpu_power_peak_watts": 3.319, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.65625, "cpu_memory_peak_mb": 1166.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.23470000072848, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577869.5009885}
