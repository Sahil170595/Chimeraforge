{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [305.9320999964257, 13.192700003855862], "ttft_ms": [291.8234000026132, 1.4401000007637776], "tokens_processed": [8, 8], "throughput_tok_s": [26.149593325098827, 606.3959612256642], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2044.567899996764], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765599664.0478754}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765599664.0489507, "build_time_s": null, "file_size_mb": 4.228824615478516, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1630.0701000000117, "compile_ms": 454.0608000024804, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765599689.848054}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.56769999297103, 14.080900000408292], "ttft_ms": [1.6236999945249408, 1.691899997240398], "tokens_processed": [8, 8], "throughput_tok_s": [513.8845175338733, 568.1455020466043], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [81.66930000152206], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765599664.0478754}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765599664.0489507, "build_time_s": null, "file_size_mb": 4.228824615478516, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1397.9674000001978, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765599689.9609191}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.019400003831834, 8.361000000149943], "ttft_ms": [1.061800001480151, 0.9059000003617257], "tokens_processed": [8, 8], "throughput_tok_s": [997.5808659223179, 956.823346472495], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.073600004427135], "resource_metrics": null, "export_metadata": {"model": "models/tiny-gpt2", "output_path": "artifacts\\onnx\\tiny-gpt2.onnx", "export_time_s": null, "file_size_mb": 1.8593082427978516, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "timestamp": 1765599664.0478754}, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 2, "dynamic_shapes": true, "profiles": 1, "timestamp": 1765599664.0489507, "build_time_s": null, "file_size_mb": 4.228824615478516, "built": false, "reused": true, "error": null}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765599690.1843677}
