{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 76, "duration_s": 8.418139219284058, "gpu_memory_mean_mb": 495.7300575657895, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.655092105263154, "gpu_power_peak_watts": 29.687, "gpu_temperature_mean_c": 50.55263157894737, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 983.5104337993421, "cpu_memory_peak_mb": 999.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589213.7730956}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 53, "duration_s": 5.937855243682861, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.287452830188679, "gpu_power_peak_watts": 29.709, "gpu_temperature_mean_c": 49.490566037735846, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1003.6743071933962, "cpu_memory_peak_mb": 1005.18359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589219.82288}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 49, "duration_s": 5.602258205413818, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.1020408163265305, "gpu_power_mean_watts": 1.8080816326530613, "gpu_power_peak_watts": 1.851, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1005.7611607142857, "cpu_memory_peak_mb": 1006.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589225.5375915}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 52, "duration_s": 5.924461126327515, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7983653846153846, "gpu_power_peak_watts": 1.83, "gpu_temperature_mean_c": 48.11538461538461, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1006.3695162259615, "cpu_memory_peak_mb": 1006.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589231.5786357}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 48, "duration_s": 5.131120443344116, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7848125000000001, "gpu_power_peak_watts": 1.802, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1007.1075846354166, "cpu_memory_peak_mb": 1008.08203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589236.8171794}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 111, "duration_s": 12.543894529342651, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7152702702702705, "gpu_power_peak_watts": 1.797, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1014.4833896396397, "cpu_memory_peak_mb": 1023.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589249.470081}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 128, "duration_s": 14.718323707580566, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.046875, "gpu_power_mean_watts": 1.717671875, "gpu_power_peak_watts": 1.809, "gpu_temperature_mean_c": 47.890625, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1028.3800964355469, "cpu_memory_peak_mb": 1032.34765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589264.3081572}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 103, "duration_s": 11.588604927062988, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.02912621359223301, "gpu_power_mean_watts": 1.7091844660194173, "gpu_power_peak_watts": 1.773, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1034.6717991504854, "cpu_memory_peak_mb": 1036.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589276.011924}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 124, "duration_s": 14.226129293441772, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7069112903225807, "gpu_power_peak_watts": 1.782, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1038.1538558467741, "cpu_memory_peak_mb": 1042.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589290.3550901}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 109, "duration_s": 12.090487718582153, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7213394495412844, "gpu_power_peak_watts": 1.793, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1044.6862456995414, "cpu_memory_peak_mb": 1047.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589302.568695}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 114, "duration_s": 13.149653911590576, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.07894736842105263, "gpu_power_mean_watts": 1.7090350877192984, "gpu_power_peak_watts": 1.78, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1049.7733004385964, "cpu_memory_peak_mb": 1053.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589315.8333983}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 104, "duration_s": 11.581018447875977, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.07692307692307693, "gpu_power_mean_watts": 1.7072115384615385, "gpu_power_peak_watts": 1.785, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1056.159405048077, "cpu_memory_peak_mb": 1060.94140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589327.5290208}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 102, "duration_s": 11.38014817237854, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.00980392156862745, "gpu_power_mean_watts": 1.7139411764705883, "gpu_power_peak_watts": 1.763, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1063.3651194852941, "cpu_memory_peak_mb": 1065.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589339.0187335}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 100, "duration_s": 11.243205070495605, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.48, "gpu_power_mean_watts": 1.71184, "gpu_power_peak_watts": 1.762, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1069.9046875, "cpu_memory_peak_mb": 1071.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589350.380544}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 101, "duration_s": 11.328884601593018, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.2376237623762376, "gpu_power_mean_watts": 1.7203861386138612, "gpu_power_peak_watts": 1.787, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1075.0337639232673, "cpu_memory_peak_mb": 1075.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589361.8202624}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 105, "duration_s": 11.866719007492065, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7151238095238095, "gpu_power_peak_watts": 1.766, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1070.2427455357142, "cpu_memory_peak_mb": 1079.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589373.8023105}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 113, "duration_s": 12.912605047225952, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7163451327433628, "gpu_power_peak_watts": 1.784, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1051.3231471238937, "cpu_memory_peak_mb": 1053.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589386.8236012}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 108, "duration_s": 12.174942970275879, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.6987407407407407, "gpu_power_peak_watts": 1.791, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1054.7470703125, "cpu_memory_peak_mb": 1059.48828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589399.1184015}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 112, "duration_s": 12.54940414428711, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8209285714285712, "gpu_power_peak_watts": 4.432, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1060.089111328125, "cpu_memory_peak_mb": 1064.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589411.794449}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 106, "duration_s": 12.111679077148438, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.6641037735849054, "gpu_power_peak_watts": 3.024, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1064.7646668632076, "cpu_memory_peak_mb": 1068.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589424.0146694}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 143, "duration_s": 16.93317937850952, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.394839160839161, "gpu_power_peak_watts": 2.992, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1072.5121831293707, "cpu_memory_peak_mb": 1077.8125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589441.0588703}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 137, "duration_s": 15.505915880203247, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.511868613138686, "gpu_power_peak_watts": 2.974, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1081.0863651916059, "cpu_memory_peak_mb": 1086.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589456.6762364}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 137, "duration_s": 15.458776235580444, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.06569343065693431, "gpu_power_mean_watts": 2.4335401459854014, "gpu_power_peak_watts": 2.978, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1092.7231979927008, "cpu_memory_peak_mb": 1098.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589472.2557373}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 180, "duration_s": 20.34387516975403, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.3618833333333336, "gpu_power_peak_watts": 2.986, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1101.3647352430555, "cpu_memory_peak_mb": 1104.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589492.7079165}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 139, "duration_s": 15.941196918487549, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.4766115107913667, "gpu_power_peak_watts": 2.985, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 1114.2083239658273, "cpu_memory_peak_mb": 1120.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589508.7610803}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 133, "duration_s": 15.17264175415039, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.6090225563909775, "gpu_power_mean_watts": 2.5400526315789476, "gpu_power_peak_watts": 2.991, "gpu_temperature_mean_c": 47.30827067669173, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1125.846951362782, "cpu_memory_peak_mb": 1130.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589524.0566833}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 153, "duration_s": 17.731799125671387, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.515339869281046, "gpu_power_peak_watts": 3.213, "gpu_temperature_mean_c": 47.66013071895425, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1131.796160130719, "cpu_memory_peak_mb": 1132.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589541.8982081}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 178, "duration_s": 20.525123357772827, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.373275280898876, "gpu_power_peak_watts": 4.352, "gpu_temperature_mean_c": 47.70786516853933, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1137.569917485955, "cpu_memory_peak_mb": 1147.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589562.540007}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 140, "duration_s": 16.41687798500061, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.07142857142857142, "gpu_power_mean_watts": 2.594992857142857, "gpu_power_peak_watts": 3.016, "gpu_temperature_mean_c": 47.964285714285715, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1148.185072544643, "cpu_memory_peak_mb": 1153.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589579.0674095}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:RuntimeError", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:RuntimeError", "exception:RuntimeError"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 149, "duration_s": 15.997278690338135, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.50051677852349, "gpu_power_peak_watts": 2.978, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1154.8216757550335, "cpu_memory_peak_mb": 1163.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 2788.427400002547, "compile_ms": 1517.507900003693, "compile_error": null, "device": "cuda", "compile": true}, "started_at": 1765589595.187999}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.3757999990484677, 2.4295000039273873], "ttft_ms": [0.3304999991087243, 0.31600000511389226], "tokens_processed": [8, 8], "throughput_tok_s": [2369.80863862046, 3292.858607560267], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6493000002810732, 0.4438999967533164, 0.3290999957243912], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.863, "gpu_power_peak_watts": 1.863, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.41796875, "cpu_memory_peak_mb": 1170.41796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.3111236}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.2897000055527315, 3.2213000013143755], "ttft_ms": [0.3833999944617972, 0.38469999708468094], "tokens_processed": [8, 8], "throughput_tok_s": [2431.832685806209, 2483.469405747924], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7465000016964041, 0.41789999522734433, 0.40440000157104805], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.624, "gpu_power_peak_watts": 2.624, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.6640625, "cpu_memory_peak_mb": 1170.6640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.432151}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [2.5015999999595806, 2.416399998764973], "ttft_ms": [0.2893999990192242, 0.29779999749735], "tokens_processed": [8, 8], "throughput_tok_s": [3197.953309933346, 3310.710149018712], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5483999993884936, 0.3063000040128827, 0.29579999682027847], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.624, "gpu_power_peak_watts": 2.624, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.8984375, "cpu_memory_peak_mb": 1170.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.5575197}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.436799997871276, 2.642200000991579], "ttft_ms": [0.440200004959479, 0.28619999648071826], "tokens_processed": [8, 8], "throughput_tok_s": [2327.7467425963487, 3027.779879266413], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8929000032367185, 0.4490999999688938, 0.4304999965825118], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.624, "gpu_power_peak_watts": 2.624, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1171.15625, "cpu_memory_peak_mb": 1171.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.6836805}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.7061999973957427, 4.06930000463035], "ttft_ms": [0.4267000040272251, 0.4904999950667843], "tokens_processed": [8, 8], "throughput_tok_s": [2158.54514209201, 1965.9400857388273], "predicted_tokens": ["", ""], "outputs": ["Hello stairs stairs stairs stairs stairs stairs stairs stairs", "Test stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7006000014371239, 0.4642999992938712, 0.43929999810643494], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.624, "gpu_power_peak_watts": 2.624, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1171.32421875, "cpu_memory_peak_mb": 1171.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.8067865}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [2.982700003485661, 2.675299998372793], "ttft_ms": [0.36410000029718503, 0.338099998771213], "tokens_processed": [8, 8], "throughput_tok_s": [2682.1336341740675, 2990.3188445654196], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.78600000415463, 0.4270999997970648, 0.3600000054575503], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.62109375, "cpu_memory_peak_mb": 1172.62109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589595.9312565}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.7358999979915097, 3.9174000048660673], "ttft_ms": [0.43030000233557075, 0.5141000001458451], "tokens_processed": [8, 8], "throughput_tok_s": [2141.3849418616533, 2042.1708250530094], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8136000033118762, 0.47230000200215727, 0.4535999978543259], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.66796875, "cpu_memory_peak_mb": 1172.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.0558863}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [2.8843000036431476, 2.9313999984879047], "ttft_ms": [0.3463000030023977, 0.42380000377306715], "tokens_processed": [8, 8], "throughput_tok_s": [2773.6365807631773, 2729.0714348524994], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7081000003381632, 0.38350000249920413, 0.35960000241175294], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.74609375, "cpu_memory_peak_mb": 1172.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.188796}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.001900000730529, 3.9894000001368113], "ttft_ms": [0.4609000025084242, 0.49139999464387074], "tokens_processed": [8, 8], "throughput_tok_s": [1999.05045067084, 2005.3140822493735], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8895999999367632, 0.48740000056568533, 0.4777999929501675], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.7890625, "cpu_memory_peak_mb": 1172.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.323793}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [2.7502000011736527, 2.85470000380883], "ttft_ms": [0.3388999975868501, 0.34810000215657055], "tokens_processed": [8, 8], "throughput_tok_s": [2908.8793529874138, 2802.396044882527], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6357999955071136, 0.43139999615959823, 0.3575000009732321], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.8671875, "cpu_memory_peak_mb": 1172.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.450738}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.040200001734775, 5.0389999960316345], "ttft_ms": [0.549600001249928, 0.6348000024445355], "tokens_processed": [8, 8], "throughput_tok_s": [1324.4594546045432, 1587.616591843668], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.873699999123346, 0.625100001343526, 0.5301999990479089], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1183.87109375, "cpu_memory_peak_mb": 1183.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.5740964}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.9429000025847927, 3.6693000001832843], "ttft_ms": [0.5032000044593588, 0.4852999991271645], "tokens_processed": [8, 8], "throughput_tok_s": [2028.963451965698, 2180.252364102252], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9991999977501109, 0.5586999977822416, 0.4655999946407974], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1184.015625, "cpu_memory_peak_mb": 1184.015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.7021213}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.5592000024043955, 4.633100004866719], "ttft_ms": [0.5799000064143911, 0.5439000015030615], "tokens_processed": [8, 8], "throughput_tok_s": [1754.6938050054882, 1726.7056596224145], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0454000002937391, 0.5992000005790032, 0.537899999471847], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.059, "gpu_power_peak_watts": 3.059, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1184.140625, "cpu_memory_peak_mb": 1184.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.8278759}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.6758999995072372, 4.1475999969406985], "ttft_ms": [0.46920000022510067, 0.4617000013240613], "tokens_processed": [8, 8], "throughput_tok_s": [2176.3377679132777, 1928.8263106135744], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0586000062176026, 0.6275999985518865, 0.4791000028490089], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1184.21484375, "cpu_memory_peak_mb": 1184.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589596.953185}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.655999997339677, 4.28259999898728], "ttft_ms": [0.5039999959990382, 0.6594000005861744], "tokens_processed": [8, 8], "throughput_tok_s": [1718.2130594009884, 1868.0240979525956], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8240999959525652, 0.5367999983718619, 0.5062999989604577], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1184.2265625, "cpu_memory_peak_mb": 1184.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.0770574}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [4.970199996023439, 4.3671000021276996], "ttft_ms": [0.5261999976937659, 0.5516999954124913], "tokens_processed": [8, 8], "throughput_tok_s": [1609.593176612741, 1831.8792782629916], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2128999951528385, 0.5631999956676736, 0.5698999957530759], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1187.3203125, "cpu_memory_peak_mb": 1187.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.2007658}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [3.9993999962462112, 4.404200000863057], "ttft_ms": [0.45449999743141234, 0.5776000034529716], "tokens_processed": [8, 8], "throughput_tok_s": [2000.3000468842085, 1816.4479357050775], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6934999983059242, 0.4774999979417771, 0.4241999995429069], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1187.33203125, "cpu_memory_peak_mb": 1187.33203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.32784}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [5.389700003433973, 5.967099998088088], "ttft_ms": [0.5806000044685788, 0.5586000042967498], "tokens_processed": [8, 8], "throughput_tok_s": [1484.3126695183241, 1340.68475516805], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9547999943606555, 0.6120000034570694, 0.5793000018456951], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1187.33203125, "cpu_memory_peak_mb": 1187.33203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.4506414}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [5.048400002124254, 4.852199999731965], "ttft_ms": [0.6523999982164241, 0.6682999955955893], "tokens_processed": [8, 8], "throughput_tok_s": [1584.6604858239798, 1648.7366556287702], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1275000069872476, 0.5834000039612874, 0.7141999958548695], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1187.3515625, "cpu_memory_peak_mb": 1187.3515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.5751145}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [5.448800002341159, 4.648200003430247], "ttft_ms": [0.40019999869400635, 0.567400005820673], "tokens_processed": [8, 8], "throughput_tok_s": [1468.2131839235574, 1721.096337097417], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words. stairs stairs stairs stairs stairs stairs stairs stairs", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9632000001147389, 0.6352000054903328, 0.5022999976063147], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1187.40234375, "cpu_memory_peak_mb": 1187.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.7004106}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [9.800599997106474, 6.287399999564514], "ttft_ms": [0.8157000047503971, 0.861699998495169], "tokens_processed": [32, 32], "throughput_tok_s": [3265.106218950643, 5089.544168052999], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8024000057484955, 0.9830000053625554, 0.8309000040753745], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1211.1328125, "cpu_memory_peak_mb": 1211.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.8222277}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [6.889000003866386, 6.055099998775404], "ttft_ms": [0.6431000001612119, 0.930599999264814], "tokens_processed": [32, 32], "throughput_tok_s": [4645.086366967674, 5284.801242997101], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2196999959996901, 0.8694999996805564, 0.6788999962736852], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1211.23828125, "cpu_memory_peak_mb": 1211.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589597.947548}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [7.893100002547726, 8.452400004898664], "ttft_ms": [0.7879999975557439, 1.092100006644614], "tokens_processed": [32, 32], "throughput_tok_s": [4054.1738974130667, 3785.906959142269], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3483000002452172, 0.8950000046752393, 0.887399997736793], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1211.28515625, "cpu_memory_peak_mb": 1211.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.0756123}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.032199999433942, 9.002800004964229], "ttft_ms": [0.8034000056795776, 1.532200003566686], "tokens_processed": [32, 32], "throughput_tok_s": [3983.964542996334, 3554.44972479172], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4407999988179654, 0.9370999978273176, 0.8317999963765033], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1211.28515625, "cpu_memory_peak_mb": 1211.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.2003894}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [8.389800001168624, 7.889000000432134], "ttft_ms": [0.7583999977214262, 1.0334999969927594], "tokens_processed": [32, 32], "throughput_tok_s": [3814.155283265714, 4056.2808972299586], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence. factors factors factors factors factors factors factors factors", "List two ways to improve throughput on local LLMs. stairs stairs stairs stairs stairs stairs stairs stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3400000025285408, 0.9617999967304058, 0.7896000024629757], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1211.28515625, "cpu_memory_peak_mb": 1211.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.3265297}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [15.14350000070408, 14.27999999577878], "ttft_ms": [0.8369999995920807, 1.385100003972184], "tokens_processed": [32, 32], "throughput_tok_s": [2113.1178392387624, 2240.8963592058344], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1789000020362437, 1.1173000020789914, 0.9351999979116954], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.25390625, "cpu_memory_peak_mb": 1240.25390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.4507174}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [11.646300001302734, 11.001999999280088], "ttft_ms": [1.0599000015645288, 1.600499999767635], "tokens_processed": [32, 32], "throughput_tok_s": [2747.653760973059, 2908.5620798122077], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.825999999709893, 1.2781999976141378, 1.0073000012198463], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.576517}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [10.896200001297984, 11.491600002045743], "ttft_ms": [1.0531000007176772, 1.6025000004447065], "tokens_processed": [32, 32], "throughput_tok_s": [2936.8036559707125, 2784.6426950384052], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8118000007234514, 1.2464000028558075, 1.000900003418792], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.7026763}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [10.354300000471994, 15.78200000221841], "ttft_ms": [0.9917999996105209, 1.859099997091107], "tokens_processed": [32, 32], "throughput_tok_s": [3090.5034621887817, 2027.626409548973], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7213999963132665, 1.2676000042119995, 1.2575000000651926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.529, "gpu_power_peak_watts": 1.529, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.827032}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [12.48650000343332, 12.63949999702163], "ttft_ms": [1.1436999993748032, 1.5056000047479756], "tokens_processed": [32, 32], "throughput_tok_s": [2562.767788507684, 2531.7457183860497], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing. factors factors factors factors factors factors factors factors", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences. factors factors factors factors factors factors factors factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1437000032165088, 1.0905000017373823, 1.1882999970111996], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 154.85449999687262, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765589598.9480307}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.0742738}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.199301}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.2890625, "cpu_memory_peak_mb": 1240.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.3233876}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.296875, "cpu_memory_peak_mb": 1240.296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.4478495}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.296875, "cpu_memory_peak_mb": 1240.296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.575948}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.6997197}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.533, "gpu_power_peak_watts": 1.533, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.824668}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589599.9464514}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.070702}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.19513}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.320714}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.30078125, "cpu_memory_peak_mb": 1240.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.446849}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.3046875, "cpu_memory_peak_mb": 1240.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.5695455}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.31640625, "cpu_memory_peak_mb": 1240.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.6976693}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.537, "gpu_power_peak_watts": 1.537, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.32421875, "cpu_memory_peak_mb": 1240.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.819667}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.3359375, "cpu_memory_peak_mb": 1240.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589600.9437747}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.3359375, "cpu_memory_peak_mb": 1240.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.068647}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.3359375, "cpu_memory_peak_mb": 1240.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.194623}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.35546875, "cpu_memory_peak_mb": 1240.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.323782}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.35546875, "cpu_memory_peak_mb": 1240.35546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.4443}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.36328125, "cpu_memory_peak_mb": 1240.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.5701475}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.36328125, "cpu_memory_peak_mb": 1240.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.6964142}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.713, "gpu_power_peak_watts": 1.713, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.36328125, "cpu_memory_peak_mb": 1240.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.8180988}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.36328125, "cpu_memory_peak_mb": 1240.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589601.9425793}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.4140625, "cpu_memory_peak_mb": 1240.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.0691607}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.42578125, "cpu_memory_peak_mb": 1240.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.1923468}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.42578125, "cpu_memory_peak_mb": 1240.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.3160694}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.42578125, "cpu_memory_peak_mb": 1240.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.4409459}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.4296875, "cpu_memory_peak_mb": 1240.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.566422}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: ort_session_missing", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["ort_session_missing", "ort_session_missing"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 504.01953125, "gpu_memory_peak_mb": 504.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.55, "gpu_power_peak_watts": 1.55, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1240.4296875, "cpu_memory_peak_mb": 1240.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 52.00939999485854, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "error": "cuda_provider_unavailable"}, "started_at": 1765589602.6921206}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 2, "duration_s": 0.11128425598144531, "gpu_memory_mean_mb": 509.529296875, "gpu_memory_peak_mb": 515.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.5510000000000002, "gpu_power_peak_watts": 1.552, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1302.720703125, "cpu_memory_peak_mb": 1356.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765589602.9152362}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.552, "gpu_power_peak_watts": 1.552, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1399.74609375, "cpu_memory_peak_mb": 1399.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.0342474}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.552, "gpu_power_peak_watts": 1.552, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1396.46484375, "cpu_memory_peak_mb": 1396.46484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.158364}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.552, "gpu_power_peak_watts": 1.552, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1396.51953125, "cpu_memory_peak_mb": 1396.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.2836182}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.311, "gpu_power_peak_watts": 7.311, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1396.53125, "cpu_memory_peak_mb": 1396.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.408081}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.311, "gpu_power_peak_watts": 7.311, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1396.546875, "cpu_memory_peak_mb": 1396.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.531546}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.311, "gpu_power_peak_watts": 7.311, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1396.546875, "cpu_memory_peak_mb": 1396.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.6574373}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 7.311, "gpu_power_peak_watts": 7.311, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1396.546875, "cpu_memory_peak_mb": 1396.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.7837665}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.433, "gpu_power_peak_watts": 20.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.5546875, "cpu_memory_peak_mb": 1396.5546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589603.9049785}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.433, "gpu_power_peak_watts": 20.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.5625, "cpu_memory_peak_mb": 1396.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.0284715}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.433, "gpu_power_peak_watts": 20.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.578125, "cpu_memory_peak_mb": 1396.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.1540172}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.433, "gpu_power_peak_watts": 20.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.578125, "cpu_memory_peak_mb": 1396.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.277566}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.67578125, "cpu_memory_peak_mb": 1396.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.4011676}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.7265625, "cpu_memory_peak_mb": 1396.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.5272164}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.73828125, "cpu_memory_peak_mb": 1396.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.6495092}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.73828125, "cpu_memory_peak_mb": 1396.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.7778127}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.7421875, "cpu_memory_peak_mb": 1396.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589604.9027233}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.7421875, "cpu_memory_peak_mb": 1396.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.027898}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.7421875, "cpu_memory_peak_mb": 1396.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.1541839}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.109, "gpu_power_peak_watts": 21.109, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.828125, "cpu_memory_peak_mb": 1396.828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.28001}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.8359375, "cpu_memory_peak_mb": 1396.8359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.4020956}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.84765625, "cpu_memory_peak_mb": 1396.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.5285196}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.84765625, "cpu_memory_peak_mb": 1396.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.6495547}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.84765625, "cpu_memory_peak_mb": 1396.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.7752376}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.84765625, "cpu_memory_peak_mb": 1396.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589605.8998725}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.84765625, "cpu_memory_peak_mb": 1396.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589606.0214539}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.859375, "cpu_memory_peak_mb": 1396.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589606.1462753}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.859375, "cpu_memory_peak_mb": 1396.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589606.2719936}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.859375, "cpu_memory_peak_mb": 1396.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589606.3949282}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.859375, "cpu_memory_peak_mb": 1396.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765589606.522686}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.859375, "cpu_memory_peak_mb": 1396.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765589606.6464722}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9140625, "cpu_memory_peak_mb": 1396.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589606.7705493}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9140625, "cpu_memory_peak_mb": 1396.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589606.8947546}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.921875, "cpu_memory_peak_mb": 1396.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.0192118}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.921875, "cpu_memory_peak_mb": 1396.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.1419024}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.826, "gpu_power_peak_watts": 29.826, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.921875, "cpu_memory_peak_mb": 1396.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.2707903}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9453125, "cpu_memory_peak_mb": 1396.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.3945112}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9453125, "cpu_memory_peak_mb": 1396.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.516852}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9453125, "cpu_memory_peak_mb": 1396.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.6412597}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.953125, "cpu_memory_peak_mb": 1396.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.765525}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.953125, "cpu_memory_peak_mb": 1396.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589607.8883393}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.953125, "cpu_memory_peak_mb": 1396.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.016244}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9609375, "cpu_memory_peak_mb": 1396.9609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.1399727}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.825, "gpu_power_peak_watts": 29.825, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.97265625, "cpu_memory_peak_mb": 1396.97265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.2644534}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.97265625, "cpu_memory_peak_mb": 1396.97265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.389874}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.984375, "cpu_memory_peak_mb": 1396.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.5127387}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.984375, "cpu_memory_peak_mb": 1396.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.6383595}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.984375, "cpu_memory_peak_mb": 1396.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.7613225}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9921875, "cpu_memory_peak_mb": 1396.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589608.8862214}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9921875, "cpu_memory_peak_mb": 1396.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.0089178}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1396.9921875, "cpu_memory_peak_mb": 1396.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.1360614}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.805, "gpu_power_peak_watts": 29.805, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0, "cpu_memory_peak_mb": 1397.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.2581866}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0, "cpu_memory_peak_mb": 1397.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.3846507}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0, "cpu_memory_peak_mb": 1397.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.5078642}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0, "cpu_memory_peak_mb": 1397.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.632012}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0, "cpu_memory_peak_mb": 1397.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.7575655}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0078125, "cpu_memory_peak_mb": 1397.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589609.8817182}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0078125, "cpu_memory_peak_mb": 1397.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589610.008699}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.0078125, "cpu_memory_peak_mb": 1397.0078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589610.1310563}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.797, "gpu_power_peak_watts": 29.797, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1397.01953125, "cpu_memory_peak_mb": 1397.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765589610.2571146}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.01953125, "cpu_memory_peak_mb": 1397.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765589610.3788939}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.01953125, "cpu_memory_peak_mb": 1397.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589610.5042374}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.02734375, "cpu_memory_peak_mb": 1397.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589610.6327074}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.02734375, "cpu_memory_peak_mb": 1397.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589610.7548623}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.02734375, "cpu_memory_peak_mb": 1397.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589610.87964}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.02734375, "cpu_memory_peak_mb": 1397.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.0037236}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.1279433}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 24.156, "gpu_power_peak_watts": 24.156, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.2514415}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.379019}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.4984903}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.6207945}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.745795}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.8705385}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589611.9945357}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.118965}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 13.995, "gpu_power_peak_watts": 13.995, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.2449205}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.3667176}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.4920225}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.6162207}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.7439048}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.8669453}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589612.9873667}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.1131494}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.712, "gpu_power_peak_watts": 2.712, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.2405665}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.3628113}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.4873815}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.0390625, "cpu_memory_peak_mb": 1397.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.614334}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.046875, "cpu_memory_peak_mb": 1397.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.7394097}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.05078125, "cpu_memory_peak_mb": 1397.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.8607507}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 689.0390625, "gpu_memory_peak_mb": 689.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.573, "gpu_power_peak_watts": 1.573, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1397.05078125, "cpu_memory_peak_mb": 1397.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "engine_deserialize_failed", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765589613.9856308}
