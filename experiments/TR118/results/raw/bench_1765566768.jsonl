{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0798779}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1023.3901999999944, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765566772.0808718}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0808718}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.77830000026734, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0818744}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 2005.6084000007104, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0828378}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.0838907}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "single_micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "single_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "single_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "single_long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "batch_short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0}, "status": "error", "error": "_compute_seq_len() got an unexpected keyword argument 'max_seq_len'", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 1, "degraded_reasons": ["exception:TypeError"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765566772.084838}
