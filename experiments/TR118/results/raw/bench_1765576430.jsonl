{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.376899999944726, 3.0721000002813525], "tokens_processed": [8, 8], "throughput_tok_s": [3365.7284699339634, 2604.081898137214], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [106.2013000009756, 2.4346000027435366, 2.216600001702318], "resource_metrics": {"samples": 2, "duration_s": 0.11722540855407715, "gpu_memory_mean_mb": 777.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.025, "gpu_power_peak_watts": 30.025, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 898.7578125, "cpu_memory_peak_mb": 949.69140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576433.9288433}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [5.098699999507517, 4.636300000129268], "tokens_processed": [8, 8], "throughput_tok_s": [1569.02739929251, 1725.5138795541588], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.02830000166432, 5.060099996626377, 6.313800000498304], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.025, "gpu_power_peak_watts": 30.025, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 950.0234375, "cpu_memory_peak_mb": 950.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.0464058}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [5.022299999836832, 3.613900000345893], "tokens_processed": [8, 8], "throughput_tok_s": [1592.8956852955637, 2213.6749769596017], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.882900000666268, 5.469100000482285, 3.3259000010730233], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.427, "gpu_power_peak_watts": 30.427, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 950.16796875, "cpu_memory_peak_mb": 950.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.1663647}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.581900000630412, 3.7978000000293832], "tokens_processed": [8, 8], "throughput_tok_s": [1746.0005672099564, 2106.4827004945246], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.271400001423899, 5.519400001503527, 4.8557000009168405], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.427, "gpu_power_peak_watts": 30.427, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 950.24609375, "cpu_memory_peak_mb": 950.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.2911263}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.9404000017384533, 1.9243999995524064], "tokens_processed": [8, 8], "throughput_tok_s": [2030.2507350701715, 4157.139888724127], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.481000000145286, 5.236000000877539, 4.456400001799921], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.427, "gpu_power_peak_watts": 30.427, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 950.3359375, "cpu_memory_peak_mb": 950.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.4164016}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8703999994613696, 3.1200000012177043], "tokens_processed": [11, 11], "throughput_tok_s": [5881.094954644855, 3525.641024265004], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7794999987236224, 2.236199998151278, 2.3158000003604684], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.427, "gpu_power_peak_watts": 30.427, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 952.55078125, "cpu_memory_peak_mb": 952.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.5378764}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.821999999170657, 4.430599998158868], "tokens_processed": [11, 11], "throughput_tok_s": [1889.3850913031515, 2482.7337165555546], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5660000030475203, 5.492399999639019, 4.961899998306762], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.491, "gpu_power_peak_watts": 30.491, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 952.63671875, "cpu_memory_peak_mb": 952.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.6625206}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.2355000000970904, 2.9753999988315627], "tokens_processed": [11, 11], "throughput_tok_s": [4920.5994182609065, 3696.9819198493283], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.091300001367927, 4.269900000508642, 1.954300001671072], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.491, "gpu_power_peak_watts": 30.491, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 952.65625, "cpu_memory_peak_mb": 952.65625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.7875917}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0167000002402347, 1.8880000025092158], "tokens_processed": [11, 11], "throughput_tok_s": [5454.455297609784, 5826.271178697367], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.25829999949201, 2.1658000005118083, 2.521900001738686], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.491, "gpu_power_peak_watts": 30.491, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 952.76953125, "cpu_memory_peak_mb": 952.76953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576434.913559}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.201999996643281, 4.545700001472142], "tokens_processed": [11, 11], "throughput_tok_s": [2114.5713200880473, 2419.8693262726556], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.729700001917081, 4.396700001962017, 3.424700000323355], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.491, "gpu_power_peak_watts": 30.491, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 952.796875, "cpu_memory_peak_mb": 952.796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.0380118}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.956399999675341, 2.521600003092317], "tokens_processed": [19, 19], "throughput_tok_s": [6426.735219214754, 7534.898467917079], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.62050000068848, 4.805600001418497, 3.78899999850546], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.528, "gpu_power_peak_watts": 30.528, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 956.90234375, "cpu_memory_peak_mb": 956.90234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.160864}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.7420999977039173, 2.570100001321407], "tokens_processed": [19, 19], "throughput_tok_s": [6928.996030746343, 7392.7084511230005], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.146499999682419, 5.347799997252878, 6.161599998449674], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.528, "gpu_power_peak_watts": 30.528, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 957.01953125, "cpu_memory_peak_mb": 957.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.2840724}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.400699999270728, 2.560500000981847], "tokens_processed": [19, 19], "throughput_tok_s": [7914.358314563136, 7420.425695260409], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.077599998709047, 2.7020999987144023, 2.0794999982172158], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.528, "gpu_power_peak_watts": 30.528, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 957.0546875, "cpu_memory_peak_mb": 957.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.4084847}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3416000003635418, 2.3605999995197635], "tokens_processed": [19, 19], "throughput_tok_s": [8114.110008989657, 8048.801153886862], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2222999980149325, 2.6385999990452547, 2.4121999995259102], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.528, "gpu_power_peak_watts": 30.528, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 957.0546875, "cpu_memory_peak_mb": 957.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.5365796}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.742199999076547, 2.486900000803871], "tokens_processed": [19, 19], "throughput_tok_s": [3308.836335038061, 7640.033774521854], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.091200000606477, 4.639899998437613, 2.787900000839727], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.538, "gpu_power_peak_watts": 30.538, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 957.05859375, "cpu_memory_peak_mb": 957.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.6600316}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.8000000020256266, 5.600399999821093], "tokens_processed": [27, 27], "throughput_tok_s": [9642.857135881133, 4821.08420842485], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6136999988229945, 3.4524000002420507, 2.5410999987798277], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.538, "gpu_power_peak_watts": 30.538, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.83984375, "cpu_memory_peak_mb": 954.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.783742}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.43409999954747, 5.331100001058076], "tokens_processed": [27, 27], "throughput_tok_s": [4968.6240595956, 5064.620808958985], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.430999997974141, 5.623199998808559, 3.9926999997987878], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.538, "gpu_power_peak_watts": 30.538, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.84765625, "cpu_memory_peak_mb": 954.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576435.9075673}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.4318000004277565, 3.886800001055235], "tokens_processed": [27, 27], "throughput_tok_s": [4197.89172520979, 6946.588451340362], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.132499998784624, 6.652200001553865, 6.875400002172682], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.538, "gpu_power_peak_watts": 30.538, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.875, "cpu_memory_peak_mb": 954.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.0336528}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.320999999938067, 2.631799998198403], "tokens_processed": [27, 27], "throughput_tok_s": [11632.916846497397, 10259.138239411366], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.787800000893185, 5.325400001311209, 3.1517999996140134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.562, "gpu_power_peak_watts": 30.562, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.8828125, "cpu_memory_peak_mb": 954.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.155824}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.747099999396596, 3.0271000032371376], "tokens_processed": [27, 27], "throughput_tok_s": [9828.546469342427, 8919.42782568352], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4489000026951544, 3.6639000027207658, 2.698799999052426], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.562, "gpu_power_peak_watts": 30.562, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.8828125, "cpu_memory_peak_mb": 954.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.2820845}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.538299999490846, 3.61940000220784], "tokens_processed": [44, 44], "throughput_tok_s": [12435.35031126007, 12156.711049665671], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.4276999979047105, 3.7798999983351678, 3.243399998609675], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.562, "gpu_power_peak_watts": 30.562, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 955.68359375, "cpu_memory_peak_mb": 955.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.4040434}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.6818000007770024, 3.551300000253832], "tokens_processed": [44, 44], "throughput_tok_s": [11950.676297113992, 12389.829075790574], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.16370000311872, 4.317299997637747, 3.6723000011988916], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.562, "gpu_power_peak_watts": 30.562, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.9375, "cpu_memory_peak_mb": 954.9375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.5294027}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.793499997002073, 4.821399998036213], "tokens_processed": [44, 44], "throughput_tok_s": [6476.779277164483, 9125.980009524512], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.528400001116097, 4.816100001335144, 7.708099998126272], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.9453125, "cpu_memory_peak_mb": 954.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.652795}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.959599998575868, 6.790300001739524], "tokens_processed": [44, 44], "throughput_tok_s": [14866.873909032432, 6479.831522720377], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.3757999992521945, 4.415900002641138, 2.715499998885207], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.953125, "cpu_memory_peak_mb": 954.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.7797883}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.329499999381369, 3.702900001371745], "tokens_processed": [44, 44], "throughput_tok_s": [13215.197479554086, 11882.57851513682], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.3985999984433874, 5.524300002434757, 4.200999999738997], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 791.0390625, "gpu_memory_peak_mb": 791.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 954.953125, "cpu_memory_peak_mb": 954.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576436.9031193}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.363500000181375, 4.6652000019093975], "tokens_processed": [76, 76], "throughput_tok_s": [17417.210953785023, 16290.834255529093], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.14530000166269, 5.404499999713153, 4.291099998226855], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 951.26953125, "cpu_memory_peak_mb": 951.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576437.023602}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.285999999818159, 5.115600000863196], "tokens_processed": [76, 76], "throughput_tok_s": [12090.35952946206, 14856.517317064647], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.217099998641061, 4.16169999880367, 4.473199998756172], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 961.21875, "cpu_memory_peak_mb": 961.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576437.1503756}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.1963000013493, 8.507999998982996], "tokens_processed": [76, 76], "throughput_tok_s": [8264.193206925516, 8932.769159506895], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.269099998055026, 6.58790000306908, 3.460899999481626], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 961.29296875, "cpu_memory_peak_mb": 961.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576437.2728627}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.52459999723942, 4.530099999101367], "tokens_processed": [76, 76], "throughput_tok_s": [16797.06494416515, 16776.671599981473], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.9246000016864855, 3.113300001132302, 3.9496999997936655], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 961.30078125, "cpu_memory_peak_mb": 961.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576437.4005194}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.90359999903012, 9.35590000153752], "tokens_processed": [76, 76], "throughput_tok_s": [8535.873130899723, 8123.216364808344], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.4773000008717645, 6.114800002251286, 5.850400000781519], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 961.3203125, "cpu_memory_peak_mb": 961.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 901.6267999977572, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765576437.5242453}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6192000000737607, 0.7509999995818362], "tokens_processed": [8, 8], "throughput_tok_s": [12919.896639287821, 10652.463388088516], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4818999989074655, 0.8182999990822282, 0.590899999224348], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.657, "gpu_power_peak_watts": 30.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 963.515625, "cpu_memory_peak_mb": 963.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576437.6477442}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7053999979689252, 0.47429999904125], "tokens_processed": [8, 8], "throughput_tok_s": [11341.083106088161, 16866.961872593718], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0684999979275744, 0.5977000000711996, 0.5592000015894882], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.657, "gpu_power_peak_watts": 30.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 963.51953125, "cpu_memory_peak_mb": 963.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576437.7745051}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5107999968458898, 0.4592000004777219], "tokens_processed": [8, 8], "throughput_tok_s": [15661.707222785337, 17421.60276933214], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7421000009344425, 0.5758000006608199, 0.590899999224348], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.657, "gpu_power_peak_watts": 30.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 963.59375, "cpu_memory_peak_mb": 963.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576437.9053319}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.4894999983662274, 0.5323999976099003], "tokens_processed": [8, 8], "throughput_tok_s": [16343.20740899098, 15026.296085489004], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.896699999429984, 0.7965000004332978, 0.767400000768248], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.657, "gpu_power_peak_watts": 30.657, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 963.59375, "cpu_memory_peak_mb": 963.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.0253172}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.666200001433026, 0.5774999990535434], "tokens_processed": [8, 8], "throughput_tok_s": [12008.405858288264, 13852.813875517033], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7917000002635177, 0.7279999990714714, 0.6315999999060296], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 963.6171875, "cpu_memory_peak_mb": 963.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.1483538}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5719000000681262, 0.6463999998231884], "tokens_processed": [11, 11], "throughput_tok_s": [19234.131838939764, 17017.326737328065], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3135000008333009, 0.7962999989103992, 0.5902999982936308], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 964.32421875, "cpu_memory_peak_mb": 964.32421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.2754548}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8309000004373956, 0.8873000006133225], "tokens_processed": [11, 11], "throughput_tok_s": [13238.65687111502, 12397.159914793805], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.155900001322152, 1.1005999986082315, 0.8392000017920509], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 964.37890625, "cpu_memory_peak_mb": 964.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.3961911}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9008000015455764, 0.9691000013845041], "tokens_processed": [11, 11], "throughput_tok_s": [12211.367652227353, 11350.737781740643], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7455000013578683, 1.1234000012336764, 0.8491000007779803], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 964.37890625, "cpu_memory_peak_mb": 964.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.5201995}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1322000027575996, 1.074199997674441], "tokens_processed": [11, 11], "throughput_tok_s": [9715.597927228644, 10240.178759834425], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.965600000199629, 1.5200000016193371, 0.8134999989124481], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.205, "gpu_power_peak_watts": 30.205, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 964.3828125, "cpu_memory_peak_mb": 964.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.6461887}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5247000008239411, 0.5732999998144805], "tokens_processed": [11, 11], "throughput_tok_s": [20964.360554081573, 19187.162050513853], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.897999998414889, 1.1032000002160203, 0.5295000009937212], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.205, "gpu_power_peak_watts": 30.205, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 964.390625, "cpu_memory_peak_mb": 964.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.7686324}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2248999992152676, 0.994999998511048], "tokens_processed": [19, 19], "throughput_tok_s": [15511.470334045516, 19095.4774155098], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0686000025307294, 1.1880999991262797, 1.1961000018345658], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.205, "gpu_power_peak_watts": 30.205, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 965.99609375, "cpu_memory_peak_mb": 965.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576438.8917668}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.006399998004781, 1.1354000016581267], "tokens_processed": [19, 19], "throughput_tok_s": [18879.173328366538, 16734.19056918495], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6089999990072101, 1.4453000003413763, 1.0102000014740042], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.205, "gpu_power_peak_watts": 30.205, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 966.00390625, "cpu_memory_peak_mb": 966.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.0177686}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2752000002365094, 1.1389999999664724], "tokens_processed": [19, 19], "throughput_tok_s": [14899.623585693302, 16681.299385916842], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.324900000327034, 1.4072000012674835, 1.089900000806665], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.296, "gpu_power_peak_watts": 30.296, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 966.00390625, "cpu_memory_peak_mb": 966.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.1427417}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0540000002947636, 0.9820000013860408], "tokens_processed": [19, 19], "throughput_tok_s": [18026.565459854293, 19348.268811794816], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.775400000042282, 1.3202000009187032, 1.6359999972337391], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.296, "gpu_power_peak_watts": 30.296, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 966.00390625, "cpu_memory_peak_mb": 966.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.2663856}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.289099996938603, 1.217100001667859], "tokens_processed": [19, 19], "throughput_tok_s": [14738.965204500679, 15610.878295919198], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.515700001618825, 1.6023999996832572, 1.0529999999562278], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.296, "gpu_power_peak_watts": 30.296, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 966.01171875, "cpu_memory_peak_mb": 966.01171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.3907614}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5443000011146069, 1.8168000024161302], "tokens_processed": [27, 27], "throughput_tok_s": [17483.64953733899, 14861.294564119979], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.629099999467144, 1.4799999989918433, 1.5327999972214457], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.296, "gpu_power_peak_watts": 30.296, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 971.4453125, "cpu_memory_peak_mb": 971.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.5175736}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.41530000109924, 1.4919999994162936], "tokens_processed": [27, 27], "throughput_tok_s": [19077.227428127993, 18096.514752388106], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.077699999063043, 1.6163000000233296, 1.4258999981393572], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.298, "gpu_power_peak_watts": 30.298, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 971.46875, "cpu_memory_peak_mb": 971.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.6454656}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.46399999721325, 1.462699998228345], "tokens_processed": [27, 27], "throughput_tok_s": [18442.622985925533, 18459.01417426882], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.117300002282718, 1.6027999990910757, 1.8039000024145935], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.298, "gpu_power_peak_watts": 30.298, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 971.46875, "cpu_memory_peak_mb": 971.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.7658198}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.356799999688519, 1.6968000018096063], "tokens_processed": [27, 27], "throughput_tok_s": [11456.211814141374, 15912.305499295728], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.132800000254065, 2.0242999999027234, 1.714699999865843], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.298, "gpu_power_peak_watts": 30.298, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 971.47265625, "cpu_memory_peak_mb": 971.47265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576439.8923109}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7153999979200307, 1.637299999856623], "tokens_processed": [27, 27], "throughput_tok_s": [15739.769169137366, 16490.563734419087], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.184299999498762, 2.1009000010963064, 2.0817999975406565], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.298, "gpu_power_peak_watts": 30.298, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 971.5625, "cpu_memory_peak_mb": 971.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.018699}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.722699999139877, 2.4696999971638434], "tokens_processed": [44, 44], "throughput_tok_s": [16160.428991038292, 17815.92908066922], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.24830000338261, 3.1101999993552454, 2.400699999270728], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.419, "gpu_power_peak_watts": 30.419, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 980.796875, "cpu_memory_peak_mb": 980.796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.1421652}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.442299999529496, 3.2113999986904673], "tokens_processed": [44, 44], "throughput_tok_s": [18015.804777658974, 13701.18951794923], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9106999973009806, 2.5481999982730485, 2.6228999995510094], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.419, "gpu_power_peak_watts": 30.419, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 980.9453125, "cpu_memory_peak_mb": 980.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.270519}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.5236000001314096, 4.247900000336813], "tokens_processed": [44, 44], "throughput_tok_s": [17435.409731220803, 10358.05927552703], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8708999998343643, 2.582299999630777, 2.3236999986693263], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.419, "gpu_power_peak_watts": 30.419, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 980.9453125, "cpu_memory_peak_mb": 980.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.399181}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.011699998547556, 1.9691999987117015], "tokens_processed": [44, 44], "throughput_tok_s": [21872.04853197193, 22344.099141166906], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8650999993260484, 2.61780000073486, 2.401100002316525], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.419, "gpu_power_peak_watts": 30.419, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 980.953125, "cpu_memory_peak_mb": 980.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.5225043}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0675000014307443, 2.2286000021267682], "tokens_processed": [44, 44], "throughput_tok_s": [21281.741218646323, 19743.336605048236], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7823999989777803, 2.97859999773209, 2.2505999986606184], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.373, "gpu_power_peak_watts": 30.373, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 980.95703125, "cpu_memory_peak_mb": 980.95703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.6453617}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.6791999991692137, 4.365700002381345], "tokens_processed": [76, 76], "throughput_tok_s": [20656.664496945334, 17408.433918625768], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.43420000030892, 4.309899999498157, 4.024000001663808], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.373, "gpu_power_peak_watts": 30.373, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 987.09765625, "cpu_memory_peak_mb": 987.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.7705975}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.070400002092356, 3.9489000009780284], "tokens_processed": [76, 76], "throughput_tok_s": [18671.38363820087, 19245.865932582998], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.83429999803775, 3.6371000023791566, 3.9318999988608994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.373, "gpu_power_peak_watts": 30.373, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 987.16796875, "cpu_memory_peak_mb": 987.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576440.8950613}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9412000005540904, 4.0320999978575855], "tokens_processed": [76, 76], "throughput_tok_s": [19283.466961665283, 18848.738880578807], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.421499997988576, 4.973899998731213, 3.801999999268446], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.373, "gpu_power_peak_watts": 30.373, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 987.16796875, "cpu_memory_peak_mb": 987.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.0224683}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.387100001622457, 4.518199999438366], "tokens_processed": [76, 76], "throughput_tok_s": [17323.51666747814, 16820.857865841965], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8567000010516495, 4.779000002599787, 5.172599998331862], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.401, "gpu_power_peak_watts": 30.401, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 987.16796875, "cpu_memory_peak_mb": 987.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.144462}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.2644999994081445, 6.280099998548394], "tokens_processed": [76, 76], "throughput_tok_s": [17821.550008335744, 12101.718128304792], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.386499997053761, 4.198599999654107, 4.256899999745656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 807.0390625, "gpu_memory_peak_mb": 807.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.401, "gpu_power_peak_watts": 30.401, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 987.16796875, "cpu_memory_peak_mb": 987.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 90.39560000019264, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.2722905}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.8143999986932613, 1.5798999993421603], "tokens_processed": [8, 8], "throughput_tok_s": [4409.1710790132465, 5063.61162309706], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [43.696999997337116, 1.6427000009571202, 1.8448999981046654], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 825.0390625, "gpu_memory_peak_mb": 825.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.401, "gpu_power_peak_watts": 30.401, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 998.19921875, "cpu_memory_peak_mb": 998.19921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.3918839}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.4843999997538049, 1.9758999987971038], "tokens_processed": [8, 8], "throughput_tok_s": [5389.382916550014, 4048.7878965890336], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8539999982749578, 1.889299997856142, 1.6286999998555984], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.401, "gpu_power_peak_watts": 30.401, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1039.16796875, "cpu_memory_peak_mb": 1039.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.515299}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.4755000011064112, 1.4824999998381827], "tokens_processed": [8, 8], "throughput_tok_s": [5421.890880380318, 5396.290051179233], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.024199999141274, 1.84850000005099, 1.9492000028549228], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.471, "gpu_power_peak_watts": 30.471, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1039.21875, "cpu_memory_peak_mb": 1039.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.6407003}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.875300000596326, 3.4087999993062112], "tokens_processed": [8, 8], "throughput_tok_s": [2782.318366202077, 2346.8669331225738], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.904000000853557, 3.841899997496512, 3.414800001337426], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.471, "gpu_power_peak_watts": 30.471, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1039.26953125, "cpu_memory_peak_mb": 1039.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.7656555}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.4971999989938922, 1.7112999994424172], "tokens_processed": [8, 8], "throughput_tok_s": [5343.307510937712, 4674.808626545078], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.796400000283029, 3.7781000028189737, 1.6610000020591542], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.471, "gpu_power_peak_watts": 30.471, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1039.29296875, "cpu_memory_peak_mb": 1039.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576441.890726}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.381199996714713, 3.457000002526911], "tokens_processed": [11, 11], "throughput_tok_s": [2510.727656406569, 3181.949665015764], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.528900000877911, 4.089100002602208, 3.81070000003092], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.471, "gpu_power_peak_watts": 30.471, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1041.578125, "cpu_memory_peak_mb": 1041.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.014904}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0852999987255316, 1.9355000003997702], "tokens_processed": [11, 11], "throughput_tok_s": [5275.020383984485, 5683.285971443033], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.385699998238124, 3.1737999997858424, 1.6751000002841465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1041.578125, "cpu_memory_peak_mb": 1041.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.1396022}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3331000013276935, 3.724599999259226], "tokens_processed": [11, 11], "throughput_tok_s": [3300.2310148565316, 2953.3372717037414], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.332500000600703, 3.564300001016818, 3.665000000182772], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1041.6328125, "cpu_memory_peak_mb": 1041.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.2799122}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.7023000000335742, 1.9040000006498303], "tokens_processed": [11, 11], "throughput_tok_s": [6461.84573799157, 5777.310922397966], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1735000009357464, 1.8053000021609478, 1.965899999049725], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1041.640625, "cpu_memory_peak_mb": 1041.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.402734}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.662999999098247, 1.810900001146365], "tokens_processed": [11, 11], "throughput_tok_s": [6614.552018018456, 6074.327678522615], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4549000008846633, 1.8123000008927193, 2.140499997040024], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.564, "gpu_power_peak_watts": 30.564, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1041.640625, "cpu_memory_peak_mb": 1041.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.52826}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.528900000877911, 4.818599998543505], "tokens_processed": [19, 19], "throughput_tok_s": [4195.279206058186, 3943.0540002787197], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.120699999679346, 5.506100002094172, 4.797000001417473], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.283, "gpu_power_peak_watts": 31.283, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1043.15234375, "cpu_memory_peak_mb": 1043.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.652784}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.9715000022843014, 5.520999999134801], "tokens_processed": [19, 19], "throughput_tok_s": [3821.784168011645, 3441.405543013494], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1815000002097804, 5.356700003176229, 5.030700001952937], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.283, "gpu_power_peak_watts": 31.283, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1043.16015625, "cpu_memory_peak_mb": 1043.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.776007}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.249400000844616, 4.735999998956686], "tokens_processed": [19, 19], "throughput_tok_s": [4471.219465388886, 4011.8243252081065], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.522999999608146, 4.458199997316115, 4.601000000548083], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.283, "gpu_power_peak_watts": 31.283, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1043.1953125, "cpu_memory_peak_mb": 1043.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576442.9035392}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9977000014914665, 2.8042000012646895], "tokens_processed": [19, 19], "throughput_tok_s": [4752.732819599134, 6775.55095621961], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.984400002285838, 5.745700000261422, 4.003699999884702], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.283, "gpu_power_peak_watts": 31.283, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1043.1953125, "cpu_memory_peak_mb": 1043.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.0258415}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.8480000004929025, 5.525000000488944], "tokens_processed": [19, 19], "throughput_tok_s": [3919.1419137929547, 3438.9140268449887], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.246300002705539, 5.595400001766393, 6.04370000291965], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.728, "gpu_power_peak_watts": 30.728, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1043.21484375, "cpu_memory_peak_mb": 1043.21484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.1515758}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.8139999996928964, 2.5451000001339708], "tokens_processed": [27, 27], "throughput_tok_s": [7079.181961765612, 10608.620485866471], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.949099999270402, 5.949300000793301, 5.994499999360414], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.728, "gpu_power_peak_watts": 30.728, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1048.96484375, "cpu_memory_peak_mb": 1048.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.2746596}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.8797999986854848, 4.262300000846153], "tokens_processed": [27, 27], "throughput_tok_s": [6959.121606564223, 6334.608074194673], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.571800000121584, 4.642799998691771, 3.9431000004697125], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.728, "gpu_power_peak_watts": 30.728, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1048.96484375, "cpu_memory_peak_mb": 1048.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.399019}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.543299997545546, 3.777599999011727], "tokens_processed": [27, 27], "throughput_tok_s": [7620.015245308887, 7147.395173407343], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.375600001774728, 4.851400000916328, 4.598399998940295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 30.728, "gpu_power_peak_watts": 30.728, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1048.96875, "cpu_memory_peak_mb": 1048.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.521991}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.34060000043246, 5.81400000010035], "tokens_processed": [27, 27], "throughput_tok_s": [6220.3382014721365, 4643.962848217058], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.814399999304442, 4.389500001707347, 3.737400002137292], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.404, "gpu_power_peak_watts": 27.404, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1048.96875, "cpu_memory_peak_mb": 1048.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.6481092}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.366399997001281, 5.645200002618367], "tokens_processed": [27, 27], "throughput_tok_s": [5031.305906210397, 4782.8243441289615], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.7943000028899405, 5.325900001480477, 4.758600000059232], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.404, "gpu_power_peak_watts": 27.404, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1048.96875, "cpu_memory_peak_mb": 1048.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.773574}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.526400000235299, 5.918800001381896], "tokens_processed": [44, 44], "throughput_tok_s": [7961.783439151455, 7433.939310287063], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.324400001380127, 5.501299998286413, 5.79220000145142], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.404, "gpu_power_peak_watts": 27.404, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1058.6953125, "cpu_memory_peak_mb": 1058.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576443.8977768}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.0625000007567, 6.397799999831477], "tokens_processed": [44, 44], "throughput_tok_s": [6230.088494907709, 6877.364094088435], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.600599998113466, 6.029700001818128, 5.404899999120971], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 27.404, "gpu_power_peak_watts": 27.404, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 1058.74609375, "cpu_memory_peak_mb": 1058.74609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.0248728}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.076599998777965, 5.8702999995148275], "tokens_processed": [44, 44], "throughput_tok_s": [7240.891289347434, 7495.357989137956], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.549699999799486, 7.874200000514975, 6.729099997755839], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 20.83, "gpu_power_peak_watts": 20.83, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1058.7734375, "cpu_memory_peak_mb": 1058.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.1444776}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.18640000175219, 6.151800000225194], "tokens_processed": [44, 44], "throughput_tok_s": [7112.375531413708, 7152.378165478288], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.523600000946317, 5.781899999419693, 6.039500000042608], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 20.83, "gpu_power_peak_watts": 20.83, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1058.78515625, "cpu_memory_peak_mb": 1058.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.275187}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.697200002236059, 6.248300000152085], "tokens_processed": [44, 44], "throughput_tok_s": [6569.909810862643, 7041.915400817667], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.014900001900969, 5.646300000080373, 5.543499999475898], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 20.83, "gpu_power_peak_watts": 20.83, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1058.7890625, "cpu_memory_peak_mb": 1058.7890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.3926806}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [15.423700002429541, 14.419200000702403], "tokens_processed": [76, 76], "throughput_tok_s": [4927.481731882005, 5270.750110706405], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.173799998592585, 16.39640000212239, 16.977999999653548], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 20.83, "gpu_power_peak_watts": 20.83, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1064.9921875, "cpu_memory_peak_mb": 1064.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.521823}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [14.276300000346964, 13.933399997767992], "tokens_processed": [76, 76], "throughput_tok_s": [5323.508191769081, 5454.519357240481], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.948899999581045, 14.331800000945805, 14.547499999025604], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 14.06, "gpu_power_peak_watts": 14.06, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1064.9921875, "cpu_memory_peak_mb": 1064.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.6415112}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [14.127099999313941, 14.937200001440942], "tokens_processed": [76, 76], "throughput_tok_s": [5379.731155275379, 5087.968293433075], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.373399997566594, 14.208599997800775, 13.964900001155911], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 14.06, "gpu_power_peak_watts": 14.06, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1064.9921875, "cpu_memory_peak_mb": 1064.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.7651384}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.768500000063796, 9.141300000919728], "tokens_processed": [76, 76], "throughput_tok_s": [7780.109535701865, 8313.915962976103], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.42189999902621, 13.608200002636295, 10.426099997857818], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 14.06, "gpu_power_peak_watts": 14.06, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1064.9921875, "cpu_memory_peak_mb": 1064.9921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576444.8928666}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [10.690300001442665, 10.172800000873394], "tokens_processed": [76, 76], "throughput_tok_s": [7109.24857017518, 7470.902798981102], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.172499999200227, 13.473499999236083, 11.223400000744732], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 14.06, "gpu_power_peak_watts": 14.06, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1064.99609375, "cpu_memory_peak_mb": 1064.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1752.9847000005248, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765576445.020995}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.541999998356914, 2.7803000011772383], "tokens_processed": [8, 8], "throughput_tok_s": [3147.128247510229, 2877.3873310839226], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6921999999321997, 2.760300001682481, 2.0327999991422985], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 10.468, "gpu_power_peak_watts": 10.468, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.2890625, "cpu_memory_peak_mb": 1067.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.1438506}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.6453999998921063, 2.858700001524994], "tokens_processed": [8, 8], "throughput_tok_s": [3024.117335875967, 2798.4748297241204], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9455999974743463, 2.502499999536667, 1.4766999993298668], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 10.468, "gpu_power_peak_watts": 10.468, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.3046875, "cpu_memory_peak_mb": 1067.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.2662163}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.9276999994181097, 1.8906000004790258], "tokens_processed": [8, 8], "throughput_tok_s": [2732.5204090548987, 4231.460910807691], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2099000018206425, 6.116100001236191, 2.5788999992073514], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 10.468, "gpu_power_peak_watts": 10.468, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.3046875, "cpu_memory_peak_mb": 1067.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.3891501}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.754199998889817, 2.1335000019462314], "tokens_processed": [8, 8], "throughput_tok_s": [2904.6547103422768, 3749.7070507158205], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9905000010330696, 2.5779000025067944, 2.9842999974789564], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 10.468, "gpu_power_peak_watts": 10.468, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.3046875, "cpu_memory_peak_mb": 1067.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.5139928}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.649599999131169, 2.6801999993040226], "tokens_processed": [8, 8], "throughput_tok_s": [3019.3236724876515, 2984.851877500705], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.346699999383418, 5.792799998744158, 2.4616000009700656], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 9.127, "gpu_power_peak_watts": 9.127, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.30859375, "cpu_memory_peak_mb": 1067.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.6392424}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.999299998919014, 2.8751999998348765], "tokens_processed": [11, 11], "throughput_tok_s": [3667.522423220265, 3825.8208126849377], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4985999991477, 3.0637999989266973, 2.715799997531576], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 9.127, "gpu_power_peak_watts": 9.127, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.8828125, "cpu_memory_peak_mb": 1067.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.7618432}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.518399997119559, 5.752800003392622], "tokens_processed": [11, 11], "throughput_tok_s": [3126.4211030597635, 1912.112361547929], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.508899997541448, 6.087399997340981, 2.864000001864042], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 9.127, "gpu_power_peak_watts": 9.127, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.88671875, "cpu_memory_peak_mb": 1067.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576445.8848321}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2644999992044177, 5.486899997777073], "tokens_processed": [11, 11], "throughput_tok_s": [3369.5818663442424, 2004.775010380446], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4190000005764887, 5.096500000945525, 2.5432000002183486], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 9.127, "gpu_power_peak_watts": 9.127, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.88671875, "cpu_memory_peak_mb": 1067.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.0095558}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.9003999989072327, 3.106899999693269], "tokens_processed": [11, 11], "throughput_tok_s": [3792.5803351759787, 3540.506614659623], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.92459999784478, 6.248400000913534, 3.1094000005396083], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 11.032, "gpu_power_peak_watts": 11.032, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.88671875, "cpu_memory_peak_mb": 1067.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.134404}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.493299998808652, 3.1168999994406477], "tokens_processed": [11, 11], "throughput_tok_s": [3148.8850095186262, 3529.147551084102], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5210000023653265, 5.543700000998797, 2.843800000846386], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 11.032, "gpu_power_peak_watts": 11.032, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1067.890625, "cpu_memory_peak_mb": 1067.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.258158}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.581799999665236, 3.691399997478584], "tokens_processed": [19, 19], "throughput_tok_s": [5304.595455295043, 5147.098665270081], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.006099999969592, 5.833600000187289, 3.6083999984839465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 11.032, "gpu_power_peak_watts": 11.032, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.42578125, "cpu_memory_peak_mb": 1069.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.3856218}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.5867000005964655, 5.122200000187149], "tokens_processed": [19, 19], "throughput_tok_s": [5297.3485367720505, 3709.3436412685564], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.7260999997670297, 3.5372000020288397, 3.520599999319529], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 11.032, "gpu_power_peak_watts": 11.032, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.42578125, "cpu_memory_peak_mb": 1069.42578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.5093284}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.0938000018068124, 3.889700001309393], "tokens_processed": [19, 19], "throughput_tok_s": [6141.314884253603, 4884.6954761560055], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.38230000124895, 3.196699999534758, 3.2163999967451673], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 10.985, "gpu_power_peak_watts": 10.985, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.4296875, "cpu_memory_peak_mb": 1069.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.6319883}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.847599997650832, 6.057999999029562], "tokens_processed": [19, 19], "throughput_tok_s": [3249.196252758894, 3136.348630413277], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.322200002614409, 4.949499998474494, 5.977500000881264], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 10.985, "gpu_power_peak_watts": 10.985, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.4296875, "cpu_memory_peak_mb": 1069.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.7578156}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.140400000731461, 5.735800001275493], "tokens_processed": [19, 19], "throughput_tok_s": [3094.260959829436, 3312.528330097788], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.481299998995382, 5.78710000263527, 6.182999997690786], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 10.985, "gpu_power_peak_watts": 10.985, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.43359375, "cpu_memory_peak_mb": 1069.43359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576446.8839011}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.286100000579609, 6.943600001250161], "tokens_processed": [27, 27], "throughput_tok_s": [4295.190976521289, 3888.4728375970367], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.937799997918773, 6.799499999033287, 6.652800002484582], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 10.985, "gpu_power_peak_watts": 10.985, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1070.96875, "cpu_memory_peak_mb": 1070.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.005215}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.148000000597676, 6.780200001230696], "tokens_processed": [27, 27], "throughput_tok_s": [3777.2803578263024, 3982.1834156955756], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.855899999209214, 7.200700001703808, 8.23849999869708], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.622, "gpu_power_peak_watts": 3.622, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1070.96875, "cpu_memory_peak_mb": 1070.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.1302125}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.128199998987839, 6.780399999115616], "tokens_processed": [27, 27], "throughput_tok_s": [3787.772509726696, 3982.0659553303162], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.230700000945944, 6.951999999728287, 6.695399999443907], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.622, "gpu_power_peak_watts": 3.622, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1070.96875, "cpu_memory_peak_mb": 1070.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.25284}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.972200000745943, 7.1356000007654075], "tokens_processed": [27, 27], "throughput_tok_s": [3872.5223024456154, 3783.8443854901925], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.161800000176299, 9.865199997875607, 6.785099998523947], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.622, "gpu_power_peak_watts": 3.622, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1070.96875, "cpu_memory_peak_mb": 1070.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.387782}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.705399999191286, 6.463800000346964], "tokens_processed": [27, 27], "throughput_tok_s": [4026.6054229809365, 4177.109440043116], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.173400001396658, 8.860699999786448, 7.0382999983849], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.622, "gpu_power_peak_watts": 3.622, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1070.96875, "cpu_memory_peak_mb": 1070.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.5198977}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.218, "gpu_power_peak_watts": 3.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.2734375, "cpu_memory_peak_mb": 1069.2734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.6606839}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.218, "gpu_power_peak_watts": 3.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.578125, "cpu_memory_peak_mb": 1069.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.7826104}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.218, "gpu_power_peak_watts": 3.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.60546875, "cpu_memory_peak_mb": 1069.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576447.9067512}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.218, "gpu_power_peak_watts": 3.218, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.60546875, "cpu_memory_peak_mb": 1069.60546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.0315533}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.277, "gpu_power_peak_watts": 3.277, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.609375, "cpu_memory_peak_mb": 1069.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.1563914}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.277, "gpu_power_peak_watts": 3.277, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.609375, "cpu_memory_peak_mb": 1069.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.2828841}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.277, "gpu_power_peak_watts": 3.277, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.61328125, "cpu_memory_peak_mb": 1069.61328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.4090776}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.277, "gpu_power_peak_watts": 3.277, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.61328125, "cpu_memory_peak_mb": 1069.61328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.5315874}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.61328125, "cpu_memory_peak_mb": 1069.61328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.6540294}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1069.61328125, "cpu_memory_peak_mb": 1069.61328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 139.12139999956707, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.7818801}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.563799997413298, 3.878600000462029], "tokens_processed": [8, 8], "throughput_tok_s": [1752.9251949108846, 2062.599906937302], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [42.335099999036174, 4.757599999720696, 4.940399998304201], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1090.7578125, "cpu_memory_peak_mb": 1090.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576448.9049401}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.7154999992926605, 4.975100000592647], "tokens_processed": [8, 8], "throughput_tok_s": [1696.5327115258244, 1608.0078790470582], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.574999999022111, 4.581100001814775, 3.862400000798516], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.28125, "cpu_memory_peak_mb": 1164.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.030749}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.32629999704659, 4.891100001259474], "tokens_processed": [8, 8], "throughput_tok_s": [1849.1551684953224, 1635.62388786571], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.014700000174344, 4.250300000421703, 3.652699997473974], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.34375, "cpu_memory_peak_mb": 1164.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.1579897}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.177399998297915, 3.6612000003515277], "tokens_processed": [8, 8], "throughput_tok_s": [1915.0667887345255, 2185.075931178817], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.037700000684708, 4.306200000428362, 4.5812000025762245], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.34375, "cpu_memory_peak_mb": 1164.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.2801542}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.373200001282385, 4.2884000031335745], "tokens_processed": [8, 8], "throughput_tok_s": [1829.324064221646, 1865.4976201273957], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.520999999338528, 4.594100002577761, 4.680199999711476], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.34375, "cpu_memory_peak_mb": 1164.34375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.4041276}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.467200000362936, 4.977100001269719], "tokens_processed": [11, 11], "throughput_tok_s": [2462.3925499432103, 2210.122359846852], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.870699998718919, 4.9767000018619, 4.696399999374989], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.233, "gpu_power_peak_watts": 3.233, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.91796875, "cpu_memory_peak_mb": 1164.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.5279124}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.256399999780115, 4.970300000422867], "tokens_processed": [11, 11], "throughput_tok_s": [2092.6870102085363, 2213.1460875730104], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.505700002686353, 5.521800001588417, 4.483900000195717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.308, "gpu_power_peak_watts": 3.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.91796875, "cpu_memory_peak_mb": 1164.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.650566}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.159799999091774, 4.946000000927597], "tokens_processed": [11, 11], "throughput_tok_s": [2131.8655765603735, 2224.019409206835], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.365199998777825, 4.678299999795854, 6.732699999702163], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.308, "gpu_power_peak_watts": 3.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.91796875, "cpu_memory_peak_mb": 1164.91796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.7762716}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.061200001160614, 4.983099999662954], "tokens_processed": [11, 11], "throughput_tok_s": [2708.5590458131605, 2207.461219069257], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.674399999814341, 5.016499999328516, 4.990700002963422], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.308, "gpu_power_peak_watts": 3.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.921875, "cpu_memory_peak_mb": 1164.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576449.9004047}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.555600000458071, 4.602799999702256], "tokens_processed": [11, 11], "throughput_tok_s": [2414.6105889221917, 2389.8496568852793], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.882600002019899, 4.527400000370108, 4.956500000844244], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.308, "gpu_power_peak_watts": 3.308, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1164.921875, "cpu_memory_peak_mb": 1164.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.02283}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.316400001902366, 6.381899998814333], "tokens_processed": [19, 19], "throughput_tok_s": [3573.8469628322237, 2977.1698089173965], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.8312999972258694, 5.964100000710459, 5.8172999997623265], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.45703125, "cpu_memory_peak_mb": 1166.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.1489074}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.2143000031937845, 7.472299999790266], "tokens_processed": [19, 19], "throughput_tok_s": [3057.464234143044, 2542.7244624189734], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.984399999055313, 6.067700000130571, 5.6721000000834465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.45703125, "cpu_memory_peak_mb": 1166.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.2743447}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.611100001260638, 5.762500000855653], "tokens_processed": [19, 19], "throughput_tok_s": [3386.145318338881, 3297.1800428943616], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.902799999603303, 5.465199999889592, 6.280599998717662], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.45703125, "cpu_memory_peak_mb": 1166.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.3944733}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.873499998415355, 5.018699997890508], "tokens_processed": [19, 19], "throughput_tok_s": [3234.868477930726, 3785.840956420229], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.862800000613788, 5.694199997378746, 6.069099999876926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.45703125, "cpu_memory_peak_mb": 1166.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.523975}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.277399999613408, 6.298899999819696], "tokens_processed": [19, 19], "throughput_tok_s": [3600.2577029203453, 3016.399688920902], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.6607000005897135, 6.182199998875149, 5.669199999829289], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.4, "gpu_power_peak_watts": 3.4, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.45703125, "cpu_memory_peak_mb": 1166.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.643465}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.72610000037821, 9.945100002369145], "tokens_processed": [27, 27], "throughput_tok_s": [4014.2132883070108, 2714.9048268562406], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.229200000438141, 7.0018000005802605, 8.263699997769436], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.4, "gpu_power_peak_watts": 3.4, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1167.99609375, "cpu_memory_peak_mb": 1167.99609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.7709851}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.5687999995134305, 6.5015000000130385], "tokens_processed": [27, 27], "throughput_tok_s": [4110.339788393613, 4152.887795115874], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.410700000036741, 6.574999999429565, 7.025200000498444], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.4, "gpu_power_peak_watts": 3.4, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.0, "cpu_memory_peak_mb": 1168.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576450.8940783}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.6103999997721985, 6.685299998935079], "tokens_processed": [27, 27], "throughput_tok_s": [4084.4729518532085, 4038.7118011608914], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.159799999499228, 6.613099998503458, 6.70929999978398], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.4, "gpu_power_peak_watts": 3.4, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.00390625, "cpu_memory_peak_mb": 1168.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.0161972}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.022399997367756, 6.666000001132488], "tokens_processed": [27, 27], "throughput_tok_s": [3844.8393725963424, 4050.405039815926], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.660899999085814, 7.254800002556294, 9.256699999241391], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.439, "gpu_power_peak_watts": 3.439, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.00390625, "cpu_memory_peak_mb": 1168.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.140895}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.889799999044044, 7.410599999275291], "tokens_processed": [27, 27], "throughput_tok_s": [3918.83654151735, 3643.429682163445], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.981899998208974, 6.984199997532414, 6.67780000003404], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.439, "gpu_power_peak_watts": 3.439, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.00390625, "cpu_memory_peak_mb": 1168.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.26809}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.439, "gpu_power_peak_watts": 3.439, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.71484375, "cpu_memory_peak_mb": 1166.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.407694}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.439, "gpu_power_peak_watts": 3.439, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.71875, "cpu_memory_peak_mb": 1166.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.5293725}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.72265625, "cpu_memory_peak_mb": 1166.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.6529875}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.7265625, "cpu_memory_peak_mb": 1166.7265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.7759573}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.73046875, "cpu_memory_peak_mb": 1166.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576451.903901}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.91015625, "cpu_memory_peak_mb": 1166.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.026176}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.333, "gpu_power_peak_watts": 3.333, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.984375, "cpu_memory_peak_mb": 1166.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.1513743}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.333, "gpu_power_peak_watts": 3.333, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.984375, "cpu_memory_peak_mb": 1166.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.279767}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.333, "gpu_power_peak_watts": 3.333, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.984375, "cpu_memory_peak_mb": 1166.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.4026566}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 6.0, "gpu_power_mean_watts": 3.333, "gpu_power_peak_watts": 3.333, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1166.984375, "cpu_memory_peak_mb": 1166.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 30.57469999839668, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.527811}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.7388000018836465, 5.043199998908676], "tokens_processed": [8, 8], "throughput_tok_s": [2139.7239745291313, 1586.2944165869212], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.472500000701984, 4.4186999984958675, 3.5121999972034246], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.58203125, "cpu_memory_peak_mb": 1168.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.654165}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.590499996993458, 4.075499997270526], "tokens_processed": [8, 8], "throughput_tok_s": [1742.7295512993333, 1962.9493326850247], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.8566999976173975, 3.673999999591615, 4.689699999289587], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.6015625, "cpu_memory_peak_mb": 1168.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.7765148}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.573400001390837, 3.7691999968956225], "tokens_processed": [8, 8], "throughput_tok_s": [1749.2456372867198, 2122.466307595494], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.084700002043974, 4.550000001472654, 5.1085000013699755], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.6015625, "cpu_memory_peak_mb": 1168.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576452.899313}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [6.554100000357721, 4.6274999986053444], "tokens_processed": [8, 8], "throughput_tok_s": [1220.6099997808033, 1728.7952463341057], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.560099998343503, 4.332599997724174, 4.781999999977415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.264, "gpu_power_peak_watts": 3.264, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.6015625, "cpu_memory_peak_mb": 1168.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.0225239}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.227400000672787, 4.52930000028573], "tokens_processed": [8, 8], "throughput_tok_s": [1892.4161420085175, 1766.2773495894116], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.620699997758493, 4.563800001051277, 4.457200000615558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1168.6015625, "cpu_memory_peak_mb": 1168.6015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.1466076}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.567899999732617, 4.91130000227713], "tokens_processed": [11, 11], "throughput_tok_s": [1975.610194243475, 2239.732859914857], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.630799998471048, 4.912000000331318, 5.0478000011935364], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.17578125, "cpu_memory_peak_mb": 1169.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.2704623}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.9772999991546385, 4.890200001682388], "tokens_processed": [11, 11], "throughput_tok_s": [2210.033552702927, 2249.396751915186], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.291699999361299, 4.5013999988441356, 4.570100001728861], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.17578125, "cpu_memory_peak_mb": 1169.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.3913853}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.14860000112094, 4.789999999047723], "tokens_processed": [11, 11], "throughput_tok_s": [2136.503126598514, 2296.450939913749], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.9589999980526045, 4.047099999297643, 5.048999999416992], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.17578125, "cpu_memory_peak_mb": 1169.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.5133808}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.876699997112155, 4.965199997968739], "tokens_processed": [11, 11], "throughput_tok_s": [2255.6236812832226, 2215.419319362784], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.209399998420849, 3.1180000005406328, 4.755699999805074], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.347, "gpu_power_peak_watts": 3.347, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.17578125, "cpu_memory_peak_mb": 1169.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.6407387}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.072699997981545, 5.843400002049748], "tokens_processed": [11, 11], "throughput_tok_s": [2168.4704406680785, 1882.4656871241777], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.958099998475518, 5.136100000527222, 5.11239999832469], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.347, "gpu_power_peak_watts": 3.347, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.17578125, "cpu_memory_peak_mb": 1169.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.765763}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.105200001911726, 5.637900001602247], "tokens_processed": [19, 19], "throughput_tok_s": [3112.1011586926743, 3370.049130811179], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.124999999883585, 5.7307000024593435, 5.938900001638103], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.347, "gpu_power_peak_watts": 3.347, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.71484375, "cpu_memory_peak_mb": 1170.71484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576453.8922887}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.953699997917283, 5.348099999537226], "tokens_processed": [19, 19], "throughput_tok_s": [3191.2928106297863, 3552.6635630680207], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.1344999994616956, 5.848699998750817, 5.887999999686144], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.347, "gpu_power_peak_watts": 3.347, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.71875, "cpu_memory_peak_mb": 1170.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.0126684}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.928699996729847, 5.268500000966014], "tokens_processed": [19, 19], "throughput_tok_s": [3204.749778278547, 3606.3395646799327], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.9571999991021585, 5.42430000132299, 5.887200000870507], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.383, "gpu_power_peak_watts": 3.383, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.71875, "cpu_memory_peak_mb": 1170.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.1395676}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.50519999928656, 6.296399998973357], "tokens_processed": [19, 19], "throughput_tok_s": [2531.578106087263, 3017.5973577120253], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.711100002372405, 5.936500001553213, 5.533999999897787], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.383, "gpu_power_peak_watts": 3.383, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.71875, "cpu_memory_peak_mb": 1170.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.2629883}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.9355000012146775, 5.738799998653121], "tokens_processed": [19, 19], "throughput_tok_s": [3201.078257284428, 3310.796683010253], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.2006999978621025, 5.689400000846945, 5.412999998952728], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.383, "gpu_power_peak_watts": 3.383, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.71875, "cpu_memory_peak_mb": 1170.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.3881052}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.694100000459002, 6.30029999956605], "tokens_processed": [27, 27], "throughput_tok_s": [4033.4025482363063, 4285.510214094519], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.2273000005225185, 9.706299999379553, 6.8525999995472375], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 3.383, "gpu_power_peak_watts": 3.383, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.3828125, "cpu_memory_peak_mb": 1172.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.5133266}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.942100000742357, 6.8771999976888765], "tokens_processed": [27, 27], "throughput_tok_s": [3889.3130316637244, 3926.0164033434403], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.469000000535743, 7.080200000928016, 6.536799999594223], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.411, "gpu_power_peak_watts": 3.411, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.3828125, "cpu_memory_peak_mb": 1172.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.6362414}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.188400002429262, 6.78909999987809], "tokens_processed": [27, 27], "throughput_tok_s": [4363.001743487998, 3976.963073232804], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.915599999047117, 6.763800000044284, 6.813900003180606], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.411, "gpu_power_peak_watts": 3.411, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.3828125, "cpu_memory_peak_mb": 1172.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.7626514}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.531399998493725, 8.394099997531157], "tokens_processed": [27, 27], "throughput_tok_s": [4133.876352118497, 3216.544955140056], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.136500000342494, 6.488099999842234, 6.601599998248275], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.411, "gpu_power_peak_watts": 3.411, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.3828125, "cpu_memory_peak_mb": 1172.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576454.887854}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.594700000277953, 6.597299998247763], "tokens_processed": [27, 27], "throughput_tok_s": [4094.1968548777054, 4092.583330630891], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.5593000001390465, 9.21100000050501, 6.45049999729963], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.411, "gpu_power_peak_watts": 3.411, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1172.3828125, "cpu_memory_peak_mb": 1172.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.0116422}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.46, "gpu_power_peak_watts": 3.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.9453125, "cpu_memory_peak_mb": 1169.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.1459837}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.46, "gpu_power_peak_watts": 3.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1169.94921875, "cpu_memory_peak_mb": 1169.94921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.27455}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.46, "gpu_power_peak_watts": 3.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.125, "cpu_memory_peak_mb": 1170.125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.4024382}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 3.46, "gpu_power_peak_watts": 3.46, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.17578125, "cpu_memory_peak_mb": 1170.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.5248864}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.395, "gpu_power_peak_watts": 3.395, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.265625, "cpu_memory_peak_mb": 1170.265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.6495028}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.395, "gpu_power_peak_watts": 3.395, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.2734375, "cpu_memory_peak_mb": 1170.2734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.774161}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.395, "gpu_power_peak_watts": 3.395, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.28125, "cpu_memory_peak_mb": 1170.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576455.900606}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.395, "gpu_power_peak_watts": 3.395, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.28125, "cpu_memory_peak_mb": 1170.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576456.0243864}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.259, "gpu_power_peak_watts": 3.259, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.28125, "cpu_memory_peak_mb": 1170.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576456.1480877}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 3.259, "gpu_power_peak_watts": 3.259, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 1170.28125, "cpu_memory_peak_mb": 1170.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.41829999932088, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765576456.2732067}
