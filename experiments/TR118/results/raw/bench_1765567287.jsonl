{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [3.483599999526632, 3.323499999169144], "tokens_processed": [1, 1], "throughput_tok_s": [287.05936391545663, 300.88761854971995], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [113.27750000054948, 3.675999998449697, 3.391399999600253], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.0632846}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [3.1355000010080403, 3.192599999238155], "tokens_processed": [1, 1], "throughput_tok_s": [318.928400471538, 313.224331340797], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4040000009554205, 3.291400000307476, 3.260999999838532], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.082799}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [3.2422000003862195, 3.068399999392568], "tokens_processed": [1, 1], "throughput_tok_s": [308.43254576549174, 325.90275068373217], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1970000000001164, 3.2961000015347963, 3.280000000813743], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.1027975}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.3117000000638654, 1.752999998643645], "tokens_processed": [1, 1], "throughput_tok_s": [432.58208243819394, 570.4506564596312], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2011000002967194, 3.193900000042049, 3.2351999998354586], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.1187985}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.977699999973993, 3.6172000000078697], "tokens_processed": [1, 1], "throughput_tok_s": [335.82966719573295, 276.45692801001445], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7084999999497086, 1.768800000718329, 1.5720000010333024], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.1337986}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.24389999898267, 4.405699999551871], "tokens_processed": [11, 11], "throughput_tok_s": [2591.9555132394435, 2496.7655539684665], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [25.93210000122781, 4.535000000032596, 4.346499999883235], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.1810472}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.3745999992097495, 3.607900000133668], "tokens_processed": [11, 11], "throughput_tok_s": [2514.515613310268, 3048.8649906018636], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.348099999333499, 4.133899999942514, 4.530999998678453], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.206523}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.9840999997977633, 3.995000000941218], "tokens_processed": [11, 11], "throughput_tok_s": [2760.974875268786, 2753.441801604108], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.416900001160684, 3.7802999995619757, 3.7924999996903352], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.23052}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.35039999865694, 4.597900000590016], "tokens_processed": [11, 11], "throughput_tok_s": [2528.503126929922, 2392.3965285431277], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9640999984840164, 4.238499999701162, 4.3578000004345085], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.256529}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.9388999994116602, 3.9931999999680556], "tokens_processed": [11, 11], "throughput_tok_s": [2792.657849055074, 2754.682961055794], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.352300000391551, 4.0913000011642, 3.970500001742039], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.2810464}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.809199999726843, 4.770800000187592], "tokens_processed": [19, 19], "throughput_tok_s": [3950.761041561835, 3982.5605766858607], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.805200000017066, 5.2247999992687255, 5.071700001280988], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.3270977}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.619000001184759, 4.801000000952627], "tokens_processed": [19, 19], "throughput_tok_s": [4113.4444674445895, 3957.508851537174], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6077999995759455, 4.434700000274461, 4.59950000004028], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.3540983}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.716199999165838, 4.669199999625562], "tokens_processed": [19, 19], "throughput_tok_s": [4028.6671479921465, 4069.2195668473555], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.631199999494129, 4.562500000247383, 4.589399999531452], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.380746}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.5714999996562256, 4.637299998648814], "tokens_processed": [19, 19], "throughput_tok_s": [4156.1850599209865, 4097.211740783666], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.479000001083477, 4.4487000013759825, 4.526099999566213], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.4077575}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.605699999956414, 4.471700000067358], "tokens_processed": [19, 19], "throughput_tok_s": [4125.322969403089, 4248.943354812219], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.400899999382091, 4.548999999315129, 4.5107999994797865], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.4337482}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.719499998827814, 4.575099999783561], "tokens_processed": [27, 27], "throughput_tok_s": [5720.945016782713, 5901.510349779746], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.173600000489387, 4.480300000068382, 5.029600000852952], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.4637206}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.007100000511855, 4.858899999817368], "tokens_processed": [27, 27], "throughput_tok_s": [5392.342872568933, 5556.813270702187], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.1717000005737646, 5.384500000218395, 5.549999999857391], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.4932828}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.188799999814364, 5.486199999722885], "tokens_processed": [27, 27], "throughput_tok_s": [5203.5152638309355, 4921.43924781521], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.736999999295222, 4.8581999999441905, 5.084000000351807], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.5242376}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.940499999065651, 5.278300001009484], "tokens_processed": [27, 27], "throughput_tok_s": [5465.033904484617, 5115.283328881686], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.483400000230176, 5.159700000149314, 4.936299999826588], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.5543132}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.346399999325513, 5.109599998831982], "tokens_processed": [27, 27], "throughput_tok_s": [5050.127189025558, 5284.170973495383], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.073899999842979, 5.154800001037074, 5.71489999856567], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.58546}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.690100000720122, 6.829199999629054], "tokens_processed": [44, 44], "throughput_tok_s": [7732.728773559602, 6442.921572422828], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.255399999849033, 6.118199999036733, 5.689300000085495], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.6275005}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.370199998855242, 5.79470000047877], "tokens_processed": [44, 44], "throughput_tok_s": [6907.161471838723, 7593.1454598796545], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.864400000064052, 5.771399999503046, 6.574000000910019], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.6624687}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.134400000519236, 6.730399998559733], "tokens_processed": [44, 44], "throughput_tok_s": [7172.665622762731, 6537.501487194781], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.696099999317084, 6.008800000927295, 5.754099998739548], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.6992116}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.26650000049267, 6.1671999992540805], "tokens_processed": [44, 44], "throughput_tok_s": [7021.463336238848, 7134.518096595177], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.853799999385956, 5.836199999976088, 6.871400000818539], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.7338672}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.824599998959457, 6.777799999326817], "tokens_processed": [44, 44], "throughput_tok_s": [7554.166811087532, 6491.7819948021715], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.752999999662279, 5.842399999892223, 5.024900001444621], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.7688727}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.997500000579748, 8.155400000759983], "tokens_processed": [76, 76], "throughput_tok_s": [10861.021792597834, 9318.978835240177], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.111299999858602, 7.847299999411916, 8.472100000290084], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.8144004}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.800199999110191, 8.421900000030291], "tokens_processed": [76, 76], "throughput_tok_s": [9743.339915472643, 9024.091950715], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.349100000486942, 7.781299998896429, 8.164599999872735], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.8604965}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.653700000650133, 7.178899999416899], "tokens_processed": [76, 76], "throughput_tok_s": [8782.370546042766, 10586.580117590864], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.363400000234833, 7.222499998533749, 8.42200000079174], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.90521}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.331400000315625, 8.109700000204612], "tokens_processed": [76, 76], "throughput_tok_s": [9122.116330643208, 9371.493396559981], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.534800001143594, 8.441800000582589, 7.88509999983944], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.9520924}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.959399999890593, 8.409400001255563], "tokens_processed": [76, 76], "throughput_tok_s": [9548.458426645811, 9037.505647091688], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.736200001090765, 8.505899999363464, 8.726199999728124], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1078.5482999999658, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765567291.9989228}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.26029999935417436, 0.25210000057995785], "tokens_processed": [1, 1], "throughput_tok_s": [3841.7211005804147, 3966.679879807588], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9789000002201647, 0.4074000007676659, 0.28279999969527125], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0058956}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.2640999991854187, 0.2516999993531499], "tokens_processed": [1, 1], "throughput_tok_s": [3786.44454026644, 3972.983720977056], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.2673999988473952, 0.26530000104685314, 0.27740000041376334], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0088882}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.24850000045262277, 0.2514000007067807], "tokens_processed": [1, 1], "throughput_tok_s": [4024.1448618856352, 3977.724730265], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.25859999914246146, 0.2747000016825041, 0.25120000100287143], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0108917}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.24950000079115853, 0.24369999846385326], "tokens_processed": [1, 1], "throughput_tok_s": [4008.0160193548054, 4103.40585270182], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.25119999918388203, 0.2507999997760635, 0.2535999992687721], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0138848}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.24419999863312114, 0.2455000012560049], "tokens_processed": [1, 1], "throughput_tok_s": [4095.0041179253667, 4073.3197347612645], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.2544999988458585, 0.24760000087553635, 0.25159999859170057], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0158966}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9950000003300374, 0.799600000391365], "tokens_processed": [11, 11], "throughput_tok_s": [11055.276378242557, 13756.878432486292], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2535999996762257, 0.826900000902242, 0.9027999985846691], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.02485}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7521000006818213, 0.8142000006046146], "tokens_processed": [11, 11], "throughput_tok_s": [14625.714652343939, 13510.194045482116], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8618000010756077, 0.7941000003484078, 0.8741000001464272], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0308504}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7912000000942498, 0.791899999967427], "tokens_processed": [11, 11], "throughput_tok_s": [13902.932253146677, 13890.64275849534], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9112999996432336, 0.9122000010393094, 0.7843000003049383], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.037854}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8116999997582752, 0.8627999995951541], "tokens_processed": [11, 11], "throughput_tok_s": [13551.804858045838, 12749.1886939748], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8665999994263984, 0.8185999995475868, 0.8484000009048032], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0448523}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9173999987979187, 0.9002000006148592], "tokens_processed": [11, 11], "throughput_tok_s": [11990.407689572101, 12219.50676792571], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7385999997495674, 0.8921999997255625, 0.8680999999342021], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0518508}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.646100001380546, 1.0898000000452157], "tokens_processed": [19, 19], "throughput_tok_s": [11542.433621326249, 17434.391630768667], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6933999995671911, 2.9560000002675224, 1.260099999853992], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.064856}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.140500000474276, 1.3825999994878657], "tokens_processed": [19, 19], "throughput_tok_s": [16659.359922927546, 13742.224798956939], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1461000012786826, 1.3824000016029458, 1.1133000007248484], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0743632}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.1879000012413599, 1.314700000875746], "tokens_processed": [19, 19], "throughput_tok_s": [15994.612324391725, 14451.966218410093], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1379000006854767, 1.1350000004313188, 1.4159000002109678], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0843637}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2585999993461883, 1.279199999771663], "tokens_processed": [19, 19], "throughput_tok_s": [15096.138574503442, 14853.033148367336], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3990000006742775, 1.227300001119147, 1.3058999993518228], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.0933633}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.6383000001951586, 1.7408999992767349], "tokens_processed": [19, 19], "throughput_tok_s": [11597.387534478832, 10913.89511625805], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.515300000392017, 1.2912999991385732, 1.2485000006563496], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.1053627}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.9192999989172677, 1.9072000013693469], "tokens_processed": [27, 27], "throughput_tok_s": [14067.628830944343, 14156.879184466403], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3546000013302546, 1.9986999996035593, 1.8718999999691732], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.1213627}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.9178999991709134, 1.8823999998858199], "tokens_processed": [27, 27], "throughput_tok_s": [14077.89770669576, 14343.391416084642], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.075499998682062, 1.9664999999804422, 2.016399999774876], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.1363633}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7507000011391938, 1.7595999997865874], "tokens_processed": [27, 27], "throughput_tok_s": [15422.40245754892, 15344.396455600527], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8760999992082361, 1.8263000001752516, 2.215600001363782], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.1503632}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.5765999998839106, 1.78559999949357], "tokens_processed": [27, 27], "throughput_tok_s": [10478.925716532054, 15120.967746224076], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8239999990328215, 1.7488000012235716, 1.7636000011407305], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.164369}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.6668000011559343, 1.6487999982928159], "tokens_processed": [27, 27], "throughput_tok_s": [7363.368602456755, 16375.545868483789], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8373000002611661, 1.8827999992936384, 1.8923000006907387], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.1798773}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.672500000699074, 4.420500001288019], "tokens_processed": [44, 44], "throughput_tok_s": [16463.98502843422, 9953.625152625165], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.8922999996866565, 3.4425000012561213, 3.1720999995741295], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.2048788}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.156600001602783, 3.0915000006643822], "tokens_processed": [44, 44], "throughput_tok_s": [13939.04833607639, 14232.573181479584], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2508000007946976, 3.231800001231022, 3.35339999946882], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.2288792}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2166000000870554, 2.7322999994794372], "tokens_processed": [44, 44], "throughput_tok_s": [13679.039979733, 16103.648943521195], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.397399999812478, 3.1424999997398118, 2.6719999987108167], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.2488775}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.023600000233273, 3.4861000003729714], "tokens_processed": [44, 44], "throughput_tok_s": [14552.18944192531, 12621.554170933858], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.814600000419887, 3.1827999991946854, 2.9722999988734955], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.2708852}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.211199998986558, 2.7837999987241346], "tokens_processed": [44, 44], "throughput_tok_s": [13702.042854349223, 15805.733177730435], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.525899999658577, 2.5865000006888295, 2.71950000023935], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.2913933}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.004099999496248, 5.705999999918276], "tokens_processed": [76, 76], "throughput_tok_s": [15187.546213634972, 13319.313004046355], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.108600000719889, 5.121800000779331, 4.931199999191449], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.3253922}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.043799999839393, 5.100099999253871], "tokens_processed": [76, 76], "throughput_tok_s": [15068.004282965228, 14901.668596913505], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.983600001651212, 5.071900000984897, 4.866999999649124], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.3573964}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.10269999904267, 5.121799998960341], "tokens_processed": [76, 76], "throughput_tok_s": [14894.075688215757, 14838.533331138859], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.146900000909227, 5.2044000003661495, 5.127500000526197], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.389911}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.6057000005675945, 5.255400001260568], "tokens_processed": [76, 76], "throughput_tok_s": [9992.505620038695, 14461.315976285445], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.193700000745594, 5.074499998954707, 4.794299999048235], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.4259102}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.7998000009101816, 4.8957999988488154], "tokens_processed": [76, 76], "throughput_tok_s": [15833.99308004254, 15523.509950951922], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.498300000908785, 5.543900000702706, 5.108800000016345], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 99.91970000010042, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.458921}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.683200000115903, 1.4941000008548144], "tokens_processed": [1, 1], "throughput_tok_s": [594.1064638374176, 669.2992433089307], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [61.968699999852106, 2.159100000426406, 1.7238999989785952], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.530433}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.6700000014679972, 1.4852999993308913], "tokens_processed": [1, 1], "throughput_tok_s": [598.8023946832094, 673.264660641276], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7869000002974644, 1.486299999669427, 1.6574000001128297], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.5404327}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.5583999993395992, 1.4367999992828118], "tokens_processed": [1, 1], "throughput_tok_s": [641.6837785060117, 695.9910916614398], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.717500001177541, 1.5085999984876253, 1.4697999995405553], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.5504339}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.789600000847713, 1.622900001166272], "tokens_processed": [1, 1], "throughput_tok_s": [558.784085564546, 616.1809102725772], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.740300000165007, 1.7205999993166188, 1.385100000334205], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.5604997}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.5062000002217246, 1.551600000311737], "tokens_processed": [1, 1], "throughput_tok_s": [663.9224537596548, 644.4960039952866], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.461999998355168, 1.5440999995917082, 1.4042000002518762], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.5704994}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2256999984383583, 3.607200000260491], "tokens_processed": [11, 11], "throughput_tok_s": [3410.112535364533, 3049.4566420507995], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.855800001285388, 4.000599999926635, 3.5480999995343154], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.6000226}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.1534000008832663, 3.509199999825796], "tokens_processed": [11, 11], "throughput_tok_s": [3488.298343666805, 3134.6175768112566], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.719799999089446, 3.9354000000457745, 3.6598000006051734], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.6220214}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.137399999104673, 3.454399999100133], "tokens_processed": [11, 11], "throughput_tok_s": [3506.0878444377813, 3184.3446048128435], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5594000000855885, 3.839999999399879, 3.7558000003627967], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.644024}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.364599999258644, 3.292499999588472], "tokens_processed": [11, 11], "throughput_tok_s": [3269.333651079992, 3340.9263481776416], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5807999993267003, 3.6837000006926246, 3.947699999116594], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.666036}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.095299998676637, 3.424700000323355], "tokens_processed": [11, 11], "throughput_tok_s": [3553.775079863966, 3211.960171390602], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3108999996329658, 3.5570000000006985, 3.336699999636039], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.68654}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.583699999784585, 4.4834999989689095], "tokens_processed": [19, 19], "throughput_tok_s": [4145.122935814499, 4237.760679016285], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2949999990232754, 4.528800000116462, 4.383299999972223], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.7135386}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.7166999993351055, 4.825600000913255], "tokens_processed": [19, 19], "throughput_tok_s": [4028.2400836767983, 3937.3342167614824], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.492600000958191, 4.617800001142314, 4.500799999732408], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.741555}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.691799998909119, 4.960100000971579], "tokens_processed": [19, 19], "throughput_tok_s": [4049.6184842528783, 3830.567931347816], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.650000000765431, 4.656699999031844, 4.68170000021928], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.7695851}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.640099999960512, 4.757900000186055], "tokens_processed": [19, 19], "throughput_tok_s": [4094.7393375491247, 3993.358414270375], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.627700000128243, 4.665499998736777, 4.758699999001692], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.7970977}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.008899999666028, 4.694400000516907], "tokens_processed": [19, 19], "throughput_tok_s": [3793.2480187799397, 4047.3755960096887], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.5952000000397675, 4.575099999783561, 4.7446000007767], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.8251486}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.268600000112201, 5.673400000887341], "tokens_processed": [27, 27], "throughput_tok_s": [4307.1818268061015, 4759.051009232047], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.114300001077936, 5.713900000046124, 6.462699999246979], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.8651495}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.525399999896763, 5.629399998724693], "tokens_processed": [27, 27], "throughput_tok_s": [4886.524052648581, 4796.2482691080195], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.864300001121592, 5.821400000058929, 5.715400000553927], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.8994377}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.714300001272932, 5.8298999992985046], "tokens_processed": [27, 27], "throughput_tok_s": [4724.988186476981, 4631.2972783836485], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.83330000154092, 5.748200001107762, 5.798399999548565], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.933437}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.934699998761062, 5.897400000321795], "tokens_processed": [27, 27], "throughput_tok_s": [4549.513876967087, 4578.288737159889], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.893000001378823, 5.481999998664833, 5.642000000079861], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567292.9674432}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.8625000001484295, 6.038400000761612], "tokens_processed": [27, 27], "throughput_tok_s": [4605.543709904717, 4471.383147289769], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.097899999076617, 5.885500000658794, 6.017700001393678], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.003956}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.186400000340655, 8.338599998751306], "tokens_processed": [44, 44], "throughput_tok_s": [5374.767907525782, 5276.665148416873], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.22180000008666, 8.433599999989383, 8.521099998688442], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.0580406}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.396999999604304, 8.779800000411342], "tokens_processed": [44, 44], "throughput_tok_s": [5239.966655004577, 5011.503678664498], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.612599998741644, 8.718499999304186, 8.642900000268128], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.1086397}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.295200001157355, 8.357999999134336], "tokens_processed": [44, 44], "throughput_tok_s": [5304.2723495348, 5264.417325264085], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.442199999990407, 8.443599999736762, 8.20930000008957], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.1586652}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.031600000322214, 6.758999999874504], "tokens_processed": [44, 44], "throughput_tok_s": [5478.360475899546, 6509.838733661334], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.34009999925911, 8.428500001173234, 8.131399999911082], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.2061737}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.321299999806797, 7.965199998579919], "tokens_processed": [44, 44], "throughput_tok_s": [5287.635345561581, 5524.029529433607], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.832000000940752, 8.8623000010557, 8.733800001209602], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.2541738}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.197699999072938, 8.67619999917224], "tokens_processed": [76, 76], "throughput_tok_s": [9270.893056417615, 8759.59521533054], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.64560000122583, 10.826100000485894, 8.998899998914567], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.309712}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [13.250899999547983, 14.206800000465591], "tokens_processed": [76, 76], "throughput_tok_s": [5735.45947841977, 5349.550919102774], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.991400000217254, 12.930799999594456, 13.27330000094662], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.383713}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [13.284500000736443, 12.949699999808217], "tokens_processed": [76, 76], "throughput_tok_s": [5720.952990009924, 5868.861827001826], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.904999999591382, 13.006099999984144, 13.868899999579298], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.4618235}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [12.749600000461214, 12.923500000397325], "tokens_processed": [76, 76], "throughput_tok_s": [5960.971324374938, 5880.75985589534], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.41580000007525, 12.430000000676955, 12.631800000235671], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.5375872}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.408999998820946, 10.367299999415991], "tokens_processed": [76, 76], "throughput_tok_s": [6661.4076613072275, 7330.741852196928], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.182499998947605, 12.769799999659881, 13.37269999930868], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1868.5953999993217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765567293.609744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.609744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.609744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.609744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.610744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.6117444}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.612746}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.613744}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6147444}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.615745}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6167455}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6177447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.618749}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.619744}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6207438}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"precision": "fp32", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "fp16", "success": false, "error": "No module named 'tensorrt'"}, {"precision": "int8", "success": false, "error": "No module named 'tensorrt'"}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765567293.6207438}
