{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.407100001117215, 4.054100001667393], "tokens_processed": [8, 8], "throughput_tok_s": [1815.2526600195079, 1973.310968330755], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [115.91789999874891, 4.533100000116974, 5.505799999809824], "resource_metrics": {"samples": 2, "duration_s": 0.11709189414978027, "gpu_memory_mean_mb": 542.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.444, "gpu_power_peak_watts": 30.444, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 714.423828125, "cpu_memory_peak_mb": 762.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.1392581}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.1449999989708886, 4.750600000988925], "tokens_processed": [8, 8], "throughput_tok_s": [1930.0361886577134, 1683.9978104522909], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.147100000409409, 4.14459999956307, 3.99719999768422], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.088, "gpu_power_peak_watts": 31.088, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 762.953125, "cpu_memory_peak_mb": 762.953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.2714908}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.9746000002196524, 4.596300001139753], "tokens_processed": [8, 8], "throughput_tok_s": [2012.7811602571046, 1740.5304262159184], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.486000001634238, 4.261800000676885, 4.099800000403775], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.088, "gpu_power_peak_watts": 31.088, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 763.0, "cpu_memory_peak_mb": 763.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.3951902}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.549500001303386, 3.881000000546919], "tokens_processed": [8, 8], "throughput_tok_s": [1758.434992352584, 2061.3244006371096], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.43979999909061, 4.223700001602992, 3.8800000002083834], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.088, "gpu_power_peak_watts": 31.088, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 763.01171875, "cpu_memory_peak_mb": 763.01171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.5262246}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.7116999992576893, 5.426099996839184], "tokens_processed": [8, 8], "throughput_tok_s": [2155.3466071072385, 1474.3554310941865], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.183499997656327, 3.9372999999613967, 3.5088000004179776], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.088, "gpu_power_peak_watts": 31.088, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 763.10546875, "cpu_memory_peak_mb": 763.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.6599498}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.27539999873261, 4.273300000932068], "tokens_processed": [11, 11], "throughput_tok_s": [2572.8586806522935, 2574.1230425200065], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.967799999169074, 2.7405999971961137, 4.690000001573935], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.52, "gpu_power_peak_watts": 31.52, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 765.34765625, "cpu_memory_peak_mb": 765.34765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.7831404}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.636900001059985, 4.36959999933606], "tokens_processed": [11, 11], "throughput_tok_s": [2372.274579457272, 2517.39289675746], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.124200000660494, 4.336699999839766, 4.592699999193428], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.52, "gpu_power_peak_watts": 31.52, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 765.3828125, "cpu_memory_peak_mb": 765.3828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577899.904098}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.51950000206125, 4.179999999905704], "tokens_processed": [11, 11], "throughput_tok_s": [2433.897553929224, 2631.5789474277867], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.491100000450388, 4.129299999476643, 3.619500002969289], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.52, "gpu_power_peak_watts": 31.52, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 765.390625, "cpu_memory_peak_mb": 765.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.0318542}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.225500000757165, 4.4863000002806075], "tokens_processed": [11, 11], "throughput_tok_s": [2603.242219389165, 2451.909145467752], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.267199998139404, 3.937100002076477, 4.415999999764608], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.52, "gpu_power_peak_watts": 31.52, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 765.390625, "cpu_memory_peak_mb": 765.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.1546214}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.315000001952285, 4.4626999988395255], "tokens_processed": [11, 11], "throughput_tok_s": [2549.246812288098, 2464.875524427012], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.987600001186365, 4.189100000075996, 4.846199997700751], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.114, "gpu_power_peak_watts": 31.114, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 765.46875, "cpu_memory_peak_mb": 765.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.2790108}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.324900000938214, 3.4407000021019485], "tokens_processed": [19, 19], "throughput_tok_s": [4393.165158935067, 5522.132120903526], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.187499999417923, 6.224500000826083, 4.20509999821661], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.114, "gpu_power_peak_watts": 31.114, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 769.5703125, "cpu_memory_peak_mb": 769.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.402609}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.821800001082011, 4.697100001067156], "tokens_processed": [19, 19], "throughput_tok_s": [3940.4371802514424, 4045.0490719131594], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2896999986842275, 5.406500000390224, 4.837200001929887], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.114, "gpu_power_peak_watts": 31.114, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 769.5859375, "cpu_memory_peak_mb": 769.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.5272102}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.440599998109974, 4.469399998924928], "tokens_processed": [19, 19], "throughput_tok_s": [3492.2618840937516, 4251.129906602737], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4522999994806014, 2.424600002996158, 3.3412999982829206], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.114, "gpu_power_peak_watts": 31.114, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 769.5859375, "cpu_memory_peak_mb": 769.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.6510212}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.69610000072862, 5.003199999919161], "tokens_processed": [19, 19], "throughput_tok_s": [4045.9104356917587, 3797.5695555458487], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.930099999910453, 5.25259999994887, 4.416499999933876], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.578, "gpu_power_peak_watts": 31.578, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 769.58984375, "cpu_memory_peak_mb": 769.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.7760832}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.7761999994691, 5.217100002482766], "tokens_processed": [19, 19], "throughput_tok_s": [3978.057870715622, 3641.8700026754495], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.612599998130463, 4.387099997984478, 6.192799999553245], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.578, "gpu_power_peak_watts": 31.578, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 769.59375, "cpu_memory_peak_mb": 769.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577900.9023407}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.330899999535177, 5.323699999280507], "tokens_processed": [27, 27], "throughput_tok_s": [5064.810820378218, 5071.660687801534], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.596899998636218, 5.377299999963725, 5.052199998317519], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.578, "gpu_power_peak_watts": 31.578, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.3203125, "cpu_memory_peak_mb": 767.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.026412}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.779799997777445, 5.08339999942109], "tokens_processed": [27, 27], "throughput_tok_s": [5648.77191776951, 5311.405752660587], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.445200000394834, 4.660099999455269, 4.76870000056806], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.578, "gpu_power_peak_watts": 31.578, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.3203125, "cpu_memory_peak_mb": 767.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.1497252}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.970800000592135, 4.766500002006069], "tokens_processed": [27, 27], "throughput_tok_s": [5431.721251465295, 5664.533722571396], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.114200001116842, 5.9844999996130355, 4.913400000077672], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.11, "gpu_power_peak_watts": 31.11, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.3203125, "cpu_memory_peak_mb": 767.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.275552}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.49060000028112, 4.8916999985522125], "tokens_processed": [27, 27], "throughput_tok_s": [6012.559568500813, 5519.553531081452], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.344799999875249, 5.251100003079046, 5.365500001062173], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.11, "gpu_power_peak_watts": 31.11, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.328125, "cpu_memory_peak_mb": 767.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.3991675}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.934600001433864, 4.5449000026565045], "tokens_processed": [27, 27], "throughput_tok_s": [5471.568109300554, 5940.72476494938], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.000600002153078, 5.923000000620959, 4.835399999137735], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.11, "gpu_power_peak_watts": 31.11, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 763.02734375, "cpu_memory_peak_mb": 763.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.5226822}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.190100001025712, 6.945299999642884], "tokens_processed": [44, 44], "throughput_tok_s": [6119.525457743721, 6335.219501283228], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.655000000842847, 6.5484000006108545, 5.945500000962056], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.11, "gpu_power_peak_watts": 31.11, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 768.140625, "cpu_memory_peak_mb": 768.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.648414}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.008699998346856, 6.719500001054257], "tokens_processed": [44, 44], "throughput_tok_s": [7322.715398023783, 6548.106256878728], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.1630999989574775, 7.394699998258147, 5.903799999941839], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.115, "gpu_power_peak_watts": 31.115, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 759.046875, "cpu_memory_peak_mb": 759.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.770809}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.869200002052821, 7.549800000560936], "tokens_processed": [44, 44], "throughput_tok_s": [7496.762758912711, 5827.968952386936], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.282700000156183, 6.44329999704496, 6.995299998379778], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.115, "gpu_power_peak_watts": 31.115, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.484375, "cpu_memory_peak_mb": 767.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577901.8963974}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.9112000019231346, 5.845400002726819], "tokens_processed": [44, 44], "throughput_tok_s": [6366.477599802698, 7527.286409736622], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.736599996656878, 6.503799999336479, 6.055100002413383], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.115, "gpu_power_peak_watts": 31.115, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 761.05078125, "cpu_memory_peak_mb": 761.05078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.0218995}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.867699997907039, 7.1017000009305775], "tokens_processed": [44, 44], "throughput_tok_s": [7498.679212586609, 6195.699620405596], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.9612000004563015, 6.886400002258597, 6.514999997307314], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 556.01953125, "gpu_memory_peak_mb": 556.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.115, "gpu_power_peak_watts": 31.115, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 767.484375, "cpu_memory_peak_mb": 767.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.1444592}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.028300002479227, 8.681300001626369], "tokens_processed": [76, 76], "throughput_tok_s": [9466.512210122986, 8754.449216794954], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.53049999952782, 9.336499999335501, 7.6196999980311375], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.154, "gpu_power_peak_watts": 31.154, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 759.0546875, "cpu_memory_peak_mb": 759.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.2716537}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.080200001131743, 7.6343000000633765], "tokens_processed": [76, 76], "throughput_tok_s": [9405.70777819301, 9955.071191775158], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.6909999988856725, 8.935899997595698, 6.982800001424039], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.154, "gpu_power_peak_watts": 31.154, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 773.6796875, "cpu_memory_peak_mb": 773.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.394086}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.484400000976166, 8.215500001824694], "tokens_processed": [76, 76], "throughput_tok_s": [10154.454597574631, 9250.80640047716], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.952799998951377, 9.00010000259499, 9.502500000962755], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.154, "gpu_power_peak_watts": 31.154, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 773.6796875, "cpu_memory_peak_mb": 773.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.5173354}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [8.535499997378793, 7.429099998262245], "tokens_processed": [76, 76], "throughput_tok_s": [8903.9892242211, 10230.041326375645], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.066400001756847, 7.690800001000753, 8.087899997917702], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.154, "gpu_power_peak_watts": 31.154, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 773.68359375, "cpu_memory_peak_mb": 773.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.639637}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.7701999980490655, 7.384600001387298], "tokens_processed": [76, 76], "throughput_tok_s": [9780.958021554401, 10291.688105750123], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.907499999622814, 9.504999998171115, 8.531499999662628], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.243, "gpu_power_peak_watts": 31.243, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 759.05859375, "cpu_memory_peak_mb": 759.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1014.8322000022745, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577902.767354}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.0636000006343238, 1.2927000025229063], "tokens_processed": [8, 8], "throughput_tok_s": [7521.624666443075, 6188.597497011487], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0893000000796746, 1.359400001092581, 1.5399000003526453], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.243, "gpu_power_peak_watts": 31.243, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.0234375, "cpu_memory_peak_mb": 776.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577902.889477}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.2825999983760994, 0.6103000014263671], "tokens_processed": [8, 8], "throughput_tok_s": [6237.330430476224, 13108.307359172115], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0067999974125996, 0.818799999251496, 0.9979999995266553], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.243, "gpu_power_peak_watts": 31.243, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.09765625, "cpu_memory_peak_mb": 776.09765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.0147116}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.8032000005187001, 0.6632999975408893], "tokens_processed": [8, 8], "throughput_tok_s": [9960.15935611761, 12060.90762801011], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2811000015062746, 0.6743999983882532, 1.0232999993604608], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.243, "gpu_power_peak_watts": 31.243, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.1875, "cpu_memory_peak_mb": 776.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.1394935}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.747000001865672, 0.8643000001029577], "tokens_processed": [8, 8], "throughput_tok_s": [10709.504658660746, 9256.045353519632], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3198999986343551, 0.6904000001668464, 0.8502999990014359], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.703, "gpu_power_peak_watts": 30.703, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.1953125, "cpu_memory_peak_mb": 776.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.2624636}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6730999994033482, 0.5404999974416569], "tokens_processed": [8, 8], "throughput_tok_s": [11885.30680001692, 14801.110153314186], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8940000006987248, 0.7034000009298325, 0.7331000015255995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.703, "gpu_power_peak_watts": 30.703, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.3046875, "cpu_memory_peak_mb": 776.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.3905833}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9100999996007886, 0.7649999970453791], "tokens_processed": [11, 11], "throughput_tok_s": [12086.583897181741, 14379.085022855876], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5225000024656765, 1.08620000173687, 0.9691999985079747], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.703, "gpu_power_peak_watts": 30.703, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.8671875, "cpu_memory_peak_mb": 776.8671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.5140047}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.4210000008461066, 0.8520999981556088], "tokens_processed": [11, 11], "throughput_tok_s": [7741.0274408517, 12909.282975953254], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5729000006103888, 0.9911000015563332, 0.9429999990970828], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.703, "gpu_power_peak_watts": 30.703, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.875, "cpu_memory_peak_mb": 776.875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.639323}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1819000028481241, 0.9180000015476253], "tokens_processed": [11, 11], "throughput_tok_s": [9307.047951173849, 11982.570785899205], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2916000014229212, 0.7400000031339005, 0.7240000013553072], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.669, "gpu_power_peak_watts": 30.669, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.8828125, "cpu_memory_peak_mb": 776.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.7627056}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9984999996959232, 1.0218999996141065], "tokens_processed": [11, 11], "throughput_tok_s": [11016.524790535674, 10764.26265207345], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2665000031120144, 0.9290999987570103, 1.066499997250503], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.669, "gpu_power_peak_watts": 30.669, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.8828125, "cpu_memory_peak_mb": 776.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577903.904985}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.1990000020887237, 0.8770999993430451], "tokens_processed": [11, 11], "throughput_tok_s": [9174.31191062335, 12541.329390307934], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2217000003147405, 1.1350000022503082, 1.0889999975915998], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.669, "gpu_power_peak_watts": 30.669, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 776.89453125, "cpu_memory_peak_mb": 776.89453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.0298736}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.141299999289913, 1.2821999989682809], "tokens_processed": [19, 19], "throughput_tok_s": [16647.682477719532, 14818.281091318284], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4599999999045394, 1.9721999997273088, 1.6839999989315402], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.669, "gpu_power_peak_watts": 30.669, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 778.50390625, "cpu_memory_peak_mb": 778.50390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.1532202}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.299800002016127, 1.4831000007689], "tokens_processed": [19, 19], "throughput_tok_s": [14617.633459400671, 12811.003971512117], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8265000035171397, 1.579600000695791, 1.094100000045728], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.977, "gpu_power_peak_watts": 34.977, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 778.5234375, "cpu_memory_peak_mb": 778.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.2764354}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3253000033728313, 1.104700000723824], "tokens_processed": [19, 19], "throughput_tok_s": [14336.376632947877, 17199.239601295176], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4841999982309062, 1.7879000006360002, 1.2174000003142282], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.977, "gpu_power_peak_watts": 34.977, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 778.5234375, "cpu_memory_peak_mb": 778.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.399812}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.522799997474067, 1.1554000011528842], "tokens_processed": [19, 19], "throughput_tok_s": [12477.01604381147, 16444.521361469077], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.576099999510916, 2.270400000270456, 1.4850999978079926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.977, "gpu_power_peak_watts": 34.977, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 778.5234375, "cpu_memory_peak_mb": 778.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.542454}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5220999994198792, 1.2018000015814323], "tokens_processed": [19, 19], "throughput_tok_s": [12482.754094502008, 15809.618884172207], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.13889999940875, 1.2279000002308749, 1.2951999997312669], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.977, "gpu_power_peak_watts": 34.977, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 778.52734375, "cpu_memory_peak_mb": 778.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.6640599}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.55570000060834, 1.6901999988476746], "tokens_processed": [27, 27], "throughput_tok_s": [17355.531265309466, 15974.440905459564], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.83320000016829, 1.5501999987463932, 1.5206999996735249], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.043, "gpu_power_peak_watts": 31.043, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 784.01953125, "cpu_memory_peak_mb": 784.01953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.789662}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6152000025613233, 1.8128000010619871], "tokens_processed": [27, 27], "throughput_tok_s": [16716.19611019342, 14894.086487302886], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.500400001736125, 2.057599998806836, 2.1613000026263762], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.043, "gpu_power_peak_watts": 31.043, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 784.0234375, "cpu_memory_peak_mb": 784.0234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577904.912766}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.808000000892207, 1.6768999994383194], "tokens_processed": [27, 27], "throughput_tok_s": [14933.628311214663, 16101.139011893194], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.282000001287088, 1.52679999882821, 1.6138999999384396], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.043, "gpu_power_peak_watts": 31.043, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 784.0390625, "cpu_memory_peak_mb": 784.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.0392036}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7194000029121526, 1.6462999992654659], "tokens_processed": [27, 27], "throughput_tok_s": [15703.15223582065, 16400.41305475713], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.7348000005295034, 2.0321000010881107, 1.6378000000258908], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 31.043, "gpu_power_peak_watts": 31.043, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 784.0390625, "cpu_memory_peak_mb": 784.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.161992}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4803999983996619, 2.4580999997851904], "tokens_processed": [27, 27], "throughput_tok_s": [18238.313988913447, 10984.093406435657], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.500599999621045, 1.8291999986104202, 1.6431000003649388], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 784.0390625, "cpu_memory_peak_mb": 784.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.2885973}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.5653000013553537, 2.0307000013417564], "tokens_processed": [44, 44], "throughput_tok_s": [12341.17745583074, 21667.405313895513], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.2104999995208345, 2.4284999999508727, 2.645299999130657], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 793.19140625, "cpu_memory_peak_mb": 793.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.4118807}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7855999978783075, 2.8746999996656086], "tokens_processed": [44, 44], "throughput_tok_s": [15795.519828228475, 15305.944969951013], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6717000000644475, 2.393099999608239, 2.3715000024822075], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 793.328125, "cpu_memory_peak_mb": 793.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.5379376}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.107399999862537, 2.586000002338551], "tokens_processed": [44, 44], "throughput_tok_s": [14159.747699667389, 17014.69449350745], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8081999989808537, 4.6249000006355345, 3.5678999993251637], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.577, "gpu_power_peak_watts": 30.577, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 793.328125, "cpu_memory_peak_mb": 793.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.6602304}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.3637999984202906, 2.8750000019499566], "tokens_processed": [44, 44], "throughput_tok_s": [18614.095959643313, 15304.347815706848], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.89469999956782, 2.580700001999503, 2.326000001630746], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.616, "gpu_power_peak_watts": 30.616, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 793.3359375, "cpu_memory_peak_mb": 793.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.7852318}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.3445000006176997, 2.518099998269463], "tokens_processed": [44, 44], "throughput_tok_s": [18767.32778349645, 17473.491930518456], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.414399998495355, 2.3906000023998786, 2.444199999445118], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.616, "gpu_power_peak_watts": 30.616, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 793.3359375, "cpu_memory_peak_mb": 793.3359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577905.911642}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.612199998518918, 5.1338999983272515], "tokens_processed": [76, 76], "throughput_tok_s": [16478.036517151322, 14803.560650726082], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.2110999970173, 4.184400000667665, 5.638899998302804], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.616, "gpu_power_peak_watts": 30.616, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 799.4765625, "cpu_memory_peak_mb": 799.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.037412}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.600499996740837, 4.348700000264216], "tokens_processed": [76, 76], "throughput_tok_s": [16519.943496107204, 17476.487225005734], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.877499999362044, 4.452500001207227, 4.145600003539585], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.616, "gpu_power_peak_watts": 30.616, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 799.4765625, "cpu_memory_peak_mb": 799.4765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.1614604}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.262999998900341, 4.524199997831602], "tokens_processed": [76, 76], "throughput_tok_s": [17827.82078808457, 16798.550027944377], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.720900000393158, 5.941700001130812, 3.650400001788512], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 799.48046875, "cpu_memory_peak_mb": 799.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.2874422}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.085299999132985, 4.399500001454726], "tokens_processed": [76, 76], "throughput_tok_s": [18603.284952421935, 17274.69030000456], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.800800001452444, 5.400800000643358, 6.0574000017368235], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 799.48046875, "cpu_memory_peak_mb": 799.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.4140043}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.6285999997053295, 3.7539000004471745], "tokens_processed": [76, 76], "throughput_tok_s": [16419.6517315902, 20245.61122857473], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.031699998653494, 4.539500001556007, 5.1248999989184085], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 572.01953125, "gpu_memory_peak_mb": 572.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 799.48046875, "cpu_memory_peak_mb": 799.48046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 108.39809999743011, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.540166}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.3246000018843915, 2.798000001348555], "tokens_processed": [8, 8], "throughput_tok_s": [3441.4522900778443, 2859.1851308592677], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [36.20949999822187, 2.873000001272885, 2.21610000153305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.606, "gpu_power_peak_watts": 30.606, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 813.19921875, "cpu_memory_peak_mb": 813.19921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.6589417}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.6051999993796926, 2.835100000083912], "tokens_processed": [8, 8], "throughput_tok_s": [3070.78151462645, 2821.7699551208843], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.311799999210052, 2.7716000004147645, 2.6617000003170688], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.713, "gpu_power_peak_watts": 30.713, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 845.6171875, "cpu_memory_peak_mb": 845.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.7815394}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.5581999980204273, 2.6670000006561168], "tokens_processed": [8, 8], "throughput_tok_s": [3127.198814084324, 2999.6250461311947], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6776000013342127, 2.855399998225039, 2.33719999960158], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.713, "gpu_power_peak_watts": 30.713, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 845.6171875, "cpu_memory_peak_mb": 845.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577906.906251}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.1780000024591573, 2.14129999949364], "tokens_processed": [8, 8], "throughput_tok_s": [3673.094578038238, 3736.0481959051913], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8266999979678076, 2.3653999996895436, 3.2274000004690606], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.713, "gpu_power_peak_watts": 30.713, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 845.6171875, "cpu_memory_peak_mb": 845.6171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.0340517}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.3211000006995164, 2.505599997675745], "tokens_processed": [8, 8], "throughput_tok_s": [3446.6416774757736, 3192.8480233959904], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9325000032258686, 2.231700000265846, 2.7464000013424084], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.713, "gpu_power_peak_watts": 30.713, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 845.6796875, "cpu_memory_peak_mb": 845.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.1687121}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8281000013521407, 3.0329000001074746], "tokens_processed": [11, 11], "throughput_tok_s": [3889.537143220112, 3626.8917536384984], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9474000004702248, 3.7677000000257976, 3.1546000027447008], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.559, "gpu_power_peak_watts": 31.559, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 848.0546875, "cpu_memory_peak_mb": 848.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.2928805}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.807699998811586, 3.1495000002905726], "tokens_processed": [11, 11], "throughput_tok_s": [3917.797487144626, 3492.617875531081], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5563000019465107, 3.324699999211589, 3.199400001903996], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.559, "gpu_power_peak_watts": 31.559, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 848.05859375, "cpu_memory_peak_mb": 848.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.4322717}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.1297999994421843, 3.690400000778027], "tokens_processed": [11, 11], "throughput_tok_s": [3514.601572611828, 2980.706697832465], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5868999984813854, 4.181000000244239, 2.589899999293266], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.559, "gpu_power_peak_watts": 31.559, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 848.05859375, "cpu_memory_peak_mb": 848.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.5549343}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.6622000006900635, 3.5303000004205387], "tokens_processed": [11, 11], "throughput_tok_s": [3003.6590022192354, 3115.882502532264], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4255999999004416, 3.5628000005090144, 3.754100001970073], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.559, "gpu_power_peak_watts": 31.559, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 848.05859375, "cpu_memory_peak_mb": 848.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.6918743}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.7728999996033963, 2.674000003025867], "tokens_processed": [11, 11], "throughput_tok_s": [2915.5291688505686, 4113.687355105658], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.147200001170859, 3.5490000009303913, 3.2069999979285058], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 32.015, "gpu_power_peak_watts": 32.015, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 848.11328125, "cpu_memory_peak_mb": 848.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.8187742}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.214900000079069, 4.607400001987116], "tokens_processed": [19, 19], "throughput_tok_s": [4507.817504482567, 4123.800840344995], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.972499998984858, 4.770499999722233, 4.550300000119023], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 32.015, "gpu_power_peak_watts": 32.015, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 849.6328125, "cpu_memory_peak_mb": 849.6328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577907.9431798}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.96050000199466, 4.207199999655131], "tokens_processed": [19, 19], "throughput_tok_s": [4797.374066514549, 4516.067693848035], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.590700002154335, 4.815000000235159, 4.184900000836933], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 32.015, "gpu_power_peak_watts": 32.015, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 849.63671875, "cpu_memory_peak_mb": 849.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.0674508}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.222699997626478, 4.513400002906565], "tokens_processed": [19, 19], "throughput_tok_s": [4499.4908496174585, 4209.686707972764], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.621300002327189, 4.851300000154879, 4.806900000403402], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 32.015, "gpu_power_peak_watts": 32.015, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 849.63671875, "cpu_memory_peak_mb": 849.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.191884}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.098600002180319, 4.371600000013132], "tokens_processed": [19, 19], "throughput_tok_s": [4635.729270944378, 4346.234788165186], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.373800002213102, 4.150200002186466, 4.1812999988906085], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.247, "gpu_power_peak_watts": 31.247, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 849.63671875, "cpu_memory_peak_mb": 849.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.3186953}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.01889999920968, 3.791600000113249], "tokens_processed": [19, 19], "throughput_tok_s": [4727.6617989341285, 5011.0771176897615], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.893900000752183, 4.823799998121103, 4.7268999987863936], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 590.01953125, "gpu_memory_peak_mb": 590.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.247, "gpu_power_peak_watts": 31.247, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 849.63671875, "cpu_memory_peak_mb": 849.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.4471796}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.621600001177285, 5.430400000477675], "tokens_processed": [27, 27], "throughput_tok_s": [4802.903087082968, 4972.0094279657105], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.412099999579368, 6.471400000009453, 5.461699998704717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.247, "gpu_power_peak_watts": 31.247, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 855.36328125, "cpu_memory_peak_mb": 855.36328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.5690038}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.078099999082042, 5.469199997605756], "tokens_processed": [27, 27], "throughput_tok_s": [5316.949253634379, 4936.736636403816], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.308300002274336, 5.5444000026909634, 5.872300000191899], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.247, "gpu_power_peak_watts": 31.247, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 855.3671875, "cpu_memory_peak_mb": 855.3671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.6921349}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.591900000581518, 5.37619999886374], "tokens_processed": [27, 27], "throughput_tok_s": [4828.41252475763, 5022.134594268527], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.8213000011164695, 5.421100002422463, 6.181699998705881], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 20.361, "gpu_power_peak_watts": 20.361, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 855.37109375, "cpu_memory_peak_mb": 855.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.818358}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.789300001197262, 5.579199998464901], "tokens_processed": [27, 27], "throughput_tok_s": [4663.776275960175, 4839.403500041039], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.800000002636807, 6.409900001017377, 5.708499997126637], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 20.361, "gpu_power_peak_watts": 20.361, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 855.37109375, "cpu_memory_peak_mb": 855.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577908.944253}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.5793999999878, 5.216099998506252], "tokens_processed": [27, 27], "throughput_tok_s": [4839.230024744425, 5176.281131061916], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.987199998140568, 5.5334999997285195, 5.343600001651794], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 598.01953125, "gpu_memory_peak_mb": 598.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 20.361, "gpu_power_peak_watts": 20.361, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 855.37109375, "cpu_memory_peak_mb": 855.37109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.0690002}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.6176000002305955, 8.49969999762834], "tokens_processed": [44, 44], "throughput_tok_s": [5776.097458342268, 5176.653295090093], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.343399997305823, 7.760500000586035, 7.78560000253492], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 20.361, "gpu_power_peak_watts": 20.361, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 865.14453125, "cpu_memory_peak_mb": 865.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.1929677}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.56019999991986, 8.444799997960217], "tokens_processed": [44, 44], "throughput_tok_s": [5140.0668209167925, 5210.306935703379], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.365400000911904, 7.64559999879566, 8.146000000124332], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 16.575, "gpu_power_peak_watts": 16.575, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 865.14453125, "cpu_memory_peak_mb": 865.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.3162704}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.723399998212699, 8.05459999901359], "tokens_processed": [44, 44], "throughput_tok_s": [5696.972837116064, 5462.716957439038], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.74460000320687, 8.401899998716544, 8.217099999455968], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 16.575, "gpu_power_peak_watts": 16.575, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 865.15234375, "cpu_memory_peak_mb": 865.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.442821}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.499999999708962, 7.68189999871538], "tokens_processed": [44, 44], "throughput_tok_s": [5866.6666668943235, 5727.749646227884], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.870600002206629, 7.434400002239272, 7.911000000603963], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 16.575, "gpu_power_peak_watts": 16.575, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 865.15234375, "cpu_memory_peak_mb": 865.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.5631468}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [10.905299997830298, 9.44320000053267], "tokens_processed": [44, 44], "throughput_tok_s": [4034.7354046889286, 4659.43747855791], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.38010000027134, 8.824100001220359, 9.851899998466251], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 16.575, "gpu_power_peak_watts": 16.575, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 865.15625, "cpu_memory_peak_mb": 865.15625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.6919684}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.055199997936143, 15.995900001144037], "tokens_processed": [76, 76], "throughput_tok_s": [4733.668843101899, 4751.217499144433], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.504299997905036, 16.470700000354555, 16.71630000055302], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 13.486, "gpu_power_peak_watts": 13.486, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 866.72265625, "cpu_memory_peak_mb": 866.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.812795}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.731399999116547, 16.395700000430224], "tokens_processed": [76, 76], "throughput_tok_s": [4542.3574837738, 4635.361710570805], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.142199998284923, 16.134500001498964, 17.12029999907827], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 13.486, "gpu_power_peak_watts": 13.486, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 871.28515625, "cpu_memory_peak_mb": 871.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577909.9365091}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [13.077799998427508, 13.419099999737227], "tokens_processed": [76, 76], "throughput_tok_s": [5811.3750026104035, 5663.569091927792], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.110200001188787, 12.669399999140296, 13.228799998614704], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 13.486, "gpu_power_peak_watts": 13.486, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 871.2890625, "cpu_memory_peak_mb": 871.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577910.062857}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [13.394900001003407, 12.753499999234919], "tokens_processed": [76, 76], "throughput_tok_s": [5673.801222428452, 5959.1484694052015], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.376099999732105, 12.15550000051735, 12.92970000213245], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 13.486, "gpu_power_peak_watts": 13.486, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 871.2890625, "cpu_memory_peak_mb": 871.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577910.1902518}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [13.520500000595348, 12.557300000480609], "tokens_processed": [76, 76], "throughput_tok_s": [5621.093894209052, 6052.256456172205], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.395999998465413, 12.793599998985883, 13.209799999458482], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 614.01953125, "gpu_memory_peak_mb": 614.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.5, "gpu_power_peak_watts": 10.5, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 871.2890625, "cpu_memory_peak_mb": 871.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1866.2081000002217, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577910.3096595}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7321999983105343, 0.7667999998375308], "tokens_processed": [8, 8], "throughput_tok_s": [10925.976534360916, 10432.968181657585], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1493999993253965, 1.048499998432817, 1.0211000007984694], "resource_metrics": {"samples": 2, "duration_s": 0.1107935905456543, "gpu_memory_mean_mb": 618.529296875, "gpu_memory_peak_mb": 623.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.5, "gpu_power_peak_watts": 10.5, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 926.509765625, "cpu_memory_peak_mb": 976.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765577910.5333302}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.3944000018236693, 0.4121999991184566], "tokens_processed": [8, 8], "throughput_tok_s": [20283.975565437973, 19408.05438405881], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.623000000108732, 0.5801000006613322, 0.4503999989537988], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 18.0, "gpu_power_mean_watts": 10.5, "gpu_power_peak_watts": 10.5, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1044.2109375, "cpu_memory_peak_mb": 1044.2109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577910.6698666}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.498199999332428, 0.877900001796661], "tokens_processed": [8, 8], "throughput_tok_s": [5339.741024939702, 9112.655181259424], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1563000007299706, 0.8882000001904089, 1.0081000000354834], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 12.158, "gpu_power_peak_watts": 12.158, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1044.28125, "cpu_memory_peak_mb": 1044.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577910.793245}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7972999992489349, 1.0443999999552034], "tokens_processed": [8, 8], "throughput_tok_s": [10033.864301437457, 7659.900421623073], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4608000019507017, 1.0093000018969178, 0.772700001107296], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 12.158, "gpu_power_peak_watts": 12.158, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1044.390625, "cpu_memory_peak_mb": 1044.390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577910.9177341}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7216000012704171, 0.8248999984061811], "tokens_processed": [8, 8], "throughput_tok_s": [11086.47448159029, 9698.14524846295], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2939999978698324, 1.0317000014765654, 0.8305999981530476], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 12.158, "gpu_power_peak_watts": 12.158, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1044.39453125, "cpu_memory_peak_mb": 1044.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.0412843}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9186000024783425, 1.2744999985443428], "tokens_processed": [11, 11], "throughput_tok_s": [11974.744143612545, 8630.835631670096], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3858999991498422, 1.1739999972633086, 0.8402999992540572], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 12.158, "gpu_power_peak_watts": 12.158, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1044.96875, "cpu_memory_peak_mb": 1044.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.1657212}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2562000010802876, 0.8736000017961487], "tokens_processed": [11, 11], "throughput_tok_s": [8756.567418038838, 12591.575065686422], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7569000010553282, 1.09119999979157, 1.0155999989365228], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 24.471, "gpu_power_peak_watts": 24.471, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1044.96875, "cpu_memory_peak_mb": 1044.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.2891133}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8629000003566034, 0.8956000019679777], "tokens_processed": [11, 11], "throughput_tok_s": [12747.711201128894, 12282.268843042395], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2263999997230712, 1.424300000508083, 1.1717000015778467], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 24.471, "gpu_power_peak_watts": 24.471, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1044.96875, "cpu_memory_peak_mb": 1044.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.4139113}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.174099998024758, 0.9456000007048715], "tokens_processed": [11, 11], "throughput_tok_s": [9368.878305515545, 11632.825710448766], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3059999982942827, 0.9475000006204937, 1.363600000331644], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 24.471, "gpu_power_peak_watts": 24.471, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1044.96875, "cpu_memory_peak_mb": 1044.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.5399017}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9330999964731745, 0.9970999999495689], "tokens_processed": [11, 11], "throughput_tok_s": [11788.6614956345, 11031.992779617245], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.80720000207657, 0.9229999996023253, 0.7970000006025657], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 24.471, "gpu_power_peak_watts": 24.471, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1044.96875, "cpu_memory_peak_mb": 1044.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.6618779}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3981999982206617, 1.8149999996239785], "tokens_processed": [19, 19], "throughput_tok_s": [13588.900031597233, 10468.319561397419], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9320999999763444, 1.8641999995452352, 1.403099999151891], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.086, "gpu_power_peak_watts": 31.086, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.5234375, "cpu_memory_peak_mb": 1046.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.7840524}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.7288999988522846, 1.0457999997015577], "tokens_processed": [19, 19], "throughput_tok_s": [10989.64660339695, 18167.909739359413], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.141900000424357, 1.4111000018601771, 1.4456999997491948], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.086, "gpu_power_peak_watts": 31.086, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.52734375, "cpu_memory_peak_mb": 1046.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577911.9089432}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2967000002390705, 1.1982999967585783], "tokens_processed": [19, 19], "throughput_tok_s": [14652.579622500964, 15855.795753480197], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3578999971505255, 1.4370000026246998, 2.03460000193445], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.086, "gpu_power_peak_watts": 31.086, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.57421875, "cpu_memory_peak_mb": 1046.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.0328298}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.6402000001107808, 0.8496000009472482], "tokens_processed": [19, 19], "throughput_tok_s": [11583.953175659504, 22363.465135141534], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3227000019687694, 1.2762999976985157, 1.328900001681177], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.086, "gpu_power_peak_watts": 31.086, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.57421875, "cpu_memory_peak_mb": 1046.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.1563184}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.7222999995283317, 1.3151000021025538], "tokens_processed": [19, 19], "throughput_tok_s": [11031.759859027656, 14447.570503857658], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1731999986513983, 1.386899999488378, 1.3792000027024187], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 845.0390625, "gpu_memory_peak_mb": 845.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.083, "gpu_power_peak_watts": 31.083, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.578125, "cpu_memory_peak_mb": 1046.578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.2814832}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.8147000009776093, 1.8580999967525713], "tokens_processed": [27, 27], "throughput_tok_s": [14878.492304763678, 14530.97252418508], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1393999997817446, 1.6801999991002958, 2.587499999208376], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.083, "gpu_power_peak_watts": 31.083, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1048.125, "cpu_memory_peak_mb": 1048.125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.4063938}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7917000004672445, 2.3075999997672625], "tokens_processed": [27, 27], "throughput_tok_s": [15069.48707538029, 11700.468019900822], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0035000017960556, 1.7950999972526915, 1.5516999992541969], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.083, "gpu_power_peak_watts": 31.083, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1048.12890625, "cpu_memory_peak_mb": 1048.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.5308979}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5817999992577825, 1.9605000015872065], "tokens_processed": [27, 27], "throughput_tok_s": [17069.161722511715, 13771.996928406528], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.472000000125263, 2.723000001424225, 2.2977999979048036], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.083, "gpu_power_peak_watts": 31.083, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1048.1328125, "cpu_memory_peak_mb": 1048.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.657101}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4081000008445699, 1.4246999999159016], "tokens_processed": [27, 27], "throughput_tok_s": [19174.77450735428, 18951.35818178829], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0321000010881107, 1.3112999986333307, 1.0976999983540736], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.125, "gpu_power_peak_watts": 31.125, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1048.1328125, "cpu_memory_peak_mb": 1048.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.7842925}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5743999974802136, 1.9056000019190833], "tokens_processed": [27, 27], "throughput_tok_s": [17149.39027134959, 14168.76572880403], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7455999988887925, 1.764000000548549, 2.6246000015817117], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.125, "gpu_power_peak_watts": 31.125, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1048.1328125, "cpu_memory_peak_mb": 1048.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577912.9062278}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.301399999851128, 3.4726999983831774], "tokens_processed": [44, 44], "throughput_tok_s": [19118.797255082234, 12670.256578594626], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [55.2966999966884, 3.1369999996968545, 3.1455000025744084], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 841.0390625, "gpu_memory_peak_mb": 841.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.125, "gpu_power_peak_watts": 31.125, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1046.13671875, "cpu_memory_peak_mb": 1046.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.052295}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.710199998546159, 3.1803999991097953], "tokens_processed": [44, 44], "throughput_tok_s": [16234.964217992421, 13834.7377727065], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.797199999098666, 3.5097999971185345, 3.002000001288252], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.125, "gpu_power_peak_watts": 31.125, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1147.765625, "cpu_memory_peak_mb": 1147.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.1830184}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8913999994983897, 2.7914999991480727], "tokens_processed": [44, 44], "throughput_tok_s": [15217.54167795299, 15762.135057649362], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.39209999947343, 2.5458000018261373, 2.8899999997520354], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.208, "gpu_power_peak_watts": 31.208, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1147.8203125, "cpu_memory_peak_mb": 1147.8203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.3066537}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7909000018553343, 3.42100000125356], "tokens_processed": [44, 44], "throughput_tok_s": [15765.523655720264, 12861.736329692207], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9202999978442676, 3.3709999988786876, 2.55019999895012], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.208, "gpu_power_peak_watts": 31.208, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1147.828125, "cpu_memory_peak_mb": 1147.828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.4286478}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.459100000123726, 3.294499998446554], "tokens_processed": [44, 44], "throughput_tok_s": [17892.724979783743, 13355.592660721564], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.77200000002631, 3.5044999967794865, 3.082799998082919], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.208, "gpu_power_peak_watts": 31.208, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1147.83203125, "cpu_memory_peak_mb": 1147.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.5551145}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.028599996876437, 5.490799998369766], "tokens_processed": [76, 76], "throughput_tok_s": [15113.550500578316, 13841.334600161108], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.16009999794187, 4.727200001070742, 4.852400001254864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.208, "gpu_power_peak_watts": 31.208, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1153.96875, "cpu_memory_peak_mb": 1153.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.6779904}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.397200002131285, 4.905699999653734], "tokens_processed": [76, 76], "throughput_tok_s": [17283.725999082017, 15492.182564234343], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.092300001706462, 5.566499999986263, 4.088099998625694], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.297, "gpu_power_peak_watts": 31.297, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1154.02734375, "cpu_memory_peak_mb": 1154.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.802748}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.6261999996204395, 4.340100000263192], "tokens_processed": [76, 76], "throughput_tok_s": [16428.169989675214, 17511.117254300872], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.009400000039022, 5.824299998494098, 3.6046999994141515], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.297, "gpu_power_peak_watts": 31.297, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1154.12109375, "cpu_memory_peak_mb": 1154.12109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577913.928402}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.7191999981587287, 5.3979000003892], "tokens_processed": [76, 76], "throughput_tok_s": [20434.50205356675, 14079.549453402295], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.8309999985795, 4.806999997526873, 5.4906000004848465], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.297, "gpu_power_peak_watts": 31.297, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1154.12890625, "cpu_memory_peak_mb": 1154.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.0523853}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.944899999827612, 5.174800000531832], "tokens_processed": [76, 76], "throughput_tok_s": [15369.370463032517, 14686.557933096781], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.0124999981781, 5.138699998497032, 5.041000000346685], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.297, "gpu_power_peak_watts": 31.297, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1154.1328125, "cpu_memory_peak_mb": 1154.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 196.78550000026007, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.1774428}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.742500000342261, 1.0015000007115304], "tokens_processed": [8, 8], "throughput_tok_s": [10774.410769444228, 7988.017967365234], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.455400001053931, 0.7326999984798022, 0.7761000015307218], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.418, "gpu_power_peak_watts": 31.418, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1142.1328125, "cpu_memory_peak_mb": 1142.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765577914.3030517}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7575000017823186, 0.6838000008428935], "tokens_processed": [8, 8], "throughput_tok_s": [10561.056080761497, 11699.327274259598], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0896000021602958, 0.8613999998487998, 1.1378000017430168], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.418, "gpu_power_peak_watts": 31.418, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1145.64453125, "cpu_memory_peak_mb": 1145.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.428067}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7313000023714267, 0.6678999998257495], "tokens_processed": [8, 8], "throughput_tok_s": [10939.42290996576, 11977.840997285737], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4111000018601771, 0.7063999983074609, 0.7311999979719985], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.418, "gpu_power_peak_watts": 31.418, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1145.6953125, "cpu_memory_peak_mb": 1145.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.553376}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7948999991640449, 0.6331999975373037], "tokens_processed": [8, 8], "throughput_tok_s": [10064.159024296372, 12634.238836251252], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1233000004722271, 0.7406999975501094, 0.7789000010234304], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 31.418, "gpu_power_peak_watts": 31.418, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1145.7734375, "cpu_memory_peak_mb": 1145.7734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.6784885}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9868000015558209, 0.8170000000973232], "tokens_processed": [8, 8], "throughput_tok_s": [8107.012553087698, 9791.921663460244], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1083000026701484, 0.8873000006133225, 1.0789000007207505], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.338, "gpu_power_peak_watts": 31.338, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1145.9140625, "cpu_memory_peak_mb": 1145.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.8043501}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.3149999977031257, 0.9879999997792765], "tokens_processed": [11, 11], "throughput_tok_s": [8365.019026017793, 11133.603241353692], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9640999998955522, 1.0375999991083518, 1.0802000033436343], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.338, "gpu_power_peak_watts": 31.338, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1146.48828125, "cpu_memory_peak_mb": 1146.48828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577914.9239419}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2433999982022215, 1.6035000007832423], "tokens_processed": [11, 11], "throughput_tok_s": [8846.710644928766, 6859.993760291215], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9825000017590355, 1.5992999979062006, 1.198800000565825], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.338, "gpu_power_peak_watts": 31.338, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1146.53515625, "cpu_memory_peak_mb": 1146.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.051467}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.4229000007617287, 1.4240000018617138], "tokens_processed": [11, 11], "throughput_tok_s": [7730.690838506789, 7724.719091024427], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7732000014802907, 1.2625000017578714, 1.1703000018314924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.338, "gpu_power_peak_watts": 31.338, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1146.55859375, "cpu_memory_peak_mb": 1146.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.177114}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0081000000354834, 0.9174000006169081], "tokens_processed": [11, 11], "throughput_tok_s": [10911.615910735858, 11990.40766579793], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1388000020815525, 1.32119999761926, 1.0216000009677373], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.216, "gpu_power_peak_watts": 31.216, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1146.56640625, "cpu_memory_peak_mb": 1146.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.3021731}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9775999969861005, 0.633299998298753], "tokens_processed": [11, 11], "throughput_tok_s": [11252.045861203494, 17369.33527482951], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1316999991540797, 1.2540999996417668, 1.4726000008522533], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.216, "gpu_power_peak_watts": 31.216, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1146.5703125, "cpu_memory_peak_mb": 1146.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.426829}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3409999992290977, 1.2032000013277866], "tokens_processed": [19, 19], "throughput_tok_s": [14168.530955199518, 15791.223386828977], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.946600001247134, 1.971199999388773, 1.7329999973298982], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.216, "gpu_power_peak_watts": 31.216, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.1171875, "cpu_memory_peak_mb": 1148.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.5504746}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.6602000032435171, 1.1632999994617421], "tokens_processed": [19, 19], "throughput_tok_s": [11444.404266281097, 16332.846220915742], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0259000011719763, 1.4812999979767483, 1.2429000016709324], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 1.0, "gpu_power_mean_watts": 31.216, "gpu_power_peak_watts": 31.216, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.1171875, "cpu_memory_peak_mb": 1148.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.6751728}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.1298000026727095, 1.3278000005811919], "tokens_processed": [19, 19], "throughput_tok_s": [16817.135736460154, 14309.383937101598], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.976300001842901, 1.2573999993037432, 1.8019999988609925], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.202, "gpu_power_peak_watts": 31.202, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.1171875, "cpu_memory_peak_mb": 1148.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.8006346}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5673000016249716, 1.3465000010910444], "tokens_processed": [19, 19], "throughput_tok_s": [12122.758872137345, 14110.657248128218], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5369000031787436, 1.5917999990051612, 1.6061999995145015], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.202, "gpu_power_peak_watts": 31.202, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.1171875, "cpu_memory_peak_mb": 1148.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577915.9247222}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3968999992357567, 1.710199998342432], "tokens_processed": [19, 19], "throughput_tok_s": [13601.546288492298, 11109.811728695631], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5236000001314096, 2.000099997530924, 1.3937000003352296], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 851.0390625, "gpu_memory_peak_mb": 851.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.202, "gpu_power_peak_watts": 31.202, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.12890625, "cpu_memory_peak_mb": 1148.12890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.046226}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.8106999996234663, 1.9317999976919964], "tokens_processed": [27, 27], "throughput_tok_s": [14911.360250518932, 13976.602149424396], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.241800000774674, 1.853800000390038, 2.480200000718469], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.202, "gpu_power_peak_watts": 31.202, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1149.67578125, "cpu_memory_peak_mb": 1149.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.1810355}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.619400002004113, 1.8554999987827614], "tokens_processed": [27, 27], "throughput_tok_s": [10307.70404647713, 14551.33388181754], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4868999971658923, 2.649800000654068, 1.82199999835575], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.753, "gpu_power_peak_watts": 31.753, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1149.67578125, "cpu_memory_peak_mb": 1149.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.31068}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.6123000025108922, 1.929900001414353], "tokens_processed": [27, 27], "throughput_tok_s": [10335.719470982705, 13990.362184679356], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1578999985649716, 2.5961999999708496, 1.6704000008758157], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.753, "gpu_power_peak_watts": 31.753, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1149.67578125, "cpu_memory_peak_mb": 1149.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.4351246}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.6215999969281256, 2.030799998465227], "tokens_processed": [27, 27], "throughput_tok_s": [10299.054024884574, 13295.253112273585], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.323900000192225, 2.6393999978608917, 1.6775000003690366], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.753, "gpu_power_peak_watts": 31.753, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1149.6796875, "cpu_memory_peak_mb": 1149.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.5605197}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.1894000019528903, 2.0803000006708317], "tokens_processed": [27, 27], "throughput_tok_s": [12332.14578236808, 12978.897270246283], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.299499999935506, 1.9743999982893001, 1.543800000945339], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 31.753, "gpu_power_peak_watts": 31.753, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1149.6796875, "cpu_memory_peak_mb": 1149.6796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.685826}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8562000006786548, 3.6106999978073873], "tokens_processed": [44, 44], "throughput_tok_s": [15405.083673953248, 12186.00272155515], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.197300000872929, 3.58570000025793, 3.184100001817569], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 847.0390625, "gpu_memory_peak_mb": 847.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.322, "gpu_power_peak_watts": 31.322, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1148.54296875, "cpu_memory_peak_mb": 1148.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.8328862}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.9018999994150363, 3.509199999825796], "tokens_processed": [44, 44], "throughput_tok_s": [15162.479757699955, 12538.470307245027], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9230000002135057, 2.0335999979579356, 2.556199997343356], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.322, "gpu_power_peak_watts": 31.322, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1157.27734375, "cpu_memory_peak_mb": 1157.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577916.9650407}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7651999989757314, 3.4821999979612883], "tokens_processed": [44, 44], "throughput_tok_s": [15912.049767213299, 12635.690088381061], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3245999984501395, 3.2468999997945502, 2.791300001263153], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.322, "gpu_power_peak_watts": 31.322, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1157.27734375, "cpu_memory_peak_mb": 1157.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.0879064}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2126000005519018, 3.280500000983011], "tokens_processed": [44, 44], "throughput_tok_s": [13696.071715259015, 13412.589540257668], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.320799998618895, 2.834300001268275, 2.7251999999862164], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.322, "gpu_power_peak_watts": 31.322, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1157.328125, "cpu_memory_peak_mb": 1157.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.2113802}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.5490000007266644, 3.0010999980731867], "tokens_processed": [44, 44], "throughput_tok_s": [17261.671238704024, 14661.290869431064], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.158100000291597, 2.733100001933053, 3.506799999740906], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.459, "gpu_power_peak_watts": 31.459, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1157.359375, "cpu_memory_peak_mb": 1157.359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.3359559}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.1445999991556164, 3.883599998516729], "tokens_processed": [76, 76], "throughput_tok_s": [35437.84390092471, 19569.47163174035], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.249199999729171, 4.135799998039147, 2.620700000989018], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.459, "gpu_power_peak_watts": 31.459, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1163.5, "cpu_memory_peak_mb": 1163.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.4611933}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.599399999482557, 5.857999996806029], "tokens_processed": [76, 76], "throughput_tok_s": [13572.882810126655, 12973.711171293557], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.88570000056643, 5.7658999976411, 6.394899999577319], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.459, "gpu_power_peak_watts": 31.459, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1163.5234375, "cpu_memory_peak_mb": 1163.5234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.5875885}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.061000000045169, 5.864200000360142], "tokens_processed": [76, 76], "throughput_tok_s": [12539.184952884609, 12959.994542364271], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.841499998699874, 6.016999999701511, 6.034499998349929], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.459, "gpu_power_peak_watts": 31.459, "gpu_temperature_mean_c": 54.0, "gpu_temperature_peak_c": 54, "cpu_memory_mean_mb": 1163.52734375, "cpu_memory_peak_mb": 1163.52734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.7225406}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.680400001438102, 5.957299999863608], "tokens_processed": [76, 76], "throughput_tok_s": [13379.339479747756, 12757.457237631144], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.7669999989448115, 6.7530000014812686, 6.385299999237759], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 15.988, "gpu_power_peak_watts": 15.988, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1163.53515625, "cpu_memory_peak_mb": 1163.53515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.851317}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.121500002336688, 5.574099999648752], "tokens_processed": [76, 76], "throughput_tok_s": [12415.257693537436, 13634.488079652157], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.794999997509876, 6.258900000830181, 5.829499998071697], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 15.988, "gpu_power_peak_watts": 15.988, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1163.5390625, "cpu_memory_peak_mb": 1163.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 36.2782000011066, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577917.9763439}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9778000021469779, 0.9886000007099938], "tokens_processed": [8, 8], "throughput_tok_s": [8181.632217666411, 8092.251663215206], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9698000034841243, 1.1281999977654777, 1.1391000007279217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 15.988, "gpu_power_peak_watts": 15.988, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1151.23046875, "cpu_memory_peak_mb": 1151.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765577918.0998447}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.0660999978426844, 1.0646000009728596], "tokens_processed": [8, 8], "throughput_tok_s": [7503.986508009068, 7514.559452084716], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1421999988669995, 0.9806000016396865, 1.332100000581704], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 15.988, "gpu_power_peak_watts": 15.988, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 1154.63671875, "cpu_memory_peak_mb": 1154.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.224292}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9499999978288542, 1.0254000007989816], "tokens_processed": [8, 8], "throughput_tok_s": [8421.05265082456, 7801.833424777139], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6223999991780147, 1.035600002069259, 0.9155000007012859], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 14.469, "gpu_power_peak_watts": 14.469, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1154.63671875, "cpu_memory_peak_mb": 1154.63671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.3607464}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.1477000007289462, 0.9761000001162756], "tokens_processed": [8, 8], "throughput_tok_s": [6970.462660032158, 8195.881568535005], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3109999999869615, 0.9995000000344589, 1.1116999994555954], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 14.469, "gpu_power_peak_watts": 14.469, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1154.64453125, "cpu_memory_peak_mb": 1154.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.4898372}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.5506999989156611, 1.2547999976959545], "tokens_processed": [8, 8], "throughput_tok_s": [5158.960473072845, 6375.518022545014], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5583000022161286, 1.2246000005688984, 1.3715999994019512], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 14.469, "gpu_power_peak_watts": 14.469, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1154.64453125, "cpu_memory_peak_mb": 1154.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.6147625}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.2601999990001787, 1.581700002134312], "tokens_processed": [11, 11], "throughput_tok_s": [4866.82594675956, 6954.542571383218], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.849600001150975, 1.8983000009029638, 1.711000000796048], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 14.469, "gpu_power_peak_watts": 14.469, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1155.21875, "cpu_memory_peak_mb": 1155.21875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.738021}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8681000001379289, 1.638400000956608], "tokens_processed": [11, 11], "throughput_tok_s": [5888.335741763197, 6713.867183579993], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8321000027062837, 1.7313000025751535, 1.7841000008047558], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.617, "gpu_power_peak_watts": 12.617, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1155.2265625, "cpu_memory_peak_mb": 1155.2265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577918.8711574}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6558000024815556, 2.2231000002648216], "tokens_processed": [11, 11], "throughput_tok_s": [6643.314399996525, 4948.045521429378], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.857300001574913, 1.627800000278512, 1.7765999982657377], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.617, "gpu_power_peak_watts": 12.617, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1155.2421875, "cpu_memory_peak_mb": 1155.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.0016823}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.646100001380546, 1.6856000002007931], "tokens_processed": [11, 11], "throughput_tok_s": [6682.461570241513, 6525.866159640277], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.209999998944113, 1.6705999987607356, 1.656399999774294], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.617, "gpu_power_peak_watts": 12.617, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1155.24609375, "cpu_memory_peak_mb": 1155.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.1263633}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6859999998123385, 2.6072999971802346], "tokens_processed": [11, 11], "throughput_tok_s": [4095.309009965946, 4218.923795457514], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8133999985584524, 2.0100000001548324, 2.238100001704879], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.504, "gpu_power_peak_watts": 12.504, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1155.24609375, "cpu_memory_peak_mb": 1155.24609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.2500682}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.332899999804795, 5.168700001377147], "tokens_processed": [19, 19], "throughput_tok_s": [5700.741096676412, 3675.9726807393827], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.122200000390876, 3.5811000016110484, 3.676399999676505], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.504, "gpu_power_peak_watts": 12.504, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.78125, "cpu_memory_peak_mb": 1156.78125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.372369}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.351499999553198, 5.720499997551087], "tokens_processed": [19, 19], "throughput_tok_s": [5669.10338729911, 3321.3879919821325], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.167899998719804, 3.566400002455339, 3.1236000031640287], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.504, "gpu_power_peak_watts": 12.504, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.78125, "cpu_memory_peak_mb": 1156.78125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.4953668}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.65189999906579, 3.6695999988296535], "tokens_processed": [19, 19], "throughput_tok_s": [3361.7013753145907, 5177.676042636711], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1823000026633963, 3.670800000691088, 3.360499998962041], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 12.504, "gpu_power_peak_watts": 12.504, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.79296875, "cpu_memory_peak_mb": 1156.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.6211498}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.6170999992464203, 3.6607999973057304], "tokens_processed": [19, 19], "throughput_tok_s": [5252.826851333506, 5190.122381442196], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9851999972597696, 3.383100000064587, 5.694200001016725], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 7.249, "gpu_power_peak_watts": 7.249, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.83984375, "cpu_memory_peak_mb": 1156.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.7434483}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.376699998625554, 2.961700000014389], "tokens_processed": [19, 19], "throughput_tok_s": [5626.795394241041, 6415.234493671774], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8143000019772444, 3.2105999998748302, 3.318400002171984], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 7.249, "gpu_power_peak_watts": 7.249, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.83984375, "cpu_memory_peak_mb": 1156.83984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.8693855}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.56560000020545, 4.633799999282928], "tokens_processed": [27, 27], "throughput_tok_s": [5913.790082088885, 5826.751263364452], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.641999999876134, 4.421199999342207, 4.736800001410302], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 7.249, "gpu_power_peak_watts": 7.249, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1158.37890625, "cpu_memory_peak_mb": 1158.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577919.9914048}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.015299997467082, 4.871800003456883], "tokens_processed": [27, 27], "throughput_tok_s": [5383.5264119067715, 5542.099425436514], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.09779999993043, 4.950599999574479, 4.513699997914955], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 7.249, "gpu_power_peak_watts": 7.249, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1158.4453125, "cpu_memory_peak_mb": 1158.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.1129065}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.0372000005154405, 4.811599999811733], "tokens_processed": [27, 27], "throughput_tok_s": [5360.120701428805, 5611.439022582186], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6045000017329585, 4.661700000724522, 7.734700000582961], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 7.249, "gpu_power_peak_watts": 7.249, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1158.4453125, "cpu_memory_peak_mb": 1158.4453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.2362466}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.849099997954909, 4.6991000017442275], "tokens_processed": [27, 27], "throughput_tok_s": [5568.043556822329, 5745.781104887756], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.960499998560408, 4.541900001640897, 5.883699999685632], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 4.807, "gpu_power_peak_watts": 4.807, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1158.453125, "cpu_memory_peak_mb": 1158.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.3627524}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.434300000866642, 4.738699997687945], "tokens_processed": [27, 27], "throughput_tok_s": [6088.897908288367, 5697.765212647677], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.005299997719703, 6.556500000442611, 5.180600001040148], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 861.0390625, "gpu_memory_peak_mb": 861.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 4.807, "gpu_power_peak_watts": 4.807, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1158.4609375, "cpu_memory_peak_mb": 1158.4609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.485432}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.842999999207677, 6.76480000038282], "tokens_processed": [44, 44], "throughput_tok_s": [6429.928394723744, 6504.257331703826], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.933299999625888, 9.26900000195019, 7.359100000030594], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 14.0, "gpu_power_mean_watts": 4.807, "gpu_power_peak_watts": 4.807, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1156.6484375, "cpu_memory_peak_mb": 1156.6484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.6332657}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.104699998308206, 6.9632000013371], "tokens_processed": [44, 44], "throughput_tok_s": [6193.08345327423, 6318.933822316027], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.967000001168344, 6.858000000647735, 6.593499998416519], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.028, "gpu_power_peak_watts": 4.028, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1165.33984375, "cpu_memory_peak_mb": 1165.33984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.768071}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.566100000782171, 7.26819999908912], "tokens_processed": [44, 44], "throughput_tok_s": [6701.085879709204, 6053.768471631801], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.941799998458009, 6.580799999937881, 6.545200001710327], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.028, "gpu_power_peak_watts": 4.028, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1165.45703125, "cpu_memory_peak_mb": 1165.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577920.8961747}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.925900001078844, 8.812299998680828], "tokens_processed": [44, 44], "throughput_tok_s": [6352.964956633238, 4993.021118957214], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.276200001797406, 6.599200001801364, 8.822499999951106], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.028, "gpu_power_peak_watts": 4.028, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1165.5, "cpu_memory_peak_mb": 1165.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.0164788}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.1906999983184505, 7.993299997906433], "tokens_processed": [44, 44], "throughput_tok_s": [6119.014840041919, 5504.610112409677], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.5877000017499086, 6.786199999623932, 6.543200001033256], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 865.0390625, "gpu_memory_peak_mb": 865.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.028, "gpu_power_peak_watts": 4.028, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1165.5, "cpu_memory_peak_mb": 1165.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.1412594}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.10520000293036, 12.830900002882117], "tokens_processed": [76, 76], "throughput_tok_s": [6843.640815108748, 5923.201021201056], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.050999997882172, 11.096900001575705, 10.671200001524994], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.076, "gpu_power_peak_watts": 4.076, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1164.765625, "cpu_memory_peak_mb": 1164.765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.264479}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.062500001571607, 11.27259999702801], "tokens_processed": [76, 76], "throughput_tok_s": [6870.056496199139, 6742.011605134325], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.660500000289176, 11.09339999675285, 12.298400000872789], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.076, "gpu_power_peak_watts": 4.076, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1168.1171875, "cpu_memory_peak_mb": 1168.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.3895855}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.658799998258473, 11.241700001846766], "tokens_processed": [76, 76], "throughput_tok_s": [6518.681168846919, 6760.543333082617], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.018800000078045, 10.84140000239131, 11.298899997200351], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.076, "gpu_power_peak_watts": 4.076, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1165.2109375, "cpu_memory_peak_mb": 1165.2109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.5142756}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.132599996926729, 10.945199999696342], "tokens_processed": [76, 76], "throughput_tok_s": [6826.796976535634, 6943.683075878787], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.740700003429083, 10.777700001199264, 11.379899999155896], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 34.0, "gpu_power_mean_watts": 4.076, "gpu_power_peak_watts": 4.076, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1163.30078125, "cpu_memory_peak_mb": 1163.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.6360276}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [11.20729999820469, 10.72339999882388], "tokens_processed": [76, 76], "throughput_tok_s": [6781.294336028707, 7087.304400501289], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [11.789599997428013, 10.848300000361633, 11.143499999889173], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 871.0390625, "gpu_memory_peak_mb": 871.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 52.0, "gpu_power_mean_watts": 4.255, "gpu_power_peak_watts": 4.255, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1169.11328125, "cpu_memory_peak_mb": 1169.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.51770000194665, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577921.7614334}
