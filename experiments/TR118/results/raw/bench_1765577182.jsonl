{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.9818999973940663, 2.24760000128299], "tokens_processed": [8, 8], "throughput_tok_s": [2682.853216738099, 3559.352195868209], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [114.56159999943338, 2.3452000023098662, 3.356300003360957], "resource_metrics": {"samples": 2, "duration_s": 0.12119102478027344, "gpu_memory_mean_mb": 781.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.686, "gpu_power_peak_watts": 29.686, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 899.890625, "cpu_memory_peak_mb": 950.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577184.4213457}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.2088000005169306, 2.119299999321811], "tokens_processed": [8, 8], "throughput_tok_s": [3621.876130988655, 3774.831313433704], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8587999986484647, 2.2852999973110855, 2.716099999815924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.078, "gpu_power_peak_watts": 30.078, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 950.73046875, "cpu_memory_peak_mb": 950.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577184.536912}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.173299999820301, 6.625199999689357], "tokens_processed": [8, 8], "throughput_tok_s": [1916.9482185187917, 1207.5107167142282], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.7063999989186414, 5.472000000736443, 3.7764000007882714], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.078, "gpu_power_peak_watts": 30.078, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 950.77734375, "cpu_memory_peak_mb": 950.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577184.661634}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.8930000005639158, 1.8095999985234812], "tokens_processed": [8, 8], "throughput_tok_s": [4226.096142428335, 4420.866493439154], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.671599999302998, 2.155900001525879, 1.9122999983665068], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.078, "gpu_power_peak_watts": 30.078, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 950.87890625, "cpu_memory_peak_mb": 950.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577184.7853096}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.0119000000704546, 1.9766000004892703], "tokens_processed": [8, 8], "throughput_tok_s": [3976.340772264948, 4047.354041293003], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2358000023814384, 1.782300001650583, 1.7358000004605856], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.078, "gpu_power_peak_watts": 30.078, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 950.93359375, "cpu_memory_peak_mb": 950.93359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577184.9086726}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.1171000007598195, 2.2807999994256534], "tokens_processed": [11, 11], "throughput_tok_s": [5195.786687474441, 4822.869169927218], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.07510000129696, 2.3069000017130747, 2.4986999997054227], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 953.19140625, "cpu_memory_peak_mb": 953.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.0318096}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8903000018326566, 1.7958999997063074], "tokens_processed": [11, 11], "throughput_tok_s": [5819.182134759264, 6125.062643687781], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3897999999462627, 2.442299999529496, 2.230099998996593], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 953.29296875, "cpu_memory_peak_mb": 953.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.1553948}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.5917999998200685, 4.56069999927422], "tokens_processed": [11, 11], "throughput_tok_s": [1967.166207724517, 2411.910452726668], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.536399999778951, 2.9131000010238495, 4.88989999939804], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 953.38671875, "cpu_memory_peak_mb": 953.38671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.2803771}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4927999984356575, 1.9103999984508846], "tokens_processed": [11, 11], "throughput_tok_s": [4412.708603539389, 5757.956453580266], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.357699999876786, 4.1711999983817805, 4.26549999974668], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.179, "gpu_power_peak_watts": 30.179, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 953.39453125, "cpu_memory_peak_mb": 953.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.4037879}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.5277999995741993, 3.0759999972360674], "tokens_processed": [11, 11], "throughput_tok_s": [3118.0905950812644, 3576.072825059826], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.557399999612244, 4.087899997102795, 4.618900002242299], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.261, "gpu_power_peak_watts": 30.261, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 952.0859375, "cpu_memory_peak_mb": 952.0859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.526219}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.440299999463605, 5.1248999989184085], "tokens_processed": [19, 19], "throughput_tok_s": [3492.4544605763167, 3707.389413258772], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.155100003321422, 2.787099998386111, 2.860699998564087], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.261, "gpu_power_peak_watts": 30.261, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 957.59765625, "cpu_memory_peak_mb": 957.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.6502545}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.754900000989437, 4.867499999818392], "tokens_processed": [19, 19], "throughput_tok_s": [3995.8779356130162, 3903.4411917224234], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.706600000237813, 3.299600000900682, 2.505399999790825], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.261, "gpu_power_peak_watts": 30.261, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 957.6640625, "cpu_memory_peak_mb": 957.6640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.772346}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.4726999981794506, 2.787400000670459], "tokens_processed": [19, 19], "throughput_tok_s": [7683.908284057481, 6816.388030218085], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9418000012810808, 2.860500000679167, 2.3422999984177295], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.261, "gpu_power_peak_watts": 30.261, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 957.671875, "cpu_memory_peak_mb": 957.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577185.896893}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.437300002289703, 4.998299998987932], "tokens_processed": [19, 19], "throughput_tok_s": [2951.5480082086947, 3801.2924401991013], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.5924000001396053, 2.8407999998307787, 2.9562999989138916], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.252, "gpu_power_peak_watts": 30.252, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 957.67578125, "cpu_memory_peak_mb": 957.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.0185995}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.389299999776995, 2.2852999973110855], "tokens_processed": [19, 19], "throughput_tok_s": [7952.119868485901, 8314.00692353549], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.75580000015907, 2.5038999992830213, 2.1621000014420133], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.252, "gpu_power_peak_watts": 30.252, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 957.67578125, "cpu_memory_peak_mb": 957.67578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.1436646}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.7018999971915036, 3.0244000008678995], "tokens_processed": [27, 27], "throughput_tok_s": [9992.96792185692, 8927.3905542428], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.706299998360919, 3.533600000082515, 2.4116999993566424], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.252, "gpu_power_peak_watts": 30.252, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 955.5, "cpu_memory_peak_mb": 955.5, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.2702205}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.160900000395486, 5.801299997983733], "tokens_processed": [27, 27], "throughput_tok_s": [4382.4765859317295, 4654.1292485105005], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.630299998505507, 5.580700002610683, 6.100599999626866], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 30.252, "gpu_power_peak_watts": 30.252, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 955.54296875, "cpu_memory_peak_mb": 955.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.394817}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.8163999995740596, 2.8183999966131523], "tokens_processed": [27, 27], "throughput_tok_s": [9586.70643519506, 9579.903502854695], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2431999970867764, 3.999900000053458, 3.1188000029942486], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.104, "gpu_power_peak_watts": 31.104, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.5703125, "cpu_memory_peak_mb": 955.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.5171728}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.508099998522084, 3.228100002161227], "tokens_processed": [27, 27], "throughput_tok_s": [10765.121014277716, 8364.053152604745], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3503000013297424, 2.8684999997494742, 2.168799997889437], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.104, "gpu_power_peak_watts": 31.104, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.6875, "cpu_memory_peak_mb": 955.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.6429656}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.702800000406569, 2.3685000014666002], "tokens_processed": [27, 27], "throughput_tok_s": [9989.640371443882, 11399.62000560748], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9883999995945487, 3.622299998824019, 2.7513999993971083], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.104, "gpu_power_peak_watts": 31.104, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.69921875, "cpu_memory_peak_mb": 955.69921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.783227}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.393700000742683, 3.410400000575464], "tokens_processed": [44, 44], "throughput_tok_s": [12965.200221107041, 12901.712406924562], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.026500003325054, 5.982599999697413, 3.673399998660898], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 31.104, "gpu_power_peak_watts": 31.104, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 956.4921875, "cpu_memory_peak_mb": 956.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577186.90695}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.7650000012945384, 3.5581000011006836], "tokens_processed": [44, 44], "throughput_tok_s": [11686.58698137351, 12366.150469741935], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.980800000746967, 6.671700000879355, 4.657499997847481], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.101, "gpu_power_peak_watts": 31.101, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 948.2421875, "cpu_memory_peak_mb": 948.2421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.0310066}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.914699999470031, 5.254699997749412], "tokens_processed": [44, 44], "throughput_tok_s": [6363.255094707266, 8373.456147609797], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.740799999330193, 5.2157999998598825, 3.6418000017874874], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.101, "gpu_power_peak_watts": 31.101, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.75, "cpu_memory_peak_mb": 955.75, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.1546547}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.542800001014257, 4.0439999975205865], "tokens_processed": [44, 44], "throughput_tok_s": [12419.555150559834, 10880.316524969536], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8649000014411286, 4.22439999965718, 3.6425999969651457], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.101, "gpu_power_peak_watts": 31.101, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.75390625, "cpu_memory_peak_mb": 955.75390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.2821321}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.9020000003802124, 4.462999997485895], "tokens_processed": [44, 44], "throughput_tok_s": [11276.26857911651, 9858.83935128527], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.428500000358326, 2.8870999994978774, 3.2997000016621314], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 795.0390625, "gpu_memory_peak_mb": 795.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 31.101, "gpu_power_peak_watts": 31.101, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 955.7578125, "cpu_memory_peak_mb": 955.7578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.408362}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.815300002519507, 4.234400003042538], "tokens_processed": [76, 76], "throughput_tok_s": [15783.02493307469, 17948.23350306816], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.542700000660261, 7.797799997206312, 5.268999997497303], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.369, "gpu_power_peak_watts": 30.369, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 949.5625, "cpu_memory_peak_mb": 949.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.529552}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.395500000100583, 4.780600000231061], "tokens_processed": [76, 76], "throughput_tok_s": [17290.410646857214, 15897.586076293077], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.502700001467019, 4.493700002058176, 4.600599997502286], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.369, "gpu_power_peak_watts": 30.369, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 962.0, "cpu_memory_peak_mb": 962.0, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.656232}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.3937999980698805, 4.433699999935925], "tokens_processed": [76, 76], "throughput_tok_s": [17297.100467337037, 17141.43943006932], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.117400000221096, 5.706100000679726, 4.3464000009407755], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.369, "gpu_power_peak_watts": 30.369, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 960.5625, "cpu_memory_peak_mb": 960.5625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.7756107}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.0551999991294, 6.211700001585996], "tokens_processed": [76, 76], "throughput_tok_s": [18741.369110356147, 12234.975929390566], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.353600000991719, 4.078099998878315, 4.401599999255268], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.0, "gpu_power_mean_watts": 30.369, "gpu_power_peak_watts": 30.369, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 962.00390625, "cpu_memory_peak_mb": 962.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577187.9030118}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.051100000651786, 4.566799998428905], "tokens_processed": [76, 76], "throughput_tok_s": [18760.33669565606, 16641.849878721627], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.11519999842858, 9.757299998454982, 3.7919999995210674], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.556, "gpu_power_peak_watts": 30.556, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 950.01171875, "cpu_memory_peak_mb": 950.01171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 855.4694999984349, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765577188.0272493}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.634899999568006, 0.6706999993184581], "tokens_processed": [8, 8], "throughput_tok_s": [12600.40952188266, 11927.836600759385], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7512000013084617, 0.9725999989314005, 0.6581000016012695], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.556, "gpu_power_peak_watts": 30.556, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.28515625, "cpu_memory_peak_mb": 964.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.15153}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5106000025989488, 0.46239999937824905], "tokens_processed": [8, 8], "throughput_tok_s": [15667.841675049123, 17301.03808554701], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7660999981453642, 0.8321000022988301, 0.828100000944687], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.556, "gpu_power_peak_watts": 30.556, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.2890625, "cpu_memory_peak_mb": 964.2890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.2756672}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7385999997495674, 0.6103999985498376], "tokens_processed": [8, 8], "throughput_tok_s": [10831.302467793816, 13106.159926287779], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8985000022221357, 0.7728000018687453, 0.7057000002532732], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.556, "gpu_power_peak_watts": 30.556, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.29296875, "cpu_memory_peak_mb": 964.29296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.401517}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6787999991502147, 0.6476000016846228], "tokens_processed": [8, 8], "throughput_tok_s": [11785.50384504294, 12353.304476821095], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7245999986480456, 0.5127000003994908, 0.5515999982890207], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.194, "gpu_power_peak_watts": 30.194, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.296875, "cpu_memory_peak_mb": 964.296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.5247319}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6629999988945201, 0.661899997794535], "tokens_processed": [8, 8], "throughput_tok_s": [12066.36502766082, 12086.417928170678], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8147000007738825, 0.6130999972810969, 0.6170999986352399], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.194, "gpu_power_peak_watts": 30.194, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.30078125, "cpu_memory_peak_mb": 964.30078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.6519608}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8314000006066635, 0.6522000003315043], "tokens_processed": [11, 11], "throughput_tok_s": [13230.69520323962, 16865.992018412835], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.107100000808714, 0.734799999918323, 0.8252000006905291], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.194, "gpu_power_peak_watts": 30.194, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.9140625, "cpu_memory_peak_mb": 964.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.7771308}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6672000017715618, 0.7269000016094651], "tokens_processed": [11, 11], "throughput_tok_s": [16486.81050778267, 15132.755503706641], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0537000016483944, 1.148200000898214, 0.7474000012734905], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 7.0, "gpu_power_mean_watts": 30.194, "gpu_power_peak_watts": 30.194, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.9140625, "cpu_memory_peak_mb": 964.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577188.9010787}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6330000032903627, 0.6657000012637582], "tokens_processed": [11, 11], "throughput_tok_s": [17377.567050270936, 16523.959710256437], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.862000000779517, 0.7315999973798171, 0.8641000022180378], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.563, "gpu_power_peak_watts": 34.563, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.9140625, "cpu_memory_peak_mb": 964.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.0255854}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8859999979904387, 0.7243000000016764], "tokens_processed": [11, 11], "throughput_tok_s": [12415.349915292783, 15187.077177929781], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8813999993435573, 0.8419000005233102, 0.7884000006015413], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.563, "gpu_power_peak_watts": 34.563, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.9140625, "cpu_memory_peak_mb": 964.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.1492288}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7845000000088476, 0.65080000058515], "tokens_processed": [11, 11], "throughput_tok_s": [14021.669853251678, 16902.274108957645], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6281999996863306, 0.8921999979065731, 0.7598999982292298], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.563, "gpu_power_peak_watts": 34.563, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 964.9453125, "cpu_memory_peak_mb": 964.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.2714484}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0961000007227995, 1.5276000012818258], "tokens_processed": [19, 19], "throughput_tok_s": [17334.184825719243, 12437.810934836929], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.930400001583621, 1.0650999975041486, 0.9831000024860259], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.563, "gpu_power_peak_watts": 34.563, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 966.5390625, "cpu_memory_peak_mb": 966.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.3999326}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2977000005776063, 1.1822000014944933], "tokens_processed": [19, 19], "throughput_tok_s": [14641.2884268653, 16071.73065131188], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5300999984901864, 1.5586999979859684, 1.0758999997051433], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.98, "gpu_power_peak_watts": 29.98, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 966.546875, "cpu_memory_peak_mb": 966.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.5218406}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.5217000000120606, 1.1553000003914349], "tokens_processed": [19, 19], "throughput_tok_s": [12486.035355095886, 16445.944770676433], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1059000025852583, 1.2596000015037134, 1.1147999975946732], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.98, "gpu_power_peak_watts": 29.98, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 966.546875, "cpu_memory_peak_mb": 966.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.6494405}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.4123000000836328, 1.0637999985192437], "tokens_processed": [19, 19], "throughput_tok_s": [13453.232315283487, 17860.500118863554], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6895999979169574, 1.8730999981926288, 1.1278999991191085], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.98, "gpu_power_peak_watts": 29.98, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 966.546875, "cpu_memory_peak_mb": 966.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.7730398}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0244000004604459, 1.1002999999618623], "tokens_processed": [19, 19], "throughput_tok_s": [18547.442396973747, 17268.017813922168], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5822999994270504, 1.6144000001077075, 1.041899999108864], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.98, "gpu_power_peak_watts": 29.98, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 966.55078125, "cpu_memory_peak_mb": 966.55078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577189.896172}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5256999977282248, 1.4010999984748196], "tokens_processed": [27, 27], "throughput_tok_s": [17696.794940160675, 19270.57314209628], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2232999983534683, 1.713899997412227, 1.3670999978785403], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.366, "gpu_power_peak_watts": 30.366, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 972.07421875, "cpu_memory_peak_mb": 972.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.0222404}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6471000017190818, 1.4273000015236903], "tokens_processed": [27, 27], "throughput_tok_s": [16392.44731456502, 18916.83596383143], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.007000002777204, 1.5094000009412412, 1.7345000014756806], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.366, "gpu_power_peak_watts": 30.366, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 972.078125, "cpu_memory_peak_mb": 972.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.1442876}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6859000024851412, 1.5235999999276828], "tokens_processed": [27, 27], "throughput_tok_s": [16015.184744172255, 17721.186664007317], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.944999999977881, 1.5961000026436523, 1.4649999975517858], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.366, "gpu_power_peak_watts": 30.366, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 972.078125, "cpu_memory_peak_mb": 972.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.2699258}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.6204999992623925, 1.2911000012536533], "tokens_processed": [27, 27], "throughput_tok_s": [16661.524228503342, 20912.40025852614], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.455400001053931, 1.6785000007075723, 1.6637000007904135], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 30.366, "gpu_power_peak_watts": 30.366, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 972.078125, "cpu_memory_peak_mb": 972.078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.397206}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5660000026400667, 1.5762000002723653], "tokens_processed": [27, 27], "throughput_tok_s": [17241.37928127817, 17129.80585924022], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0690999990620185, 1.6329999998561107, 1.8258000018249732], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.902, "gpu_power_peak_watts": 29.902, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 972.16796875, "cpu_memory_peak_mb": 972.16796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.5185714}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.8595999974641018, 2.24779999916791], "tokens_processed": [44, 44], "throughput_tok_s": [15386.767393698166, 19574.695264831353], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.910699997708434, 2.5052999990293756, 2.598399998532841], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.902, "gpu_power_peak_watts": 29.902, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 981.4921875, "cpu_memory_peak_mb": 981.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.6414826}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.9424999993352685, 2.060500002698973], "tokens_processed": [44, 44], "throughput_tok_s": [14953.271031415432, 21354.04025351421], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.0072000008658506, 2.403599999524886, 2.4658000002091285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.902, "gpu_power_peak_watts": 29.902, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 981.4921875, "cpu_memory_peak_mb": 981.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.7690492}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6195000027655624, 2.779899998131441], "tokens_processed": [44, 44], "throughput_tok_s": [16797.098665221063, 15827.907489325293], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1644999978889246, 2.066900000500027, 2.1919999999227002], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.902, "gpu_power_peak_watts": 29.902, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 981.4921875, "cpu_memory_peak_mb": 981.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577190.8932476}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.597899998363573, 2.8091999993193895], "tokens_processed": [44, 44], "throughput_tok_s": [16936.7566217775, 15662.822159568661], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.433400001085829, 2.367099998082267, 2.3025999980745837], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.9, "gpu_power_peak_watts": 29.9, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 981.4921875, "cpu_memory_peak_mb": 981.4921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.0198154}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.7379999992263038, 2.5377999991178513], "tokens_processed": [44, 44], "throughput_tok_s": [16070.124182773336, 17337.8516885864], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3048999976017512, 2.0420999971975107, 2.2877000010339543], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.9, "gpu_power_peak_watts": 29.9, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 981.49609375, "cpu_memory_peak_mb": 981.49609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.1429343}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.1918999995687045, 4.581199998938246], "tokens_processed": [76, 76], "throughput_tok_s": [18130.203489543994, 16589.539862397192], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.856500000139931, 3.631100000347942, 5.088400001113769], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.9, "gpu_power_peak_watts": 29.9, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 987.640625, "cpu_memory_peak_mb": 987.640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.2690663}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.622899999958463, 4.443199999514036], "tokens_processed": [76, 76], "throughput_tok_s": [16439.897034476813, 17104.789342886277], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.929200000333367, 4.378300000098534, 4.099400000995956], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.9, "gpu_power_peak_watts": 29.9, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 987.64453125, "cpu_memory_peak_mb": 987.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.3939164}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.165800000919262, 4.174199999397388], "tokens_processed": [76, 76], "throughput_tok_s": [18243.7947052737, 18207.081599102057], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.775800000061281, 3.3858000024338253, 3.906400001142174], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.937, "gpu_power_peak_watts": 29.937, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 987.66015625, "cpu_memory_peak_mb": 987.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.5193388}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.6034000004292466, 4.0672999966773205], "tokens_processed": [76, 76], "throughput_tok_s": [21091.19164981592, 18685.61455070595], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.747300001326948, 3.440499996941071, 4.326199999923119], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.937, "gpu_power_peak_watts": 29.937, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 987.66015625, "cpu_memory_peak_mb": 987.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.6435978}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.8128000014694408, 6.195000001753215], "tokens_processed": [76, 76], "throughput_tok_s": [19932.857734659527, 12267.958027198005], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.769299997657072, 3.686399999423884, 4.152400000748457], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 811.0390625, "gpu_memory_peak_mb": 811.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.937, "gpu_power_peak_watts": 29.937, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 987.66015625, "cpu_memory_peak_mb": 987.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 83.98160000069765, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.7670205}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.5120000025490299, 1.9404000013309997], "tokens_processed": [8, 8], "throughput_tok_s": [5291.005282085363, 4122.861262890369], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [32.250699998257915, 1.8315999986953102, 1.6020000002754387], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 29.937, "gpu_power_peak_watts": 29.937, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1005.37890625, "cpu_memory_peak_mb": 1005.37890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577191.8890495}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.5883000014582649, 1.555999999254709], "tokens_processed": [8, 8], "throughput_tok_s": [5036.83182815272, 5141.388177269813], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4396000010019634, 1.8417999999655876, 1.3456999986374285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.005, "gpu_power_peak_watts": 30.005, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1036.3671875, "cpu_memory_peak_mb": 1036.3671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.0126011}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.028199997061165, 1.8702000015764497], "tokens_processed": [8, 8], "throughput_tok_s": [2641.8334349659576, 4277.617363520774], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.432500001101289, 1.8524000006436836, 3.642700001364574], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.005, "gpu_power_peak_watts": 30.005, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1036.4296875, "cpu_memory_peak_mb": 1036.4296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.1381905}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.1325000016076956, 1.5877000005275477], "tokens_processed": [8, 8], "throughput_tok_s": [3751.465413349958, 5038.735275771132], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.128000000491738, 3.004399997735163, 1.8163999993703328], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.005, "gpu_power_peak_watts": 30.005, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1036.43359375, "cpu_memory_peak_mb": 1036.43359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.2638948}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.5781000003917143, 3.490100003546104], "tokens_processed": [8, 8], "throughput_tok_s": [3103.0603928414284, 2292.1979289623873], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3598000009078532, 3.896300000633346, 3.436299997702008], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.005, "gpu_power_peak_watts": 30.005, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1036.44140625, "cpu_memory_peak_mb": 1036.44140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.3849304}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.765400000702357, 3.396000000066124], "tokens_processed": [11, 11], "throughput_tok_s": [2921.3363780602804, 3239.1048291477673], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.812899998796638, 3.595800000766758, 2.6615999995556194], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.176, "gpu_power_peak_watts": 30.176, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1038.77734375, "cpu_memory_peak_mb": 1038.77734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.5073137}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.63310000061756, 2.299799998581875], "tokens_processed": [11, 11], "throughput_tok_s": [6735.656111591653, 4783.02461378508], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2621000025537796, 1.548299998830771, 2.0526999978756066], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.176, "gpu_power_peak_watts": 30.176, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1038.79296875, "cpu_memory_peak_mb": 1038.79296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.6343906}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.802700000553159, 1.9051000017498154], "tokens_processed": [11, 11], "throughput_tok_s": [6101.958171977948, 5773.975114112965], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.075100001500687, 3.297399998700712, 1.7668000000412576], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.176, "gpu_power_peak_watts": 30.176, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1038.8046875, "cpu_memory_peak_mb": 1038.8046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.7730145}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4628999999549706, 1.940999998623738], "tokens_processed": [11, 11], "throughput_tok_s": [4466.279589183935, 5667.181869036335], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7230999983439688, 2.0578000003297348, 1.742799999192357], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.176, "gpu_power_peak_watts": 30.176, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1038.83203125, "cpu_memory_peak_mb": 1038.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577192.898127}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.649800000450341, 1.4760999983991496], "tokens_processed": [11, 11], "throughput_tok_s": [6667.47484361581, 7452.069651059988], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8597999991907272, 2.0522000013443176, 1.9905000008293428], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1038.83203125, "cpu_memory_peak_mb": 1038.83203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.0200996}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.073600000789156, 4.49549999757437], "tokens_processed": [19, 19], "throughput_tok_s": [6181.676208719968, 4226.448673173573], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.187200000364101, 4.487400001380593, 2.1204999975452665], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1040.40234375, "cpu_memory_peak_mb": 1040.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.1458554}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.4425000010523945, 4.495000001043081], "tokens_processed": [19, 19], "throughput_tok_s": [7778.915042707682, 4226.918797684311], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2303000007232185, 2.241199999843957, 3.0776999992667697], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1040.40625, "cpu_memory_peak_mb": 1040.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.268148}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.5805000004766043, 2.780399998300709], "tokens_processed": [19, 19], "throughput_tok_s": [7362.91416256183, 6833.549133798083], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4277000011352357, 3.6806999996770173, 3.3051999998860992], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.61, "gpu_power_peak_watts": 30.61, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1040.40625, "cpu_memory_peak_mb": 1040.40625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.392288}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.034800000226824, 3.7781000028189737], "tokens_processed": [19, 19], "throughput_tok_s": [4709.031426323952, 5028.982818301111], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.481399999349378, 2.4432999998680316, 2.7937999984715134], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.502, "gpu_power_peak_watts": 30.502, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1040.4140625, "cpu_memory_peak_mb": 1040.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.5250733}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.861299999494804, 3.117299998848466], "tokens_processed": [19, 19], "throughput_tok_s": [6640.338308934635, 6095.018126910666], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.689299999678042, 4.545400002825772, 2.933100000518607], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 829.0390625, "gpu_memory_peak_mb": 829.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.502, "gpu_power_peak_watts": 30.502, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1040.4140625, "cpu_memory_peak_mb": 1040.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.6441605}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.1424000012048054, 5.088699999760138], "tokens_processed": [27, 27], "throughput_tok_s": [5250.466706921711, 5305.873799059225], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.775400000857189, 6.128299999545561, 6.27869999880204], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.502, "gpu_power_peak_watts": 30.502, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1046.16015625, "cpu_memory_peak_mb": 1046.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.7713902}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.611400000110734, 5.825699998240452], "tokens_processed": [27, 27], "throughput_tok_s": [4083.8551592019508, 4634.636182459595], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.355799996526912, 6.566199997905642, 4.794899999978952], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 2.0, "gpu_power_mean_watts": 30.502, "gpu_power_peak_watts": 30.502, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 1046.16015625, "cpu_memory_peak_mb": 1046.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577193.89067}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.33899999957066, 4.226400000334252], "tokens_processed": [27, 27], "throughput_tok_s": [4259.346900430463, 6388.415672407879], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.787000001873821, 5.314899997756584, 4.857399999309564], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.999, "gpu_power_peak_watts": 14.999, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1046.1953125, "cpu_memory_peak_mb": 1046.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.017997}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.266199998208322, 4.625099998520454], "tokens_processed": [27, 27], "throughput_tok_s": [4308.8315099613865, 5837.711618913571], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.3379999992321245, 5.44620000073337, 5.654699998558499], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.999, "gpu_power_peak_watts": 14.999, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1046.20703125, "cpu_memory_peak_mb": 1046.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.1437573}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.5481000017607585, 5.339999999705469], "tokens_processed": [27, 27], "throughput_tok_s": [4866.530882902473, 5056.179775559775], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.086299999878975, 5.163800000445917, 4.673800001910422], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 837.0390625, "gpu_memory_peak_mb": 837.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.999, "gpu_power_peak_watts": 14.999, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1046.26953125, "cpu_memory_peak_mb": 1046.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.2639008}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.987299999309471, 7.840399997803615], "tokens_processed": [44, 44], "throughput_tok_s": [6297.139095837929, 5611.958575114282], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.609500000806293, 7.584499999211403, 8.659900002385257], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 14.999, "gpu_power_peak_watts": 14.999, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 1056.0546875, "cpu_memory_peak_mb": 1056.0546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.395019}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.052199998724973, 9.082399999897461], "tokens_processed": [44, 44], "throughput_tok_s": [6239.187772320004, 4844.534484331977], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.496600003127242, 7.079200000589481, 8.434800001850817], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 13.857, "gpu_power_peak_watts": 13.857, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1056.05859375, "cpu_memory_peak_mb": 1056.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.5156782}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.199399999284651, 7.077199999912409], "tokens_processed": [44, 44], "throughput_tok_s": [5366.246311173834, 6217.14802471946], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.695699998294003, 7.6367000001482666, 7.203100001788698], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 13.857, "gpu_power_peak_watts": 13.857, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1056.05859375, "cpu_memory_peak_mb": 1056.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.6412735}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.566899999801535, 6.979999998293351], "tokens_processed": [44, 44], "throughput_tok_s": [5814.798662748818, 6303.724929908058], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.2942999977385625, 8.90600000275299, 8.477300001686672], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 13.857, "gpu_power_peak_watts": 13.857, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1056.06640625, "cpu_memory_peak_mb": 1056.06640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.7670486}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [8.621500001027016, 8.81900000240421], "tokens_processed": [44, 44], "throughput_tok_s": [5103.52026848676, 4989.227802245703], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.264399999869056, 11.43440000305418, 10.085400001116795], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.0, "gpu_power_mean_watts": 13.857, "gpu_power_peak_watts": 13.857, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1056.07421875, "cpu_memory_peak_mb": 1056.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577194.8901074}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [14.541999997163657, 14.805200000409968], "tokens_processed": [76, 76], "throughput_tok_s": [5226.241233312021, 5133.331532022228], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.314399999420857, 14.317400000436464, 13.687400001799688], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.884, "gpu_power_peak_watts": 12.884, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1060.64453125, "cpu_memory_peak_mb": 1060.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577195.0135596}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [14.02080000116257, 14.272899999923538], "tokens_processed": [76, 76], "throughput_tok_s": [5420.518086963531, 5324.776324391479], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.54950000011013, 14.924200000677956, 14.221900000848109], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.884, "gpu_power_peak_watts": 12.884, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1062.20703125, "cpu_memory_peak_mb": 1062.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577195.1434164}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [16.480999998748302, 14.936800002033124], "tokens_processed": [76, 76], "throughput_tok_s": [4611.370669605731, 5088.104546466127], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.576199999282835, 15.485899999475805, 15.51820000167936], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.884, "gpu_power_peak_watts": 12.884, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1062.20703125, "cpu_memory_peak_mb": 1062.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577195.2829435}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [17.106900002545444, 13.320699999894714], "tokens_processed": [76, 76], "throughput_tok_s": [4442.6517948132905, 5705.405872108876], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.88329999888083, 14.82889999897452, 15.223700000206009], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 12.884, "gpu_power_peak_watts": 12.884, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1062.20703125, "cpu_memory_peak_mb": 1062.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577195.412776}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.020100002089748, 9.82280000243918], "tokens_processed": [76, 76], "throughput_tok_s": [8425.627208389325, 7737.1014355507405], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.942699999461183, 10.963500000798376, 9.562499999447027], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 853.0390625, "gpu_memory_peak_mb": 853.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 4.016, "gpu_power_peak_watts": 4.016, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1062.20703125, "cpu_memory_peak_mb": 1062.20703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 700.9689999977127, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765577195.5432281}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.17740000152844, 3.132400001049973], "tokens_processed": [8, 8], "throughput_tok_s": [3674.1067302215247, 2553.952240237013], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.92939999801456, 3.000400000018999, 3.3339000001433305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 4.016, "gpu_power_peak_watts": 4.016, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.484375, "cpu_memory_peak_mb": 1064.484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577195.668568}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.9756000003544614, 2.767000001767883], "tokens_processed": [8, 8], "throughput_tok_s": [2688.5334047072924, 2891.2179237038904], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.471500000159722, 2.3746000006212853, 3.272100002504885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 4.016, "gpu_power_peak_watts": 4.016, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.51171875, "cpu_memory_peak_mb": 1064.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577195.7908874}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.2834999983606394, 2.715100003115367], "tokens_processed": [8, 8], "throughput_tok_s": [2436.42454819375, 2946.4844723290557], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.832899997883942, 2.886199999920791, 2.7587999975366984], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 4.016, "gpu_power_peak_watts": 4.016, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.51171875, "cpu_memory_peak_mb": 1064.51171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577195.9293187}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.2452999983215705, 2.8745000017806888], "tokens_processed": [8, 8], "throughput_tok_s": [3562.9982657017954, 2783.092710051897], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4119999982067384, 3.397899999981746, 3.0943999990995508], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 11.433, "gpu_power_peak_watts": 11.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.5546875, "cpu_memory_peak_mb": 1064.5546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.0583472}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.866300001187483, 3.075700002227677], "tokens_processed": [8, 8], "throughput_tok_s": [2791.054668627035, 2601.03390909573], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.782700001465855, 2.7483000012580305, 3.408200002013473], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 11.433, "gpu_power_peak_watts": 11.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.55859375, "cpu_memory_peak_mb": 1064.55859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.1795018}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.146399998513516, 2.5171999986923765], "tokens_processed": [11, 11], "throughput_tok_s": [3496.0589897015116, 4369.934850514154], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.407700002047932, 3.843300000880845, 3.1812999986868817], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 11.433, "gpu_power_peak_watts": 11.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1065.13671875, "cpu_memory_peak_mb": 1065.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.3022976}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.750600001192652, 3.702599999087397], "tokens_processed": [11, 11], "throughput_tok_s": [1912.843876763928, 2970.885324558753], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.387500000826549, 2.993000001879409, 3.6197999979776796], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 11.433, "gpu_power_peak_watts": 11.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1065.13671875, "cpu_memory_peak_mb": 1065.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.4291523}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.531900001486065, 2.7810999999928754], "tokens_processed": [11, 11], "throughput_tok_s": [4344.563368831193, 3955.2694976909065], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.145599999697879, 2.864800000679679, 2.3910999989311676], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 12.126, "gpu_power_peak_watts": 12.126, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1065.140625, "cpu_memory_peak_mb": 1065.140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.5509834}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.250499998102896, 2.7616000006673858], "tokens_processed": [11, 11], "throughput_tok_s": [3384.094756628205, 3983.1981450397125], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.820800000947202, 2.8741999994963408, 3.2008999987738207], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 12.126, "gpu_power_peak_watts": 12.126, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1065.14453125, "cpu_memory_peak_mb": 1065.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.6759915}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.723199999309145, 5.493000000569737], "tokens_processed": [11, 11], "throughput_tok_s": [4039.365453433687, 2002.5486981356407], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.7288999992597383, 3.5623000003397465, 3.0287000008684117], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 12.126, "gpu_power_peak_watts": 12.126, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1065.1484375, "cpu_memory_peak_mb": 1065.1484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.8004313}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.1117999975977, 3.5549000022001565], "tokens_processed": [19, 19], "throughput_tok_s": [3108.7404704781125, 5344.735432288038], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.002999998192536, 3.5891000006813556, 3.7736999984190334], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 12.126, "gpu_power_peak_watts": 12.126, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.68359375, "cpu_memory_peak_mb": 1066.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577196.9276793}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.450899999734247, 3.6642999984906055], "tokens_processed": [19, 19], "throughput_tok_s": [5505.8100789542395, 5185.164972252943], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8985999999567866, 4.780699997354532, 3.495700002531521], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 12.151, "gpu_power_peak_watts": 12.151, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.68359375, "cpu_memory_peak_mb": 1066.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.0543668}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.573100002540741, 5.801199997222284], "tokens_processed": [19, 19], "throughput_tok_s": [5317.51140088147, 3275.184446165885], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.13259999913862, 3.12359999952605, 3.436799997871276], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 12.151, "gpu_power_peak_watts": 12.151, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.68359375, "cpu_memory_peak_mb": 1066.68359375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.1789374}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.881199998839293, 6.129900000814814], "tokens_processed": [19, 19], "throughput_tok_s": [3230.6332047455994, 3099.561166980609], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.635599998640828, 6.157200001325691, 5.718100001104176], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 12.151, "gpu_power_peak_watts": 12.151, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.6875, "cpu_memory_peak_mb": 1066.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.303458}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.2919000010879245, 8.737500000279397], "tokens_processed": [19, 19], "throughput_tok_s": [3019.7555582121036, 2174.5350500019963], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.769400002463954, 5.851800000527874, 5.694299998140195], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 12.151, "gpu_power_peak_watts": 12.151, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.6875, "cpu_memory_peak_mb": 1066.6875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.425741}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.128900000680005, 7.318799998756731], "tokens_processed": [27, 27], "throughput_tok_s": [3787.4005803734867, 3689.129366096434], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.228499998745974, 9.38289999976405, 6.933100001333514], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 3.593, "gpu_power_peak_watts": 3.593, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1068.23046875, "cpu_memory_peak_mb": 1068.23046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.5615819}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.983700001001125, 6.714799998007948], "tokens_processed": [27, 27], "throughput_tok_s": [3866.145452429157, 4020.9686078528], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.241200000862591, 6.5487000028952025, 6.461600001784973], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 3.593, "gpu_power_peak_watts": 3.593, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1068.234375, "cpu_memory_peak_mb": 1068.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.693423}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.0250999997369945, 6.731900000886526], "tokens_processed": [27, 27], "throughput_tok_s": [3843.361660476125, 4010.7547640999364], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.210700001451187, 7.300100001884857, 8.837999997922452], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 3.593, "gpu_power_peak_watts": 3.593, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1068.234375, "cpu_memory_peak_mb": 1068.234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.8172054}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.6144000011263415, 6.982399998378241], "tokens_processed": [27, 27], "throughput_tok_s": [4082.0029020625107, 3866.8652621263636], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.296399999177083, 7.02110000202083, 6.656800000200747], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 3.593, "gpu_power_peak_watts": 3.593, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1068.23828125, "cpu_memory_peak_mb": 1068.23828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577197.945586}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.973899999138666, 7.028200001514051], "tokens_processed": [27, 27], "throughput_tok_s": [3871.578313903945, 3841.6664286991722], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.640199998102617, 6.9827000006625894, 7.757100000162609], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.474, "gpu_power_peak_watts": 3.474, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1064.11328125, "cpu_memory_peak_mb": 1064.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.065624}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.474, "gpu_power_peak_watts": 3.474, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1066.703125, "cpu_memory_peak_mb": 1066.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.2050717}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.474, "gpu_power_peak_watts": 3.474, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.1875, "cpu_memory_peak_mb": 1067.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.3456786}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.474, "gpu_power_peak_watts": 3.474, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.19140625, "cpu_memory_peak_mb": 1067.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.484373}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.121, "gpu_power_peak_watts": 3.121, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.19140625, "cpu_memory_peak_mb": 1067.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.6083784}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.121, "gpu_power_peak_watts": 3.121, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.44921875, "cpu_memory_peak_mb": 1067.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.7327654}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.121, "gpu_power_peak_watts": 3.121, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.44921875, "cpu_memory_peak_mb": 1067.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.8606184}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 19.0, "gpu_power_mean_watts": 3.121, "gpu_power_peak_watts": 3.121, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.44921875, "cpu_memory_peak_mb": 1067.44921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577198.9815168}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.137, "gpu_power_peak_watts": 3.137, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.45703125, "cpu_memory_peak_mb": 1067.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.1093621}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.137, "gpu_power_peak_watts": 3.137, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.45703125, "cpu_memory_peak_mb": 1067.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.2317917}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.137, "gpu_power_peak_watts": 3.137, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1067.45703125, "cpu_memory_peak_mb": 1067.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 220.89879999839468, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.3571577}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.269299999577925, 4.619399998773588], "tokens_processed": [8, 8], "throughput_tok_s": [1873.8434874079833, 1731.8266446127059], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [54.071800001111114, 4.4430999987525865, 3.844399998342851], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.137, "gpu_power_peak_watts": 3.137, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1084.7109375, "cpu_memory_peak_mb": 1084.7109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.4796112}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.808199999388307, 3.8328000009641983], "tokens_processed": [8, 8], "throughput_tok_s": [1663.8243003655732, 2087.246920785713], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.714499998954125, 4.648999998607906, 4.4692999981634784], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.213, "gpu_power_peak_watts": 3.213, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.3046875, "cpu_memory_peak_mb": 1162.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.608306}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.633799999282928, 4.72059999810881], "tokens_processed": [8, 8], "throughput_tok_s": [1726.4448187746525, 1694.699826972207], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.71099999776925, 4.567600000882521, 3.8170000007085036], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.213, "gpu_power_peak_watts": 3.213, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.3046875, "cpu_memory_peak_mb": 1162.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.7289038}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.378299996460555, 4.852300000493415], "tokens_processed": [8, 8], "throughput_tok_s": [1827.1932043183997, 1648.7026769133206], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.035399997723289, 5.1505999981600326, 4.253700000845129], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.213, "gpu_power_peak_watts": 3.213, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.3046875, "cpu_memory_peak_mb": 1162.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.8551}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.233600000588922, 4.261499998392537], "tokens_processed": [8, 8], "throughput_tok_s": [1889.6447465247418, 1877.2732612971129], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.365299999946728, 4.979400000593159, 4.732699999294709], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 3.0, "gpu_power_mean_watts": 3.213, "gpu_power_peak_watts": 3.213, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.39453125, "cpu_memory_peak_mb": 1162.39453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577199.981668}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.492399999435293, 5.077800000435673], "tokens_processed": [11, 11], "throughput_tok_s": [2448.579824010046, 2166.292488687267], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.497900001500966, 4.972700000507757, 4.85820000176318], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.303, "gpu_power_peak_watts": 3.303, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.96875, "cpu_memory_peak_mb": 1162.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.106153}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.0396000006003305, 4.89709999965271], "tokens_processed": [11, 11], "throughput_tok_s": [2182.712913463301, 2246.2273592085303], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.209599999943748, 4.663300001993775, 4.39370000094641], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.303, "gpu_power_peak_watts": 3.303, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.9765625, "cpu_memory_peak_mb": 1162.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.2301455}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.178700001124525, 7.173199999670032], "tokens_processed": [11, 11], "throughput_tok_s": [2124.085194664957, 1533.4857525938214], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.329899999196641, 6.775300000299467, 5.037599999923259], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.303, "gpu_power_peak_watts": 3.303, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.9765625, "cpu_memory_peak_mb": 1162.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.3542678}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.064299999503419, 4.909499999484979], "tokens_processed": [11, 11], "throughput_tok_s": [2172.067215820273, 2240.5540281401227], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.701599999156315, 4.745800000819145, 4.70839999979944], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.9765625, "cpu_memory_peak_mb": 1162.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.491742}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.973899998731213, 4.618599999957951], "tokens_processed": [11, 11], "throughput_tok_s": [2211.5442616067835, 2381.674100398421], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.159000000276137, 4.343299999163719, 4.993299997295253], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1162.984375, "cpu_memory_peak_mb": 1162.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.6161358}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.729199998313561, 5.988900000374997], "tokens_processed": [19, 19], "throughput_tok_s": [3316.3443422454816, 3172.5358578053247], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.25299999996787, 5.637000002025161, 5.913400000281399], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.51953125, "cpu_memory_peak_mb": 1164.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.742553}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.156799998279894, 5.854699997144053], "tokens_processed": [19, 19], "throughput_tok_s": [3086.0187118808926, 3245.2559497955967], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.358799997542519, 6.991599999309983, 6.1308000003919005], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.0, "gpu_power_mean_watts": 3.386, "gpu_power_peak_watts": 3.386, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.51953125, "cpu_memory_peak_mb": 1164.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577200.8812103}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.037200000719167, 6.067599999369122], "tokens_processed": [19, 19], "throughput_tok_s": [3147.1543095701104, 3131.38638044293], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.803800002468051, 5.776699999842094, 8.25759999861475], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.414, "gpu_power_peak_watts": 3.414, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.51953125, "cpu_memory_peak_mb": 1164.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.0062728}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.762200002209283, 5.900399999518413], "tokens_processed": [19, 19], "throughput_tok_s": [3297.351704681409, 3220.1206700479233], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.866399998922134, 5.718999997043284, 5.647300000418909], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.414, "gpu_power_peak_watts": 3.414, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.51953125, "cpu_memory_peak_mb": 1164.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.1305943}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.987100001220824, 8.162800000718562], "tokens_processed": [19, 19], "throughput_tok_s": [3173.489668808894, 2327.63267485758], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.303099999058759, 6.274899998970795, 5.720900000596885], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.414, "gpu_power_peak_watts": 3.414, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.51953125, "cpu_memory_peak_mb": 1164.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.2521174}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.603199999517528, 6.624900001042988], "tokens_processed": [27, 27], "throughput_tok_s": [4088.9265813503744, 4075.5332149540773], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.28299999961746, 7.130499998311279, 6.795999997848412], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.414, "gpu_power_peak_watts": 3.414, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.3125, "cpu_memory_peak_mb": 1166.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.3752792}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.536700002470752, 7.0454999986395705], "tokens_processed": [27, 27], "throughput_tok_s": [4130.524575059969, 3832.233341170035], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.9464000007428695, 6.747699997504242, 7.145800002035685], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.447, "gpu_power_peak_watts": 3.447, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.3125, "cpu_memory_peak_mb": 1166.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.501901}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.946199999219971, 6.93189999947208], "tokens_processed": [27, 27], "throughput_tok_s": [3887.0173624473796, 3895.035993314426], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.929400002263719, 7.112900002539391, 6.323300000076415], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.447, "gpu_power_peak_watts": 3.447, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.3125, "cpu_memory_peak_mb": 1166.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.6300304}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.640800002060132, 6.8016999975952785], "tokens_processed": [27, 27], "throughput_tok_s": [4065.7752065449895, 3969.595837738473], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.097700003214413, 6.698500001220964, 7.024300000921357], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.447, "gpu_power_peak_watts": 3.447, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.3203125, "cpu_memory_peak_mb": 1166.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.7520053}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.641299998591421, 6.241700000828132], "tokens_processed": [27, 27], "throughput_tok_s": [4065.4691108256716, 4325.744588240017], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.149400000344031, 6.3293000021076296, 7.100899998476962], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.447, "gpu_power_peak_watts": 3.447, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.3203125, "cpu_memory_peak_mb": 1166.3203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577201.8748858}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.499, "gpu_power_peak_watts": 3.499, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.80859375, "cpu_memory_peak_mb": 1164.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.0125003}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.499, "gpu_power_peak_watts": 3.499, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.88671875, "cpu_memory_peak_mb": 1164.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.1437354}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.499, "gpu_power_peak_watts": 3.499, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.90625, "cpu_memory_peak_mb": 1164.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.2673151}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.499, "gpu_power_peak_watts": 3.499, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.90625, "cpu_memory_peak_mb": 1164.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.39156}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.433, "gpu_power_peak_watts": 3.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.91015625, "cpu_memory_peak_mb": 1164.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.5162387}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.433, "gpu_power_peak_watts": 3.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.91015625, "cpu_memory_peak_mb": 1164.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.6418374}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.433, "gpu_power_peak_watts": 3.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.91015625, "cpu_memory_peak_mb": 1164.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.7670562}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 30.0, "gpu_power_mean_watts": 3.433, "gpu_power_peak_watts": 3.433, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.91015625, "cpu_memory_peak_mb": 1164.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577202.8912082}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.312, "gpu_power_peak_watts": 3.312, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.91015625, "cpu_memory_peak_mb": 1164.91015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.0155687}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.312, "gpu_power_peak_watts": 3.312, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1164.96875, "cpu_memory_peak_mb": 1164.96875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 23.842800001148134, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.141899}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.369999998540152, 4.6118999998725485], "tokens_processed": [8, 8], "throughput_tok_s": [2373.8872413844256, 1734.6429888378073], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.79300000006333, 4.808199999388307, 4.294800000934629], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.312, "gpu_power_peak_watts": 3.312, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.53125, "cpu_memory_peak_mb": 1166.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.2684114}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [4.4809999999415595, 4.602100001648068], "tokens_processed": [8, 8], "throughput_tok_s": [1785.3157777514696, 1738.336845599857], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.0702999978966545, 4.073300002346514, 4.34300000051735], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.312, "gpu_power_peak_watts": 3.312, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.53125, "cpu_memory_peak_mb": 1166.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.3940651}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.8531000027433038, 4.636300000129268], "tokens_processed": [8, 8], "throughput_tok_s": [2076.2502904944627, 1725.5138795541588], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.693299998209113, 4.961300001014024, 4.9006999979610555], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.5390625, "cpu_memory_peak_mb": 1166.5390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.5143044}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [5.003099999157712, 4.2167999999946915], "tokens_processed": [8, 8], "throughput_tok_s": [1599.0086149281099, 1897.173211916636], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.509499998675892, 4.695499999797903, 4.942499999742722], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.54296875, "cpu_memory_peak_mb": 1166.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.6426666}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [3.559299999324139, 4.486699999688426], "tokens_processed": [8, 8], "throughput_tok_s": [2247.6329619641747, 1783.0476743610118], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.499799997574883, 4.477200000110315, 4.263399998308159], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 855.0390625, "gpu_memory_peak_mb": 855.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1166.57421875, "cpu_memory_peak_mb": 1166.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.7654123}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.803300002095057, 5.078300000604941], "tokens_processed": [11, 11], "throughput_tok_s": [2290.0922272608677, 2166.079199474165], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.809099999169121, 4.918400001770351, 5.495199999131728], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.273, "gpu_power_peak_watts": 3.273, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.19140625, "cpu_memory_peak_mb": 1167.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577203.892591}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.076299999927869, 7.913400000688853], "tokens_processed": [11, 11], "throughput_tok_s": [2166.9326084266695, 1390.0472614858925], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.268900000373833, 5.088999998406507, 4.849700002523605], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.359, "gpu_power_peak_watts": 3.359, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.19140625, "cpu_memory_peak_mb": 1167.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.0171893}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.817299999966053, 4.822700000659097], "tokens_processed": [11, 11], "throughput_tok_s": [1613.5420181090424, 2280.8800046647475], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.366100002400344, 4.862800000410061, 5.043199998908676], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.359, "gpu_power_peak_watts": 3.359, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.19140625, "cpu_memory_peak_mb": 1167.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.1400356}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.605999998602783, 4.994200000510318], "tokens_processed": [11, 11], "throughput_tok_s": [2388.189319004954, 2202.5549635328975], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.799599999387283, 4.99620000118739, 4.565300001559081], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.359, "gpu_power_peak_watts": 3.359, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.19140625, "cpu_memory_peak_mb": 1167.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.263346}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.385700001876103, 4.845499999646563], "tokens_processed": [11, 11], "throughput_tok_s": [2508.1514912772077, 2270.147559756961], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.052800002886215, 4.879500000242842, 4.510999999183696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.359, "gpu_power_peak_watts": 3.359, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1167.19921875, "cpu_memory_peak_mb": 1167.19921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.3872306}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.851599999004975, 5.146799998328788], "tokens_processed": [19, 19], "throughput_tok_s": [3246.975186825966, 3691.614208084532], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.660900002112612, 7.65769999998156, 6.008000000292668], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.734375, "cpu_memory_peak_mb": 1168.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.5119038}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.567399999563349, 5.554399998800363], "tokens_processed": [19, 19], "throughput_tok_s": [3412.724072545563, 3420.7115087324664], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.8495999983279034, 5.180200001632329, 5.905699999857461], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.734375, "cpu_memory_peak_mb": 1168.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.6373258}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.044599998858757, 6.1940999985381495], "tokens_processed": [19, 19], "throughput_tok_s": [3143.3014597470915, 3067.4351406151227], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.205099998624064, 7.627200000570156, 5.936999998084502], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.734375, "cpu_memory_peak_mb": 1168.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.7762086}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.107400000473717, 5.941899999015732], "tokens_processed": [19, 19], "throughput_tok_s": [3110.980122233074, 3197.6303881161457], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.630200001178309, 5.558000000746688, 5.445499999041203], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 20.0, "gpu_power_mean_watts": 3.435, "gpu_power_peak_watts": 3.435, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.734375, "cpu_memory_peak_mb": 1168.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577204.9160204}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.653199998050695, 5.902799999603303], "tokens_processed": [19, 19], "throughput_tok_s": [3360.928324940118, 3218.8114117498294], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.478500002936926, 5.970300000626594, 4.976599997462472], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 857.0390625, "gpu_memory_peak_mb": 857.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.483, "gpu_power_peak_watts": 3.483, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.734375, "cpu_memory_peak_mb": 1168.734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.0434823}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.81080000140355, 6.593999998585787], "tokens_processed": [27, 27], "throughput_tok_s": [3964.2920059957596, 4094.6314840446894], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.581200003187405, 6.532700001116609, 6.9231000015861355], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.483, "gpu_power_peak_watts": 3.483, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1170.26953125, "cpu_memory_peak_mb": 1170.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.1674075}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.900500000483589, 6.767599999875529], "tokens_processed": [27, 27], "throughput_tok_s": [3912.759944657319, 3989.5974940151], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.958699999813689, 6.623499997658655, 6.885399998282082], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.483, "gpu_power_peak_watts": 3.483, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1170.26953125, "cpu_memory_peak_mb": 1170.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.2891762}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.642399999691406, 6.1597000021720305], "tokens_processed": [27, 27], "throughput_tok_s": [4064.795857108029, 4383.330355452258], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.553100000019185, 7.653699998627417, 6.926099998963764], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.483, "gpu_power_peak_watts": 3.483, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1170.26953125, "cpu_memory_peak_mb": 1170.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.4140294}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [7.514800003264099, 7.111599999916507], "tokens_processed": [27, 27], "throughput_tok_s": [3592.9099893905873, 3796.613982833257], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.229599999845959, 6.604500002140412, 10.027200001786696], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.507, "gpu_power_peak_watts": 3.507, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1170.26953125, "cpu_memory_peak_mb": 1170.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.5371325}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.2397000001510605, 6.91230000302312], "tokens_processed": [27, 27], "throughput_tok_s": [4327.131111967938, 3906.080463549246], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.1253000023716595, 6.200499999977183, 6.604899997910252], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 859.0390625, "gpu_memory_peak_mb": 859.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.507, "gpu_power_peak_watts": 3.507, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1170.26953125, "cpu_memory_peak_mb": 1170.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.6617432}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.507, "gpu_power_peak_watts": 3.507, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.56640625, "cpu_memory_peak_mb": 1168.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.7990901}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.0, "gpu_power_mean_watts": 3.507, "gpu_power_peak_watts": 3.507, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.56640625, "cpu_memory_peak_mb": 1168.56640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577205.9270546}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.492, "gpu_power_peak_watts": 3.492, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.5703125, "cpu_memory_peak_mb": 1168.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.057101}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.492, "gpu_power_peak_watts": 3.492, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.5703125, "cpu_memory_peak_mb": 1168.5703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.1798494}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 863.0390625, "gpu_memory_peak_mb": 863.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.492, "gpu_power_peak_watts": 3.492, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.5859375, "cpu_memory_peak_mb": 1168.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.3020747}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.492, "gpu_power_peak_watts": 3.492, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.5859375, "cpu_memory_peak_mb": 1168.5859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.4253523}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.388, "gpu_power_peak_watts": 3.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.58984375, "cpu_memory_peak_mb": 1168.58984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.5521972}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.388, "gpu_power_peak_watts": 3.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.59375, "cpu_memory_peak_mb": 1168.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.6758971}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.388, "gpu_power_peak_watts": 3.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.59375, "cpu_memory_peak_mb": 1168.59375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.8018672}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: execute_async_v3_failed", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["execute_async_v3_failed", "execute_async_v3_failed"], "warmup_latencies_ms": [0.0, 0.0, 0.0], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 869.0390625, "gpu_memory_peak_mb": 869.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 10.0, "gpu_power_mean_watts": 3.388, "gpu_power_peak_watts": 3.388, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 1168.59765625, "cpu_memory_peak_mb": 1168.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": null, "trt_build_metadata": [], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 23.511600000347244, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765577206.9273598}
