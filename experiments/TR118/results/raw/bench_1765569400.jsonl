{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.704099999187747, 2.0380999994813465], "tokens_processed": [1, 1], "throughput_tok_s": [586.8200225788664, 490.6530593466851], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [100.42760000214912, 1.8005000019911677, 1.728999999613734], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.5929112}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.6749999995226972, 1.6256999988399912], "tokens_processed": [1, 1], "throughput_tok_s": [597.0149255432578, 615.1196412090449], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9366999986232258, 1.7987999999604654, 1.636799999687355], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.6059303}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.7613999989407603, 1.728999999613734], "tokens_processed": [1, 1], "throughput_tok_s": [567.7302149434328, 578.3689995508411], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9115000031888485, 1.7994000008911826, 1.686600000539329], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.6204596}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.9159999974363018, 1.6594999979133718], "tokens_processed": [1, 1], "throughput_tok_s": [521.9206687568095, 602.5911426679022], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.992400000744965, 2.0292999979574233, 1.8664000017452054], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.6349788}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.84850000005099, 1.7525000002933666], "tokens_processed": [1, 1], "throughput_tok_s": [540.9791722869437, 570.6134093196011], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8812999987858348, 1.7602000007173046, 1.8016999965766445], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.6490176}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.610100000514649, 3.364000000146916], "tokens_processed": [11, 11], "throughput_tok_s": [3047.0070076817433, 3269.9167656122463], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.710300000733696, 3.6360000012791716, 3.5118999985570554], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.68356}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4074000031978358, 3.461500000412343], "tokens_processed": [11, 11], "throughput_tok_s": [3228.267884509165, 3177.813086433526], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6760000002686866, 3.511599999910686, 3.8408000000345055], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.7081146}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4894000018539373, 3.608799997891765], "tokens_processed": [11, 11], "throughput_tok_s": [3152.404423154594, 3048.104634899723], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6117999989073724, 3.4904999993159436, 3.4453999978723004], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.7321444}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2941999998001847, 3.418000000237953], "tokens_processed": [11, 11], "throughput_tok_s": [3339.2022344324037, 3218.256290004156], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4712000015133526, 3.368199999385979, 3.542300000844989], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.7561774}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.705999999510823, 3.4999999988940544], "tokens_processed": [11, 11], "throughput_tok_s": [2968.1597413523896, 3142.8571438502368], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8489999969897326, 3.378499997779727, 3.562699999747565], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.7814002}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.381999999575783, 8.141399997839471], "tokens_processed": [19, 19], "throughput_tok_s": [2977.1231590822545, 2333.750952544051], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.909299998369534, 7.631200001924299, 7.059200001094723], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.826524}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.94079999771202, 8.598100001108833], "tokens_processed": [19, 19], "throughput_tok_s": [3845.531089863686, 2209.790534833244], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.5026999978290405, 4.520300000876887, 4.365100001450628], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.8610835}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.646999997930834, 4.300199998397147], "tokens_processed": [19, 19], "throughput_tok_s": [4088.65935193891, 4418.3991458727605], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.9701999998651445, 4.540500001894543, 4.432300000189571], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.8926134}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.519300000742078, 7.639699997525895], "tokens_processed": [19, 19], "throughput_tok_s": [3442.465529586256, 2487.0086529776195], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.994599999918137, 4.337499998655403, 4.603299999871524], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.9262128}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.649900001822971, 4.682800001319265], "tokens_processed": [19, 19], "throughput_tok_s": [4086.1093770943767, 4057.4015534823634], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.419900000357302, 4.628099999536062, 4.503099997236859], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.956766}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.006900002626935, 5.54299999930663], "tokens_processed": [27, 27], "throughput_tok_s": [5392.558266758693, 4871.008479772219], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.464300000312505, 5.311600001732586, 5.499800001416588], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569435.9913135}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.557199998293072, 5.152999998244923], "tokens_processed": [27, 27], "throughput_tok_s": [4858.561867180093, 5239.666215640602], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.54550000015297, 5.562199999985751, 5.605400001513772], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.026356}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.345599998690886, 5.0612999984878115], "tokens_processed": [27, 27], "throughput_tok_s": [5050.882970407845, 5334.597832190725], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.428399999800604, 5.452100002003135, 5.125599996972596], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.0599086}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [6.421699999918928, 7.000800000241725], "tokens_processed": [27, 27], "throughput_tok_s": [4204.494137119589, 3856.7020910564133], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.728699998144293, 5.194900000788039, 5.691599999408936], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.0959506}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.473599997960264, 3.700500001286855], "tokens_processed": [27, 27], "throughput_tok_s": [7772.915711611785, 7296.311306745225], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.31319999936386, 4.333799999585608, 3.7271000001055654], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.122679}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.903299999568844, 4.784900000231573], "tokens_processed": [44, 44], "throughput_tok_s": [8973.54842735892, 9195.594473838648], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7427999998035375, 5.101500002638204, 4.590900000039255], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.1581135}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.868899999564746, 4.891399999905843], "tokens_processed": [44, 44], "throughput_tok_s": [9036.94879827751, 8995.379646082303], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.747699997096788, 4.9515999999130145, 5.298200001561781], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.1902409}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.019500000344124, 4.782399999385234], "tokens_processed": [44, 44], "throughput_tok_s": [8765.813327419759, 9200.401473246926], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.743299999972805, 4.962700000760378, 5.0265999998373445], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.222781}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.994499999156687, 4.958200002874946], "tokens_processed": [44, 44], "throughput_tok_s": [8809.690661213199, 8874.188208318985], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.05650000195601, 4.9878999998327345, 4.943799998727627], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.2578294}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.941400002280716, 4.903200002445374], "tokens_processed": [44, 44], "throughput_tok_s": [8904.359084407595, 8973.731436216323], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.841599999053869, 5.407399999967311, 4.900500000076136], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.28938}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.1906999983184505, 6.969599999138154], "tokens_processed": [76, 76], "throughput_tok_s": [10569.207450981496, 10904.499542211604], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.059500000148546, 6.902599998284131, 7.0666999999957625], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.3334286}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.836699998530094, 6.957899997360073], "tokens_processed": [76, 76], "throughput_tok_s": [11116.474324797076, 10922.835917278991], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.982800001424039, 6.714999999530846, 6.615800000872696], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.3800056}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.316200000786921, 6.844399998954032], "tokens_processed": [76, 76], "throughput_tok_s": [10387.906289033315, 11103.968209282684], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.204300000012154, 6.815000000642613, 6.811799998104107], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.4210565}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.87610000022687, 6.692899998597568], "tokens_processed": [76, 76], "throughput_tok_s": [11052.777009859143, 11355.316830660111], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.870600002002902, 7.293500002560904, 6.825699998444179], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.4651039}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.6389999992679805, 7.513900000049034], "tokens_processed": [76, 76], "throughput_tok_s": [11447.50715595418, 10114.587630858015], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.642000000283588, 7.419999998091953, 6.77200000063749], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1154.5865000007325, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765569436.5071719}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.15219999841065146, 0.16039999900385737], "tokens_processed": [1, 1], "throughput_tok_s": [6570.302302513143, 6234.414003805271], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8621999986644369, 0.21399999968707561, 0.16390000018873252], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5101845}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.14649999866378494, 0.1494999996793922], "tokens_processed": [1, 1], "throughput_tok_s": [6825.938628811755, 6688.963225047049], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.1931000006152317, 0.1564999984111637, 0.19160000010742806], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.511186}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.2137000010407064, 0.1644000003580004], "tokens_processed": [1, 1], "throughput_tok_s": [4679.457160178095, 6082.725047581399], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.17360000128974207, 0.1542999998491723, 0.15239999993355013], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5131845}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.15900000289548188, 0.15730000086477958], "tokens_processed": [1, 1], "throughput_tok_s": [6289.308061568695, 6357.279049601748], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.17609999849810265, 0.17490000027464703, 0.15979999807314016], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5141847}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.16250000044237822, 0.2303000001120381], "tokens_processed": [1, 1], "throughput_tok_s": [6153.846137093369, 4342.162394761234], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.18510000154492445, 0.17050000315066427, 0.16619999951217324], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5167024}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5849000008311123, 0.6572999991476536], "tokens_processed": [11, 11], "throughput_tok_s": [18806.633585860105, 16735.128577915908], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.124799997342052, 0.6676000011793803, 0.6346000009216368], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5217044}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7200000000011642, 0.7644999968761113], "tokens_processed": [11, 11], "throughput_tok_s": [15277.777777753075, 14388.489267427129], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7211999982246198, 0.7174999991548248, 0.7468000003427733], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5282102}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8056000006035902, 0.7631999978912063], "tokens_processed": [11, 11], "throughput_tok_s": [13654.419056303783, 14412.997943388416], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8441999998467509, 0.5849000008311123, 0.6476999988080934], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5342104}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8162999984051567, 0.9869000023172703], "tokens_processed": [11, 11], "throughput_tok_s": [13475.437978061022, 11146.012741079821], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9089999985008035, 0.7727999982307665, 0.7132000027922913], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5417235}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.696400002198061, 0.719700001354795], "tokens_processed": [11, 11], "throughput_tok_s": [15795.519766341878, 15284.146143244569], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9812999996938743, 0.9905000006256159, 0.852699999086326], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5482302}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.6687999996065628, 0.9935999987646937], "tokens_processed": [19, 19], "throughput_tok_s": [11385.426656567264, 19122.38327659219], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.925400000094669, 1.145800000813324, 1.1609000030148309], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.559747}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2034999999741558, 1.0346000017307233], "tokens_processed": [19, 19], "throughput_tok_s": [15787.28707969091, 18364.58531627294], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2258999995538034, 1.2171999987913296, 1.0045999988506082], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5692558}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2443000014172867, 1.0798999974213075], "tokens_processed": [19, 19], "throughput_tok_s": [15269.629493175727, 17594.22172920649], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0223999997833744, 0.969299999269424, 1.1578000012377743], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5787778}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.998200001049554, 1.2475000003178138], "tokens_processed": [19, 19], "throughput_tok_s": [19034.261650994304, 15230.460917963566], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0922000001301058, 0.9984000025724526, 1.1271000003034715], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5872867}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.008300001558382, 1.150799998868024], "tokens_processed": [19, 19], "throughput_tok_s": [18843.598106351754, 16510.2537527713], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2318000008235686, 1.1802000008174218, 0.9901000012177974], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.5957937}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.3474000006681308, 1.5366000006906688], "tokens_processed": [27, 27], "throughput_tok_s": [20038.592835543714, 17571.261218185657], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.018700001121033, 1.5349000022979453, 1.5004000015323982], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6088197}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2365000002318993, 1.53399999908288], "tokens_processed": [27, 27], "throughput_tok_s": [21835.826926758014, 17601.043035294828], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7802000002120622, 1.636499997403007, 1.6484000007039867], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6212852}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.378699998895172, 1.781000002665678], "tokens_processed": [27, 27], "throughput_tok_s": [19583.66578779762, 15160.022436602056], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6252999994321726, 1.8970000019180588, 1.6423000015493017], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6337943}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4769000008527655, 1.7588000009709504], "tokens_processed": [27, 27], "throughput_tok_s": [18281.535638438712, 15351.375929664871], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7220000008819625, 1.7989000007219147, 1.71050000062678], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6464224}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4636999985668808, 1.5501000016229227], "tokens_processed": [27, 27], "throughput_tok_s": [18446.402969485476, 17418.23106362916], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0064000018464867, 1.7517999986012, 1.692199999524746], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6589503}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6477999999769963, 2.6321999976062216], "tokens_processed": [44, 44], "throughput_tok_s": [16617.569302961805, 16716.055026219336], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.377599998406367, 2.3021000015432946, 2.331899999262532], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.6789901}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.3475999987567775, 2.231200000096578], "tokens_processed": [44, 44], "throughput_tok_s": [18742.54558838863, 19720.329866482363], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.217599998402875, 2.3421000005328096, 3.032199998415308], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.696014}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4115000014717225, 3.070899998419918], "tokens_processed": [44, 44], "throughput_tok_s": [18245.905027222514, 14328.047159672893], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6572000024316367, 2.648199999384815, 2.2053000029700343], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.714051}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.730100000917446, 2.289200001541758], "tokens_processed": [44, 44], "throughput_tok_s": [16116.62575920804, 19220.688437168596], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.42910000088159, 2.3564000002807006, 2.4540999984310474], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.7310917}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.456599999277387, 2.8256000005058013], "tokens_processed": [44, 44], "throughput_tok_s": [17910.933816226767, 15571.913926997348], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4505000001227017, 3.5692000019480474, 2.3342999993474223], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.750126}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.223300002195174, 4.815300002519507], "tokens_processed": [76, 76], "throughput_tok_s": [17995.40642637202, 15783.02493307469], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.716600000392646, 4.299799998989329, 3.9658999994571786], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.7806652}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.188399998587556, 5.988999997498468], "tokens_processed": [76, 76], "throughput_tok_s": [14648.061063273757, 12689.931546459222], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.482200001802994, 4.55100000181119, 4.419699998834403], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.812247}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.162900000868831, 4.283099999156548], "tokens_processed": [76, 76], "throughput_tok_s": [14720.409069943336, 17744.157272761866], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.466800000955118, 4.2167999999946915, 4.615699999703793], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.8427925}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.46630000078585, 4.518500001722714], "tokens_processed": [76, 76], "throughput_tok_s": [17016.322232413346, 16819.7410580999], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.6941000002552755, 4.268300002877368, 4.2777999988175], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.874576}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.513700001552934, 4.760899999382673], "tokens_processed": [76, 76], "throughput_tok_s": [16837.62766108786, 15963.368272775026], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.491800002142554, 4.478200000448851, 4.420199999003671], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 81.74290000170004, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569436.9041505}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [2.7512000015121885, 1.9522000002325512], "tokens_processed": [1, 1], "throughput_tok_s": [363.4777549615997, 512.2425980334378], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [281.10259999812115, 3.4024999986286275, 2.8972000000067055], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.199499}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.9016000003612135, 0.9210000025632326], "tokens_processed": [1, 1], "throughput_tok_s": [1109.1393074527107, 1085.7763270541832], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6211000006005634, 2.410999997664476, 1.825000003009336], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.2113216}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.8014999986917246, 1.3018999998166692], "tokens_processed": [1, 1], "throughput_tok_s": [555.0929784769439, 768.108149735631], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1639999975159299, 1.179399998363806, 0.8166000006895047], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.218955}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [1.245399998879293, 0.8687000008649193], "tokens_processed": [1, 1], "throughput_tok_s": [802.9548746586455, 1151.145388516579], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7743999997037463, 1.2681000007432885, 1.5626999993401114], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.227202}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.8675999997649342, 0.8444000013696495], "tokens_processed": [1, 1], "throughput_tok_s": [1152.6048873570055, 1184.2728545451932], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3209999997343402, 1.1402999989513773, 0.7793999975547194], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.2332003}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.6077999973495025, 2.6962999982060865], "tokens_processed": [11, 11], "throughput_tok_s": [4218.114890398077, 4079.664728449566], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.183999998233048, 3.381700000318233, 2.6108000020030886], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.254256}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.9126000008545816, 5.6667999997443985], "tokens_processed": [11, 11], "throughput_tok_s": [3776.69436131721, 1941.1307970099801], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.845600000000559, 3.192999996826984, 3.097900000284426], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.2750778}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.932799998234259, 3.0322999991767574], "tokens_processed": [11, 11], "throughput_tok_s": [3750.6819444294642, 3627.609406386704], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.723000001424225, 3.073299998504808, 2.9173000002629124], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.2925215}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.1022999974084087, 2.6122999988729134], "tokens_processed": [11, 11], "throughput_tok_s": [3545.7563772649814, 4210.848679227497], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9536000001826324, 2.933899999334244, 2.5793999993766192], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.3095589}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.759300001343945, 3.18400000105612], "tokens_processed": [11, 11], "throughput_tok_s": [3986.5183179220594, 3454.7738682007994], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6718000012333505, 2.9376999991654884, 3.472600001259707], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.328766}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.378699999913806, 3.700799999933224], "tokens_processed": [19, 19], "throughput_tok_s": [2978.66336404859, 5134.025075751953], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.987900000647642, 4.197900001599919, 3.9399000015691854], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.3604372}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.594800000428222, 4.142999998293817], "tokens_processed": [19, 19], "throughput_tok_s": [5285.412261526836, 4586.048758828057], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.9044000004651025, 3.7419000000227243, 5.410999998275656], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.384096}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.7210000009508803, 4.04049999997369], "tokens_processed": [19, 19], "throughput_tok_s": [5106.154258302784, 4702.388318308061], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.283700000087265, 3.19600000148057, 3.47920000058366], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.4059815}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [5.344100001821062, 5.970899997919332], "tokens_processed": [19, 19], "throughput_tok_s": [3555.3226911033735, 3182.099852052604], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.2623000006424263, 6.317400002444629, 6.417900000087684], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.4369087}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.4786000032909214, 3.794300002482487], "tokens_processed": [19, 19], "throughput_tok_s": [5461.967453005546, 5007.511263624099], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.114399999001762, 5.46559999929741, 4.614199999195989], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.464434}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.185899997741217, 5.674700001691235], "tokens_processed": [27, 27], "throughput_tok_s": [5206.42511651983, 4757.960771838717], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.6038000004482456, 4.058300000906456, 4.685599997173995], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.4941733}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.686299999069888, 4.674899999372428], "tokens_processed": [27, 27], "throughput_tok_s": [4748.254577566503, 5775.524610927411], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.71579999793903, 4.682999999204185, 4.290299999411218], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.5219562}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [5.1615000011224765, 7.127299999410752], "tokens_processed": [27, 27], "throughput_tok_s": [5231.037487964406, 3788.2508105779493], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.799199999979464, 7.337399998505134, 5.101700000523124], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.5547428}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.506799999944633, 4.395899999508401], "tokens_processed": [27, 27], "throughput_tok_s": [5990.94701347557, 6142.086945339849], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.71569999717758, 5.149700002220925, 4.9442000017734244], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.582863}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [4.659500002162531, 4.441600001882762], "tokens_processed": [27, 27], "throughput_tok_s": [5794.613153228666, 6078.890487336747], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.206400001043221, 4.127000000153203, 4.32849999924656], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.6090045}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.354099998337915, 6.3799000017752405], "tokens_processed": [44, 44], "throughput_tok_s": [5983.057071557954, 6896.659820335236], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.665900003019487, 9.292899998399662, 7.3974000006273855], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.664053}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [7.155899998906534, 6.662699997832533], "tokens_processed": [44, 44], "throughput_tok_s": [6148.772342643619, 6603.929340104432], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.332199998723809, 6.004700000630692, 6.125600000814302], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.7007282}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.115500000305474, 6.122800001321593], "tokens_processed": [44, 44], "throughput_tok_s": [7194.832801537433, 7186.254653181991], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.202900000062073, 9.490800002822652, 6.3836000008450355], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.7391267}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.465800001024036, 7.400099999358645], "tokens_processed": [44, 44], "throughput_tok_s": [6805.0357253598, 5945.865596926178], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.939900002180366, 6.605799997487338, 6.3286999975389335], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.7758257}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [6.238300000404706, 6.993400002102135], "tokens_processed": [44, 44], "throughput_tok_s": [7053.203596676262, 6291.646407580592], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.427199998346623, 6.158899999718415, 6.528999998408835], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.8141663}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [12.113299999327864, 10.478000000148313], "tokens_processed": [76, 76], "throughput_tok_s": [6274.095416130785, 7253.292612991434], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.069200001453282, 9.486300001299242, 10.492999997950392], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.8723986}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.500799998932052, 9.614299997338094], "tokens_processed": [76, 76], "throughput_tok_s": [7999.3263734151715, 7904.8916739692], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.773500001756474, 9.23250000050757, 9.55979999707779], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.9258075}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [10.260500002914341, 8.593500002461951], "tokens_processed": [76, 76], "throughput_tok_s": [7407.046438128097, 8843.893638008583], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.513900000456488, 10.361799999373034, 11.668499999359483], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569437.9818797}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.979000002203975, 9.466899999097222], "tokens_processed": [76, 76], "throughput_tok_s": [7615.993584849638, 8027.97114232193], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [9.424100000614999, 10.119700000359444, 10.524100001930492], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569438.0361366}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [9.98039999831235, 8.977699999377364], "tokens_processed": [76, 76], "throughput_tok_s": [7614.92525478451, 8465.419874274132], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.104600001795916, 11.806099999375874, 10.64570000016829], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 300.4155000016908, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765569438.093892}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.14240000018617138, 0.13720000060857274], "tokens_processed": [1, 1], "throughput_tok_s": [7022.471900931297, 7288.629705279436], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5134000020916574, 0.5307999999786261, 0.13649999891640618], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.0976202}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.1726000009512063, 0.12860000060754828], "tokens_processed": [1, 1], "throughput_tok_s": [5793.742725891978, 7776.049729981915], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.22119999994174577, 0.16089999917312525, 0.14910000027157366], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1004982}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.13309999849298038, 0.13080000280751847], "tokens_processed": [1, 1], "throughput_tok_s": [7513.148094083108, 7645.259774738471], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.49140000191982836, 0.20569999833242036, 0.13339999713934958], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.102498}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.15019999773357995, 0.13920000128564425], "tokens_processed": [1, 1], "throughput_tok_s": [6657.789714309907, 7183.907979626796], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8487999984936323, 0.2817999993567355, 0.21489999926416203], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1060069}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.13780000153928995, 0.12440000136848539], "tokens_processed": [1, 1], "throughput_tok_s": [7256.893968284006, 8038.5851205732615], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.49199999921256676, 0.25949999690055847, 0.1348999976471532], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.108522}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.271900000574533, 1.6374000006180722], "tokens_processed": [11, 11], "throughput_tok_s": [8648.478650075607, 6717.967506930384], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3595000020577572, 1.38399999923422, 1.3754000028711744], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1180868}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7059999988996424, 0.6236000008357223], "tokens_processed": [11, 11], "throughput_tok_s": [15580.736568193175, 17639.512484378232], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2476999982027337, 0.7033000001683831, 0.6462000019382685], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.125088}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.2290999984543305, 0.7471999997505918], "tokens_processed": [11, 11], "throughput_tok_s": [8949.637957719618, 14721.627413907514], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5829000003577676, 0.9411999999429099, 1.1169999997946434], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1346102}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9621999997762032, 0.7318999996641651], "tokens_processed": [11, 11], "throughput_tok_s": [11432.13469399135, 15029.375604655539], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.709099997242447, 0.7680999988224357, 0.6809000005887356], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.143133}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.18530000327155, 0.8202000026358292], "tokens_processed": [11, 11], "throughput_tok_s": [9280.350940385446, 13411.36303907576], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.337400000920752, 0.7556000018666964, 0.7810999995854218], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1513402}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.8687999979883898, 0.732399999833433], "tokens_processed": [19, 19], "throughput_tok_s": [21869.244986179092, 25942.10814352963], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6938999979174696, 1.1282000014034566, 1.0523999990255106], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.159863}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.551999997900566, 1.6654000028211158], "tokens_processed": [19, 19], "throughput_tok_s": [12242.268057797573, 11408.670570322336], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9649999994726386, 2.0024000004923437, 1.7101000012189616], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1733732}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.509599998826161, 1.4893000006850343], "tokens_processed": [19, 19], "throughput_tok_s": [12586.115537078746, 12757.671383375115], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7446999991079792, 1.7193999992741738, 1.402800000505522], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1858876}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0016000014729798, 0.9339999996882398], "tokens_processed": [19, 19], "throughput_tok_s": [18969.648534403048, 20342.61242649038], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2768999986292329, 0.6903000030433759, 1.1242000000493135], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.1934266}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.6601999994018115, 1.0377999969932716], "tokens_processed": [19, 19], "throughput_tok_s": [28779.157857036294, 18307.959197385873], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1538999972108286, 1.2141999977757223, 0.7417999986500945], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.202927}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.1056000003009103, 0.7991999991645571], "tokens_processed": [27, 27], "throughput_tok_s": [24421.128792195577, 33783.783819099626], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.47519999902579, 1.436000002286164, 1.0903000002144836], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.2139716}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2189999979455024, 1.1646999992080964], "tokens_processed": [27, 27], "throughput_tok_s": [22149.302744467343, 23181.93527806118], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9080000020039733, 1.2540000025182962, 1.52180000077351], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.224561}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.139200001693098, 2.488000001903856], "tokens_processed": [27, 27], "throughput_tok_s": [12621.540752912535, 10852.090023850153], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.922699997725431, 1.7481999966548756, 2.957200002128957], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.2427168}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7707999977574218, 2.3661999985051807], "tokens_processed": [27, 27], "throughput_tok_s": [15247.345851701697, 11410.700708755361], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.054199998587137, 1.9926000022678636, 2.389400000538444], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.2587867}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2872999977844302, 1.5122000004339498], "tokens_processed": [27, 27], "throughput_tok_s": [20974.13194008363, 17854.7811084856], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.224299998488277, 1.6862000011315104, 1.2372999990475364], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.2715642}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.465900000970578, 3.2759999994596], "tokens_processed": [44, 44], "throughput_tok_s": [17843.383747387, 13431.013433228974], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.234199998289114, 2.513399998861132, 2.34930000078748], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.3301632}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.310899999429239, 2.1137000003363937], "tokens_processed": [44, 44], "throughput_tok_s": [19040.200792274612, 20816.57756209369], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7288999990560114, 1.9873000019288156, 1.8539999982749578], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.3457198}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.538299999490846, 3.008899999258574], "tokens_processed": [44, 44], "throughput_tok_s": [12435.35031126007, 14623.284260308446], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1134000018937513, 1.905199998873286, 2.1140999997442123], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.362898}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8874000015784986, 1.8278999996255152], "tokens_processed": [44, 44], "throughput_tok_s": [23312.49335763551, 24071.338699608485], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.891800002747914, 1.9395999988773838, 2.169999999750871], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.378449}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8855000016628765, 2.037500002188608], "tokens_processed": [44, 44], "throughput_tok_s": [23335.985129246958, 21595.09200134322], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.79690000024857, 2.2542999977304135, 1.5733000000182074], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.394204}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3438999996869825, 3.3105000002251472], "tokens_processed": [76, 76], "throughput_tok_s": [32424.59149714129, 22957.2572103402], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.706900002929615, 2.560299999458948, 2.8503000030468684], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.4131095}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.594499998347601, 4.52210000003106], "tokens_processed": [76, 76], "throughput_tok_s": [16541.517037182108, 16806.35103148493], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.403900002420414, 4.608700000972021, 4.094699997949647], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.444241}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3873999998613726, 2.529199999116827], "tokens_processed": [76, 76], "throughput_tok_s": [31833.79408746462, 30049.027370923017], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.008700001781108, 3.266499999881489, 2.529000001231907], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.4646184}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.9348000025493093, 2.2933000000193715], "tokens_processed": [76, 76], "throughput_tok_s": [25896.14281517743, 33140.01656972835], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.716000003099907, 3.3720999999786727, 2.569000000221422], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.485022}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.4649999977555126, 3.264300001319498], "tokens_processed": [76, 76], "throughput_tok_s": [30831.64303010192, 23282.17381039709], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.487599999469239, 2.5357999984407797, 2.8888999986520503], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 43.682699997589225, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.507024}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.11470000026747584, 0.10349999865866266], "tokens_processed": [1, 1], "throughput_tok_s": [8718.395794839056, 9661.835874007547], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.13770000077784061, 0.09309999950346537, 0.07519999780924991], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.510634}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.08800000068731606, 0.07550000009359792], "tokens_processed": [1, 1], "throughput_tok_s": [11363.636274881708, 13245.033096162813], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.11369999992894009, 0.1173999989987351, 0.09969999882741831], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5126965}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.08399999933317304, 0.1140000022132881], "tokens_processed": [1, 1], "throughput_tok_s": [11904.76199926686, 8771.929654256075], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.09040000077220611, 0.07539999933214858, 0.07860000187065452], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.514635}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.10459999975864775, 0.1083999995898921], "tokens_processed": [1, 1], "throughput_tok_s": [9560.229467565801, 9225.092285823646], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.08769999840296805, 0.11369999992894009, 0.09900000077323057], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5161428}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "ok", "error": null, "latencies_ms": [0.07589999950141646, 0.07959999857121147], "tokens_processed": [1, 1], "throughput_tok_s": [13175.230653082386, 12562.814295849308], "predicted_tokens": ["!", "!"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.11520000043674372, 0.1021999996737577, 0.09030000001075678], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5171516}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6103000014263671, 0.6921000021975487], "tokens_processed": [11, 11], "throughput_tok_s": [18023.92261886166, 15893.65693551931], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0545000006677583, 0.867799997649854, 0.6542999981320463], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5245147}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.749400001950562, 0.788100001955172], "tokens_processed": [11, 11], "throughput_tok_s": [14678.409355976584, 13957.619556795396], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.28489999769954, 0.8261000002676155, 0.9455999970668927], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5320544}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.42769999729353, 1.3809000010951422], "tokens_processed": [11, 11], "throughput_tok_s": [7704.699881524507, 7965.8193868319895], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.603400000021793, 1.7238000000361353, 1.3532999982999172], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5445638}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9960999996110331, 1.2643000009120442], "tokens_processed": [11, 11], "throughput_tok_s": [11043.067969375954, 8700.46665511729], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3772999991488177, 1.3671000015165191, 1.076900000043679], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5540915}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.0522999982640613, 0.8744000006117858], "tokens_processed": [11, 11], "throughput_tok_s": [10453.29280447237, 12580.054885983189], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.406799998221686, 0.8270999969681725, 0.7556000018666964], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5628772}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9190999990096316, 0.8992000002763234], "tokens_processed": [19, 19], "throughput_tok_s": [20672.39693229604, 21129.893231940965], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.62759999895934, 1.6138999999384396, 2.426000002742512], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5759435}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9595999981684145, 1.1516999984451104], "tokens_processed": [19, 19], "throughput_tok_s": [19799.91666972201, 16497.35176317753], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.634200001717545, 0.8725999978196342, 0.79340000229422], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.58348}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2900000001536682, 1.1812000011559576], "tokens_processed": [19, 19], "throughput_tok_s": [14728.682168788117, 16085.336929737583], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.4298999994935002, 0.7789000010234304, 0.6940000021131709], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.5920093}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7193000019469764, 1.1797999977716245], "tokens_processed": [19, 19], "throughput_tok_s": [26414.56964906361, 16104.424509142826], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9574000000138767, 1.155599999037804, 0.8078999999270309], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6028287}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.8674999990034848, 0.973300000623567], "tokens_processed": [19, 19], "throughput_tok_s": [21902.01731622558, 19521.216467509723], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.548600001115119, 1.401000001351349, 1.0278999980073422], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6123009}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.495799999247538, 1.121099998272257], "tokens_processed": [27, 27], "throughput_tok_s": [18050.54152532581, 24083.48946713949], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.426200000627432, 1.151899999968009, 1.395899998897221], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6229625}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.1785999995481689, 1.179200000478886], "tokens_processed": [27, 27], "throughput_tok_s": [22908.535559435593, 22896.87923086415], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.713699999731034, 1.886699999886332, 1.5205999989120755], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6362977}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2127000009058975, 1.5892000010353513], "tokens_processed": [27, 27], "throughput_tok_s": [22264.36874728355, 16989.680331241954], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7474000014772173, 1.4493999988189898, 1.0326000010536518], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6468341}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7396999974153005, 1.1518000028445385], "tokens_processed": [27, 27], "throughput_tok_s": [15519.917250166307, 23441.569659072367], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0784000007552095, 2.4026999999477994, 1.8763000007311348], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.6603577}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.030799998465227, 1.6471999988425523], "tokens_processed": [27, 27], "throughput_tok_s": [13295.253112273585, 16391.4521727612], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.455099998769583, 2.005399997869972, 2.3710000023129396], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.676423}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.000699998665368, 2.7138000004924834], "tokens_processed": [44, 44], "throughput_tok_s": [14663.245249298508, 16213.427663061078], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.187000002275454, 2.1330000017769635, 2.846999999746913], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.7308779}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.822799997375114, 3.4021000028587878], "tokens_processed": [44, 44], "throughput_tok_s": [15587.360082512061, 12933.188313990406], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.040899999381509, 3.42119999913848, 3.7432999997690786], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.7549112}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.564700000628363, 4.2620999993232545], "tokens_processed": [44, 44], "throughput_tok_s": [9639.187678038663, 10323.549425632064], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.070599999977276, 2.4744999973336235, 2.884100002120249], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.7799156}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.956200001790421, 3.186699999787379], "tokens_processed": [44, 44], "throughput_tok_s": [14883.972658599358, 13807.386952940578], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.304900001443457, 3.646899996965658, 3.6622000006900635], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.803952}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.4472999977879226, 3.1515999980911147], "tokens_processed": [44, 44], "throughput_tok_s": [12763.612110415135, 13961.162592540379], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.011900000477908, 2.326000001630746, 3.057099998841295], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.8257058}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.7116999990539625, 4.4643000001087785], "tokens_processed": [76, 76], "throughput_tok_s": [28026.699128411812, 17023.945522959515], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.573700000240933, 4.995100000087405, 3.8101000027381815], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.8527143}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.748500002780929, 2.4034999987634365], "tokens_processed": [76, 76], "throughput_tok_s": [27651.446215427794, 31620.55337595208], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.817900000489317, 3.418000000237953, 2.5157000018225517], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.8728054}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.561799999966752, 2.3354000004474074], "tokens_processed": [76, 76], "throughput_tok_s": [29666.64064368271, 32542.60511494399], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.612699998688186, 2.8013000010105316, 3.2516999999643303], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.8947594}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.6722000002337154, 2.962300000945106], "tokens_processed": [76, 76], "throughput_tok_s": [28440.98495372835, 25655.740463745267], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.132599999342347, 2.4800999999570195, 3.4163999989687], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.9160683}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.0264999986684415, 2.8457999978854787], "tokens_processed": [76, 76], "throughput_tok_s": [25111.51496231206, 26706.022930799936], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.903900000499561, 4.563600003166357, 4.2897000021184795], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 29.05310000278405, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765569438.9414945}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9435003}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9435003}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9435003}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 1}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9444554}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.945962}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.945962}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.945962}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.946969}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.946969}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.946969}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9479795}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9479795}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9489708}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9489708}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9489708}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9489708}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9499707}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9499707}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9499707}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9509706}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9509706}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9509706}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9509706}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "degraded", "error": "2 degraded: trt_engine_missing_or_unavailable", "latencies_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "degraded_count": 2, "degraded_reasons": ["trt_engine_missing_or_unavailable", "trt_engine_missing_or_unavailable"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "build_time_s": 17.974325999999564, "file_size_mb": 3.2930870056152344, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765569418.6241345}, {"precision": "int8", "success": false, "error": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": null, "error": "trt_engine_missing", "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan"}, "started_at": 1765569438.9509706}
