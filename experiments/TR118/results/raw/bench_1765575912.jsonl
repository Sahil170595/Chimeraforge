{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.160700001695659, 2.0078999987163115], "tokens_processed": [8, 8], "throughput_tok_s": [3702.5038153014375, 3984.262166997635], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [79.21260000148322, 2.6440999972692225, 2.1589999996649567], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.1030278}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.9630999995570164, 2.2103999981482048], "tokens_processed": [8, 8], "throughput_tok_s": [4075.1872048317664, 3619.254436618765], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0402000009198673, 1.9257999992987607, 2.187999998568557], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.1155584}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.9949000015913043, 2.193600001191953], "tokens_processed": [8, 8], "throughput_tok_s": [4010.2260732961604, 3646.973010418025], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0351999992271885, 1.8393999998806976, 1.9797999993897974], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.1280675}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.8926000011560973, 2.126200000930112], "tokens_processed": [8, 8], "throughput_tok_s": [4226.989324269887, 3762.5811290096785], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0370999991428107, 1.6854999994393438, 2.098900000419235], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.140585}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.761900002748007, 1.8855000016628765], "tokens_processed": [8, 8], "throughput_tok_s": [4540.552805223071, 4242.90638713581], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9783999996434432, 2.2306999999273103, 1.9142999990435783], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.152117}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.1481000003404915, 2.2804999971413054], "tokens_processed": [11, 11], "throughput_tok_s": [5120.804431011782, 4823.503623674161], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.7140999991388526, 2.383300001383759, 2.613299999211449], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.167653}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.3843999988457654, 2.217700002802303], "tokens_processed": [11, 11], "throughput_tok_s": [4613.319914999519, 4960.093784596796], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1397999989858363, 2.355699998588534, 2.059999998891726], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.1816804}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.109199998812983, 2.3485000019718427], "tokens_processed": [11, 11], "throughput_tok_s": [5215.247490133979, 4683.8407454818835], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1636999990732875, 1.9505999989632983, 2.4365999997826293], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.1952093}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.3513000014645513, 1.9877999984601047], "tokens_processed": [11, 11], "throughput_tok_s": [4678.263085590288, 5533.755915344303], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1726999984821305, 2.2314999987429474, 2.0136999992246274], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.208719}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0757999991474207, 2.3243000032380223], "tokens_processed": [11, 11], "throughput_tok_s": [5299.1617711330355, 4732.607660231343], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.395699997578049, 2.0369999983813614, 2.1617999991576653], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.2227802}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.648500001669163, 2.2232999981497414], "tokens_processed": [19, 19], "throughput_tok_s": [7173.871998499391, 8545.855267310773], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.128799999307375, 2.8257000012672506, 2.5234999993699603], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.240295}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.2797999990871176, 2.324400000361493], "tokens_processed": [19, 19], "throughput_tok_s": [8334.064394950443, 8174.152468183231], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.421699999104021, 2.2022000011929777, 2.6579000004858244], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.2548814}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.9947000000684056, 2.32279999909224], "tokens_processed": [19, 19], "throughput_tok_s": [9525.241890684523, 8179.783023689203], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.169999999750871, 2.682199999981094, 2.3528999990958255], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.2694023}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.5007999975059647, 2.6617000003170688], "tokens_processed": [19, 19], "throughput_tok_s": [7597.56878556806, 7138.295073726066], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6037999996333383, 2.295799997227732, 2.775200002361089], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.2854254}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.519999998185085, 2.281000000948552], "tokens_processed": [19, 19], "throughput_tok_s": [7539.6825451126515, 8329.679961463773], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.398299999185838, 2.5519000009808224, 2.1594999998342246], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.2999425}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.483599997503916, 2.6930999993055593], "tokens_processed": [27, 27], "throughput_tok_s": [10871.315842782944, 10025.621034110207], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.243899998778943, 2.3452000023098662, 2.662800001417054], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.3170335}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.761100000498118, 2.423999998427462], "tokens_processed": [27, 27], "throughput_tok_s": [9778.711381380264, 11138.613868612169], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.362799998081755, 2.749200000835117, 2.522900002077222], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.3324199}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.421699999104021, 2.6278999976057094], "tokens_processed": [27, 27], "throughput_tok_s": [11149.19271998573, 10274.363569618255], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6711999998951796, 2.4434999977529515, 2.7750000008381903], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.3475764}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.9451999980665278, 3.5822000027110334], "tokens_processed": [27, 27], "throughput_tok_s": [9167.45892222091, 7537.267595211383], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6437999986228533, 2.5580000001355074, 2.5577000014891382], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.3656106}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.7036999999836553, 2.4496000005456153], "tokens_processed": [27, 27], "throughput_tok_s": [9986.315049807014, 11022.20770492575], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.644199998030672, 2.9833000007783994, 2.637900000991067], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.382661}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.352600000653183, 3.450600001087878], "tokens_processed": [44, 44], "throughput_tok_s": [13124.142454043886, 12751.405548637347], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3804999984567985, 3.8234999992710073, 3.1879000016488135], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.4027216}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.339100003358908, 3.660499998659361], "tokens_processed": [44, 44], "throughput_tok_s": [13177.203424796797, 12020.215821913609], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3108999996329658, 3.560100001777755, 3.6398999982338864], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.4237587}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.2553999990341254, 3.4688000014284626], "tokens_processed": [44, 44], "throughput_tok_s": [13516.004181684206, 12684.501839794933], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.857899999275105, 3.006999999342952, 3.5984000023745466], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.4445853}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.3333999999740627, 3.9098999986890703], "tokens_processed": [44, 44], "throughput_tok_s": [13199.736005382601, 11253.484747628463], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.838799999357434, 4.431500001373934, 3.0952000015531667], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.4656396}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.238600002077874, 3.747099999600323], "tokens_processed": [44, 44], "throughput_tok_s": [13586.117449444131, 11742.41413484913], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.991900000779424, 3.416700001253048, 3.545199997461168], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.4856837}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.857299998344388, 4.605000001902226], "tokens_processed": [76, 76], "throughput_tok_s": [19702.901001379298, 16503.8002103379], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.163399997603847, 5.307700001139892, 5.190600000787526], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.5152552}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.547900000034133, 4.837000000406988], "tokens_processed": [76, 76], "throughput_tok_s": [16711.009476776006, 15712.218315816688], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6791999991692137, 4.270199999155011, 5.0526000013633166], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.54128}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.506400000536814, 4.612600001564715], "tokens_processed": [76, 76], "throughput_tok_s": [16864.90324670395, 16476.60754763448], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.4105000013369136, 4.096600001503248, 4.47590000112541], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.5655735}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9364000003843103, 4.401099999086], "tokens_processed": [76, 76], "throughput_tok_s": [19306.980995981132, 17268.41017377095], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.739299998618662, 4.12010000218288, 4.358499998488696], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.5913162}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.9576999988639727, 4.224699998303549], "tokens_processed": [76, 76], "throughput_tok_s": [19203.07249711075, 17989.44304459919], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6098000020720065, 3.96050000199466, 4.424999999173451], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 722.1615999987989, "compile_ms": null, "compile_error": "RuntimeError: Windows not yet supported for torch.compile", "device": "cuda", "compile": true}, "started_at": 1765575958.616536}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6023000023560598, 0.5478000020957552], "tokens_processed": [8, 8], "throughput_tok_s": [13282.417348009016, 14603.869969685768], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5019999991636723, 0.7302999983949121, 0.515899999300018], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.622044}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.7484999987354968, 0.6819000009272713], "tokens_processed": [8, 8], "throughput_tok_s": [10688.042770227206, 11731.92548631958], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6828999976278283, 0.5268999993859325, 0.5326999998942483], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.628046}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6733999980497174, 0.7272000002558343], "tokens_processed": [8, 8], "throughput_tok_s": [11880.011914418445, 11001.100106140733], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7468000003427733, 0.8099000006041024, 0.7774000005156267], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6345584}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.9107000005315058, 0.5988000011711847], "tokens_processed": [8, 8], "throughput_tok_s": [8784.451515681358, 13360.053414083015], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8081000014499296, 0.8314000006066635, 0.732399999833433], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.641556}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6150999979581684, 0.8366000001842622], "tokens_processed": [8, 8], "throughput_tok_s": [13006.015325241577, 9562.51493932344], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.5703999995603226, 0.5936999987170566, 0.59299999702489], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6465733}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.9420000023965258, 0.8707000015419908], "tokens_processed": [11, 11], "throughput_tok_s": [11677.282348211349, 12633.51324281525], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2199999982840382, 0.8626999988337047, 0.9477000021433923], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6540892}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7549000001745299, 0.743499997042818], "tokens_processed": [11, 11], "throughput_tok_s": [14571.466416024432, 14794.889097177109], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.89990000196849, 0.7631000007677358, 0.7335999980568886], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6615953}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8911999975680374, 0.9550999966450036], "tokens_processed": [11, 11], "throughput_tok_s": [12342.908471743147, 11517.118666778235], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.023900000291178, 1.1592000009841286, 0.8828999998513609], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.669601}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7795000019541476, 0.6553999992320314], "tokens_processed": [11, 11], "throughput_tok_s": [14111.60997103763, 16783.643596108195], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8548000005248468, 0.8647000031487551, 0.8706000007805414], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6761124}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7098999994923361, 0.7000000005064066], "tokens_processed": [11, 11], "throughput_tok_s": [15495.140171666888, 15714.285702917401], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7970000006025657, 0.686799998220522, 0.7810000024619512], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6826267}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9924000005412381, 1.1677000002237037], "tokens_processed": [19, 19], "throughput_tok_s": [19145.505833975938, 16271.302557471996], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.960599998710677, 1.3144000004103873, 1.2209000014991034], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.6931374}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.2621000023500528, 1.2152999988757074], "tokens_processed": [19, 19], "throughput_tok_s": [15054.27459363098, 15633.999849894833], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0441000013088342, 1.0873999999603257, 1.7341999991913326], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7026496}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0586999997030944, 1.065800002834294], "tokens_processed": [19, 19], "throughput_tok_s": [17946.53821226828, 17826.984377437686], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1856999990413897, 1.1011999995389488, 0.9299999983340967], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7106595}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.3109999999869615, 1.0642999986885116], "tokens_processed": [19, 19], "throughput_tok_s": [14492.753623332543, 17852.109389657835], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2566999976115767, 1.5133000015339348, 1.027299997076625], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7201643}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9895000002870802, 1.0091000003740191], "tokens_processed": [19, 19], "throughput_tok_s": [19201.616972700955, 18828.659194289685], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.029200000630226, 0.9902000019792467, 0.9469000033277553], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7286756}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.509599998826161, 1.3025000007473864], "tokens_processed": [27, 27], "throughput_tok_s": [17885.532605322427, 20729.36659079244], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.201999999873806, 1.5335999996750616, 1.8352999977651052], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.741695}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.7054000018106308, 1.6423999986727722], "tokens_processed": [27, 27], "throughput_tok_s": [15832.062842344307, 16439.35705176496], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5304000007745344, 1.6834999987622723, 1.6565000005357433], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7557204}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.557299998443341, 1.6451000010420103], "tokens_processed": [27, 27], "throughput_tok_s": [10558.01040802222, 16412.37613695103], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5777999979036395, 1.7156000030809082, 1.5028000016172882], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.769238}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4605999967898242, 2.0165999994787853], "tokens_processed": [27, 27], "throughput_tok_s": [18485.55392259474, 13388.872362877357], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6555000001972076, 1.6087999974843115, 1.4192999988154043], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7818975}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.2757000004057772, 1.4541000018652994], "tokens_processed": [27, 27], "throughput_tok_s": [21164.850663488112, 18568.186483298792], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9489000005705748, 2.0991000019421335, 1.4107999995758291], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.7944245}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.4564999985159375, 2.4517999991076067], "tokens_processed": [44, 44], "throughput_tok_s": [17911.66294589132, 17945.998864513782], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.525399999693036, 2.675799998542061, 2.449499999784166], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.8144677}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.341400002478622, 2.9013999992457684], "tokens_processed": [44, 44], "throughput_tok_s": [18792.175601529554, 15165.092717804506], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.481799998349743, 2.930399998149369, 2.624400000058813], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.8334832}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.71470000006957, 2.169899998989422], "tokens_processed": [44, 44], "throughput_tok_s": [16208.052454736217, 20277.432149173663], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.2401000023819506, 2.319200000783894, 2.4094000000332016], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.8505023}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.1016999999119435, 2.4177999985113274], "tokens_processed": [44, 44], "throughput_tok_s": [20935.433221603227, 18198.362158611715], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.248900000267895, 2.618499998789048, 2.330300001631258], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.8675268}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.437799998006085, 2.5176999988616444], "tokens_processed": [44, 44], "throughput_tok_s": [18049.060643198085, 17476.268030303137], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8558999983943067, 2.2960000023886096, 2.353600000787992], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.884557}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.767599999468075, 4.78819999989355], "tokens_processed": [76, 76], "throughput_tok_s": [15940.93464394651, 15872.352867818725], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.513500000233762, 4.56560000020545, 4.082600000401726], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.9168816}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.556699997920077, 4.694700000982266], "tokens_processed": [76, 76], "throughput_tok_s": [16678.736812757146, 16188.467843333678], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.498300000705058, 4.177000002528075, 4.4173999995109625], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.9469264}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.442599998583319, 4.88490000134334], "tokens_processed": [76, 76], "throughput_tok_s": [17107.09945172541, 15558.148576040476], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.400300000270363, 4.5376999987638555, 4.657800000131829], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575958.977473}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.4956000019737985, 3.9861999975983053], "tokens_processed": [76, 76], "throughput_tok_s": [16905.418624128506, 19065.77694189709], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.531099999439903, 4.533700001047691, 4.26309999966179], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.006005}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [4.1233000010834076, 4.637000001821434], "tokens_processed": [76, 76], "throughput_tok_s": [18431.838571054934, 16389.907261191904], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.745300000649877, 3.9595000016561244, 4.447899998922367], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 82.38110000093002, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.0355492}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [2.0111000012548175, 2.2343999989971053], "tokens_processed": [8, 8], "throughput_tok_s": [3977.922527476721, 3580.3795218361724], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [35.069499997916864, 2.355399999942165, 2.8822999993280973], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.0841234}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.7120999982580543, 1.4289999999164138], "tokens_processed": [8, 8], "throughput_tok_s": [4672.624267355563, 5598.320504176307], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.972800000658026, 1.7739000031724572, 2.178099999582628], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.095635}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.6891000013856683, 1.4928000018699095], "tokens_processed": [8, 8], "throughput_tok_s": [4736.250070118483, 5359.0567992892875], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.108699998643715, 1.4890999991621356, 1.9598999970185105], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1067345}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.803999999538064, 1.634200001717545], "tokens_processed": [8, 8], "throughput_tok_s": [4434.589801578989, 4895.361639696485], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.227400000061607, 1.9036000012420118, 1.3830999996571336], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.116233}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [1.5351000001828652, 1.3676999988092575], "tokens_processed": [8, 8], "throughput_tok_s": [5211.386879712734, 5849.235948647316], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5841999993426725, 1.2247000013303477, 1.6089999990072101], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1247435}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0135000013397075, 1.6037999994296115], "tokens_processed": [11, 11], "throughput_tok_s": [5463.123909948355, 6858.7105648535535], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.761200001259567, 1.8892000007326715, 1.4654000005975831], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1365914}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8256000003020745, 1.6042000024754088], "tokens_processed": [11, 11], "throughput_tok_s": [6025.4163004929205, 6857.000363437302], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.341100000194274, 1.7679000011412427, 2.29149999722722], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1496158}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.8285000005562324, 1.6931999998632818], "tokens_processed": [11, 11], "throughput_tok_s": [6015.859992701003, 6496.574533952397], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1038000013504643, 1.8406999988656025, 2.3522999981651083], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.161794}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.9505000018398277, 1.7578000006324146], "tokens_processed": [11, 11], "throughput_tok_s": [5639.57958965606, 6257.822275595894], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.094200001010904, 1.71309999859659, 2.438400002574781], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1727643}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0641000010073185, 2.2649999991699588], "tokens_processed": [11, 11], "throughput_tok_s": [5329.199164106293, 4856.51214306009], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.031899999565212, 1.8301000018254854, 1.9033999997191131], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.1863527}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.1114999983401503, 2.2850999994261656], "tokens_processed": [19, 19], "throughput_tok_s": [6106.379562955382, 8314.734587007693], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.6674000000639353, 2.5773999986995477, 2.4802999978419393], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2025793}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.200199997081654, 2.2838000004412606], "tokens_processed": [19, 19], "throughput_tok_s": [5937.128934856132, 8319.467552469107], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8203000001667533, 2.323400000022957, 3.0435000007855706], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2189188}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.2429999989981297, 2.791899998555891], "tokens_processed": [19, 19], "throughput_tok_s": [8470.798042125118, 6805.401343109617], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9818000002705958, 2.3123999999370426, 2.889100000174949], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2355359}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3366999994323123, 2.8567000008479226], "tokens_processed": [19, 19], "throughput_tok_s": [8131.125092915624, 6651.030907816866], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.3525999968114775, 2.709200001845602, 3.2610000016575214], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2514668}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.5088999973377213, 2.747899998212233], "tokens_processed": [19, 19], "throughput_tok_s": [7573.03998571547, 6914.370978696926], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.4051000000326894, 2.6825999993889127, 3.314400000817841], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2693946}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.5633000006782822, 3.9209000024129637], "tokens_processed": [27, 27], "throughput_tok_s": [7577.245810024553, 6886.174088444977], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.889299998467322, 3.762699998333119, 3.0073999987507705], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.2913828}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.777800000330899, 3.5099000015179627], "tokens_processed": [27, 27], "throughput_tok_s": [9719.922239464213, 7692.526849290017], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.9555000000982545, 3.267500000220025, 3.7597000009554904], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.3113766}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.359700000146404, 3.161500000715023], "tokens_processed": [27, 27], "throughput_tok_s": [8036.431823919825, 8540.249879453906], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.633399999671383, 2.9049000004306436, 3.305700000055367], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.331275}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [2.83099999796832, 2.986100000271108], "tokens_processed": [27, 27], "throughput_tok_s": [9537.265990595788, 9041.894108552517], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.5310000021127053, 3.316999998787651, 3.0435000007855706], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.3499908}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [3.702400001202477, 2.616999998281244], "tokens_processed": [27, 27], "throughput_tok_s": [7292.566981209717, 10317.157056833272], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3145000015792903, 2.5010999997903127, 3.155700000206707], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.3699524}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.868200001510559, 4.001100001914892], "tokens_processed": [44, 44], "throughput_tok_s": [9038.248220358078, 10996.97582638324], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.729599997925106, 4.91150000016205, 4.244399999151938], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.3990593}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.020799999329029, 4.216000001179054], "tokens_processed": [44, 44], "throughput_tok_s": [8763.54365955228, 10436.432634652485], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.857899999478832, 4.958199999236967, 5.022400000598282], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.42729}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [4.498700000112876, 4.69370000064373], "tokens_processed": [44, 44], "throughput_tok_s": [9780.603285148154, 9374.26763405533], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.791100000147708, 3.9804000007279683, 4.348399997979868], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.4535978}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [3.787700003158534, 4.470599997148383], "tokens_processed": [44, 44], "throughput_tok_s": [11616.54829139286, 9842.079369226913], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.169299998669885, 4.450500000530155, 4.968199998984346], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.4798982}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [5.059400002210168, 4.978200002369704], "tokens_processed": [44, 44], "throughput_tok_s": [8696.683397394723, 8838.536012826984], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.448100000445265, 4.8439999991387594, 5.362099997000769], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.5093732}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.535900000220863, 6.827199998951983], "tokens_processed": [76, 76], "throughput_tok_s": [10085.05951482538, 11131.942818676247], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.6509999998961575, 7.207099999504862, 7.613300000230083], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.5522459}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [6.802700001571793, 6.196299997100141], "tokens_processed": [76, 76], "throughput_tok_s": [11172.034630726017, 12265.384186622321], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.358800001384225, 7.002199999988079, 6.827299999713432], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.591331}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.354000001214445, 7.263999999850057], "tokens_processed": [76, 76], "throughput_tok_s": [10334.51182858979, 10462.555066295263], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.098199999745702, 7.8018000021984335, 6.15250000191736], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.6325076}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.656699999643024, 7.237400001031347], "tokens_processed": [76, 76], "throughput_tok_s": [9925.947210096167, 10501.0086480186], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.53029999739374, 7.1649999990768265, 7.252999999764143], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.6734245}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [7.331500000873348, 7.1447000009357], "tokens_processed": [76, 76], "throughput_tok_s": [10366.227919381665, 10637.255586665182], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [7.205400001112139, 6.580299999768613, 7.53900000199792], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 197.54370000009658, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx"}, "started_at": 1765575959.7156227}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.49330000183545053, 0.47789999734959565], "tokens_processed": [8, 8], "throughput_tok_s": [16217.311920198512, 16739.90383839195], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0385999996506143, 0.7009000000834931, 0.48409999726573005], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7215939}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6100999999034684, 0.5625999983749352], "tokens_processed": [8, 8], "throughput_tok_s": [13112.604493141747, 14219.694317646507], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6629000017710496, 0.42519999988144264, 0.473000000056345], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7265975}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.6618000006710645, 0.6151000015961472], "tokens_processed": [8, 8], "throughput_tok_s": [12088.24417027502, 13006.015248318135], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6854000021121465, 0.5964999982097652, 0.6152999994810671], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7321}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5997999978717417, 0.5079999973531812], "tokens_processed": [8, 8], "throughput_tok_s": [13337.779307079427, 15748.031578114538], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7564000006823335, 0.5611999986285809, 0.7207999988168012], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.737404}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.39459999970858917, 0.5674000021826942], "tokens_processed": [8, 8], "throughput_tok_s": [20273.6948958641, 14099.400721228974], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6898999999975786, 0.4960999976901803, 0.40269999954034574], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7414021}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7740000000922009, 0.785399999585934], "tokens_processed": [11, 11], "throughput_tok_s": [14211.886303216603, 14005.602248280167], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9371000014652964, 0.6302999972831458, 0.6353999997372739], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7485485}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7834999996703118, 0.6306999966909643], "tokens_processed": [11, 11], "throughput_tok_s": [14039.566055684338, 17440.938731112554], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8832999992591795, 0.6248999998206273, 0.8139999990817159], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7546253}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8244999989983626, 0.6843999981356319], "tokens_processed": [11, 11], "throughput_tok_s": [13341.41905805126, 16072.472282239925], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9337999981653411, 0.46939999811002053, 0.5271999980323017], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7596252}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6966000000829808, 0.5266000007395633], "tokens_processed": [11, 11], "throughput_tok_s": [15790.98478135178, 20888.720061814412], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8775999995123129, 0.6872999983897898, 0.8491000007779803], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7661333}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5423000002338085, 0.8004000010259915], "tokens_processed": [11, 11], "throughput_tok_s": [20283.975650483928, 13743.128418165501], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9224000023095869, 0.49199999921256676, 0.48120000064955093], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7716353}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9233999990101438, 0.8027000003494322], "tokens_processed": [19, 19], "throughput_tok_s": [20576.131709299774, 23670.113357080976], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2136999976064544, 0.8311000019602943, 1.3318999990588054], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.77937}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.8610000004409812, 0.8328999974764884], "tokens_processed": [19, 19], "throughput_tok_s": [22067.36351947585, 22811.86223744267], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9933000001183245, 0.9194999984174501, 1.077699998859316], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7868917}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.6584000002476387, 0.597800000832649], "tokens_processed": [19, 19], "throughput_tok_s": [28857.83717019089, 31783.205041043406], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7283000015595462, 1.082700000551995, 0.8363999986613635], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.7954166}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0926000031759031, 1.0583000002952758], "tokens_processed": [19, 19], "throughput_tok_s": [17389.712561570526, 17953.321359443275], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.74939999851631, 0.9496000020590145, 0.8457000003545545], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.803555}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.1464999988675117, 1.001099997665733], "tokens_processed": [19, 19], "throughput_tok_s": [16572.17620476912, 18979.123008992447], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.222400002006907, 0.6025000002409797, 0.6355000004987232], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.8105586}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0416000004624948, 0.7247999965329655], "tokens_processed": [27, 27], "throughput_tok_s": [25921.65897466529, 37251.65580732999], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.926899996760767, 1.419000000169035, 1.0073000012198463], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.819604}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.57049999688752, 1.0834000022441614], "tokens_processed": [27, 27], "throughput_tok_s": [17191.977111435648, 24921.543238021077], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0088999990548473, 0.9308000007877126, 1.110499997594161], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.8296845}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.056999997672392, 0.9867000007943716], "tokens_processed": [27, 27], "throughput_tok_s": [25543.99248765979, 27363.94038538853], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3650000000779983, 0.7681000024604145, 1.3996000016049948], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.8376896}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [0.7742999987385701, 1.459800001612166], "tokens_processed": [27, 27], "throughput_tok_s": [34870.20540357267, 18495.68431989443], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.1137000003363937, 1.123000001825858, 0.9834999982558656], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.8469894}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.043000000208849, 0.9694000000308733], "tokens_processed": [27, 27], "throughput_tok_s": [25886.864807855756, 27852.27975978967], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.655100000789389, 1.590700001543155, 1.1488999989524018], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.8562376}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.118000000336906, 1.7192999985127244], "tokens_processed": [44, 44], "throughput_tok_s": [20774.315388574603, 25591.810642739532], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.727699998416938, 1.2091999997210223, 1.1610000001383014], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.900963}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6993000026559457, 1.6520999997737817], "tokens_processed": [44, 44], "throughput_tok_s": [25893.014730318107, 26632.770417059997], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.636299999721814, 1.542199999676086, 1.903099997434765], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9137096}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.5864000015426427, 1.525499999843305], "tokens_processed": [44, 44], "throughput_tok_s": [27735.753881249144, 28843.002297292398], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.334500000870321, 1.2326999967626762, 2.102900001773378], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9263136}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.580599997396348, 1.5836999991734046], "tokens_processed": [44, 44], "throughput_tok_s": [27837.530097734558, 27783.039731619203], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.501200000551762, 1.2390000010782387, 1.9327000009070616], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9385126}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6394000012951437, 1.5149999999266583], "tokens_processed": [44, 44], "throughput_tok_s": [26839.087449822815, 29042.90429183502], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.502300001651747, 1.2533000008261297, 2.1315999983926304], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9512155}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.277100000559585, 2.461200001562247], "tokens_processed": [76, 76], "throughput_tok_s": [23191.236149956527, 30879.245876710138], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.6483999974734616, 3.22030000097584, 2.633399999467656], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9702716}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.4593999987700954, 3.1105000016395934], "tokens_processed": [76, 76], "throughput_tok_s": [30901.845994147483, 24433.37082782164], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.152600002475083, 2.4118999972415622, 2.342200001294259], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575959.9912887}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.5113999981840607, 3.6314999997557607], "tokens_processed": [76, 76], "throughput_tok_s": [30262.005277914297, 20927.991189621764], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.971599999204045, 2.639199999975972, 3.4058999990520533], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.011317}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.6409999993338715, 2.7267999976174906], "tokens_processed": [76, 76], "throughput_tok_s": [20873.38643611765, 27871.49775062495], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.7235000020009466, 2.989799999340903, 2.7991999995720107], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0336952}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3891999990155455, 3.4763999974529725], "tokens_processed": [76, 76], "throughput_tok_s": [31809.810828442707, 21861.69602338118], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.918200000247452, 2.57929999861517, 2.8114000015193596], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 28.46329999738373, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0544941}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.46469999870168976, 0.5058999995526392], "tokens_processed": [8, 8], "throughput_tok_s": [17215.407838069594, 15813.401872058304], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5884000022197142, 0.7503000015276484, 0.5937000023550354], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0611944}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5859999982931186, 0.5242000006546732], "tokens_processed": [8, 8], "throughput_tok_s": [13651.87717287054, 15261.350610470818], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9503000001132023, 0.6714000010106247, 0.5942999996477738], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0671978}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.525999999808846, 0.534200000402052], "tokens_processed": [8, 8], "throughput_tok_s": [15209.125480812329, 14975.664533843139], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0081000000354834, 0.5708999997295905, 0.5801000006613322], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0733361}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5464999994728714, 0.43960000039078295], "tokens_processed": [8, 8], "throughput_tok_s": [14638.609346233174, 18198.362131229278], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6409999987226911, 0.6446000006690156, 0.5860999990545679], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.078334}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5619000003207475, 0.5194000004848931], "tokens_processed": [8, 8], "throughput_tok_s": [14237.408783472836, 15402.387355663244], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6923000000824686, 0.6694000003335532, 0.6142999991425313], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0828445}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5320999989635311, 0.595200002862839], "tokens_processed": [11, 11], "throughput_tok_s": [20672.805903827702, 18481.182706806703], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1411000014049932, 0.7383999982266687, 0.627500001428416], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.088852}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.659799999993993, 0.5807999987155199], "tokens_processed": [11, 11], "throughput_tok_s": [16671.71870278895, 18939.393981279743], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7082000010996126, 0.7800000021234155, 0.731400003132876], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.0943596}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6141000012576114, 0.6983999992371537], "tokens_processed": [11, 11], "throughput_tok_s": [17912.392081864797, 15750.286386046746], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.877900001796661, 0.9466999981668778, 0.7421000009344425], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1013641}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.7606999970448669, 0.5810000002384186], "tokens_processed": [11, 11], "throughput_tok_s": [14460.365509047331, 18932.874346791825], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.6896000013512094, 0.6403000006685033, 0.7628000021213666], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1068347}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6690999980492052, 0.6119999998190906], "tokens_processed": [11, 11], "throughput_tok_s": [16439.99406975199, 17973.856214463463], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0091000003740191, 0.8220999989134725, 0.7879000004322734], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1126761}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0146999993594363, 1.6479999976581894], "tokens_processed": [19, 19], "throughput_tok_s": [18724.74624223356, 11529.12622997514], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.0812000000441913, 0.629599999228958, 0.9475000006204937], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1200294}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7627999984833878, 0.6302000001596753], "tokens_processed": [19, 19], "throughput_tok_s": [24908.23287595193, 30149.158989504802], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6725999994378071, 0.8451000030618161, 0.8679000020492822], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1275895}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9066000020538922, 1.047199999447912], "tokens_processed": [19, 19], "throughput_tok_s": [20957.423292472657, 18143.621094362945], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6603000003669877, 0.8784000019659288, 0.765799999498995], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1356378}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7106999983079731, 1.13229999988107], "tokens_processed": [19, 19], "throughput_tok_s": [26734.205776326147, 16780.005300711513], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2089000010746531, 0.8654000012029428, 0.6505999990622513], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1431537}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.865399997564964, 0.8521999989170581], "tokens_processed": [19, 19], "throughput_tok_s": [21955.16530328359, 22295.235888458632], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2962000000698026, 1.0808999977598432, 1.0532000014791265], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1516213}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0958999991999008, 1.2103000008210074], "tokens_processed": [27, 27], "throughput_tok_s": [24637.284441748583, 22308.518533987062], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2967000002390705, 1.550400000269292, 1.094100000045728], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1597497}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.5321999999287073, 1.1345999992045108], "tokens_processed": [27, 27], "throughput_tok_s": [17621.72040285622, 23796.932856451793], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5807999989192467, 0.8897999978216831, 0.784400002885377], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1693218}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [0.8971999995992519, 0.7407999983115587], "tokens_processed": [27, 27], "throughput_tok_s": [30093.624623339238, 36447.084316332024], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.0363000003271736, 1.1689999992086086, 1.044600001478102], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.178439}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.53399999908288, 1.0505999998713378], "tokens_processed": [27, 27], "throughput_tok_s": [17601.043035294828, 25699.600231588203], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.9025000001420267, 1.069999998435378, 1.2292999999772292], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1883972}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.0203999991063029, 1.0812000000441913], "tokens_processed": [27, 27], "throughput_tok_s": [26460.211704868107, 24972.253051143587], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2133999989600852, 1.4049999990675133, 1.2748999979521614], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.1963813}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.6598000001977198, 2.152000000933185], "tokens_processed": [44, 44], "throughput_tok_s": [26509.217974911797, 20446.096645408925], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.3432000018365216, 1.6407000002800487, 1.8393999998806976], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.2445133}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.5248999989125878, 2.132599998731166], "tokens_processed": [44, 44], "throughput_tok_s": [28854.35112556664, 20632.092293997324], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.305900001374539, 2.0431000011740252, 1.6066999996837694], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.2575293}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.5209000011964235, 2.180600000428967], "tokens_processed": [44, 44], "throughput_tok_s": [28930.238651710948, 20177.932675109754], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.027099999395432, 2.0574999980453867, 1.5329000016208738], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.2701542}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.5681999975640792, 2.2366000011970755], "tokens_processed": [44, 44], "throughput_tok_s": [28057.645752038134, 19672.71750713148], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.300599997397512, 2.195899996877415, 1.5734000007796567], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.2832673}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.053599997452693, 1.6500999990967102], "tokens_processed": [44, 44], "throughput_tok_s": [21425.788885166567, 26665.050617590612], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.006000002438668, 2.17020000127377, 1.5199000008578878], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.2965453}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.0616999972844496, 3.19360000139568], "tokens_processed": [76, 76], "throughput_tok_s": [36862.78318868058, 23797.59517998064], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.586199996992946, 2.507799999875715, 2.829399996699067], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3156166}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.3967000015545636, 2.8443999981391244], "tokens_processed": [76, 76], "throughput_tok_s": [31710.268264991184, 26719.167504472312], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.6445000007224735, 1.6731999967305455, 3.0492999976559076], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3346364}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.1319000006769784, 2.695099999982631], "tokens_processed": [76, 76], "throughput_tok_s": [35648.951628062496, 28199.324700563913], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.8023999988799915, 3.2299999984388705, 2.449999999953434], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3536994}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.2298000005539507, 2.4622999990242533], "tokens_processed": [76, 76], "throughput_tok_s": [23530.868780409022, 30865.451013327725], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.077500001585577, 2.258500000607455, 2.4755999984336086], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3733613}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.1130999996094033, 2.451100001053419], "tokens_processed": [76, 76], "throughput_tok_s": [24412.964572142115, 31006.486870114306], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.497099998843623, 3.5472000017762184, 2.4550000016461127], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 26.390800001536263, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3925638}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.42329999996582046, 0.6388000001606997], "tokens_processed": [8, 8], "throughput_tok_s": [18899.12591695243, 12523.481524714278], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.8159000028390437, 0.6524999989778735, 0.48329999845009297], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.3997395}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5211999996390659, 0.6979000027058646], "tokens_processed": [8, 8], "throughput_tok_s": [15349.194177935624, 11462.960265056285], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.7807000001776032, 0.5088999969302677, 0.6184000012581237], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4056938}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.44490000072983094, 0.3988999997091014], "tokens_processed": [8, 8], "throughput_tok_s": [17981.568862388165, 20055.15168170974], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.815100000181701, 0.5648000005749054, 0.4955000003974419], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4111953}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.4750000007334165, 0.4989000008208677], "tokens_processed": [8, 8], "throughput_tok_s": [16842.105237153097, 16035.277584359908], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9738999979163054, 0.5989999990561046, 0.5436999999801628], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4161992}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 8}, "status": "ok", "error": null, "latencies_ms": [0.5721000015910249, 0.5614000001514796], "tokens_processed": [8, 8], "throughput_tok_s": [13983.569267176705, 14250.089059211617], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9492999997746665, 0.6309999989753123, 0.4655999982787762], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4213896}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5968999976175837, 0.5338999981177039], "tokens_processed": [11, 11], "throughput_tok_s": [18428.54756894701, 20603.109269116223], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.3064999984635506, 0.6619999985559843, 0.6487999999080785], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4285405}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5154999998921994, 0.6429000022762921], "tokens_processed": [11, 11], "throughput_tok_s": [21338.50630902096, 17109.970385834047], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.01619999986724, 0.6730000022798777, 0.5391000013332814], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4339702}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.6367000023601577, 0.8674000018800143], "tokens_processed": [11, 11], "throughput_tok_s": [17276.582313844105, 12681.577099560127], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1851999988721218, 0.6592000027012546, 0.6276000021898653], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4396837}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.5119000015838537, 0.7638999995833728], "tokens_processed": [11, 11], "throughput_tok_s": [21488.57192022904, 14399.790556354685], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.8483000019623432, 0.6760000032954849, 0.5337000002327841], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.446195}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [0.8804999997664709, 0.6864000024506822], "tokens_processed": [11, 11], "throughput_tok_s": [12492.901763676839, 16025.640968424019], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [0.9312000001955312, 0.6914000005053822, 0.6608000003325287], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4533935}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.7459000007656869, 0.8848999968904536], "tokens_processed": [19, 19], "throughput_tok_s": [25472.58343007907, 21471.35277067032], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2870999998995103, 1.2354999998933636, 1.0058000007120427], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4603999}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.8499000032315962, 1.0852000013983343], "tokens_processed": [19, 19], "throughput_tok_s": [22355.571158672574, 17508.293379577546], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6321000002790242, 0.9640999996918254, 0.7758000028843526], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4685495}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.6769999999960419, 1.0717000004660804], "tokens_processed": [19, 19], "throughput_tok_s": [28064.992614639712, 17728.84201897633], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.1462000002211425, 0.8865999989211559, 0.6242999988899101], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.4760666}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [1.0781000019051135, 0.7735999970464036], "tokens_processed": [19, 19], "throughput_tok_s": [17623.597037774834, 24560.49647433014], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.2276000015845057, 0.9538000012980774, 1.132800000050338], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.484438}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [0.9435000029043294, 1.1472000005596783], "tokens_processed": [19, 19], "throughput_tok_s": [20137.78478167805, 16562.06414812637], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.7186999975820072, 1.0049999982584268, 0.7255000018631108], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.493784}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.4569999984814785, 1.274300000659423], "tokens_processed": [27, 27], "throughput_tok_s": [18531.22857113251, 21188.10326142045], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.600999999936903, 0.8087000023806468, 0.7851000009395648], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.503293}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [0.8544000011170283, 0.7557999997516163], "tokens_processed": [27, 27], "throughput_tok_s": [31601.123554190835, 35723.736449951306], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.089900001010392, 1.1269999995420221, 1.046699999278644], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.5122893}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.315099998464575, 1.126200000726385], "tokens_processed": [27, 27], "throughput_tok_s": [20530.758141223814, 23974.427262107383], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.5812999990885146, 1.0428999994473998, 1.612399999430636], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.5224009}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.1006000022462104, 1.5978999981598463], "tokens_processed": [27, 27], "throughput_tok_s": [24532.073364433767, 16897.177564987425], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6586999990977347, 1.4517000017804094, 1.0399999991932418], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.5319035}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27}, "status": "ok", "error": null, "latencies_ms": [1.1006999993696809, 1.0562999996182043], "tokens_processed": [27, 27], "throughput_tok_s": [24529.84465836434, 25560.92020236585], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1.6952000005403534, 0.9183000001939945, 1.4658000000054017], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.541413}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0659000001614913, 1.5167999990808312], "tokens_processed": [44, 44], "throughput_tok_s": [21298.223532872125, 29008.438836144287], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.1539999983797316, 1.5550000025541522, 1.2371000011626165], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.586898}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.105799998389557, 1.574499998241663], "tokens_processed": [44, 44], "throughput_tok_s": [20894.67187465556, 27945.37951675922], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.1033999985083938, 1.6493999974045437, 1.0400000028312206], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.599398}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [1.9611999996413942, 1.4761000020371284], "tokens_processed": [44, 44], "throughput_tok_s": [22435.24373243188, 29808.278530774816], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.409799999644747, 1.67439999859198, 1.3580000013462268], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.6129396}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.175999998144107, 1.4601000002585351], "tokens_processed": [44, 44], "throughput_tok_s": [20220.588252540096, 30134.922260262356], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8953000000910833, 1.3781000016024336, 1.0604000017337967], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.6254513}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 11}, "status": "ok", "error": null, "latencies_ms": [2.0956000007572584, 1.5201000023807865], "tokens_processed": [44, 44], "throughput_tok_s": [20996.37334610628, 28945.464068868518], "predicted_tokens": [" stairs", " stairs"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2.8144999996584374, 1.5389000000141095, 1.0747999986051582], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.6376095}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.197499998350395, 2.738900002441369], "tokens_processed": [76, 76], "throughput_tok_s": [23768.56920694566, 27748.366107654896], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.462000000785338, 2.1502000017790124, 2.7979000005871058], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.6566534}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.843999998731306, 3.522099999827333], "tokens_processed": [76, 76], "throughput_tok_s": [26722.925469023634, 21578.03583195418], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.924900000332855, 3.0793999976594932, 3.707400002895156], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.6823745}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.0148000005283393, 2.4950000006356277], "tokens_processed": [76, 76], "throughput_tok_s": [25208.969081425337, 30460.921835927133], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.799399997864384, 2.0320000003266614, 2.769099999568425], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.701909}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [2.839999997377163, 2.394600000116043], "tokens_processed": [76, 76], "throughput_tok_s": [26760.563404995988, 31738.07733914517], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.631399999198038, 3.3853000022645574, 2.4677000001247507], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.7211943}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "models/tiny-gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19}, "status": "ok", "error": null, "latencies_ms": [3.2563000022491906, 2.514000003429828], "tokens_processed": [76, 76], "throughput_tok_s": [23339.37289178064, 30230.707993760487], "predicted_tokens": [" factors", " factors"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.914900000381749, 3.3075999999709893, 2.4195000005420297], "resource_metrics": null, "export_metadata": null, "trt_build_metadata": [{"onnx_path": "artifacts\\onnx\\tiny-gpt2.onnx", "output_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "build_time_s": 41.043937799997366, "file_size_mb": 3.333454132080078, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765575955.5167906}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 35.78199999901699, "engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "engine": {"engine_path": "artifacts\\tensorrt\\tiny-gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765575960.7416086}
