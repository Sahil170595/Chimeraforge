{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [47.62819999996282, 46.32599999968079], "ttft_ms": [5.849199998920085, 5.701400001271395], "tokens_processed": [8, 8], "throughput_tok_s": [167.96771660499968, 172.68920260879688], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2349.2763999984163, 187.30110000069544, 5.84799999887764], "resource_metrics": {"samples": 28, "duration_s": 3.061344861984253, "gpu_memory_mean_mb": 2620.305245535714, "gpu_memory_peak_mb": 3218.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.07142857142857142, "gpu_power_mean_watts": 29.14557142857143, "gpu_power_peak_watts": 29.367, "gpu_temperature_mean_c": 43.142857142857146, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 1738.9715401785713, "cpu_memory_peak_mb": 2062.66015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652418.5979693}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.58349999933853, 45.44560000067577], "ttft_ms": [5.6512999999540625, 5.578299998887815], "tokens_processed": [8, 8], "throughput_tok_s": [175.5021005433126, 176.03464361524638], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.400000000212458, 5.7761000007303664, 5.6957000015245285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3218.01953125, "gpu_memory_peak_mb": 3218.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 85.0, "gpu_power_mean_watts": 34.657, "gpu_power_peak_watts": 34.657, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2062.9140625, "cpu_memory_peak_mb": 2062.9140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652418.722705}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.57390000081796, 45.17110000051616], "ttft_ms": [5.549800000153482, 5.558700000619865], "tokens_processed": [8, 8], "throughput_tok_s": [175.53906950812672, 177.10438753779707], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.057399999917834, 5.700100000467501, 5.5864999994810205], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 3218.01953125, "gpu_memory_peak_mb": 3218.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 85.0, "gpu_power_mean_watts": 34.657, "gpu_power_peak_watts": 34.657, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2062.984375, "cpu_memory_peak_mb": 2062.984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652418.862202}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.647099999769125, 49.10999999992782], "ttft_ms": [5.692099999578204, 6.2009000012039905], "tokens_processed": [8, 8], "throughput_tok_s": [175.257573866477, 162.89961311365826], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.922399999690242, 5.86240000120597, 5.707700000129989], "resource_metrics": {"samples": 2, "duration_s": 0.10943818092346191, "gpu_memory_mean_mb": 3218.01953125, "gpu_memory_peak_mb": 3218.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 85.0, "gpu_power_mean_watts": 34.657, "gpu_power_peak_watts": 34.657, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2063.02734375, "cpu_memory_peak_mb": 2063.02734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652419.1096456}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.44979999991483, 45.184900000094785], "ttft_ms": [5.638300001010066, 5.558000000746688], "tokens_processed": [8, 8], "throughput_tok_s": [176.0183763188175, 177.05029777609818], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.225799999810988, 5.757099999755155, 5.676299999322509], "resource_metrics": {"samples": 2, "duration_s": 0.10831499099731445, "gpu_memory_mean_mb": 3218.01953125, "gpu_memory_peak_mb": 3218.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 85.0, "gpu_power_mean_watts": 55.643, "gpu_power_peak_watts": 55.643, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2063.0390625, "cpu_memory_peak_mb": 2063.0390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652419.3262835}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [129.83819999863044, 112.12559999876248], "ttft_ms": [24.27679999891552, 12.310699999943608], "tokens_processed": [8, 8], "throughput_tok_s": [61.61514870110942, 71.34855911663612], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [2218.690899999274, 13.521899998522713, 13.346600000659237], "resource_metrics": {"samples": 27, "duration_s": 2.8143856525421143, "gpu_memory_mean_mb": 3673.3528645833335, "gpu_memory_peak_mb": 3738.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 9.444444444444445, "gpu_power_mean_watts": 42.48455555555556, "gpu_power_peak_watts": 63.505, "gpu_temperature_mean_c": 44.592592592592595, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2081.1545138888887, "cpu_memory_peak_mb": 2433.609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652422.2554147}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.16479999914009, 108.38949999924807], "ttft_ms": [23.603199999342905, 17.66739999948186], "tokens_processed": [8, 8], "throughput_tok_s": [70.69336048012094, 73.80788729586813], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [45.41359999893757, 31.408500000907225, 39.58570000031614], "resource_metrics": {"samples": 4, "duration_s": 0.32378506660461426, "gpu_memory_mean_mb": 3738.01953125, "gpu_memory_peak_mb": 3738.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 5.75, "gpu_power_mean_watts": 32.10175, "gpu_power_peak_watts": 36.061, "gpu_temperature_mean_c": 44.25, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1994.943359375, "cpu_memory_peak_mb": 2002.00390625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652422.6884928}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [101.12979999939853, 102.76229999908537], "ttft_ms": [12.431500001184759, 12.553500000649365], "tokens_processed": [8, 8], "throughput_tok_s": [79.1062575032046, 77.84956156169338], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.138000000457396, 11.969699999099248, 11.887799999385606], "resource_metrics": {"samples": 3, "duration_s": 0.20786213874816895, "gpu_memory_mean_mb": 3738.01953125, "gpu_memory_peak_mb": 3738.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 36.061, "gpu_power_peak_watts": 36.061, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1994.4127604166667, "cpu_memory_peak_mb": 1994.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652423.0065975}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [97.68160000021453, 97.6554999997461], "ttft_ms": [12.47950000106357, 11.903399999937392], "tokens_processed": [8, 8], "throughput_tok_s": [81.89874039719282, 81.92062915064487], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.079700000365847, 15.001800000391086, 13.485899999068351], "resource_metrics": {"samples": 3, "duration_s": 0.21810579299926758, "gpu_memory_mean_mb": 3738.01953125, "gpu_memory_peak_mb": 3738.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 23.0, "gpu_power_mean_watts": 39.685, "gpu_power_peak_watts": 41.497, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1994.453125, "cpu_memory_peak_mb": 1994.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652423.333827}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [97.5936000013462, 98.36939999877359], "ttft_ms": [12.029900000925409, 11.842800000522402], "tokens_processed": [8, 8], "throughput_tok_s": [81.97258836531954, 81.3261034437512], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.615799999271985, 14.18779999949038, 12.21839999925578], "resource_metrics": {"samples": 3, "duration_s": 0.21552777290344238, "gpu_memory_mean_mb": 3738.01953125, "gpu_memory_peak_mb": 3738.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 25.333333333333332, "gpu_power_mean_watts": 41.195, "gpu_power_peak_watts": 41.497, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 1994.4609375, "cpu_memory_peak_mb": 1994.4609375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652423.6599946}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.07970000112255, 107.70699999920907], "ttft_ms": [14.255199999752222, 12.776499999745283], "tokens_processed": [8, 8], "throughput_tok_s": [74.71070613679468, 74.27558097485536], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1497.5159000005078, 12.613999999302905, 13.438500000120257], "resource_metrics": {"samples": 21, "duration_s": 2.096579074859619, "gpu_memory_mean_mb": 4183.9242931547615, "gpu_memory_peak_mb": 4258.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 12.857142857142858, "gpu_power_mean_watts": 26.249285714285715, "gpu_power_peak_watts": 40.591, "gpu_temperature_mean_c": 43.61904761904762, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2018.0926339285713, "cpu_memory_peak_mb": 2391.1171875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652425.8663676}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [119.20129999998608, 106.67850000027101], "ttft_ms": [11.903699998583761, 12.794500000381959], "tokens_processed": [8, 8], "throughput_tok_s": [67.11336201871066, 74.99168061024176], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.211999999039108, 12.335100000200327, 12.010899999950198], "resource_metrics": {"samples": 3, "duration_s": 0.21709251403808594, "gpu_memory_mean_mb": 4258.01953125, "gpu_memory_peak_mb": 4258.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.650333333333332, "gpu_power_peak_watts": 18.353, "gpu_temperature_mean_c": 43.0, "gpu_temperature_peak_c": 43, "cpu_memory_mean_mb": 2010.046875, "cpu_memory_peak_mb": 2010.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652426.1916957}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.94349999923725, 106.58730000068317], "ttft_ms": [12.708399999610265, 12.725500000669854], "tokens_processed": [8, 8], "throughput_tok_s": [74.11284607277446, 75.05584624011232], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.141000001269276, 22.317999999359017, 12.701399999059504], "resource_metrics": {"samples": 3, "duration_s": 0.22031188011169434, "gpu_memory_mean_mb": 4258.01953125, "gpu_memory_peak_mb": 4258.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 18.353, "gpu_power_peak_watts": 18.353, "gpu_temperature_mean_c": 43.0, "gpu_temperature_peak_c": 43, "cpu_memory_mean_mb": 2010.07421875, "cpu_memory_peak_mb": 2010.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652426.5200841}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [103.36610000013025, 106.1003000013443], "ttft_ms": [12.930000000778819, 13.110400001096423], "tokens_processed": [8, 8], "throughput_tok_s": [77.39481319300931, 75.40035230719083], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.888000001112232, 18.844099999114405, 13.339299999643117], "resource_metrics": {"samples": 3, "duration_s": 0.2231764793395996, "gpu_memory_mean_mb": 4258.01953125, "gpu_memory_peak_mb": 4258.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 21.614, "gpu_power_peak_watts": 21.614, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2010.10546875, "cpu_memory_peak_mb": 2010.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652426.852373}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [105.71759999947972, 106.31979999925534], "ttft_ms": [12.807400000383495, 13.76430000163964], "tokens_processed": [8, 8], "throughput_tok_s": [75.67330321573108, 75.24468631483535], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.230399999883957, 13.082500001473818, 17.70339999893622], "resource_metrics": {"samples": 3, "duration_s": 0.2177596092224121, "gpu_memory_mean_mb": 4258.01953125, "gpu_memory_peak_mb": 4258.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 21.731666666666666, "gpu_power_peak_watts": 21.967, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2010.11328125, "cpu_memory_peak_mb": 2010.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652427.1783288}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [108.32490000029793, 105.05209999973886], "ttft_ms": [14.121599999270984, 12.90309999967576], "tokens_processed": [8, 8], "throughput_tok_s": [73.85190293254826, 76.15268995117553], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1736.7395000001125, 12.589099998876918, 20.714700000098674], "resource_metrics": {"samples": 22, "duration_s": 2.331291675567627, "gpu_memory_mean_mb": 4707.110440340909, "gpu_memory_peak_mb": 4780.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 28.5, "gpu_power_mean_watts": 19.950227272727275, "gpu_power_peak_watts": 21.967, "gpu_temperature_mean_c": 43.18181818181818, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2025.2560369318182, "cpu_memory_peak_mb": 2356.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652429.6182506}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.75899999983085, 105.45089999868651], "ttft_ms": [12.963099999979022, 12.97570000133419], "tokens_processed": [8, 8], "throughput_tok_s": [76.36575377784169, 75.86469153036766], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [12.95370000116236, 18.652899998414796, 13.376599999901373], "resource_metrics": {"samples": 3, "duration_s": 0.2220458984375, "gpu_memory_mean_mb": 4780.01953125, "gpu_memory_peak_mb": 4780.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 62.0, "gpu_power_mean_watts": 21.548999999999996, "gpu_power_peak_watts": 21.549, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2023.66796875, "cpu_memory_peak_mb": 2023.66796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652429.947573}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [107.1007999998983, 105.41720000037458], "ttft_ms": [13.085199998386088, 13.228399999206886], "tokens_processed": [8, 8], "throughput_tok_s": [74.69598733163147, 75.88894411890634], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.916500000050291, 18.943300001410535, 13.03860000007262], "resource_metrics": {"samples": 3, "duration_s": 0.21974658966064453, "gpu_memory_mean_mb": 4780.01953125, "gpu_memory_peak_mb": 4780.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 62.0, "gpu_power_mean_watts": 22.673000000000002, "gpu_power_peak_watts": 23.235, "gpu_temperature_mean_c": 43.333333333333336, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2023.671875, "cpu_memory_peak_mb": 2023.671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652430.2749963}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [103.33539999919594, 106.44489999867801], "ttft_ms": [12.899000001198146, 13.090699998429045], "tokens_processed": [8, 8], "throughput_tok_s": [77.41780648318242, 75.15625455140975], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.248200001224177, 12.779399999999441, 13.123900000209687], "resource_metrics": {"samples": 3, "duration_s": 0.21835899353027344, "gpu_memory_mean_mb": 4780.01953125, "gpu_memory_peak_mb": 4780.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 62.0, "gpu_power_mean_watts": 23.235, "gpu_power_peak_watts": 23.235, "gpu_temperature_mean_c": 43.0, "gpu_temperature_peak_c": 43, "cpu_memory_mean_mb": 2023.6953125, "cpu_memory_peak_mb": 2023.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652430.6011443}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [104.31559999960882, 105.67349999837461], "ttft_ms": [12.87400000001071, 12.875600001279963], "tokens_processed": [8, 8], "throughput_tok_s": [76.69035120375092, 75.70488343930171], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.954699999885634, 14.380200000232435, 12.969100000191247], "resource_metrics": {"samples": 3, "duration_s": 0.2204298973083496, "gpu_memory_mean_mb": 4780.01953125, "gpu_memory_peak_mb": 4780.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 43.0, "gpu_power_mean_watts": 24.648, "gpu_power_peak_watts": 24.648, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2023.6953125, "cpu_memory_peak_mb": 2023.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652430.930798}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [150.36519999921438, 130.07870000001276], "ttft_ms": [20.302300001276308, 14.719200000399724], "tokens_processed": [32, 32], "throughput_tok_s": [212.81519926264315, 246.00491856081635], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1534.3119999997725, 19.39979999951902, 24.220899998908862], "resource_metrics": {"samples": 22, "duration_s": 2.174002170562744, "gpu_memory_mean_mb": 5229.474076704545, "gpu_memory_peak_mb": 5302.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.727272727272727, "gpu_power_mean_watts": 20.94540909090909, "gpu_power_peak_watts": 24.648, "gpu_temperature_mean_c": 43.13636363636363, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2038.2794744318182, "cpu_memory_peak_mb": 2395.9375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652433.210827}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [122.39489999956277, 115.50759999954607], "ttft_ms": [14.563599999746657, 14.573200000086217], "tokens_processed": [32, 32], "throughput_tok_s": [261.4488021977575, 277.0380477139665], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.988600000331644, 14.82890000079351, 14.767200000278535], "resource_metrics": {"samples": 3, "duration_s": 0.21091580390930176, "gpu_memory_mean_mb": 5302.01953125, "gpu_memory_peak_mb": 5302.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.27, "gpu_power_peak_watts": 20.27, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2052.52734375, "cpu_memory_peak_mb": 2057.40234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652433.5295296}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.27580000013404, 113.70579999857], "ttft_ms": [13.402699998550816, 13.607599999886588], "tokens_processed": [32, 32], "throughput_tok_s": [285.0124425741059, 281.4280362162919], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.154300000882358, 14.84589999927266, 13.44520000020566], "resource_metrics": {"samples": 3, "duration_s": 0.2215712070465088, "gpu_memory_mean_mb": 5302.01953125, "gpu_memory_peak_mb": 5302.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 24.231000000000005, "gpu_power_peak_watts": 24.231, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2057.4140625, "cpu_memory_peak_mb": 2057.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652433.8576238}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.22800000016287, 112.8190999988874], "ttft_ms": [13.832500000717118, 13.59969999975874], "tokens_processed": [32, 32], "throughput_tok_s": [282.61560744651473, 283.63991558446736], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.901799999075592, 32.20890000011423, 14.04739999998128], "resource_metrics": {"samples": 3, "duration_s": 0.21801304817199707, "gpu_memory_mean_mb": 5302.01953125, "gpu_memory_peak_mb": 5302.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 25.980666666666668, "gpu_power_peak_watts": 29.48, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2057.0807291666665, "cpu_memory_peak_mb": 2057.4140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652434.1836035}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.20720000003348, 112.35429999942426], "ttft_ms": [12.898999999379157, 13.647399999172194], "tokens_processed": [32, 32], "throughput_tok_s": [282.66753351368584, 284.8133093274043], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.283500000601634, 21.140200000445475, 13.110699999742792], "resource_metrics": {"samples": 3, "duration_s": 0.2207012176513672, "gpu_memory_mean_mb": 5302.01953125, "gpu_memory_peak_mb": 5302.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 47.0, "gpu_power_mean_watts": 29.48, "gpu_power_peak_watts": 29.48, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2057.4375, "cpu_memory_peak_mb": 2057.4375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652434.5122333}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [148.0039999987639, 136.25449999926786], "ttft_ms": [19.504100000631297, 17.423400000552647], "tokens_processed": [32, 32], "throughput_tok_s": [216.21037269443568, 234.8546286557284], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [1572.8928999997152, 19.218400000681868, 19.492899999022484], "resource_metrics": {"samples": 22, "duration_s": 2.2893221378326416, "gpu_memory_mean_mb": 5738.837713068182, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 11.545454545454545, "gpu_power_mean_watts": 25.427454545454545, "gpu_power_peak_watts": 32.796, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2047.8998579545455, "cpu_memory_peak_mb": 2316.45703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652436.9117079}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.43839999951888, 115.68259999876318], "ttft_ms": [13.85389999995823, 14.244599999074126], "tokens_processed": [32, 32], "throughput_tok_s": [284.6002789094911, 276.61895566266776], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [20.585399999617948, 13.87340000110271, 13.700999999855412], "resource_metrics": {"samples": 3, "duration_s": 0.20776081085205078, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.616333333333333, "gpu_power_peak_watts": 25.699, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2085.14453125, "cpu_memory_peak_mb": 2085.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652437.2278907}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [110.2097999992111, 115.99289999867324], "ttft_ms": [13.354700000490993, 13.913799999500043], "tokens_processed": [32, 32], "throughput_tok_s": [290.3553041583331, 275.8789546633115], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.084900000147172, 20.943899999110727, 13.471199999912642], "resource_metrics": {"samples": 3, "duration_s": 0.2195737361907959, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 25.699, "gpu_power_peak_watts": 25.699, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2085.16015625, "cpu_memory_peak_mb": 2085.16015625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652437.556024}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [111.18879999958153, 112.98510000051465], "ttft_ms": [13.717599998926744, 13.700299999982235], "tokens_processed": [32, 32], "throughput_tok_s": [287.79877110033055, 283.2231860648372], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.977599999634549, 17.27469999968889, 13.899300000048243], "resource_metrics": {"samples": 3, "duration_s": 0.21694660186767578, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 43.183, "gpu_power_peak_watts": 43.183, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2085.1640625, "cpu_memory_peak_mb": 2085.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652437.8808596}
{"spec": {"backend": "transformers-gpu-compile", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [113.33750000085274, 113.80940000162809], "ttft_ms": [13.823500001308275, 13.830100000632228], "tokens_processed": [32, 32], "throughput_tok_s": [282.3425609331354, 281.17185399046326], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.168999998422805, 18.815499999618623, 13.951299999462208], "resource_metrics": {"samples": 3, "duration_s": 0.21883392333984375, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 47.73333333333333, "gpu_power_peak_watts": 56.834, "gpu_temperature_mean_c": 46.666666666666664, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2085.1640625, "cpu_memory_peak_mb": 2085.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "transformers-gpu-compile", "init_ms": 1611.9693999989977, "compile_ms": 701.9200999984605, "compile_error": null, "compile_backend": "cudagraphs", "device": "cuda", "compile": true}, "started_at": 1765652438.2072434}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [112.26510000051348, 111.3389999991341], "ttft_ms": [13.531000000511995, 13.608900000690483], "tokens_processed": [8, 8], "throughput_tok_s": [71.25990178571443, 71.8526302559051], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.10850000017672, 13.901300000725314, 13.753100000030827], "resource_metrics": {"samples": 3, "duration_s": 0.2165393829345703, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 35.0, "gpu_power_mean_watts": 56.834, "gpu_power_peak_watts": 56.834, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2092.7278645833335, "cpu_memory_peak_mb": 2094.57421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652438.5310771}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [110.7929999998305, 110.76979999961623], "ttft_ms": [13.898799999878975, 13.610599999083206], "tokens_processed": [8, 8], "throughput_tok_s": [72.206727861979, 72.22185108240438], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.223500000298372, 13.707600000998355, 13.794300000881776], "resource_metrics": {"samples": 3, "duration_s": 0.22069835662841797, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 50.16, "gpu_power_peak_watts": 50.16, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2094.70703125, "cpu_memory_peak_mb": 2094.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652438.8587685}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [105.69440000108443, 112.06679999850166], "ttft_ms": [13.818499999615597, 14.01359999908891], "tokens_processed": [8, 8], "throughput_tok_s": [75.68991356134212, 71.3859947826382], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.02820000112115, 13.763000000835746, 14.095200000156183], "resource_metrics": {"samples": 3, "duration_s": 0.22162318229675293, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 40.60733333333333, "gpu_power_peak_watts": 50.16, "gpu_temperature_mean_c": 44.666666666666664, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2094.70703125, "cpu_memory_peak_mb": 2094.70703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652439.1881764}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [111.66279999997641, 110.55739999937941], "ttft_ms": [13.853300000846502, 14.02570000027481], "tokens_processed": [8, 8], "throughput_tok_s": [71.64427186136913, 72.36060182353154], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.923500000601052, 13.921300000220072, 14.254100000471226], "resource_metrics": {"samples": 3, "duration_s": 0.2093057632446289, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.502, "gpu_power_peak_watts": 21.502, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2094.73046875, "cpu_memory_peak_mb": 2094.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652439.5042784}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [101.13000000092143, 101.85880000062753], "ttft_ms": [12.566499999593361, 12.44340000084776], "tokens_processed": [8, 8], "throughput_tok_s": [79.10610105732334, 78.54009668237515], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [13.586100001703016, 12.082499999451102, 12.492899999415386], "resource_metrics": {"samples": 3, "duration_s": 0.2084801197052002, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 21.010666666666665, "gpu_power_peak_watts": 21.502, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2094.73046875, "cpu_memory_peak_mb": 2094.73046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652439.8204343}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [118.39979999967909, 111.5600999983144], "ttft_ms": [14.009900000019115, 13.71590000053402], "tokens_processed": [8, 8], "throughput_tok_s": [67.56768170234817, 71.71022614824543], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.745700000479701, 14.319600000817445, 14.610399999583024], "resource_metrics": {"samples": 3, "duration_s": 0.20868730545043945, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 20.765, "gpu_power_peak_watts": 20.765, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2095.5169270833335, "cpu_memory_peak_mb": 2095.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652440.137081}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [120.03390000063519, 119.76359999971464], "ttft_ms": [14.962499999455758, 14.797800000451389], "tokens_processed": [8, 8], "throughput_tok_s": [66.64783865189473, 66.79825923752344], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.51140000083251, 14.654399999926682, 14.77829999930691], "resource_metrics": {"samples": 3, "duration_s": 0.20821571350097656, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.031, "gpu_power_peak_watts": 19.031, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2095.8984375, "cpu_memory_peak_mb": 2095.8984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652440.452574}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [114.58450000100129, 112.17489999944519], "ttft_ms": [14.919100000042818, 14.485000001513981], "tokens_processed": [8, 8], "throughput_tok_s": [69.8174709487766, 71.31720197690899], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.501399999266141, 13.528700001188554, 14.04250000086904], "resource_metrics": {"samples": 3, "duration_s": 0.20780181884765625, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 17.263666666666666, "gpu_power_peak_watts": 19.031, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2095.90625, "cpu_memory_peak_mb": 2095.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652440.7672868}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [153.80410000034317, 150.41889999884006], "ttft_ms": [13.94599999912316, 18.820200000845944], "tokens_processed": [8, 8], "throughput_tok_s": [52.0142180863979, 53.184805899136954], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [15.459899999768822, 14.714299999468494, 14.196600001014303], "resource_metrics": {"samples": 4, "duration_s": 0.32303357124328613, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.258499999999998, "gpu_power_peak_watts": 16.38, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2095.90625, "cpu_memory_peak_mb": 2095.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652441.1987925}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [123.99750000076892, 124.09119999938412], "ttft_ms": [15.049999999973807, 15.738199999759672], "tokens_processed": [8, 8], "throughput_tok_s": [64.51742978649078, 64.46871333373926], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.636100000643637, 16.330099999322556, 14.60370000131661], "resource_metrics": {"samples": 3, "duration_s": 0.22195863723754883, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.894, "gpu_power_peak_watts": 15.894, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2095.90625, "cpu_memory_peak_mb": 2095.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652441.528116}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [138.47809999970195, 138.8970000007248], "ttft_ms": [17.3625000006723, 15.624600000592181], "tokens_processed": [8, 8], "throughput_tok_s": [57.770867740221874, 57.59663635613623], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.035899998722016, 17.849300000307267, 17.347099999824422], "resource_metrics": {"samples": 4, "duration_s": 0.3216972351074219, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 15.894, "gpu_power_peak_watts": 15.894, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2105.1787109375, "cpu_memory_peak_mb": 2106.54296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652441.9578145}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [130.52989999960118, 140.12279999951716], "ttft_ms": [16.50830000107817, 17.056300001058844], "tokens_processed": [8, 8], "throughput_tok_s": [61.28863961455914, 57.09277862009299], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.586199999641394, 15.456999999514665, 16.07979999971576], "resource_metrics": {"samples": 4, "duration_s": 0.31583166122436523, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.585249999999998, "gpu_power_peak_watts": 15.894, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2106.546875, "cpu_memory_peak_mb": 2106.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652442.3814826}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [140.8222999998543, 134.18629999978293], "ttft_ms": [17.960699999093777, 16.35580000038317], "tokens_processed": [8, 8], "throughput_tok_s": [56.809184340891164, 59.6186048800283], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.317600000751554, 18.635499998708838, 17.892700001539197], "resource_metrics": {"samples": 4, "duration_s": 0.3136329650878906, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 10.149, "gpu_power_peak_watts": 10.149, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2106.59765625, "cpu_memory_peak_mb": 2106.59765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652442.802137}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [133.87169999987236, 131.4870999995037], "ttft_ms": [15.736800000013318, 17.74440000008326], "tokens_processed": [8, 8], "throughput_tok_s": [59.758709271695416, 60.84247047832218], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.7761000013561, 16.579600000113714, 17.617700001210324], "resource_metrics": {"samples": 4, "duration_s": 0.3177347183227539, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.3265, "gpu_power_peak_watts": 10.149, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2106.703125, "cpu_memory_peak_mb": 2106.703125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652443.227242}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [140.9246000002895, 129.08519999837154], "ttft_ms": [17.997700000705663, 16.30709999881219], "tokens_processed": [8, 8], "throughput_tok_s": [56.76794541182707, 61.974571833958684], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [17.493999999715015, 17.479799998909584, 18.87659999920288], "resource_metrics": {"samples": 4, "duration_s": 0.3084859848022461, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.859, "gpu_power_peak_watts": 6.859, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2106.72265625, "cpu_memory_peak_mb": 2106.72265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652443.6438222}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [163.7204999988171, 164.50199999962933], "ttft_ms": [19.84000000084052, 20.71040000009816], "tokens_processed": [8, 8], "throughput_tok_s": [48.86376477018944, 48.63162757910558], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [18.653099999937695, 19.001900000148453, 19.74559999871417], "resource_metrics": {"samples": 4, "duration_s": 0.3098278045654297, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 6.859, "gpu_power_peak_watts": 6.859, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2109.04296875, "cpu_memory_peak_mb": 2109.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652444.061802}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [148.10140000008687, 149.5896000014909], "ttft_ms": [17.94279999921855, 18.80880000135221], "tokens_processed": [8, 8], "throughput_tok_s": [54.01704507854286, 53.47965366522985], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.471499999781372, 18.588400000226102, 18.42419999957201], "resource_metrics": {"samples": 4, "duration_s": 0.30842041969299316, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.92, "gpu_power_peak_watts": 2.92, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2109.80859375, "cpu_memory_peak_mb": 2109.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652444.4784963}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [154.82279999923776, 147.01869999953487], "ttft_ms": [20.38420000098995, 18.491299999368493], "tokens_processed": [8, 8], "throughput_tok_s": [51.67197596245118, 54.414846546903966], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.59259999966889, 20.69109999865759, 20.44930000010936], "resource_metrics": {"samples": 4, "duration_s": 0.3090095520019531, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.92, "gpu_power_peak_watts": 2.92, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2109.80859375, "cpu_memory_peak_mb": 2109.80859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652444.8959348}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [160.6461000010313, 164.97530000015104], "ttft_ms": [20.51949999986391, 20.52419999927224], "tokens_processed": [8, 8], "throughput_tok_s": [49.79890579322276, 48.492107606366986], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [21.217599998635706, 22.151500001200475, 20.47630000015488], "resource_metrics": {"samples": 4, "duration_s": 0.32205891609191895, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.332, "gpu_power_peak_watts": 2.92, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2109.859375, "cpu_memory_peak_mb": 2109.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652445.326196}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [154.94539999963308, 159.2746000005718], "ttft_ms": [19.28609999959008, 19.749400000364403], "tokens_processed": [8, 8], "throughput_tok_s": [51.6310906940054, 50.227719925030605], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [19.67530000001716, 20.104700000956655, 18.96619999934046], "resource_metrics": {"samples": 4, "duration_s": 0.3235323429107666, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.744, "gpu_power_peak_watts": 1.744, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2109.87890625, "cpu_memory_peak_mb": 2109.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652445.7575452}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [267.2238000013749, 277.5987000004534], "ttft_ms": [34.4807999990735, 33.47610000128043], "tokens_processed": [32, 32], "throughput_tok_s": [119.74981270319243, 115.27431504523521], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [34.18150000106834, 34.72409999994852, 35.50409999843396], "resource_metrics": {"samples": 7, "duration_s": 0.6239690780639648, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.745142857142857, "gpu_power_peak_watts": 1.746, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2128.4765625, "cpu_memory_peak_mb": 2134.05859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652446.488746}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [267.94990000053076, 246.70530000003055], "ttft_ms": [34.89869999975781, 28.433200001018122], "tokens_processed": [32, 32], "throughput_tok_s": [119.42531047758038, 129.70941443088591], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [29.843099999197875, 35.63720000056492, 33.95799999998417], "resource_metrics": {"samples": 6, "duration_s": 0.5217282772064209, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.7459999999999998, "gpu_power_peak_watts": 1.746, "gpu_temperature_mean_c": 44.0, "gpu_temperature_peak_c": 44, "cpu_memory_mean_mb": 2134.06640625, "cpu_memory_peak_mb": 2134.06640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652447.1175616}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [281.23059999961697, 260.6361999987712], "ttft_ms": [34.85009999894828, 33.082600000852835], "tokens_processed": [32, 32], "throughput_tok_s": [113.78562645758883, 122.7764984301907], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [32.0865000012418, 34.752100000332575, 35.56639999987965], "resource_metrics": {"samples": 7, "duration_s": 0.6131350994110107, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.711, "gpu_power_peak_watts": 1.711, "gpu_temperature_mean_c": 44.285714285714285, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2134.07421875, "cpu_memory_peak_mb": 2134.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652447.8381567}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [271.7164000005141, 251.2678999992204], "ttft_ms": [34.06800000084331, 31.09050000057323], "tokens_processed": [32, 32], "throughput_tok_s": [117.7698512122914, 127.3541108915993], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [34.22560000035446, 33.62599999854865, 34.16730000026291], "resource_metrics": {"samples": 7, "duration_s": 0.6110537052154541, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.6917142857142857, "gpu_power_peak_watts": 1.711, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2134.07421875, "cpu_memory_peak_mb": 2134.07421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652448.556583}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [273.80380000067817, 268.0590999989363], "ttft_ms": [32.84460000031686, 34.174299998994684], "tokens_processed": [32, 32], "throughput_tok_s": [116.87200835021552, 119.37665984899219], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not going to", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [35.291500000312226, 35.17130000000179, 35.32749999976659], "resource_metrics": {"samples": 7, "duration_s": 0.6216018199920654, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.682, "gpu_power_peak_watts": 1.684, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2134.08984375, "cpu_memory_peak_mb": 2134.08984375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652449.2855263}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [332.10890000009385, 350.3616999987571], "ttft_ms": [38.88410000035947, 42.801600000530016], "tokens_processed": [32, 32], "throughput_tok_s": [96.35393691644806, 91.33418407352607], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [40.520100001231185, 40.80400000020745, 38.45089999958873], "resource_metrics": {"samples": 8, "duration_s": 0.7192370891571045, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.677, "gpu_power_peak_watts": 1.677, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2156.51806640625, "cpu_memory_peak_mb": 2162.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652450.112705}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [319.5912999999564, 337.2533999990992], "ttft_ms": [40.8093000005465, 40.183799999795156], "tokens_processed": [32, 32], "throughput_tok_s": [100.12788207940694, 94.88414349591575], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [43.71440000068105, 46.53379999945173, 45.60499999934109], "resource_metrics": {"samples": 8, "duration_s": 0.7141067981719971, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.662, "gpu_power_peak_watts": 1.662, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2162.96484375, "cpu_memory_peak_mb": 2162.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652450.9352922}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [351.43390000121144, 333.3855000000767], "ttft_ms": [41.93359999953827, 45.58469999938097], "tokens_processed": [32, 32], "throughput_tok_s": [91.05552993006563, 95.984978350866], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [43.97160000007716, 43.91059999943536, 44.9014999994688], "resource_metrics": {"samples": 9, "duration_s": 0.8121757507324219, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.6522222222222223, "gpu_power_peak_watts": 1.662, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2162.96484375, "cpu_memory_peak_mb": 2162.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652451.8548968}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [362.23659999996016, 362.85919999863836], "ttft_ms": [45.16640000110783, 44.354899999234476], "tokens_processed": [32, 32], "throughput_tok_s": [88.34005177832256, 88.1884764121182], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [46.06730000159587, 46.578899999076384, 43.70860000017274], "resource_metrics": {"samples": 9, "duration_s": 0.8211777210235596, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.6408888888888888, "gpu_power_peak_watts": 1.651, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2162.97265625, "cpu_memory_peak_mb": 2162.97265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652452.7843902}
{"spec": {"backend": "onnxruntime-cpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [353.736500001105, 361.6017999993346], "ttft_ms": [45.48109999996086, 43.7820000006468], "tokens_processed": [32, 32], "throughput_tok_s": [90.46281624853539, 88.49513470358522], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [43.81899999862071, 48.65989999962039, 47.442500001125154], "resource_metrics": {"samples": 9, "duration_s": 0.8152625560760498, "gpu_memory_mean_mb": 5822.01953125, "gpu_memory_peak_mb": 5822.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.63, "gpu_power_peak_watts": 1.638, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2162.97265625, "cpu_memory_peak_mb": 2162.97265625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-cpu", "init_ms": 1008.767600000283, "providers": ["CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652453.7076766}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [162.79369999938353, 48.97340000024997], "ttft_ms": [44.77760000008857, 7.985600001120474], "tokens_processed": [8, 8], "throughput_tok_s": [49.14195082506445, 163.35398399864349], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [125.38130000029923, 44.752100000550854, 44.55630000120436], "resource_metrics": {"samples": 5, "duration_s": 0.41109347343444824, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 1.8719999999999999, "gpu_power_peak_watts": 2.856, "gpu_temperature_mean_c": 45.2, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2281.89765625, "cpu_memory_peak_mb": 2310.26953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.2263284}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.89529999952356, 27.031499999793596], "ttft_ms": [3.461699998297263, 3.3748999994713813], "tokens_processed": [8, 8], "throughput_tok_s": [297.44974029446473, 295.9510201084322], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [14.701300000524498, 11.345899998559617, 3.2934000009845477], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.856, "gpu_power_peak_watts": 2.856, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2310.27734375, "cpu_memory_peak_mb": 2310.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.3422115}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [26.574499999696855, 26.380700001027435], "ttft_ms": [3.2565999990765704, 3.30490000123973], "tokens_processed": [8, 8], "throughput_tok_s": [301.0404711317714, 303.2519986083928], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [3.8555000010092044, 3.2998999995470513, 3.3634000010351883], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.856, "gpu_power_peak_watts": 2.856, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2310.30859375, "cpu_memory_peak_mb": 2310.30859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.4686568}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.02850000100443, 29.04599999965285], "ttft_ms": [3.766999998333631, 3.6147000009805197], "tokens_processed": [8, 8], "throughput_tok_s": [275.59122929959136, 275.4251876367009], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.77830000090762, 3.7979999997332925, 3.5009000002901303], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 2.856, "gpu_power_peak_watts": 2.856, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2310.31640625, "cpu_memory_peak_mb": 2310.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.5918622}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [27.94249999897147, 27.556799999729265], "ttft_ms": [3.474199998890981, 3.4142999993491685], "tokens_processed": [8, 8], "throughput_tok_s": [286.30222779974844, 290.30946989776015], "predicted_tokens": ["", ""], "outputs": ["Hello, I'm sorry, but I'm", "Test.java:784) at net."], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.092799999853014, 3.5540000008040806, 3.5616000004665693], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 14.188, "gpu_power_peak_watts": 14.188, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2310.31640625, "cpu_memory_peak_mb": 2310.31640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.7160141}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.400699999314384, 29.59480000026815], "ttft_ms": [3.5860999996657483, 3.736900000149035], "tokens_processed": [8, 8], "throughput_tok_s": [272.1023649160244, 270.31775852269703], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.465300000447314, 3.702500000144937, 3.6825999995926395], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 14.188, "gpu_power_peak_watts": 14.188, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2311.78515625, "cpu_memory_peak_mb": 2311.78515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.8416648}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.378600000200095, 31.116099999053404], "ttft_ms": [3.6985000006097835, 3.7106999989191536], "tokens_processed": [8, 8], "throughput_tok_s": [272.3070534315969, 257.10162906801855], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.196600000796025, 3.7210999998933403, 3.5702999994100537], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 14.188, "gpu_power_peak_watts": 14.188, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2311.8515625, "cpu_memory_peak_mb": 2311.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652454.9684918}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.681599999501486, 29.912899999544607], "ttft_ms": [4.170899999735411, 3.66310000026715], "tokens_processed": [8, 8], "throughput_tok_s": [252.51249937269208, 267.44314326333426], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.36389999979292, 4.798599999048747, 4.772700000103214], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 14.188, "gpu_power_peak_watts": 14.188, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2311.8515625, "cpu_memory_peak_mb": 2311.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.094719}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.96430000005057, 30.118399999992107], "ttft_ms": [4.1143000016745646, 3.7277999999787426], "tokens_processed": [8, 8], "throughput_tok_s": [258.36204919817123, 265.6183595410811], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.4434999999793945, 4.0218999984062975, 3.8418000003730413], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 52.347, "gpu_power_peak_watts": 52.347, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2311.859375, "cpu_memory_peak_mb": 2311.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.2208643}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.392299999220995, 31.400900001244736], "ttft_ms": [3.8122000005387235, 3.8466000005428214], "tokens_processed": [8, 8], "throughput_tok_s": [263.22456675556157, 254.76976773541136], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [16.209600000365754, 16.659900000377093, 3.7909000002400717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 52.347, "gpu_power_peak_watts": 52.347, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2311.921875, "cpu_memory_peak_mb": 2311.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.3591042}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.86790000088513, 31.611899999916204], "ttft_ms": [3.7491000002773944, 3.789800000959076], "tokens_processed": [8, 8], "throughput_tok_s": [259.1689100901131, 253.06925556582192], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.926899999190937, 3.800500000579632, 3.99210000068706], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 52.347, "gpu_power_peak_watts": 52.347, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2317.92578125, "cpu_memory_peak_mb": 2317.92578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.486005}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.14840000125696, 30.989499999122927], "ttft_ms": [3.6915000000590226, 4.062500000145519], "tokens_processed": [8, 8], "throughput_tok_s": [256.83502201323887, 258.15195470163826], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.614600000422797, 3.961600001275656, 3.5963999998784857], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 24.0, "gpu_power_mean_watts": 52.347, "gpu_power_peak_watts": 52.347, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2323.1796875, "cpu_memory_peak_mb": 2323.1796875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.6095493}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.411899999307934, 31.204799999613897], "ttft_ms": [3.823299999567098, 3.8362999985110946], "tokens_processed": [8, 8], "throughput_tok_s": [263.0549225856343, 256.3708147496214], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.861299999902258, 3.820800000539748, 3.953600000386359], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 59.657, "gpu_power_peak_watts": 59.657, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2323.1875, "cpu_memory_peak_mb": 2323.1875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.7342377}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [29.90519999912067, 30.16829999978654], "ttft_ms": [3.894699999364093, 3.9211999992403435], "tokens_processed": [8, 8], "throughput_tok_s": [267.5120046090724, 265.17901240893934], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.736800001410302, 3.881000000546919, 3.684199999042903], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 59.657, "gpu_power_peak_watts": 59.657, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2323.1953125, "cpu_memory_peak_mb": 2323.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.8610177}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [31.92480000143405, 31.749400000990136], "ttft_ms": [4.33320000047388, 3.753099999812548], "tokens_processed": [8, 8], "throughput_tok_s": [250.58888386585485, 251.97326562865794], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.675800000972231, 4.869500000495464, 4.3203999994148035], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 59.657, "gpu_power_peak_watts": 59.657, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2323.1953125, "cpu_memory_peak_mb": 2323.1953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652455.9871964}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [34.44310000122641, 31.922000000122353], "ttft_ms": [3.664500000013504, 3.897400001733331], "tokens_processed": [8, 8], "throughput_tok_s": [232.26713041843342, 250.610863979993], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.965099999026279, 3.874200001519057, 3.9443999994546175], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 59.657, "gpu_power_peak_watts": 59.657, "gpu_temperature_mean_c": 50.0, "gpu_temperature_peak_c": 50, "cpu_memory_mean_mb": 2324.6953125, "cpu_memory_peak_mb": 2324.6953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.1153076}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [61.02710000050138, 66.17019999976037], "ttft_ms": [6.283000000621541, 12.05159999881289], "tokens_processed": [8, 8], "throughput_tok_s": [131.08930294794075, 120.90034486867157], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.412099999986822, 10.791999999128166, 8.53129999995872], "resource_metrics": {"samples": 2, "duration_s": 0.1136178970336914, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 60.22, "gpu_power_peak_watts": 60.22, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2326.203125, "cpu_memory_peak_mb": 2326.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.3388193}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [30.524899999363697, 30.783999998675426], "ttft_ms": [3.78160000036587, 3.704900000229827], "tokens_processed": [8, 8], "throughput_tok_s": [262.0811206643351, 259.87525988644177], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [4.96469999961846, 4.104599998754566, 3.9013000005070353], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 60.22, "gpu_power_peak_watts": 60.22, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2326.203125, "cpu_memory_peak_mb": 2326.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.4554114}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [45.816600000762264, 35.959400000137975], "ttft_ms": [3.7614000011672033, 4.590700000335346], "tokens_processed": [8, 8], "throughput_tok_s": [174.6092027751274, 222.47312246503847], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.925900001078844, 9.525100000246312, 3.887800001393771], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 32.0, "gpu_power_mean_watts": 60.22, "gpu_power_peak_watts": 60.22, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2326.203125, "cpu_memory_peak_mb": 2326.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.5781882}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [33.50500000124157, 32.37770000123419], "ttft_ms": [4.176700000243727, 4.061599998749443], "tokens_processed": [8, 8], "throughput_tok_s": [238.7703327773034, 247.08364089157203], "predicted_tokens": ["", ""], "outputs": ["Provide a concise overview of the attention mechanism and how KV cache impacts latency in local inference pipelines. Keep it under 120 words.\n\nThe KV cache is a", "Explain how dynamic shapes affect TensorRT engine builds and runtime performance, and when you would choose static vs dynamic profiles.\n\nThe following is a list of"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [8.042500001465669, 6.975599999350379, 4.707199999756995], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 59.666, "gpu_power_peak_watts": 59.666, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2326.203125, "cpu_memory_peak_mb": 2326.203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.7042434}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [39.337300000624964, 36.15180000088003], "ttft_ms": [4.830999998375773, 4.421800000272924], "tokens_processed": [32, 32], "throughput_tok_s": [813.477284904953, 885.1564790472684], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.487099999503698, 4.668100000344566, 4.758099999889964], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 59.666, "gpu_power_peak_watts": 59.666, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2334.28125, "cpu_memory_peak_mb": 2334.28125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.8276672}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.539900000207126, 36.852400000498164], "ttft_ms": [4.821700000320561, 4.92110000050161], "tokens_processed": [32, 32], "throughput_tok_s": [875.7549965878015, 868.3287926856169], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.824600000778446, 5.120199999510078, 4.7786999984964496], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 59.666, "gpu_power_peak_watts": 59.666, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2349.859375, "cpu_memory_peak_mb": 2349.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652456.955211}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.42309999850113, 37.2148999995261], "ttft_ms": [4.51950000024226, 4.435800001374446], "tokens_processed": [32, 32], "throughput_tok_s": [878.5633293518907, 859.8706432210619], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.866999999852851, 4.595600001266575, 4.650000000765431], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 59.666, "gpu_power_peak_watts": 59.666, "gpu_temperature_mean_c": 51.0, "gpu_temperature_peak_c": 51, "cpu_memory_mean_mb": 2349.859375, "cpu_memory_peak_mb": 2349.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.077874}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [37.32830000080867, 37.64720000071975], "ttft_ms": [4.549999999653664, 4.818600000362494], "tokens_processed": [32, 32], "throughput_tok_s": [857.2584339310058, 849.9968124957026], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.395999998654588, 4.668499999752385, 4.537799999525305], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 64.116, "gpu_power_peak_watts": 64.116, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 2349.859375, "cpu_memory_peak_mb": 2349.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.2013986}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [36.98929999882239, 36.324799999420065], "ttft_ms": [4.766699999890989, 4.480499999772292], "tokens_processed": [32, 32], "throughput_tok_s": [865.1150468113419, 880.9408448363346], "predicted_tokens": ["", ""], "outputs": ["Summarize RLHF in one sentence.\n\n\"I'm not sure if", "List two ways to improve throughput on local LLMs.\n\nThe first is to use the"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [10.114800001247204, 4.639500000848784, 4.739299998618662], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 64.116, "gpu_power_peak_watts": 64.116, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 2349.859375, "cpu_memory_peak_mb": 2349.859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.3252213}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.868000000249594, 40.592699999251636], "ttft_ms": [5.0771000005624956, 5.06630000018049], "tokens_processed": [32, 32], "throughput_tok_s": [764.3068692034307, 788.3190820169624], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.798500000513741, 5.264299999907962, 5.055699999502394], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 64.116, "gpu_power_peak_watts": 64.116, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 2356.10546875, "cpu_memory_peak_mb": 2356.10546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.4491756}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [40.35209999892686, 41.41340000023774], "ttft_ms": [5.104000001665554, 4.9051000005420065], "tokens_processed": [32, 32], "throughput_tok_s": [793.0194463448252, 772.6967599814625], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [6.287500000325963, 4.96000000021013, 4.990400000679074], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 33.0, "gpu_power_mean_watts": 64.116, "gpu_power_peak_watts": 64.116, "gpu_temperature_mean_c": 52.0, "gpu_temperature_peak_c": 52, "cpu_memory_mean_mb": 2378.84375, "cpu_memory_peak_mb": 2378.84375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.5759985}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.185399999449146, 41.00490000018908], "ttft_ms": [4.926400000840658, 5.286300000079791], "tokens_processed": [32, 32], "throughput_tok_s": [776.9743647124467, 780.3945382101272], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.902599999899394, 5.051599999205791, 5.110100000820239], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 65.0, "gpu_power_mean_watts": 70.595, "gpu_power_peak_watts": 70.595, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 2378.84375, "cpu_memory_peak_mb": 2378.84375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.6968935}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [42.57770000003802, 40.29599999921629], "ttft_ms": [5.505700000867364, 5.145099999936065], "tokens_processed": [32, 32], "throughput_tok_s": [751.5671349079782, 794.1234862175492], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.6745000001683366, 5.264999999781139, 5.618799999865587], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 65.0, "gpu_power_mean_watts": 70.595, "gpu_power_peak_watts": 70.595, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 2378.8515625, "cpu_memory_peak_mb": 2378.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.8379502}
{"spec": {"backend": "onnxruntime-gpu", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "ok", "error": null, "latencies_ms": [41.386499999134685, 41.17480000059004], "ttft_ms": [5.114999999932479, 4.951799999616924], "tokens_processed": [32, 32], "throughput_tok_s": [773.1989900249855, 777.1743882068993], "predicted_tokens": ["", ""], "outputs": ["Explain how backpressure works in an inference service and when to enable queueing.\n\nThe following example shows how to", "Compare torch.compile vs ONNXRuntime on CPU for small models in two sentences.\n\nThe following code snippet shows how"], "degraded_count": 0, "degraded_reasons": [], "warmup_latencies_ms": [5.767799999375711, 5.239699999947334, 4.893199999060016], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 5832.01953125, "gpu_memory_peak_mb": 5832.01953125, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 65.0, "gpu_power_mean_watts": 70.595, "gpu_power_peak_watts": 70.595, "gpu_temperature_mean_c": 53.0, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 2378.8515625, "cpu_memory_peak_mb": 2378.8515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "onnxruntime-gpu", "init_ms": 1488.0880000000616, "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"], "input_type": "tensor(int32)", "onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx"}, "started_at": 1765652457.963086}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [9.343399999124813, 2.158699999199598, 2.118600001267623], "resource_metrics": {"samples": 10, "duration_s": 0.9371321201324463, "gpu_memory_mean_mb": 6104.333203125, "gpu_memory_peak_mb": 6817.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 39.0, "gpu_power_mean_watts": 65.61330000000001, "gpu_power_peak_watts": 72.554, "gpu_temperature_mean_c": 49.9, "gpu_temperature_peak_c": 53, "cpu_memory_mean_mb": 2850.1953125, "cpu_memory_peak_mb": 3331.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32"}, "started_at": 1765652459.007118}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.440000000206055, 2.181600000767503, 2.077099999951315], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 55.692, "gpu_power_peak_watts": 55.692, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.0859375, "cpu_memory_peak_mb": 2579.0859375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.1258488}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.9581000000907807, 3.202199999577715, 2.2045999994588783], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 38.185, "gpu_power_peak_watts": 38.185, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.109375, "cpu_memory_peak_mb": 2579.109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.2484393}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.526599999939208, 2.9697000009036856, 2.4183999994420446], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 38.185, "gpu_power_peak_watts": 38.185, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.1328125, "cpu_memory_peak_mb": 2579.1328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.3727863}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6276999999245163, 2.6673000011214754, 2.093099999910919], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 38.185, "gpu_power_peak_watts": 38.185, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.13671875, "cpu_memory_peak_mb": 2579.13671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.4944038}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.5751999985222938, 2.166800000850344, 2.210200000263285], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 38.185, "gpu_power_peak_watts": 38.185, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.84765625, "cpu_memory_peak_mb": 2579.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.6187103}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.786899998682202, 2.163999999538646, 2.3003999995125923], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.508, "gpu_power_peak_watts": 37.508, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.890625, "cpu_memory_peak_mb": 2579.890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.7446291}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2702000007702736, 2.1643000000040047, 2.1486999994522193], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.508, "gpu_power_peak_watts": 37.508, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.90234375, "cpu_memory_peak_mb": 2579.90234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.8697948}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.7282999999442836, 2.2425000006478513, 2.191899999161251], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.508, "gpu_power_peak_watts": 37.508, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.90625, "cpu_memory_peak_mb": 2579.90625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652459.994819}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.8984999989916105, 2.248900000267895, 2.252000000225962], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7031.0390625, "gpu_memory_peak_mb": 7031.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.508, "gpu_power_peak_watts": 37.508, "gpu_temperature_mean_c": 49.0, "gpu_temperature_peak_c": 49, "cpu_memory_mean_mb": 2579.9453125, "cpu_memory_peak_mb": 2579.9453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.119779}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.530099999712547, 2.4348999995709164, 2.398999999059015], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7033.0390625, "gpu_memory_peak_mb": 7033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.322, "gpu_power_peak_watts": 37.322, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2581.51953125, "cpu_memory_peak_mb": 2581.51953125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.243728}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1560999996145256, 2.476899999237503, 2.3349000002781395], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7033.0390625, "gpu_memory_peak_mb": 7033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.322, "gpu_power_peak_watts": 37.322, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2581.515625, "cpu_memory_peak_mb": 2581.515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.3674376}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.4854000004997943, 2.3462999997718725, 2.3741999993944773], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7033.0390625, "gpu_memory_peak_mb": 7033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.322, "gpu_power_peak_watts": 37.322, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2581.53125, "cpu_memory_peak_mb": 2581.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.4930866}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2644000002619578, 2.411999999822001, 2.3540999991382705], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7033.0390625, "gpu_memory_peak_mb": 7033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 37.322, "gpu_power_peak_watts": 37.322, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2581.53125, "cpu_memory_peak_mb": 2581.53125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.6192374}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9296000011527212, 2.4009000007936265, 2.518900000723079], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7033.0390625, "gpu_memory_peak_mb": 7033.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.674, "gpu_power_peak_watts": 34.674, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2581.546875, "cpu_memory_peak_mb": 2581.546875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.7441497}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.332500000600703, 2.555400000346708, 2.5722999998833984], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7035.0390625, "gpu_memory_peak_mb": 7035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.674, "gpu_power_peak_watts": 34.674, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2583.14453125, "cpu_memory_peak_mb": 2583.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.8683014}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.8881999989826, 2.653600000485312, 2.561200000855024], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7035.0390625, "gpu_memory_peak_mb": 7035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.674, "gpu_power_peak_watts": 34.674, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2583.14453125, "cpu_memory_peak_mb": 2583.14453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652460.9924676}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.683500001192442, 2.802499999233987, 2.709500000491971], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7035.0390625, "gpu_memory_peak_mb": 7035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.674, "gpu_power_peak_watts": 34.674, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2583.15234375, "cpu_memory_peak_mb": 2583.15234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.117146}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.7981999994372018, 2.7448000000731554, 2.6062999986606883], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7035.0390625, "gpu_memory_peak_mb": 7035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.158, "gpu_power_peak_watts": 33.158, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2583.1640625, "cpu_memory_peak_mb": 2583.1640625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.2403498}
{"spec": {"backend": "tensorrt-fp32", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.181399999448331, 2.613299999211449, 2.613700000438257], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7035.0390625, "gpu_memory_peak_mb": 7035.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.158, "gpu_power_peak_watts": 33.158, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2583.17578125, "cpu_memory_peak_mb": 2583.17578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.3671777}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.280799999236478, 3.5719999996217666, 3.500700000586221], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7027.0390625, "gpu_memory_peak_mb": 7027.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.158, "gpu_power_peak_watts": 33.158, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2582.921875, "cpu_memory_peak_mb": 2582.921875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.4910755}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.166099999769358, 3.52759999987029, 3.505099999529193], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7043.0390625, "gpu_memory_peak_mb": 7043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 33.158, "gpu_power_peak_watts": 33.158, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2604.27734375, "cpu_memory_peak_mb": 2604.27734375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.6168158}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.9515999999130145, 3.5165000008419156, 3.509000000121887], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7043.0390625, "gpu_memory_peak_mb": 7043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 33.755, "gpu_power_peak_watts": 33.755, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2604.28515625, "cpu_memory_peak_mb": 2604.28515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.7427373}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.087399999363697, 3.5997000013594516, 3.7904999990132637], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7043.0390625, "gpu_memory_peak_mb": 7043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 33.755, "gpu_power_peak_watts": 33.755, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2604.328125, "cpu_memory_peak_mb": 2604.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.868763}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.917199999908917, 3.530599999066908, 3.5504999996192055], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7043.0390625, "gpu_memory_peak_mb": 7043.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 33.755, "gpu_power_peak_watts": 33.755, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2604.328125, "cpu_memory_peak_mb": 2604.328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652461.99389}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.370300000431598, 4.278899999917485, 4.179899999144254], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7049.0390625, "gpu_memory_peak_mb": 7049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 33.755, "gpu_power_peak_watts": 33.755, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2610.64453125, "cpu_memory_peak_mb": 2610.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652462.1190884}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.004300001222873, 4.240199999912875, 4.214299999148352], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7049.0390625, "gpu_memory_peak_mb": 7049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 34.378, "gpu_power_peak_watts": 34.378, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2610.64453125, "cpu_memory_peak_mb": 2610.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652462.2450776}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.627799999478157, 4.238699999405071, 4.198999999061925], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7049.0390625, "gpu_memory_peak_mb": 7049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 34.378, "gpu_power_peak_watts": 34.378, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2610.64453125, "cpu_memory_peak_mb": 2610.64453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652462.3679528}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.117100001574727, 4.2714000010164455, 4.271100000551087], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7049.0390625, "gpu_memory_peak_mb": 7049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 34.378, "gpu_power_peak_watts": 34.378, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2610.65234375, "cpu_memory_peak_mb": 2610.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652462.492526}
{"spec": {"backend": "tensorrt-fp32", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.587099998796475, 4.127199999857112, 4.247200000463636], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7049.0390625, "gpu_memory_peak_mb": 7049.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 13.0, "gpu_power_mean_watts": 34.378, "gpu_power_peak_watts": 34.378, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2610.65234375, "cpu_memory_peak_mb": 2610.65234375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp32", "init_ms": 1015.9626999993634, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 5, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652462.6180665}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [86.77830000124231, 3.098600000157603, 1.9937999986723298], "resource_metrics": {"samples": 3, "duration_s": 0.21363496780395508, "gpu_memory_mean_mb": 7225.705729166667, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 35.467, "gpu_power_peak_watts": 35.467, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2734.5, "cpu_memory_peak_mb": 2902.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16"}, "started_at": 1765652462.943254}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.133800001000054, 3.0007000004843576, 2.9479999993782258], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 35.467, "gpu_power_peak_watts": 35.467, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2703.9296875, "cpu_memory_peak_mb": 2703.9296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.0687072}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.135299999688868, 2.796299999317853, 2.3414999996020924], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.004, "gpu_power_peak_watts": 34.004, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2703.9375, "cpu_memory_peak_mb": 2703.9375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.194031}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.418299999088049, 2.8505000009317882, 2.6830000006157206], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.004, "gpu_power_peak_watts": 34.004, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2703.96484375, "cpu_memory_peak_mb": 2703.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.3175254}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.6402000005182344, 2.982699999847682, 3.08729999960633], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.004, "gpu_power_peak_watts": 34.004, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2703.96484375, "cpu_memory_peak_mb": 2703.96484375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.4411087}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.312499999286956, 1.7167999994853744, 1.6925999989325646], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 34.004, "gpu_power_peak_watts": 34.004, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2704.71875, "cpu_memory_peak_mb": 2704.71875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.5671809}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.44050000057905, 2.90090000089549, 3.168200000800425], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.276, "gpu_power_peak_watts": 32.276, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2704.73828125, "cpu_memory_peak_mb": 2704.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.6880298}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.447299999606912, 3.0405000015889527, 2.9119999999238644], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.276, "gpu_power_peak_watts": 32.276, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2704.73828125, "cpu_memory_peak_mb": 2704.73828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.811989}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.2168000014062272, 1.5750000002299203, 1.466799998524948], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.276, "gpu_power_peak_watts": 32.276, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2704.7421875, "cpu_memory_peak_mb": 2704.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652463.9358716}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.641899999318412, 1.6603999993094476, 1.5478000004804926], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7335.0390625, "gpu_memory_peak_mb": 7335.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.276, "gpu_power_peak_watts": 32.276, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2704.7421875, "cpu_memory_peak_mb": 2704.7421875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.0604703}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.962800001114374, 1.6465000007883646, 1.5893999989202712], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7337.0390625, "gpu_memory_peak_mb": 7337.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.057, "gpu_power_peak_watts": 32.057, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2706.3046875, "cpu_memory_peak_mb": 2706.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.1842146}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6943000011669938, 1.7148999995697523, 1.5963000005285721], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7337.0390625, "gpu_memory_peak_mb": 7337.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.057, "gpu_power_peak_watts": 32.057, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2706.3046875, "cpu_memory_peak_mb": 2706.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.308291}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.446500000587548, 1.6276999995170627, 1.5934999992168741], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7337.0390625, "gpu_memory_peak_mb": 7337.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.057, "gpu_power_peak_watts": 32.057, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2706.3046875, "cpu_memory_peak_mb": 2706.3046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.4380374}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.108099999735714, 2.741400001468719, 2.7114999993500533], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7337.0390625, "gpu_memory_peak_mb": 7337.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 4.0, "gpu_power_mean_watts": 32.057, "gpu_power_peak_watts": 32.057, "gpu_temperature_mean_c": 48.0, "gpu_temperature_peak_c": 48, "cpu_memory_mean_mb": 2706.3125, "cpu_memory_peak_mb": 2706.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.556931}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2154999989870703, 2.7602999998634914, 2.7453000002424233], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7337.0390625, "gpu_memory_peak_mb": 7337.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 29.528, "gpu_power_peak_watts": 29.528, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2706.3125, "cpu_memory_peak_mb": 2706.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.6815484}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.683999999542721, 3.1625999999960186, 3.1376000006275717], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7339.0390625, "gpu_memory_peak_mb": 7339.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 29.528, "gpu_power_peak_watts": 29.528, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2707.84765625, "cpu_memory_peak_mb": 2707.84765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.8047693}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.0585000006103655, 3.3285999998042826, 3.2630000005156035], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7339.0390625, "gpu_memory_peak_mb": 7339.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 29.528, "gpu_power_peak_watts": 29.528, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2707.87109375, "cpu_memory_peak_mb": 2707.87109375, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652464.93114}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.05750000027183, 3.5349999998288695, 3.5444000004645204], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7339.0390625, "gpu_memory_peak_mb": 7339.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 29.528, "gpu_power_peak_watts": 29.528, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2707.87890625, "cpu_memory_peak_mb": 2707.87890625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.0550869}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.488300000957679, 3.634599999713828, 3.6315999986982206], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7339.0390625, "gpu_memory_peak_mb": 7339.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 22.735, "gpu_power_peak_watts": 22.735, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2707.88671875, "cpu_memory_peak_mb": 2707.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.178271}
{"spec": {"backend": "tensorrt-fp16", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.6351999990292825, 3.6443999997572973, 3.6847999999736203], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 7339.0390625, "gpu_memory_peak_mb": 7339.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 8.0, "gpu_power_mean_watts": 22.735, "gpu_power_peak_watts": 22.735, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2707.88671875, "cpu_memory_peak_mb": 2707.88671875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.3012977}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.4268706}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.5505564}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.675284}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.801084}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_short", "prompt_set": "batch_short", "model": "gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x19", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x19"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652465.940299}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "gpt2", "repetition": 0, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652466.068129}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "gpt2", "repetition": 1, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652466.1916277}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "gpt2", "repetition": 2, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652466.315378}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "gpt2", "repetition": 3, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652466.4409583}
{"spec": {"backend": "tensorrt-fp16", "scenario": "batch_medium", "prompt_set": "batch_medium", "model": "gpt2", "repetition": 4, "batch_size": 0, "seq_len": 0, "mode": "generate"}, "status": "error", "error": "set_input_shape_failed:input_ids:4x27", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 1, "degraded_reasons": ["exception:RuntimeError:set_input_shape_failed:input_ids:4x27"], "warmup_latencies_ms": [], "resource_metrics": null, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-fp16", "init_ms": 198.14380000025267, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 1, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652466.5657625}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [8.762699999351753, 2.2159000000101514, 2.1951999988232274], "resource_metrics": {"samples": 7, "duration_s": 0.6978795528411865, "gpu_memory_mean_mb": 7799.324776785715, "gpu_memory_peak_mb": 8305.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 11.463, "gpu_power_peak_watts": 12.606, "gpu_temperature_mean_c": 45.57142857142857, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 3261.9737723214284, "cpu_memory_peak_mb": 3482.3125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8"}, "started_at": 1765652467.3728604}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.908400000000256, 3.696499999932712, 2.734499999860418], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.939, "gpu_power_peak_watts": 9.939, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2728.453125, "cpu_memory_peak_mb": 2728.453125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652467.4938045}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.9500000000552973, 2.1548999993683537, 2.142999999705353], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 9.939, "gpu_power_peak_watts": 9.939, "gpu_temperature_mean_c": 45.0, "gpu_temperature_peak_c": 45, "cpu_memory_mean_mb": 2728.46875, "cpu_memory_peak_mb": 2728.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652467.6185367}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.32120000004943, 3.4967000010510674, 2.117599999110098], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.414, "gpu_power_peak_watts": 16.414, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2728.46875, "cpu_memory_peak_mb": 2728.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652467.7430382}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_micro", "prompt_set": "micro", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 16, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.606000000014319, 2.134100001057959, 2.144299998690258], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.414, "gpu_power_peak_watts": 16.414, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2728.46875, "cpu_memory_peak_mb": 2728.46875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652467.8707922}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.54130000071018, 2.2379000001819804, 2.307900000232621], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.414, "gpu_power_peak_watts": 16.414, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2729.04296875, "cpu_memory_peak_mb": 2729.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652467.9939687}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.511799999818322, 3.6041000003024237, 2.203600000939332], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 16.414, "gpu_power_peak_watts": 16.414, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2729.04296875, "cpu_memory_peak_mb": 2729.04296875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.1184914}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.2465000003867317, 2.242599999590311, 2.2004999991622753], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 28.252, "gpu_power_peak_watts": 28.252, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2729.046875, "cpu_memory_peak_mb": 2729.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.2436607}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0363000005309004, 2.209700000094017, 2.198599999246653], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 28.252, "gpu_power_peak_watts": 28.252, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2729.046875, "cpu_memory_peak_mb": 2729.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.3670707}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [2.6560000005702022, 2.2214000000531087, 2.1967000011500204], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8309.0390625, "gpu_memory_peak_mb": 8309.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 28.252, "gpu_power_peak_watts": 28.252, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2729.046875, "cpu_memory_peak_mb": 2729.046875, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.4911625}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [4.386700000395649, 2.383400000326219, 2.4227000012615463], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 28.252, "gpu_power_peak_watts": 28.252, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2730.58203125, "cpu_memory_peak_mb": 2730.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.6153288}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.731599999809987, 2.4051000000326894, 2.3660999995627208], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.583, "gpu_power_peak_watts": 32.583, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2730.58203125, "cpu_memory_peak_mb": 2730.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.739945}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1918999993649777, 2.4099999991449295, 2.373999999690568], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.583, "gpu_power_peak_watts": 32.583, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2730.58203125, "cpu_memory_peak_mb": 2730.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.8658683}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.1221999997796956, 2.379999999902793, 2.3794999997335253], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.583, "gpu_power_peak_watts": 32.583, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2730.58203125, "cpu_memory_peak_mb": 2730.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652468.9911861}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [3.0476000010821735, 2.415599999949336, 2.392100001088693], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8311.0390625, "gpu_memory_peak_mb": 8311.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.583, "gpu_power_peak_watts": 32.583, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2730.58203125, "cpu_memory_peak_mb": 2730.58203125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.116819}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 0, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [6.490499999927124, 4.80980000065756, 4.768999999214429], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8313.0390625, "gpu_memory_peak_mb": 8313.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.651, "gpu_power_peak_watts": 32.651, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2732.11328125, "cpu_memory_peak_mb": 2732.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.2393763}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 1, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.523599998923601, 4.930099999910453, 5.017800000132411], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8313.0390625, "gpu_memory_peak_mb": 8313.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.651, "gpu_power_peak_watts": 32.651, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2732.11328125, "cpu_memory_peak_mb": 2732.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.362512}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 2, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.466900000101305, 4.999499999030377, 4.982799999197596], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8313.0390625, "gpu_memory_peak_mb": 8313.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.651, "gpu_power_peak_watts": 32.651, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2732.11328125, "cpu_memory_peak_mb": 2732.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.4876435}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 3, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [5.603100000371342, 5.083199999717181, 5.064999999376596], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8313.0390625, "gpu_memory_peak_mb": 8313.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 32.651, "gpu_power_peak_watts": 32.651, "gpu_temperature_mean_c": 47.0, "gpu_temperature_peak_c": 47, "cpu_memory_mean_mb": 2732.11328125, "cpu_memory_peak_mb": 2732.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.6130896}
{"spec": {"backend": "tensorrt-int8", "scenario": "single_long", "prompt_set": "long", "model": "gpt2", "repetition": 4, "batch_size": 1, "seq_len": 35, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [7.119500000044354, 5.305399999997462, 5.330399999365909], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8313.0390625, "gpu_memory_peak_mb": 8313.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 26.218, "gpu_power_peak_watts": 26.218, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2732.11328125, "cpu_memory_peak_mb": 2732.11328125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.7533555}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [15.665300001273863, 9.53040000058536, 9.551300001476193], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8305.0390625, "gpu_memory_peak_mb": 8305.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 26.218, "gpu_power_peak_watts": 26.218, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2730.2578125, "cpu_memory_peak_mb": 2730.2578125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.8750312}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.42799999959243, 9.563400000843103, 9.511299998848699], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8323.0390625, "gpu_memory_peak_mb": 8323.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 26.218, "gpu_power_peak_watts": 26.218, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2752.80078125, "cpu_memory_peak_mb": 2752.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652469.9993784}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [10.928199999398203, 9.969999999157153, 9.89579999986745], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8323.0390625, "gpu_memory_peak_mb": 8323.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 26.218, "gpu_power_peak_watts": 26.218, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2752.80078125, "cpu_memory_peak_mb": 2752.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.125925}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.372200000550947, 10.14979999854404, 10.172800000873394], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8323.0390625, "gpu_memory_peak_mb": 8323.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.545, "gpu_power_peak_watts": 19.545, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2749.19140625, "cpu_memory_peak_mb": 2749.19140625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.2497802}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_short", "prompt_set": "short", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 19, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [11.329199998726835, 10.264700000334415, 10.254300001179217], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8323.0390625, "gpu_memory_peak_mb": 8323.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.545, "gpu_power_peak_watts": 19.545, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2752.80078125, "cpu_memory_peak_mb": 2752.80078125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.3740432}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 0, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.72579999951995, 11.432600000262028, 11.397099999157945], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8329.0390625, "gpu_memory_peak_mb": 8329.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.545, "gpu_power_peak_watts": 19.545, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2759.03515625, "cpu_memory_peak_mb": 2759.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.5005627}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 1, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.279500000659027, 11.593199998969794, 11.57950000015262], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8329.0390625, "gpu_memory_peak_mb": 8329.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 0.0, "gpu_power_mean_watts": 19.545, "gpu_power_peak_watts": 19.545, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2749.9765625, "cpu_memory_peak_mb": 2749.9765625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.62431}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 2, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [12.889900001027854, 11.76349999877857, 11.771299999963958], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8329.0390625, "gpu_memory_peak_mb": 8329.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 18.047, "gpu_power_peak_watts": 18.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2745.8828125, "cpu_memory_peak_mb": 2745.8828125, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.7476685}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 3, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.056299998424947, 11.801900000136811, 11.907499998415005], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8329.0390625, "gpu_memory_peak_mb": 8329.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 18.047, "gpu_power_peak_watts": 18.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2759.03515625, "cpu_memory_peak_mb": 2759.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.873937}
{"spec": {"backend": "tensorrt-int8", "scenario": "batch_medium", "prompt_set": "medium", "model": "gpt2", "repetition": 4, "batch_size": 4, "seq_len": 27, "mode": "generate"}, "status": "degraded", "error": "2 degraded: exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "latencies_ms": [], "ttft_ms": [], "tokens_processed": [], "throughput_tok_s": [], "predicted_tokens": [], "outputs": [], "degraded_count": 2, "degraded_reasons": ["exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument", "exception:LogicError:cuMemcpyHtoDAsync failed: invalid argument"], "warmup_latencies_ms": [13.126900001225295, 11.986799998339848, 11.984200000370038], "resource_metrics": {"samples": 1, "duration_s": 0.0, "gpu_memory_mean_mb": 8329.0390625, "gpu_memory_peak_mb": 8329.0390625, "gpu_memory_total_mb": 12282.0, "gpu_utilization_mean_pct": 21.0, "gpu_power_mean_watts": 18.047, "gpu_power_peak_watts": 18.047, "gpu_temperature_mean_c": 46.0, "gpu_temperature_peak_c": 46, "cpu_memory_mean_mb": 2759.03515625, "cpu_memory_peak_mb": 2759.03515625, "cpu_utilization_mean_pct": 0.0}, "export_metadata": {"model": "gpt2", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "export_time_s": null, "file_size_mb": 622.3690748214722, "opset_version": 17, "dynamic_axes": true, "trt_friendly_inputs": true, "valid": null, "reused": true, "onnx_sha256": null, "onnx_inspect": {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "exists": true, "onnx_file_size_bytes": 652601275, "onnx_file_size_mb": 622.3690748214722, "external_data": false, "external_files": [], "external_total_size_bytes": 0, "external_total_size_mb": 0.0, "total_artifact_size_bytes": 652601275, "total_artifact_size_mb": 622.3690748214722, "initializer_count": 149, "initializer_numel": 163037184, "initializer_bytes_est": 652148736, "initializer_bytes_est_mb": 621.9375, "initializer_dtype_counts": {"FLOAT": 149}, "opset_import": {"ai.onnx": 17}, "ir_version": 8, "parse_error": null}, "model_weight_files": {"model_path": "gpt2", "is_local_dir": false, "weight_files": [], "total_size_bytes": 0}, "timestamp": 1765652102.1210456}, "trt_build_metadata": [{"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "precision": "fp32", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 66.80240330000015, "file_size_mb": 778.6761207580566, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp32.plan", "exists": true, "file_size_bytes": 816501092, "file_size_mb": 778.6761207580566, "deserialize_error": null, "num_layers": 901, "num_profiles": 5, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 248, "Float": 780}, "has_int8_tensors": false}, "int8_calibration": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652171.467091, "built": true, "reused": false}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "precision": "fp16", "workspace_gb": 6, "builder_settings": {}, "int8_calibration_config": null, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652180.8132806, "build_time_s": null, "file_size_mb": 312.3549919128418, "built": false, "reused": true, "error": null, "engine_sha256": "7e9b9f5ff13d84f954d7a41b146fc9673fa982e3c2d3bcb2bdebedecddc6bb18", "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_fp16.plan", "exists": true, "file_size_bytes": 327527948, "file_size_mb": 312.3549919128418, "deserialize_error": null, "num_layers": 137, "num_profiles": 1, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Half": 112, "Int64": 48, "Float": 1}, "has_int8_tensors": false}}, {"onnx_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\onnx\\gpt2.onnx", "output_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "precision": "int8", "workspace_gb": 6, "builder_settings": {}, "applied_builder_settings": {"builder_optimization_level": 3, "max_num_tactics": -1, "tiling_optimization_level": "TilingOptimizationLevel.NONE", "profiling_verbosity": "ProfilingVerbosity.DETAILED"}, "tensorrt_version": "10.12.0.36", "build_time_s": 153.0360956000004, "file_size_mb": 781.0202217102051, "engine_sha256": null, "engine_inspect": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "exists": true, "file_size_bytes": 818959060, "file_size_mb": 781.0202217102051, "deserialize_error": null, "num_layers": 1025, "num_profiles": 6, "io_names": ["input_ids", "attention_mask", "logits"], "engine_inspector": {"layer_entry_type": "dict", "has_int8_in_json": false}, "layer_output_dtype_counts": {"Int64": 249, "Float": 930}, "has_int8_tensors": false}, "int8_calibration": {"source": "dataset", "tokenizer_available": true, "datasets_available": true, "dataset_name": "wikitext", "dataset_config": "wikitext-2-raw-v1", "split": "test", "text_field": "text", "samples": 512, "texts_loaded": 512, "batch_size": 8, "seq_len": 128, "seed": 42, "num_batches": 64, "random_vocab_size": null, "cache_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\calib\\gpt2_wikitext-2-raw-v1_test_512x8x128.calib", "cache_hit_before": false, "cache_size_bytes_before": null, "cache_sha256_before": null, "cache_size_bytes_after": 51819, "cache_sha256_after": "f733866440893b46e6f3bdc2fc0d69f1188ec4975cf7227052857ddc17eeac31"}, "dynamic_shapes": true, "profiles": 5, "timestamp": 1765652337.9803503, "built": true, "reused": false}], "backend_metadata": {"backend": "tensorrt-int8", "init_ms": 730.4049000013038, "engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "engine": {"engine_path": "C:\\Users\\sahil\\OneDrive\\Documents\\GitHub\\Banterhearts\\artifacts\\tr118v2\\gpt2\\tensorrt\\gpt2_int8.plan", "api": "tensors", "num_io_tensors": 3, "num_profiles": 6, "input_names": ["input_ids", "attention_mask"], "output_names": ["logits"], "output_dtype": "float32"}}, "started_at": 1765652470.9968107}
